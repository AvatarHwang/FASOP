{"id": "9406", "revid": "42975076", "url": "https://en.wikipedia.org/wiki?curid=9406", "title": "Foreign relations of Ethiopia", "text": "Overview of the foreign relations of Ethiopia\nThe foreign relations of Ethiopia refers to overall diplomatic relationship of Ethiopia. The Ministry of Foreign Affairs oversees foreign relations and diplomatic missions of the country.\nEthiopia is one of few early African countries admitted to the League of Nations, becoming a member on 28 September 1923, and was one of the founding members of the United Nations. During the Scramble for Africa, Ethiopia had maintained its full sovereignty over European colonial power and fought the First Italo-Ethiopian War in 1895\u201396. However, the League did not protect in accord with the envisaged \"collective security\" of the country, resulted Italy's occupation of Ethiopia for 5 years (1936\u20131941). \nFrom 1950s, Ethiopia participated to UN peacekeeping missions such as in Korean War and Congo Crisis. Virtually, Ethiopia maintains diplomatic relations to most countries, and is non-permanent member of the UN Security Council.\nHistory.\nAntiquity.\nLand of Punt.\nPunt (2500 BCE \u2013 980 BCE) was predominantly a trading centre dominated by Ancient Egypt to Horn of Africa. Trading commodities includes exports of Egypt; one of the most essential was incense, which was mainly used for religious rituals for embalming corpse. Other were ivory, spices, hides and exotic animals that convey route to coast of Ethiopia, thus Ethiopia has been an integral part of Punt. Egyptian expedition to southeastern African region was generally commenced in the second millennium BC, after stabilizing relations with kingdoms of today's Sudan, the Kush, Napata and Mero\u00eb.\nSouth Arabia.\nSome theorists hypothesized Ancient South Arabian people migrated out of Africa to the strait Bab-el-Mandeb when its sea level decreased to current status. When their civilization came to appear from 4th millennium BC, onward Mesopotamia and the Persian Gulf, adaptation of Semitic language was from end of Mediterranean, though they used Canaanite alphabet developed from Syria or Palestine during second millennium BC. Apparently, these languages similarity compared to Hebrew and Phoenician alphabets, even though lacked scholarly consensus. By 500 BC, it was widely spoken such as the Ge'ez language.\nWriting system through inscription on stone often detailed historical rival kingdoms in the region, most notability the Saba, Qataban, Himyar, Hadhramaut, Ma'in and others. In 1959, American archeologists collected numerous artifacts and body of inscriptions in the area, belonging to primary sources. The inscription not only detailed about South Arabia, but also the early Ethiopian history associated with Kingdom of Aksum and its rulers.\nKingdom of Aksum.\nThe Kingdom of Aksum has been a great power in classic Africa; once it has been referenced by Persian prophet Mani in the 3rd century and Greco-Roman trading guide \"Periplus of the Erythraean Sea\" in first century. Axum maintained well-defined foreign relations with powerful realms in the era. According to Stuart Munro-Hay witness, the Aksumite had several account of ambassadors that had delegation with neighboring powers. Occasionally, Aksumite contact with foreign powers also attested by archaeological or scarce finds.\nEgypt.\nAksumite relations with pre-Roman Egypt was ostensibly uncertain. However, it was considered that Aksumite contact were also existed during the fall of Ptolemaic dynasty with Cleopatra death in 30 BC. Few artifacts were uncovered from Egypt such as cippus of Horus given to Bruce, and illustrated by him, and a few amulet figurines of blue faience or cornaline found at various sites of Ethiopia. Other include the double-uraeus, perhaps brought from Mero\u00eb.\nAnother discoveries are an inscription of Ptolemy III copied by Kosmas at Adulis and ankh'-sign engraved on one of the stelae. During King Ezana's reign, he expedited to the Nile after Mero\u00eb was entirely sacked. After its successor Noba emerged, it behaved badly to consign Aksumite ambassadors punished with military expedition. An aggressive mistreatment was objected by tribes such as the Mangurto, the Barya, and the Khasa by asking support, either regarded Aksum would an aide of Noba or possibly a suzerain. Ezana's expedition also attacked Kasu, the remnants of Meroitic state. Nuba, Kasu, and Beja were integral to Ezana's kingdom. Meroitic artifacts have been found in Ethiopian location Addi Galamo (Atse Dera) such as bronze bowls, which was brought from Roman Egypt. It was possibly made up of diorite thumb-ring found by the BIEA expedition at Aksum, and corna line amulet of Harpocrates with typical double-uraeus of the Meroites.\nSouth Arabia.\nSaba, Himyar and Hadhramawit kingdom commonly known as South Arabian states\u2014had special relations with Ethiopia. Culturally, linguistically, and socially, Aksumite civilization completely inspired by those overseas. While Aksumite intervention to states generally uncertain, it was viable to have a military expedition beginning in 3rd century. During the period of GDRT and Adhebah reign, (\u2019DBH), Aksumite commenced a military treaty with Saba and then with Hadhramawit in the first half of third century. \nDuring Adhebah period, Shamir called Himyar prince Dhu-Raydan sent military aid from Aksum. Later, Aksumite king adopted nominally \"king of Saba and Himyar\", asserting suzerainty. Foreign contact also continued during the fifth and early sixth centuries between the two sides of Red Sea. Byzantine scholar Procopius told the voyage of crossing Red Sea for five days and nights and that \"the harbor of the Homeritae from which they are accustomed to putting to sea is called Boulikas\", presumably somewhere near Mukha, and \" at the end of the sail across the sea they always put in at the harbor of the Adulitae\" at the reign of King Kaleb. \nArabian titles were experienced in South Arabia during Kaleb's reign; after his viceroy deposed by Jewish Himyar king Yusuf Asar, Yemen was no longer requisite to Aksum. The event led Aksumite to decline its dominion. An inscription dated to 543 AD mentioned that the new king named Abraha dealing with the restoration of great dam at Marib, and mentioned embassies from various foreign countries such as Aksum, Rome, Persia and various Arab groups. Procopius noted that Abreha was subordinated by Kaleb, a period which unbeknownst to Abreha regaining the kingdom reputations and he received little damage.\nMiddle Ages.\nForeign relations in the Middle Ages have impacted by an interaction with Iberian countries\u2014Spain and Portugal\u2014especially the latter had considerable power on internal affairs. Portuguese influence spanned from 1500 to 1672, they had an interest of spreading Jesuit order from 1556 to 1632. According to their narrative effluence, the Portuguese authors underscored their involvement to Ethiopia, but overturned to smoothly decay. Portuguese authors works notably Francisco \u00c1lvares, Miguel de Castanhoso, and Pedro P\u00e1ez survived to this day. Prester John, a fabulous Christian king, spurred the Portuguese to pursue Ethiopia whose kingdom they equates with Garden of Eden. According to the legend, he was born about 1460 and last seen in 1526. There is also speculation about his age where he lived for fifteen or twenty seven years beyond 1526.\nPero da Covilh\u00e3 profoundly marched overland into the Ethiopian Highlands about the end of 1492 or beginning of 1493, characterized by conquest and superiority. He sent an information to Lisbon a few years later that contributed Vasco da Gama mobilisation to African southern cap into the Indian Ocean. The Portuguese navy almost dominated the coastline of Eastern Hemisphere.\nIn the early 15th century, Ethiopia sought to make diplomatic contact with European kingdoms for the first time since the Aksumite era. Atse Dawit I first made contact with the Republic of Venice by requesting for religious artifacts and craftsmen. A letter from Henry IV of England to the Ethiopian Emperor survives. In 1428, Yeshaq I sent two emissaries to Alfonso V of Aragon, who sent his own emissaries that failed to complete the return trip home to Aragon.\nThe first continuous relations with a European country began in 1508 with Portugal under Dawit II (Lebna Dengel), who had just inherited the throne from his father. In 1487, King John II of Portugal sent two emissaries to the Orient, Pero da Covilh\u00e3 and Afonso de Paiva; Afonso would die on this mission. By the end of Middle Ages, the Ethiopian Empire was in a 13 year long war with neighboring Muslim states, and a Portuguese expedition force was sent from Goa, India to aid the Ethiopian Army due to an ongoing rivalry with the Ottoman Empire, who provided logistical support to the Adal Sultanate.\nEarly modern period.\nGondarine period.\nSince 16th century, Roman Catholicism and the Jesuits increasingly influenced on state power. Besides, the Oromo migrations had vital role in the northern Ethiopia. Among other Jesuit, Spanish Jesuit Pedro Paez had favorable relations to the Emperors of Ethiopia like Za Dengel and Susenyos I, the latter promulgated that Roman Catholicism state administrative to the Empire in 1622 on behalf of Orthodox Tewahedo Church, resulted in grave conflict for the years.\nThe reign of Emperor Fasilides in 1632 arranged this status by restoring Orthodox Tewahedo state leadership and expelled Jesuits from his land. After founding Gondar in 1636, Ethiopia then prospered again with the beginning of \"Gondarine period\" characterized as relatively peaceful governance. However, few Franciscan and Capuchin friars said to be lived during the 18th century such as Franciscan Giuseppe Maria di Gerusalemme, Remedius Prutky (who left credible records to the city). \nArchitecture of this period was slightly influenced by the remnant Jesuits, but also the presence of Arab, Indians (brought by the Jesuits) as well as Turkish in Ottoman occupied northern area had involvement. One of the example is castles in Fasil Ghebbi.\nPost-Zemene Mesafint.\nEmperor Tewodros II reinstated the imperial power and foreign relations. His connection of Queen Victoria and other European leaders unfavorable when he sent unresponsive letter to the Queen, eventually leading to brief war with the British Empire. The British sent 13,000 soldiers, 26,000 men for logistical support and 40,000 animals including war elephants from India during their expedition, resulting in Tewodros suicide at Magdala in 1868. Not only modernized the empire, but he also paved the way of coherence the succession for subsequent emperors. Ethiopia was briefly isolated from world power in the post-Zemene Mesafint period; Emperor Yohannes IV faced Egyptian invasion as they laid linkage of Suez Canal to Massawa, and opening road between Addi Quala and Gundet used to penetrate the Ethiopian Empire. Yohannes IV on other side was reluctant to improve the road from the Ethiopian Highland to the coast of Red Sea. According to British assistant John Kirkham, he \"preferred to keep his money hoarded up\". Likewise, German traveller Gerhard Rohlfs asserted that he wanted to build churches rather than roads. Road working, on the sides, was completed by Swedish missionaries at Monkulu. British traveller Augustus B. Wylde supposed that Abyssinians were \"in fear of foreign invasion\" where lastly commented \"I suppose they are right\".\nWylde noted that the first Ethiopian diaspora took place in mid-1880s, who had been from Massawa to Europe, adapting European trousers. This was strictly outlawed by the Emperor. The empire nonetheless, was surged into modernization by foreign contribution, numerous missionary schools were expanded by Swedish Protestants at Monkulu and the French Lazarist at Keren, the later described by Wylde \"a very useful education\" with \"very well conducted\". Ethiopia had received broad European population in the 19th-century: Jean Baraglion of French origin who had lived for over a decade and according to Wylde, he enjoyed monopoly at Adwa. Despite rejoice, Baraglion encountered at least two rivals, a Hungarian named Andr\u00e9 who made an artificial limbs, and a Greek who have lived to Shewa over several years.\nMenelik II.\nEthiopia had strong diplomatic relations under Emperor Menelik II with Britain, France and Italy, the latter pursued hegemony to Ethiopian Empire after establishing colony in Eritrea (1882). The British and French rival with Italy due to insecurity with their respective protectorate in East Africa. However, both feared the process of Menelik's Expansions. In 1891, the British policy makers sent a circular note to the other world powers concerning the large portion of Nile Valley belonged to Ethiopia, \"the activities and the pretension of the Negus were practically enough in themselves to bring the British to he support of Italian policy in East Africa.\"\nOn 2 May 1889, the Treaty of Wuchale was signed between Ethiopia and Italy with respective bilingual version. The treaty was signed after the Italian occupation of Eritrea and aimed to create friendship with both countries. The Amharic and Italian language, however confused by Article 17 in which Menelik denounced in 1893, resulting Italy's threatening over the status of newly formed boundary. \nIn 1895, the First Italo-Ethiopian War began, ending with Italy's defeat at Battle of Adwa by Ethiopian troops who were assisted logistically by Menelik. By early 1900, European agencies opened legation in Addis Ababa and had huge impact on investment in the country's infrastructure (schools, banks, road, railway etc.).\nHaile Selassie.\nDuring Haile Selassie coronation in 1930, emissaries from the United States, Egypt, Turkey, Sweden, Belgium, and Japan were also presented. Since then, he led the forefront diplomatic relations of Ethiopia with world powers.\nIn 1930s, Ethiopia faced Italian renewed imperialist design. Together with the failure of the League of Nations envision of Ethiopia's \"collective security\", Italy invaded Ethiopia again in October 1935, culminating in the Second Italo-Ethiopian War. In May 1936, Mussolini declared Ethiopia as part of Italian East Africa by merging with Eritrea and Somaliland. Haile Selassie fled to England's Fairfield House, Bath, and delivered an address that made him a worldwide figure, and the 1935 \"Time\" Man of the Year.\nOn 10 June 1940, Mussolini declared war on France and Britain and attacked British and Commonwealth forces in Egypt, Sudan, Kenya and British Somaliland. In January 1941, the British army together with Arbegnoch (\"the Patriots\") and Gideon Force occupied Ethiopia. On 5 May, Haile Selassie with auspice of Ethiopian Free Forces entered Addis Ababa and reclaimed his throne while the war continued until November. After their defeat, the Italian began guerrilla offensive in Ethiopia that lasted until the Armistice between Italy and Allied armed forces in September 1943.\nOn 31 January 1942, the British and Ethiopia signed Anglo-Ethiopian Agreement which Britain recognized Ethiopian sovereignty, except military occupation of Ogaden with their colony in Somaliland and the former Italian colony of Somaliland, creating a single polity. Ethiopians discontent about the privilege of military administration of some south-eastern region until formal agreement signed on 19 December 1944 that ended British advantage in the Ethiopian regions. The Italian Republic signed peace treaty on 10 February 1947 that recognized Ethiopia's sovereignty with agreement to pay $25,000,000 in reparations.\nIn 1952, Eritrea federated with Ethiopia with majority vote in the United Nations and this attitude declined by 1961, culminating in the Eritrean War of Independence since armed forces formed such as the Eritrean Liberation Front (ELF).\nOppositions against Haile Selassie came to existence with students began marching through 1960s and early 1970s, chanting \"land for tiller\" and embracing several Marxist-Leninist theme. Haile Selassie deposed on 12 September 1974 by officers of Ethiopian Army led by Aman Andom named Coordinating Committee of the Armed Forces, Police and Territorial Army. The committee renamed itself Provisional Military Administrative Council known as the Derg after abolishing the Ethiopian Empire in March 1975.\nThe Derg era.\nThe Derg aligned itself with Soviet bloc\u2014had similar Marxist Leninist policy on Ethiopia. The Derg suffered from internal insurgency and ambivalent relations with neighboring countries such as Eritrea and Somalia. In 1977, the Ogaden War was fought between the Derg supported by Cuba, Soviet Union and South Yemen, and Somalia with the United States and Egypt. Although ending on 15 March 1978, the relations between Ethiopia and Somalia marred with political dispute with involvement of the Ogaden National Liberation Front (ONLF) in relations of the disputed Ogaden region. \nBy the 1990, the Derg and Soviet Union relations was deteriorated after Mengistu Haile Mariam banned the Ethiopian media to use the term \"glasnost\" and \"perestroika\", defying Mikhail Gorbachev who was believed has not fondness for him. By early 1990, Mengistu helped emigration of the Ethiopian Jews to Israel by which many Jewish organizations and US Congress discerned Mengistu's task in the lobbying effort.\nFederal Democratic Republic era.\nAfter defeating the Derg in 1991, the newly formed coalition the Ethiopian People's Revolutionary Democratic Front (EPRDF), led by President and later Prime Minister Meles Zenawi, experienced opposition from factions in Somalia as well as within the country; in May 1991, a pan-Islamist Al-Itihaad al-Islamiya (Islamic Unity) established to consolidate Somalia's power in the Greater Somalia. Relations with Eritrea was somewhat better intensified after its UN-sponsored session from Ethiopia in May 1993.\nLater in 1998, their relations was deteriorated after large-scale Eritrean mechanized force penetrated to Badme region, triggering the Eritrean\u2013Ethiopian War. Both countries spent favorable amount of armaments ahead of the war and suffered reportedly 100,000 casualties combined as a direct consequence thereof, excluding indeterminate number of refugees. In December 2000, the two countries government signed Algiers Agreement which finalized the war and created binding judicial commissions, the Eritrea\u2013Ethiopia Border Commission and the Eritrean\u2013Ethiopian Claims Commissions, to oversee the disputed border and related claims. Since then, there was elevated tensions with border conflict and stalemate what is described \"war footing\" and \"no-war-no-peace\" with absence of foreign and domestic policy domination. This was ended after Prime Minister Abiy Ahmed came to power in 2018, signed the 2018 Eritrea\u2013Ethiopia summit on 8\u20139 July.\nMeles' government relations with Djibouti was friendly as Djibouti accessed Port of Djibouti to Ethiopia. Ethiopia had 90% imports arrived from Port of Djibouti and 95% of Djiboutian regional exports. In 2006, the Islamic Courts Union (ICU) virtually controlled the whole of southern Somalia and successfully united Mogadishu and imposed Shari'a law. With support of the Transitional Federal Government of Somalia, Ethiopia, under UN peacekeeping mission against War on Terrorism, attacked ICU. The ICU's split eventually led to the formation of Al-Shabaab, regrouping to continue the insurgency against TFG and Ethiopian military presence in Somalia. \nIn May 2010, the Nile Basin Initiative was signed by five upstream countries such as Ethiopia, Tanzania, Uganda, Kenya, and Rwanda and Burundi as Egypt considerate as breach to the 1929 Anglo-Egyptian treaty that gave its right to share water. On 2 April 2011, the Grand Ethiopian Renaissance Dam (GERD) inaugurated construction expected producing 15,000 megawatts of power within 10 years, spending 12 billion dollars of strategy to improve power generating capabilities. Egypt and Sudan continued objecting the filling of the dam in 2020.\nUnder Abiy Ahmed premiership since 2018, Ethiopia repleted its relations Somalia and Eritrea. In October 2018, Ethiopia signed peace agreement with the rebel faction ONLF ending 34 year long conflict since 1984. ONLF has clashed with the Ethiopian troops to contain vast oil and gas deposits, where Chinese oil firms developing two gas field in the area. In 2007, ONLF launched deadly attack against Chinese-run oil field which killed 65 Ethiopians and 9 Chinese nationals.\nDuring the Tigray War, Ethiopia was allied to countries such as Turkey, United Arab Emirates and Iran who supplied drones to the Ethiopian government. With involvement of Eritrean Defence Forces (EDF), the US President Joe Biden designated six targets of sanction per Executive Order 14046, which was signed in September 2021.\nMinistry of Foreign Affairs.\nForeign relations are upheld by Ministry of Foreign Affairs with the ability and capacity to marshal strategic partners for the continent and the region; to play a central role in Ethiopia's growth into a democratic developmental state and in the achievement of peace and stability in the Horn of Africa.\nUnited Nations.\nEthiopia was admitted to the League of Nations on 28 September 1923, becoming one of few African countries to do so due to not colonized by European powers during the 19th century Scramble for Africa. The League envisaged the membership for Ethiopia's \"collective security\" and protection against external attacks. The League however was unable to maintain Ethiopia's sovereignty as Japan invaded Manchuria, which Italy invaded Ethiopia in 1936. \nAfter its resumption of independence after World War II, Ethiopia was one of the founding members of the United Nations. Since the 1950s, Ethiopia has keeping UN peacekeeping missions toward Korean War and Congo Crisis and some African states like Rwanda and Burundi in 1990s. Ethiopia has now over 80,000 peacekeeping forces that are active.\nThe UN delivers development and humanitarian plan in Ethiopia with 28 representatives of funds and specialized agencies in the UN Country Team (UNCT). Ethiopia is non-permanent member of the UN Security Council which has close cooperation with the regional organizations the African Union and the Intergovernmental Authority on Development (IGAD).\nEuropean Union.\nEthiopia has strong relations to the European Union while the EU funding financed by the European Development Fund (EDF) with objectives of resilience. Their relations has been defined by Cotonou Agreement article 8 to 13 with strong bilateral partners and dialogue regarding sustainable development on diverse aspect of the country.\nIn addition, the EU is the second largest trade partner for Ethiopia with total expenditure of 4.1 billion euro; exports representing 12% while Ethiopia exports representing 26% of worldwide exports in 2016. This has been compared to China (8%), Somalia (14%) and Kuwait (13%).\nAfrican Union.\nEthiopia is one of founding African states of the Organization of African Unity (OAU) (now the African Union) on 25 May 1963 under Emperor Haile Selassie, headquartered in Addis Ababa. At the time, the organization evolved up to 54 African states, except Morocco.\nThe country is driving force of maintaining UN-AU peacekeeping missions, especially in the Horn of Africa region. The AU does not readily aggregate the preference of each member states. Therefore, every AU norms, institution and overlaps as consensus stated in the AU Constitution Act and its various decision and policy making, and implementation organs. As such, the AU offers for member states like Ethiopia to influence and impact on policy internally and regionally. Today, Ethiopian capital Addis Ababa is home of major organizations such as African Union, Pan African Chamber of Commerce and Industry, United Nations Economic Commission for Africa and African Standby Force.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9407", "revid": "44161985", "url": "https://en.wikipedia.org/wiki?curid=9407", "title": "Europa Island", "text": "French atoll in the Mozambique Channel\nEuropa Island (, ]), in Malagasy Nosy Ampela is a low-lying tropical atoll in the Mozambique Channel, about a third of the way from southern Madagascar to southern Mozambique. The island had never been inhabited until 1820, when the French family \"Rosier\" moved to it. The island officially became a possession of France in 1897.\nThe island, garrisoned by a detachment from R\u00e9union, has a weather station and is visited by scientists. Though uninhabited now, it is part of the Scattered Islands of the French Southern and Antarctic Lands administrative region.\nEuropa Island was the setting of \"Search in the Deep\", a 1968 episode of \"The Undersea World of Jacques Cousteau\", partly focusing on the breeding habits of the green sea turtle.\nDescription.\nEuropa is in diameter, with a maximum altitude of , and has of coastline. It is surrounded by coral beaches and a fringing reef and encloses a mangrove lagoon of around and open to the sea on one side.\nThere are no ports or harbours but anchorage is possible offshore. Its exclusive economic zone, contiguous with that of Bassas da India, is . The airstrip is metres long.\nEcology.\nThe island is a nature reserve. Its vegetation consists of dry forest, scrub, \"Euphorbia\", the mangrove swamp, and the remains of a sisal plantation. It is one of the world's largest nesting sites for green sea turtles. It is also home to goats introduced by settlers in the late 18th century.\nThe island has been identified as an Important Bird Area by BirdLife International because it supports a large and diverse population of breeding seabirds and other waterbirds. It is the only known breeding site outside Aldabra and Madagascar for Malagasy pond herons. Seabirds include the second largest colony in the western Indian Ocean of great frigatebirds (with up to 1100 pairs), Audubon's shearwaters (up to 100 pairs, probably of the subspecies \"Puffinus lherminieri bailloni\" previously considered endemic to the Mascarene Islands), dimorphic egrets and Caspian terns.\nEuropa is home to an endemic subspecies of white-tailed tropicbird (\"Phaethon lepturus europae\"), three kinds of landbird (including an endemic subspecies of the Malagasy white-eye) and its own species of hissing cockroach.\nClimate.\nEuropa Island's climate is affected by the Agulhas Current with water temperatures usually above , southeast trade winds during the (austral) winter and occasional cyclones. The climate can be described as a semi-arid and tropical combination with wet summers and dry winters.\nHistory.\nWhile the island has probably been sighted by navigators since at least the 16th century, it takes its name from the British ship \"Europa\", which visited it in December 1774. Ruins and graves on Europa island attest to several attempts at settlement from the 1860s to the 1920s. For example, the French Rosiers family moved to the island in 1860, but subsequently abandoned it.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9409", "revid": "202276", "url": "https://en.wikipedia.org/wiki?curid=9409", "title": "Geography of Europa Island", "text": ""}
{"id": "9410", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9410", "title": "Europa Island/People", "text": ""}
{"id": "9411", "revid": "202276", "url": "https://en.wikipedia.org/wiki?curid=9411", "title": "Government of Europa Island", "text": ""}
{"id": "9414", "revid": "202276", "url": "https://en.wikipedia.org/wiki?curid=9414", "title": "Transportation on Europa Island", "text": ""}
{"id": "9415", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9415", "title": "Europa Island/Military", "text": ""}
{"id": "9416", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9416", "title": "Europa Island/Transnational issues", "text": ""}
{"id": "9417", "revid": "34639254", "url": "https://en.wikipedia.org/wiki?curid=9417", "title": "Euclidean geometry", "text": "Mathematical model of the physical space\nEuclidean geometry is a mathematical system attributed to ancient Greek mathematician Euclid, which he described in his textbook on geometry, \"Elements\". Euclid's approach consists in assuming a small set of intuitively appealing axioms (postulates) and deducing many other propositions (theorems) from these. Although many of Euclid's results had been stated earlier, Euclid was the first to organize these propositions into a logical system in which each result is \"proved\" from axioms and previously proved theorems.\nThe \"Elements\" begins with plane geometry, still taught in secondary school (high school) as the first axiomatic system and the first examples of mathematical proofs. It goes on to the solid geometry of three dimensions. Much of the \"Elements\" states results of what are now called algebra and number theory, explained in geometrical language.\nFor more than two thousand years, the adjective \"Euclidean\" was unnecessary because\nEuclid's axioms seemed so intuitively obvious (with the possible exception of the parallel postulate) that theorems proved from them were deemed absolutely true, and thus no other sorts of geometry were possible. Today, however, many other self-consistent non-Euclidean geometries are known, the first ones having been discovered in the early 19th century. An implication of Albert Einstein's theory of general relativity is that physical space itself is not Euclidean, and Euclidean space is a good approximation for it only over short distances (relative to the strength of the gravitational field).\nEuclidean geometry is an example of synthetic geometry, in that it proceeds logically from axioms describing basic properties of geometric objects such as points and lines, to propositions about those objects. This is in contrast to analytic geometry, introduced almost 2,000 years later by Ren\u00e9 Descartes, which uses coordinates to express geometric properties by means of algebraic formulas.\nThe \"Elements\".\nThe \"Elements\" is mainly a systematization of earlier knowledge of geometry. Its improvement over earlier treatments was rapidly recognized, with the result that there was little interest in preserving the earlier ones, and they are now nearly all lost.\nThere are 13 books in the \"Elements\":\nBooks I\u2013IV and VI discuss plane geometry. Many results about plane figures are proved, for example, \"In any triangle, two angles taken together in any manner are less than two right angles.\" (Book I proposition 17) and the Pythagorean theorem \"In right-angled triangles the square on the side subtending the right angle is equal to the squares on the sides containing the right angle.\" (Book I, proposition 47)\nBooks V and VII\u2013X deal with number theory, with numbers treated geometrically as lengths of line segments or areas of surface regions. Notions such as prime numbers and rational and irrational numbers are introduced. It is proved that there are infinitely many prime numbers.\nBooks XI\u2013XIII concern solid geometry. A typical result is the 1:3 ratio between the volume of a cone and a cylinder with the same height and base. The platonic solids are constructed.\nAxioms.\nEuclidean geometry is an axiomatic system, in which all theorems (\"true statements\") are derived from a small number of simple axioms. Until the advent of non-Euclidean geometry, these axioms were considered to be obviously true in the physical world, so that all the theorems would be equally true. However, Euclid's reasoning from assumptions to conclusions remains valid independent of their physical reality.\nNear the beginning of the first book of the \"Elements\", Euclid gives five postulates (axioms) for plane geometry, stated in terms of constructions (as translated by Thomas Heath):\nLet the following be postulated:\nAlthough Euclid explicitly only asserts the existence of the constructed objects, in his reasoning he also implicitly assumes them to be unique.\nThe \"Elements\" also include the following five \"common notions\":\nModern scholars agree that Euclid's postulates do not provide the complete logical foundation that Euclid required for his presentation. Modern treatments use more extensive and complete sets of axioms.\nParallel postulate.\nTo the ancients, the parallel postulate seemed less obvious than the others. They aspired to create a system of absolutely certain propositions, and to them, it seemed as if the parallel line postulate required proof from simpler statements. It is now known that such a proof is impossible since one can construct consistent systems of geometry (obeying the other axioms) in which the parallel postulate is true, and others in which it is false. Euclid himself seems to have considered it as being qualitatively different from the others, as evidenced by the organization of the \"Elements\": his first 28 propositions are those that can be proved without it.\nMany alternative axioms can be formulated which are logically equivalent to the parallel postulate (in the context of the other axioms). For example, Playfair's axiom states:\nIn a plane, through a point not on a given straight line, at most one line can be drawn that never meets the given line.\nThe \"at most\" clause is all that is needed since it can be proved from the remaining axioms that at least one parallel line exists.\nMethods of proof.\nEuclidean Geometry is \"constructive\". Postulates 1, 2, 3, and 5 assert the existence and uniqueness of certain geometric figures, and these assertions are of a constructive nature: that is, we are not only told that certain things exist, but are also given methods for creating them with no more than a compass and an unmarked straightedge. In this sense, Euclidean geometry is more concrete than many modern axiomatic systems such as set theory, which often assert the existence of objects without saying how to construct them, or even assert the existence of objects that cannot be constructed within the theory. Strictly speaking, the lines on paper are \"models\" of the objects defined within the formal system, rather than instances of those objects. For example, a Euclidean straight line has no width, but any real drawn line will. Though nearly all modern mathematicians consider nonconstructive methods just as sound as constructive ones, Euclid's constructive proofs often supplanted fallacious nonconstructive ones\u2014e.g., some of the Pythagoreans' proofs that involved irrational numbers, which usually required a statement such as \"Find the greatest common measure of ...\"\nEuclid often used proof by contradiction. Euclidean geometry also allows the method of superposition, in which a figure is transferred to another point in space. For example, proposition I.4, side-angle-side congruence of triangles, is proved by moving one of the two triangles so that one of its sides coincides with the other triangle's equal side, and then proving that the other sides coincide as well. Some modern treatments add a sixth postulate, the rigidity of the triangle, which can be used as an alternative to superposition.\nNotation and terminology.\nNaming of points and figures.\nPoints are customarily named using capital letters of the alphabet. Other figures, such as lines, triangles, or circles, are named by listing a sufficient number of points to pick them out unambiguously from the relevant figure, e.g., triangle ABC would typically be a triangle with vertices at points A, B, and C.\nComplementary and supplementary angles.\nAngles whose sum is a right angle are called complementary. Complementary angles are formed when a ray shares the same vertex and is pointed in a direction that is in between the two original rays that form the right angle. The number of rays in between the two original rays is infinite.\nAngles whose sum is a straight angle are supplementary. Supplementary angles are formed when a ray shares the same vertex and is pointed in a direction that is in between the two original rays that form the straight angle (180 degree angle). The number of rays in between the two original rays is infinite.\nModern versions of Euclid's notation.\nIn modern terminology, angles would normally be measured in degrees or radians.\nModern school textbooks often define separate figures called lines (infinite), rays (semi-infinite), and line segments (of finite length). Euclid, rather than discussing a ray as an object that extends to infinity in one direction, would normally use locutions such as \"if the line is extended to a sufficient length\", although he occasionally referred to \"infinite lines\". A \"line\" in Euclid could be either straight or curved, and he used the more specific term \"straight line\" when necessary.\nSome important or well known results.\nPons asinorum.\nThe pons asinorum (\"bridge of asses\") states that \"in isosceles triangles the angles at the base equal one another, and, if the equal straight lines are produced further, then the angles under the base equal one another\". Its name may be attributed to its frequent role as the first real test in the \"Elements\" of the intelligence of the reader and as a bridge to the harder propositions that followed. It might also be so named because of the geometrical figure's resemblance to a steep bridge that only a sure-footed donkey could cross.\nCongruence of triangles.\nTriangles are congruent if they have all three sides equal (SSS), two sides and the angle between them equal (SAS), or two angles and a side equal (ASA) (Book I, propositions 4, 8, and 26). Triangles with three equal angles (AAA) are similar, but not necessarily congruent. Also, triangles with two equal sides and an adjacent angle are not necessarily equal or congruent.\nTriangle angle sum.\nThe sum of the angles of a triangle is equal to a straight angle (180 degrees). This causes an equilateral triangle to have three interior angles of 60 degrees. Also, it causes every triangle to have at least two acute angles and up to one obtuse or right angle.\nPythagorean theorem.\nThe celebrated Pythagorean theorem (book I, proposition 47) states that in any right triangle, the area of the square whose side is the hypotenuse (the side opposite the right angle) is equal to the sum of the areas of the squares whose sides are the two legs (the two sides that meet at a right angle).\nThales' theorem.\nThales' theorem, named after Thales of Miletus states that if A, B, and C are points on a circle where the line AC is a diameter of the circle, then the angle ABC is a right angle. Cantor supposed that Thales proved his theorem by means of Euclid Book I, Prop. 32 after the manner of Euclid Book III, Prop. 31.\nScaling of area and volume.\nIn modern terminology, the area of a plane figure is proportional to the square of any of its linear dimensions, formula_1, and the volume of a solid to the cube, formula_2. Euclid proved these results in various special cases such as the area of a circle and the volume of a parallelepipedal solid. Euclid determined some, but not all, of the relevant constants of proportionality. E.g., it was his successor Archimedes who proved that a sphere has 2/3 the volume of the circumscribing cylinder.\nSystem of measurement and arithmetic.\nEuclidean geometry has two fundamental types of measurements: angle and distance. The angle scale is absolute, and Euclid uses the right angle as his basic unit, so that, for example, a 45-degree angle would be referred to as half of a right angle. The distance scale is relative; one arbitrarily picks a line segment with a certain nonzero length as the unit, and other distances are expressed in relation to it. Addition of distances is represented by a construction in which one line segment is copied onto the end of another line segment to extend its length, and similarly for subtraction.\nMeasurements of area and volume are derived from distances. For example, a rectangle with a width of 3 and a length of 4 has an area that represents the product, 12. Because this geometrical interpretation of multiplication was limited to three dimensions, there was no direct way of interpreting the product of four or more numbers, and Euclid avoided such products, although they are implied, for example in the proof of book IX, proposition 20.\nEuclid refers to a pair of lines, or a pair of planar or solid figures, as \"equal\" (\u1f34\u03c3\u03bf\u03c2) if their lengths, areas, or volumes are equal respectively, and similarly for angles. The stronger term \"congruent\" refers to the idea that an entire figure is the same size and shape as another figure. Alternatively, two figures are congruent if one can be moved on top of the other so that it matches up with it exactly. (Flipping it over is allowed.) Thus, for example, a 2x6 rectangle and a 3x4 rectangle are equal but not congruent, and the letter R is congruent to its mirror image. Figures that would be congruent except for their differing sizes are referred to as similar. Corresponding angles in a pair of similar shapes are congruent and corresponding sides are in proportion to each other.\nApplications.\nBecause of Euclidean geometry's fundamental status in mathematics, it is impractical to give more than a representative sampling of applications here.\nAs suggested by the etymology of the word, one of the earliest reasons for interest in and also one of the most common current use of geometry is surveying, and certain practical results from Euclidean geometry, such as the right-angle property of the 3-4-5 triangle, were used long before they were proved formally. The fundamental types of measurements in Euclidean geometry are distances and angles, both of which can be measured directly by a surveyor. Historically, distances were often measured by chains, such as Gunter's chain, and angles using graduated circles and, later, the theodolite.\nAn application of Euclidean solid geometry is the determination of packing arrangements, such as the problem of finding the most efficient packing of spheres in n dimensions. This problem has applications in error detection and correction.\nGeometric optics uses Euclidean geometry to analyze the focusing of light by lenses and mirrors.\nGeometry is used extensively in architecture.\nGeometry can be used to design origami. Some classical construction problems of geometry are impossible using compass and straightedge, but can be solved using origami.\nMuch of CAD (computer-aided design) and CAM (computer-aided manufacturing) is based on Euclidean geometry. Design geometry typically consists of shapes bounded by planes, cylinders, cones, tori, and other similar shapes. In the present day, CAD/CAM is essential in the design of almost everything, including cars, airplanes, ships, and smartphones. A few decades ago, sophisticated draftsmen would learn fairly advanced Euclidean geometry, including things like Pascal's theorem and Brianchon's theorem, but in modern times this is no longer necessary. \nLater history.\nArchimedes and Apollonius.\nArchimedes (c. 287 BCE \u2013 c. 212 BCE), a colorful figure about whom many historical anecdotes are recorded, is remembered along with Euclid as one of the greatest of ancient mathematicians. Although the foundations of his work were put in place by Euclid, his work, unlike Euclid's, is believed to have been entirely original. He proved equations for the volumes and areas of various figures in two and three dimensions, and enunciated the Archimedean property of finite numbers.\nApollonius of Perga (c. 262 BCE \u2013 c. 190 BCE) is mainly known for his investigation of conic sections.\n17th century: Descartes.\nRen\u00e9 Descartes (1596\u20131650) developed analytic geometry, an alternative method for formalizing geometry which focused on turning geometry into algebra.\nIn this approach, a point on a plane is represented by its Cartesian (\"x\", \"y\") coordinates, a line is represented by its equation, and so on.\nIn Euclid's original approach, the Pythagorean theorem follows from Euclid's axioms. In the Cartesian approach, the axioms are the axioms of algebra, and the equation expressing the Pythagorean theorem is then a definition of one of the terms in Euclid's axioms, which are now considered theorems.\nThe equation\nformula_3\ndefining the distance between two points \"P\" = (\"px\", \"py\") and \"Q\" = (\"qx\", \"qy\") is then known as the \"Euclidean metric\", and other metrics define non-Euclidean geometries.\nIn terms of analytic geometry, the restriction of classical geometry to compass and straightedge constructions means a restriction to first- and second-order equations, e.g., \"y\" = 2\"x\" + 1 (a line), or \"x\"2 + \"y\"2 = 7 (a circle).\nAlso in the 17th century, Girard Desargues, motivated by the theory of perspective, introduced the concept of idealized points, lines, and planes at infinity. The result can be considered as a type of generalized geometry, projective geometry, but it can also be used to produce proofs in ordinary Euclidean geometry in which the number of special cases is reduced.\n18th century.\nGeometers of the 18th century struggled to define the boundaries of the Euclidean system. Many tried in vain to prove the fifth postulate from the first four. By 1763, at least 28 different proofs had been published, but all were found incorrect.\nLeading up to this period, geometers also tried to determine what constructions could be accomplished in Euclidean geometry. For example, the problem of trisecting an angle with a compass and straightedge is one that naturally occurs within the theory, since the axioms refer to constructive operations that can be carried out with those tools. However, centuries of efforts failed to find a solution to this problem, until Pierre Wantzel published a proof in 1837 that such a construction was impossible. Other constructions that were proved impossible include doubling the cube and squaring the circle. In the case of doubling the cube, the impossibility of the construction originates from the fact that the compass and straightedge method involve equations whose order is an integral power of two, while doubling a cube requires the solution of a third-order equation.\nEuler discussed a generalization of Euclidean geometry called affine geometry, which retains the fifth postulate unmodified while weakening postulates three and four in a way that eliminates the notions of angle (whence right triangles become meaningless) and of equality of length of line segments in general (whence circles become meaningless) while retaining the notions of parallelism as an equivalence relation between lines, and equality of length of parallel line segments (so line segments continue to have a midpoint).\n19th century.\nIn the early 19th century, Carnot and M\u00f6bius systematically developed the use of signed angles and line segments as a way of simplifying and unifying results.\nHigher dimensions.\nIn the 1840s William Rowan Hamilton developed the quaternions, and John T. Graves and Arthur Cayley the octonions. These are normed algebras which extend the complex numbers. Later it was understood that the quaternions are also a Euclidean geometric system with four real Cartesian coordinates. Cayley used quaternions to study rotations in 4-dimensional Euclidean space.\nAt mid-century Ludwig Schl\u00e4fli developed the general concept of Euclidean space, extending Euclidean geometry to higher dimensions. He defined \"polyschemes\", later called polytopes, which are the higher-dimensional analogues of polygons and polyhedra. He developed their theory and discovered all the regular polytopes, i.e. the formula_4-dimensional analogues of regular polygons and Platonic solids. He found there are six regular convex polytopes in dimension four, and three in all higher dimensions.\n!valign=top align=right|Short radius\n!valign=top align=right|Area\n!valign=top align=right|Volume\n!valign=top align=right|4-Content\nSchl\u00e4fli performed this work in relative obscurity and it was published in full only posthumously in 1901. It had little influence until it was rediscovered and fully documented in 1948 by H.S.M. Coxeter.\nIn 1878 William Kingdon Clifford introduced what is now termed geometric algebra, unifying Hamilton's quaternions with Hermann Grassmann's algebra and revealing the geometric nature of these systems, especially in four dimensions. The operations of geometric algebra have the effect of mirroring, rotating, translating, and mapping the geometric objects that are being modeled to new positions. The Clifford torus on the surface of the 3-sphere is the simplest and most symmetric flat embedding of the Cartesian product of two circles (in the same sense that the surface of a cylinder is \"flat\").\nNon-Euclidean geometry.\nThe century's most influential development in geometry occurred when, around 1830, J\u00e1nos Bolyai and Nikolai Ivanovich Lobachevsky separately published work on non-Euclidean geometry, in which the parallel postulate is not valid. Since non-Euclidean geometry is provably relatively consistent with Euclidean geometry, the parallel postulate cannot be proved from the other postulates.\nIn the 19th century, it was also realized that Euclid's ten axioms and common notions do not suffice to prove all of the theorems stated in the \"Elements\". For example, Euclid assumed implicitly that any line contains at least two points, but this assumption cannot be proved from the other axioms, and therefore must be an axiom itself. The very first geometric proof in the \"Elements,\" shown in the figure above, is that any line segment is part of a triangle; Euclid constructs this in the usual way, by drawing circles around both endpoints and taking their intersection as the third vertex. His axioms, however, do not guarantee that the circles actually intersect, because they do not assert the geometrical property of continuity, which in Cartesian terms is equivalent to the completeness property of the real numbers. Starting with Moritz Pasch in 1882, many improved axiomatic systems for geometry have been proposed, the best known being those of Hilbert, George Birkhoff, and Tarski.\n20th century and relativity.\nEinstein's theory of special relativity involves a four-dimensional space-time, the Minkowski space, which is non-Euclidean. This shows that non-Euclidean geometries, which had been introduced a few years earlier for showing that the parallel postulate cannot be proved, are also useful for describing the physical world.\nHowever, the three-dimensional \"space part\" of the Minkowski space remains the space of Euclidean geometry. This is not the case with general relativity, for which the geometry of the space part of space-time is not Euclidean geometry. For example, if a triangle is constructed out of three rays of light, then in general the interior angles do not add up to 180 degrees due to gravity. A relatively weak gravitational field, such as the Earth's or the Sun's, is represented by a metric that is approximately, but not exactly, Euclidean. Until the 20th century, there was no technology capable of detecting these deviations in rays of light from Euclidean geometry, but Einstein predicted that such deviations would exist. They were later verified by observations such as the slight bending of starlight by the Sun during a solar eclipse in 1919, and such considerations are now an integral part of the software that runs the GPS system.\nAs a description of the structure of space.\nEuclid believed that his axioms were self-evident statements about physical reality. Euclid's proofs depend upon assumptions perhaps not obvious in Euclid's fundamental axioms, in particular that certain movements of figures do not change their geometrical properties such as the lengths of sides and interior angles, the so-called \"Euclidean motions\", which include translations, reflections and rotations of figures. Taken as a physical description of space, postulate 2 (extending a line) asserts that space does not have holes or boundaries; postulate 4 (equality of right angles) says that space is isotropic and figures may be moved to any location while maintaining congruence; and postulate 5 (the parallel postulate) that space is flat (has no intrinsic curvature).\nAs discussed above, Albert Einstein's theory of relativity significantly modifies this view.\nThe ambiguous character of the axioms as originally formulated by Euclid makes it possible for different commentators to disagree about some of their other implications for the structure of space, such as whether or not it is infinite (see below) and what its topology is. Modern, more rigorous reformulations of the system typically aim for a cleaner separation of these issues. Interpreting Euclid's axioms in the spirit of this more modern approach, axioms 1\u20134 are consistent with either infinite or finite space (as in elliptic geometry), and all five axioms are consistent with a variety of topologies (e.g., a plane, a cylinder, or a torus for two-dimensional Euclidean geometry).\nTreatment of infinity.\nInfinite objects.\nEuclid sometimes distinguished explicitly between \"finite lines\" (e.g., Postulate 2) and \"infinite lines\" (book I, proposition 12). However, he typically did not make such distinctions unless they were necessary. The postulates do not explicitly refer to infinite lines, although for example some commentators interpret postulate 3, existence of a circle with any radius, as implying that space is infinite.\nThe notion of infinitesimal quantities had previously been discussed extensively by the Eleatic School, but nobody had been able to put them on a firm logical basis, with paradoxes such as Zeno's paradox occurring that had not been resolved to universal satisfaction. Euclid used the method of exhaustion rather than infinitesimals.\nLater ancient commentators, such as Proclus (410\u2013485 CE), treated many questions about infinity as issues demanding proof and, e.g., Proclus claimed to prove the infinite divisibility of a line, based on a proof by contradiction in which he considered the cases of even and odd numbers of points constituting it.\nAt the turn of the 20th century, Otto Stolz, Paul du Bois-Reymond, Giuseppe Veronese, and others produced controversial work on non-Archimedean models of Euclidean geometry, in which the distance between two points may be infinite or infinitesimal, in the Newton\u2013Leibniz sense. Fifty years later, Abraham Robinson provided a rigorous logical foundation for Veronese's work.\nInfinite processes.\nAncient geometers may have considered the parallel postulate \u2013 that two parallel lines do not ever intersect \u2013 less certain than the others because it makes a statement about infinitely remote regions of space, and so cannot be physically verified.\nThe modern formulation of proof by induction was not developed until the 17th century, but some later commentators consider it implicit in some of Euclid's proofs, e.g., the proof of the infinitude of primes.\nSupposed paradoxes involving infinite series, such as Zeno's paradox, predated Euclid. Euclid avoided such discussions, giving, for example, the expression for the partial sums of the geometric series in IX.35 without commenting on the possibility of letting the number of terms become infinite.\nLogical basis.\nClassical logic.\nEuclid frequently used the method of proof by contradiction, and therefore the traditional presentation of Euclidean geometry assumes classical logic, in which every proposition is either true or false, i.e., for any proposition P, the proposition \"P or not P\" is automatically true.\nModern standards of rigor.\nPlacing Euclidean geometry on a solid axiomatic basis was a preoccupation of mathematicians for centuries. The role of primitive notions, or undefined concepts, was clearly put forward by Alessandro Padoa of the Peano delegation at the 1900 Paris conference: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...when we begin to formulate the theory, we can imagine that the undefined symbols are \"completely devoid of meaning\" and that the unproved propositions are simply \"conditions\" imposed upon the undefined symbols.\nThen, the \"system of ideas\" that we have initially chosen is simply \"one interpretation\" of the undefined symbols; but..this interpretation can be ignored by the reader, who is free to replace it in his mind by \"another interpretation\".. that satisfies the conditions...\n\"Logical\" questions thus become completely independent of \"empirical\" or \"psychological\" questions...\nThe system of undefined symbols can then be regarded as the \"abstraction\" obtained from the \"specialized theories\" that result when...the system of undefined symbols is successively replaced by each of the interpretations...\nThat is, mathematics is context-independent knowledge within a hierarchical framework. As said by Bertrand Russell:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If our hypothesis is about \"anything\", and not about some one or more particular things, then our deductions constitute mathematics. Thus, mathematics may be defined as the subject in which we never know what we are talking about, nor whether what we are saying is true.\nSuch foundational approaches range between foundationalism and formalism.\nAxiomatic formulations.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Geometry is the science of correct reasoning on incorrect figures.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9418", "revid": "5231945", "url": "https://en.wikipedia.org/wiki?curid=9418", "title": "Epic poetry", "text": "Lengthy narrative poem, ordinarily detailing extraordinary and heroic deeds\nAn epic poem, or simply an epic, is a lengthy narrative poem typically about the extraordinary deeds of extraordinary characters who, in dealings with gods or other superhuman forces, gave shape to the mortal universe for their descendants.\nEtymology.\nThe English word \"epic\" comes from Latin \"epicus\", which itself comes from the Ancient Greek adjective (\"epikos\"), from (\"epos\"),\n\"word, story, poem.\"\nIn ancient Greek, 'epic' could refer to all poetry in dactylic hexameter (\"epea\"), which included not only Homer but also the wisdom poetry of Hesiod, the utterances of the Delphic oracle, and the strange theological verses attributed to Orpheus. Later tradition, however, has restricted the term 'epic' to \"heroic epic\", as described in this article.\nOverview.\nOriginating before the invention of writing, primary epics, such as those of Homer, were composed by bards who used complex rhetorical and metrical schemes by which they could memorize the epic as received in tradition and add to the epic in their performances. Later writers like Virgil, Apollonius of Rhodes, Dante, Cam\u00f5es, and Milton adopted and adapted Homer's style and subject matter, but used devices available only to those who write.\nThe oldest epic recognized is the \"Epic of Gilgamesh\" (c.\u20092500\u20131300 BCE), which was recorded in ancient Sumer during the Neo-Sumerian Empire. The poem details the exploits of Gilgamesh, the king of Uruk. Although recognized as a historical figure, Gilgamesh, as represented in the epic, is a largely legendary or mythical figure.\nThe longest written epic from antiquity is the ancient Indian \"Mahabharata\" (c.\u20093rd century BC\u20133rd century AD), which consists of 100,000 \u015blokas or over 200,000 verse lines (each shloka is a couplet), as well as long prose passages, so that at ~1.8 million words it is roughly twice the length of \"Shahnameh\", four times the length of the \"R\u0101m\u0101ya\u1e47a\", and roughly ten times the length of the \"Iliad\" and the \"Odyssey\" combined.\nFamous examples of epic poetry include the Sumerian \"Epic of Gilgamesh\", the ancient Indian \"Mahabharata\" and \"R\u0101m\u0101ya\u1e47a\" in Sanskrit and \"Silappatikaram\" and \"Manimekalai\" in Tamil, the Persian \"Shahnameh\", the Ancient Greek \"Odyssey\" and \"Iliad\", Virgil's \"Aeneid\", the Old English \"Beowulf\", Dante's \"Divine Comedy\", the Finnish \"Kalevala\", the German , the French \"Song of Roland\", the Spanish \"Cantar de mio Cid\", the Portuguese \"Os Lus\u00edadas\", the Armenian \"Daredevils of Sassoun\", John Milton's \"Paradise Lost\", \"The Secret History of the Mongols\", the Kyrgyz \"Manas\", and the Malian \"Sundiata\". Epic poems of the modern era include Derek Walcott's \"Omeros\", Mircea C\u0103rt\u0103rescu's \"The Levant\" and Adam Mickiewicz's \"Pan Tadeusz\". \"Paterson\" by William Carlos Williams, published in five volumes from 1946 to 1958, was inspired in part by another modern epic, \"The Cantos\" by Ezra Pound.\nOral epics.\nThe first epics were products of preliterate societies and oral history poetic traditions. Oral tradition was used alongside written scriptures to communicate and facilitate the spread of culture.\nIn these traditions, poetry is transmitted to the audience and from performer to performer by purely oral means. Early 20th-century study of living oral epic traditions in the Balkans by Milman Parry and Albert Lord demonstrated the paratactic model used for composing these poems. What they demonstrated was that oral epics tend to be constructed in short episodes, each of equal status, interest and importance. This facilitates memorization, as the poet is recalling each episode in turn and using the completed episodes to recreate the entire epic as he performs it. Parry and Lord also contend that the most likely source for written texts of the epics of Homer was dictation from an oral performance.\nMilman Parry and Albert Lord have argued that the Homeric epics, the earliest works of Western literature, were fundamentally an oral poetic form. These works form the basis of the epic genre in Western literature. Nearly all of Western epic (including Virgil's \"Aeneid\" and Dante's \"Divine Comedy\") self-consciously presents itself as a continuation of the tradition begun by these poems.\nComposition and conventions.\nIn his work \"Poetics\", Aristotle defines an epic as one of the forms of poetry, contrasted with lyric poetry and drama (in the form of tragedy and comedy).\nEpic poetry agrees with Tragedy in so far as it is an imitation in verse of characters of a higher type. They differ in that Epic poetry admits but one kind of meter and is narrative in form. They differ, again, in their length: for Tragedy endeavors, as far as possible, to confine itself to a single revolution of the sun, or but slightly to exceed this limit, whereas the Epic action has no limits of time. This, then, is a second point of difference; though at first the same freedom was admitted in Tragedy as in Epic poetry.\nOf their constituent parts some are common to both, some peculiar to Tragedy: whoever, therefore knows what is good or bad Tragedy, knows also about Epic poetry. All the elements of an Epic poem are found in Tragedy, but the elements of a Tragedy are not all found in the Epic poem. \u2013 Aristotle, \"Poetics\" Part V\nHarmon &amp; Holman (1999) define an epic:\n \u2014 Harmon &amp; Holman (1999)\nHarmon and Holman delineate ten main characteristics of an epic:\nThe hero generally participates in a cyclical journey or quest, faces adversaries that try to defeat him in his journey, and returns home significantly transformed by his journey. The epic hero illustrates traits, performs deeds, and exemplifies certain morals that are valued by the society the epic originates from. Many epic heroes are recurring characters in the legends of their native cultures.\nConventions of the Indian Epic.\nIn the Indian mah\u0101k\u0101vya epic genre, more emphasis was laid on description than on narration. Indeed, the traditional characteristics of a \"mah\u0101k\u0101vya\" are listed as:\nThemes.\nClassical epic poetry recounts a journey, either physical (as typified by Odysseus in the \"Odyssey\") or mental (as typified by Achilles in the \"Iliad\") or both. Epics also tend to highlight cultural norms and to define or call into question cultural values, particularly as they pertain to heroism.\nConventions.\nProem.\nIn the proem or preface, the poet may begin by invoking a Muse or similar divinity. The poet prays to the Muses to provide him with divine inspiration to tell the story of a great hero.\nExample opening lines with invocations:\nSing goddess the baneful wrath of Achilles son of Peleus \u2013 \"Iliad\" 1.1\nMuse, tell me in verse of the man of many wiles \u2013 \"Odyssey\" 1.1\nFrom the Heliconian Muses let us begin to sing \u2013 Hesiod, \"Theogony\" 1.1\nBeginning with thee, Oh Phoebus, I will recount the famous deeds of men of old \u2013 \"Argonautica\" 1.1\nMuse, remember to me the causes \u2013 \"Aeneid\" 1.8\nSing Heav'nly Muse, that on the secret top\nof Oreb, or of Sinai, didst inspire \u2013 \"Paradise Lost\" 1.6\u20137\nAn alternative or complementary form of proem, found in Virgil and his imitators, opens with the performative verb \"I sing\". Examples:\nI sing arms and the man \u2013 \"Aeneid\" 1.1\nI sing pious arms and their captain \u2013 \"Gerusalemme liberata\" 1.1\nI sing ladies, knights, arms, loves, courtesies, audacious deeds \u2013 \"Orlando Furioso\" 1.1\u20132\nThis Virgilian epic convention is referenced in Walt Whitman's poem title / opening line \"I sing the body electric\".\nCompare the first six lines of the \"Kalevala\":\nMastered by desire impulsive,\nBy a mighty inward urging,\nI am ready now for singing,\nReady to begin the chanting\nOf our nation\u2019s ancient folk-song\nHanded down from by-gone ages.\nThese conventions are largely restricted to European classical culture and its imitators. The \"Epic of Gilgamesh\", for example, or the \"Bhagavata Purana\" do not contain such elements, nor do early medieval Western epics that are not strongly shaped by the classical traditions, such as the \"Chanson de Roland\" or the \"Poem of the Cid\".\nIn medias res.\nNarrative opens \"in the middle of things\", with the hero at his lowest point. Usually flashbacks show earlier portions of the story. For example, the \"Iliad\" does not tell the entire story of the Trojan War, starting with the judgment of Paris, but instead opens abruptly on the rage of Achilles and its immediate causes. So too, \"Orlando Furioso\" is not a complete biography of Roland, but picks up from the plot of \"Orlando Innamorato\", which in turn presupposes a knowledge of the romance and oral traditions.\nEnumeratio.\nEpic catalogues and genealogies are given, called \"enumeratio\". These long lists of objects, places, and people place the finite action of the epic within a broader, universal context, such as the catalog of ships. Often, the poet is also paying homage to the ancestors of audience members. Examples:\nStylistic features.\nIn the Homeric and post-Homeric tradition, epic style is typically achieved through the use of the following stylistic features:\nForm.\nMany verse forms have been used in epic poems through the ages, but each language's literature typically gravitates to one form, or at least to a very limited set.\nAncient Sumerian epic poems did not use any kind of poetic meter and lines did not have consistent lengths;\ninstead, Sumerian poems derived their rhythm solely through constant repetition and parallelism, with subtle variations between lines.\nIndo-European epic poetry, by contrast, usually places strong emphasis on the importance of line consistency and poetic meter. Ancient Greek epics were composed in dactylic hexameter.\nVery early Latin epicists, such Livius Andronicus and Gnaeus Naevius, used Saturnian meter. By the time of Ennius, however, Latin poets had adopted dactylic hexameter.\nDactylic hexameter has been adapted by a few anglophone poets such as Longfellow in \"Evangeline\", whose first line is as follows:\nThis is the | forest pri | meval. The | murmuring | pines and the | hemlocks\nOld English, German and Norse poems were written in alliterative verse,\nusually without rhyme. The alliterative form can be seen in the Old English \u201cFinnsburg Fragment\u201d (alliterated sounds are in bold):\n&lt;templatestyles src=\"Verse translation/styles.css\" /&gt;\nWhile the above classical and Germanic forms would be considered stichic, Italian, Spanish and Portuguese long poems favored stanzaic forms, usually written in terza rima\nor especially ottava rima.\n\"Terza rima\" is a rhyming verse stanza form that consists of an interlocking three-line rhyme scheme. An example is found in the first lines of the Divine Comedy by Dante, who originated the form:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn ottava rima, each stanza consists of three alternate rhymes and one double rhyme, following the ABABABCC rhyme scheme. Example:\n&lt;templatestyles src=\"Verse translation/styles.css\" /&gt;\nFrom the 14th century English epic poems were written in heroic couplets,\nand rhyme royal,\nthough in the 16th century the Spenserian stanza\nand blank verse\nwere also introduced. The French alexandrine is currently the heroic line in French literature, though in earlier literature \u2013 such as the chanson de geste \u2013 the decasyllable grouped in laisses took precedence. In Polish literature, couplets of Polish alexandrines (syllabic lines of 7+6 syllables) prevail.\nIn Russian, iambic tetrameter verse is the most popular.\nIn Serbian poetry, the decasyllable is the only form employed.\nBalto-Finnic (e.g. Estonian, Finnish, Karelian) folk poetry uses a form of trochaic tetrameter that has been called the Kalevala meter. The Finnish and Estonian national epics, \"Kalevala\" and \"Kalevipoeg\", are both written in this meter. The meter is thought to have originated during the Proto-Finnic period.\nIn Indic epics such as the Ramayana and Mahabharata, the shloka form is used.\nGenres and related forms.\nThe primary form of epic, especially as discussed in this article, is the heroic epic, including such works as the \"Iliad\" and \"Mahabharata\". Ancient sources also recognized didactic epic as a category, represented by such works as Hesiod's \"Works and Days\" and Lucretius's \"De rerum natura\".\nA related type of poetry is the epyllion (plural: epyllia), a brief narrative poem with a romantic or mythological theme. The term, which means \"little epic\", came into use in the nineteenth century. It refers primarily to the erudite, shorter hexameter poems of the Hellenistic period and the similar works composed at Rome from the age of the neoterics; to a lesser degree, the term includes some poems of the English Renaissance, particularly those influenced by Ovid.\nThe most famous example of classical epyllion is perhaps Catullus 64.\nEpyllion is to be understood as distinct from mock epic, another light form.\nRomantic epic is a term used to designate works such as \"Morgante\", \"Orlando Innamorato\", \"Orlando Furioso\" and \"Gerusalemme Liberata\", which freely lift characters, themes, plots and narrative devices from the world of prose chivalric romance.\nNon-European forms\nLong poetic narratives that do not fit the traditional European definition of the heroic epic are sometimes known as folk epics. Indian folk epics have been investigated by Lauri Honko (1998), Brenda Beck (1982) and John Smith, amongst others. Folk epics are an important part of community identities. For example, in Egypt, the folk genre known as al-sira relates the saga of the Hil\u0101l\u012b tribe and their migrations across the Middle East and north Africa, see Bridget Connelly (1986). In India, folk epics reflect the caste system of Indian society and the life of the lower levels of society, such as cobblers and shepherds, see C.N. Ramachandran, \u201cAmbivalence and Angst: A Note on Indian folk epics,\u201d in Lauri Honko (2002. p.\u00a0295). Some Indian oral epics feature strong women who actively pursue personal freedom in their choice of a romantic partner (Stuart, Claus, Flueckiger and Wadley, eds, 1989, p.\u00a05). Japanese traditional performed narratives were sung by blind singers. One of the most famous, The Tale of the Heike, deals with historical wars and had a ritual function to placate the souls of the dead (Tokita 2015, p.\u00a07). A variety of epic forms are found in Africa. Some have a linear, unified style while others have a more cyclical, episodic style (Barber 2007, p.\u00a050). People in the rice cultivation zones of south China sang long narrative songs about the origin of rice growing, rebel heroes, and transgressive love affairs (McLaren 2022). The borderland ethnic populations of China sang heroic epics, such as the Epic of King Gesar of the Mongols, and the creation-myth epics of the Yao people of south China.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;* Albanian epic poetry\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9419", "revid": "18872885", "url": "https://en.wikipedia.org/wiki?curid=9419", "title": "Eocene", "text": "Second epoch of the Paleogene Period \nThe Eocene ( ) Epoch is a geological epoch that lasted from about 56 to 33.9 million years ago (Ma). It is the second epoch of the Paleogene Period in the modern Cenozoic Era. The name \"Eocene\" comes from the Ancient Greek (\"\u0113\u1e53s\", \"dawn\") and (\"kain\u00f3s\", \"new\") and refers to the \"dawn\" of modern ('new') fauna that appeared during the epoch.\nThe Eocene spans the time from the end of the Paleocene Epoch to the beginning of the Oligocene Epoch. The start of the Eocene is marked by a brief period in which the concentration of the carbon isotope 13C in the atmosphere was exceptionally low in comparison with the more common isotope 12C. The end is set at a major extinction event called the \"Grande Coupure\" (the \"Great Break\" in continuity) or the Eocene\u2013Oligocene extinction event, which may be related to the impact of one or more large bolides in Siberia and in what is now Chesapeake Bay. As with other geologic periods, the strata that define the start and end of the epoch are well identified, though their exact dates are slightly uncertain.\nEtymology.\nThe term \"Eocene\" is derived from Ancient Greek \"eos\" meaning \"dawn\", and \"kainos\" meaning \"new\" or \"recent\", as the epoch saw the dawn of recent, or modern, life.\nScottish geologist Charles Lyell (ignoring the Quaternary) divided the Tertiary Epoch into the Eocene, Miocene, Pliocene, and New Pliocene (Holocene) Periods in 1833. British geologist John Phillips proposed the Cenozoic in 1840 in place of the Tertiary, and Austrian paleontologist Moritz H\u00f6rnes introduced the Paleogene for the Eocene and Neogene for the Miocene and Pliocene in 1853. After decades of inconsistent usage, the newly formed International Commission on Stratigraphy (ICS), in 1969, standardized stratigraphy based on the prevailing opinions in Europe: the Cenozoic Era subdivided into the Tertiary and Quaternary sub-eras, and the Tertiary subdivided into the Paleogene and Neogene periods. In 1978, the Paleogene was officially defined as the Paleocene, Eocene, and Oligocene epochs; and the Neogene as the Miocene and Pliocene epochs. In 1989, Tertiary and Quaternary were removed from the time scale due to the arbitrary nature of their boundary, but Quaternary was reinstated in 2009.\nGeology.\nBoundaries.\nThe Eocene is a dynamic epoch that represents global climatic transitions between two climatic extremes, transitioning from the hot house to the cold house. The beginning of the Eocene is marked by the Paleocene\u2013Eocene Thermal Maximum, a short period of intense warming and ocean acidification brought about by the release of carbon en masse into the atmosphere and ocean systems, which led to a mass extinction of 30\u201350% of benthic foraminifera\u2013single-celled species which are used as bioindicators of the health of a marine ecosystem\u2014one of the largest in the Cenozoic. This event happened around 55.8 mya, and was one of the most significant periods of global change during the Cenozoic.\nThe middle Eocene was characterized by the shift towards a cooler climate at the end of the EECO, around 47.8 Ma, which was briefly interrupted by another warming event called the middle Eocene climatic optimum (MECO). Lasting for about 400, 000 years, the MECO was responsible for a globally uniform 4\u00b0 to 6\u00b0C warming of both the surface and deep oceans, as inferred from foraminiferal stable oxygen isotope records. The resumption of a long-term gradual cooling trend resulted in a glacial maximum at the late Eocene/early Oligocene boundary. \nThe end of the Eocene was also marked by the Eocene\u2013Oligocene extinction event, also known as the \"Grande Coupure\".\nStratigraphy.\nThe Eocene is conventionally divided into early (56\u201347.8\u00a0 Ma), middle (47.8\u201338 Ma), and late (38\u201333.9 Ma) subdivisions. The corresponding rocks are referred to as lower, middle, and upper Eocene. The Ypresian Stage constitutes the lower, the Priabonian Stage the upper; and the Lutetian and Bartonian stages are united as the middle Eocene.\nPalaeogeography and tectonics.\nDuring the Eocene, the continents continued to drift toward their present positions.\nAt the beginning of the period, Australia and Antarctica remained connected, and warm equatorial currents may have mixed with colder Antarctic waters, distributing the heat around the planet and keeping global temperatures high. When Australia split from the southern continent around 45 Ma, the warm equatorial currents were routed away from Antarctica. An isolated cold water channel developed between the two continents. However, modeling results call into question the thermal isolation model for late Eocene cooling, and decreasing carbon dioxide levels in the atmosphere may have been more important. Once the Antarctic region began to cool down, the ocean surrounding Antarctica began to freeze, sending cold water and icefloes north and reinforcing the cooling.\nThe northern supercontinent of Laurasia began to fragment, as Europe, Greenland and North America drifted apart.\nIn western North America, the Laramide Orogeny came to an end in the Eocene, and compression was replaced with crustal extension that ultimately gave rise to the Basin and Range Province. Huge lakes formed in the high flat basins among uplifts, resulting in the deposition of the Green River Formation lagerst\u00e4tte.\nAt about 35 Ma, an asteroid impact on the eastern coast of North America formed the Chesapeake Bay impact crater.\nIn Europe, the Tethys Sea finally disappeared, while the uplift of the Alps isolated its final remnant, the Mediterranean, and created another shallow sea with island archipelagos to the north. Though the North Atlantic was opening, a land connection appears to have remained between North America and Europe since the faunas of the two regions are very similar.\nEurasia was separated in three different landmasses 50 Ma; Western Europe, Balkanatolia and Asia. About 40 Ma, Balkanatolia and Asia were connected, while Europe was connected 34 Ma.\nIndia collided with Asia, folding to initiate formation of the Himalayas. India collided with the Kohistan\u2013Ladakh Arc around 50.2 Ma and with Karakoram around 40.4 Ma, with the final collision between Asia and India occurring ~40 Ma.\nClimate.\nThe Eocene Epoch contained a wide variety of different climate conditions that includes the warmest climate in the Cenozoic Era, and arguably the warmest time interval since the Permian-Triassic mass extinction and Early Triassic, and ends in an icehouse climate. The evolution of the Eocene climate began with warming after the end of the Paleocene\u2013Eocene Thermal Maximum (PETM) at 56 Ma to a maximum during the Eocene Optimum at around 49 Ma. Recent study show elevation-dependent temperature changes during the Eocene hothouse. During this period of time, little to no ice was present on Earth with a smaller difference in temperature from the equator to the poles. Because of this the maximum sea level was 150 meters higher than current levels. Following the maximum was a descent into an icehouse climate from the Eocene Optimum to the Eocene-Oligocene transition at 34 Ma. During this decrease, ice began to reappear at the poles, and the Eocene-Oligocene transition is the period of time where the Antarctic ice sheet began to rapidly expand.\nEarly Eocene.\nGreenhouse gases, in particular carbon dioxide and methane, played a significant role during the Eocene in controlling the surface temperature. The end of the PETM was met with very large sequestration of carbon dioxide into the forms of methane clathrate, coal, and crude oil at the bottom of the Arctic Ocean, that reduced the atmospheric carbon dioxide. This event was similar in magnitude to the massive release of greenhouse gasses at the beginning of the PETM, and it is hypothesized that the sequestration was mainly due to organic carbon burial and weathering of silicates. For the early Eocene there is much discussion on how much carbon dioxide was in the atmosphere. This is due to numerous proxies representing different atmospheric carbon dioxide content. For example, diverse geochemical and paleontological proxies indicate that at the maximum of global warmth the atmospheric carbon dioxide values were at 700\u2013900 ppm while other proxies such as pedogenic (soil building) carbonate and marine boron isotopes indicate large changes of carbon dioxide of over 2,000 ppm over periods of time of less than 1 million years. Sources for this large influx of carbon dioxide could be attributed to volcanic out-gassing due to North Atlantic rifting or oxidation of methane stored in large reservoirs deposited from the PETM event in the sea floor or wetland environments. For contrast, today the carbon dioxide levels are at 400 ppm or 0.04%.\nAt about the beginning of the Eocene Epoch (55.8\u201333.9 Ma) the amount of oxygen in the earth's atmosphere more or less doubled.\nDuring the early Eocene, methane was another greenhouse gas that had a drastic effect on the climate. The warming effect of one ton of methane dimensions unspecified is approximately 30 times the warming effect of one ton of carbon on a 100-year scale (i.e., methane has a global warming potential of 29.8\u00b111). Most of the methane released to the atmosphere during this period of time would have been from wetlands, swamps, and forests. The atmospheric methane concentration today is 0.000179% or 1.79 ppmv. As a result of the warmer climate and the sea level rise associated with the early Eocene, more wetlands, more forests, and more coal deposits would have been available for methane release. If we compare the early Eocene production of methane to current levels of atmospheric methane, the early Eocene would have produced triple the amount of methane. The warm temperatures during the early Eocene could have increased methane production rates, and methane that is released into the atmosphere would in turn warm the troposphere, cool the stratosphere, and produce water vapor and carbon dioxide through oxidation. Biogenic production of methane produces carbon dioxide and water vapor along with the methane, as well as yielding infrared radiation. The breakdown of methane in an atmosphere containing oxygen produces carbon monoxide, water vapor and infrared radiation. The carbon monoxide is not stable, so it eventually becomes carbon dioxide and in doing so releases yet more infrared radiation. Water vapor traps more infrared than does carbon dioxide.\nHyperthermals through the early Eocene.\nDuring the warming in the early Eocene between 55 and 52 Ma, there were a series of short-term changes of carbon isotope composition in the ocean. These isotope changes occurred due to the release of carbon from the ocean into the atmosphere that led to a temperature increase of at the surface of the ocean. These hyperthermals led to increased perturbations in planktonic and benthic foraminifera, with a higher rate of sedimentation as a consequence of the warmer temperatures. Recent analysis of and research into these hyperthermals in the early Eocene has led to hypotheses that the hyperthermals are based on orbital parameters, in particular eccentricity and obliquity. The hyperthermals in the early Eocene, notably the Palaeocene\u2013Eocene Thermal Maximum (PETM), the Eocene Thermal Maximum 2 (ETM2), and the Eocene Thermal Maximum 3 (ETM3), were analyzed and found that orbital control may have had a role in triggering the ETM2 and ETM3.\nEquable climate problem.\nOne of the unique features of the Eocene's climate as mentioned before was the equable and homogeneous climate that existed in the early parts of the Eocene. A multitude of proxies support the presence of a warmer equable climate being present during this period of time. A few of these proxies include the presence of fossils native to warm climates, such as crocodiles, located in the higher latitudes, the presence in the high latitudes of frost-intolerant flora such as palm trees which cannot survive during sustained freezes, and fossils of snakes found in the tropics that would require much higher average temperatures to sustain them. TEX86 BAYSPAR measurements indicate extremely high sea surface temperatures of to at low latitudes, although clumped isotope analyses point to a maximum low latitude sea surface temperature of \u00b1 during the Early Eocene Climatic Optimum. Relative to present-day values, bottom water temperatures are higher according to isotope proxies. With these bottom water temperatures, temperatures in areas where deep water forms near the poles are unable to be much cooler than the bottom water temperatures.\nAn issue arises, however, when trying to model the Eocene and reproduce the results that are found with the proxy data. Using all different ranges of greenhouse gasses that occurred during the early Eocene, models were unable to produce the warming that was found at the poles and the reduced seasonality that occurs with winters at the poles being substantially warmer. The models, while accurately predicting the tropics, tend to produce significantly cooler temperatures of up to colder than the actual determined temperature at the poles. This error has been classified as the \"equable climate problem\". To solve this problem, the solution would involve finding a process to warm the poles without warming the tropics. Some hypotheses and tests which attempt to find the process are listed below.\nLarge lakes.\nDue to the nature of water as opposed to land, less temperature variability would be present if a large body of water is also present. In an attempt to try to mitigate the cooling polar temperatures, large lakes were proposed to mitigate seasonal climate changes. To replicate this case, a lake was inserted into North America and a climate model was run using varying carbon dioxide levels. The model runs concluded that while the lake did reduce the seasonality of the region greater than just an increase in carbon dioxide, the addition of a large lake was unable to reduce the seasonality to the levels shown by the floral and faunal data.\nOcean heat transport.\nThe transport of heat from the tropics to the poles, much like how ocean heat transport functions in modern times, was considered a possibility for the increased temperature and reduced seasonality for the poles. With the increased sea surface temperatures and the increased temperature of the deep ocean water during the early Eocene, one common hypothesis was that due to these increases there would be a greater transport of heat from the tropics to the poles. Simulating these differences, the models produced lower heat transport due to the lower temperature gradients and were unsuccessful in producing an equable climate from only ocean heat transport.\nOrbital parameters.\nWhile typically seen as a control on ice growth and seasonality, the orbital parameters were theorized as a possible control on continental temperatures and seasonality. Simulating the Eocene by using an ice free planet, eccentricity, obliquity, and precession were modified in different model runs to determine all the possible different scenarios that could occur and their effects on temperature. One particular case led to warmer winters and cooler summer by up to 30% in the North American continent, and it reduced the seasonal variation of temperature by up to 75%. While orbital parameters did not produce the warming at the poles, the parameters did show a great effect on seasonality and needed to be considered.\nPolar stratospheric clouds.\nAnother method considered for producing the warm polar temperatures were polar stratospheric clouds. Polar stratospheric clouds are clouds that occur in the lower stratosphere at very low temperatures. Polar stratospheric clouds have a great impact on radiative forcing. Due to their minimal albedo properties and their optical thickness, polar stratospheric clouds act similar to a greenhouse gas and traps outgoing longwave radiation. Different types of polar stratospheric clouds occur in the atmosphere: polar stratospheric clouds that are created due to interactions with nitric or sulfuric acid and water (Type I) or polar stratospheric clouds that are created with only water ice (Type II).\nMethane is an important factor in the creation of the primary Type II polar stratospheric clouds that were created in the early Eocene. Since water vapor is the only supporting substance used in Type II polar stratospheric clouds, the presence of water vapor in the lower stratosphere is necessary where in most situations the presence of water vapor in the lower stratosphere is rare. When methane is oxidized, a significant amount of water vapor is released. Another requirement for polar stratospheric clouds is cold temperatures to ensure condensation and cloud production. Polar stratospheric cloud production, since it requires the cold temperatures, is usually limited to nighttime and winter conditions. With this combination of wetter and colder conditions in the lower stratosphere, polar stratospheric clouds could have formed over wide areas in Polar Regions.\nTo test the polar stratospheric clouds effects on the Eocene climate, models were run comparing the effects of polar stratospheric clouds at the poles to an increase in atmospheric carbon dioxide. The polar stratospheric clouds had a warming effect on the poles, increasing temperatures by up to 20\u00a0\u00b0C in the winter months. A multitude of feedbacks also occurred in the models due to the polar stratospheric clouds' presence. Any ice growth was slowed immensely and would lead to any present ice melting. Only the poles were affected with the change in temperature and the tropics were unaffected, which with an increase in atmospheric carbon dioxide would also cause the tropics to increase in temperature. Due to the warming of the troposphere from the increased greenhouse effect of the polar stratospheric clouds, the stratosphere would cool and would potentially increase the amount of polar stratospheric clouds.\nWhile the polar stratospheric clouds could explain the reduction of the equator to pole temperature gradient and the increased temperatures at the poles during the early Eocene, there are a few drawbacks to maintaining polar stratospheric clouds for an extended period of time. Separate model runs were used to determine the sustainability of the polar stratospheric clouds. It was determined that in order to maintain the lower stratospheric water vapor, methane would need to be continually released and sustained. In addition, the amounts of ice and condensation nuclei would need to be high in order for the polar stratospheric cloud to sustain itself and eventually expand.\nMiddle Eocene.\nThe Eocene is not only known for containing the warmest period during the Cenozoic; it also marked the decline into an icehouse climate and the rapid expansion of the Antarctic ice sheet. The transition from a warming climate into a cooling climate began at around 49 Ma. Isotopes of carbon and oxygen indicate a shift to a global cooling climate. The cause of the cooling has been attributed to a significant decrease of &gt;2,000\u00a0ppm in atmospheric carbon dioxide concentrations. One proposed cause of the reduction in carbon dioxide during the warming to cooling transition was the azolla event. With the equable climate during the early Eocene, warm temperatures in the arctic allowed for the growth of azolla, which is a floating aquatic fern, on the Arctic Ocean. The significantly high amounts of carbon dioxide also acted to facilitate azolla blooms across the Arctic Ocean. Compared to current carbon dioxide levels, these azolla grew rapidly in the enhanced carbon dioxide levels found in the early Eocene. The isolation of the Arctic Ocean, evidenced by euxinia that occurred at this time, led to stagnant waters and as the azolla sank to the sea floor, they became part of the sediments on the seabed and effectively sequestered the carbon by locking it out of the atmosphere for good. The ability for the azolla to sequester carbon is exceptional, and the enhanced burial of azolla could have had a significant effect on the world atmospheric carbon content and may have been the event to begin the transition into an ice house climate. The azolla event could have led to a draw down of atmospheric carbon dioxide of up to 470 ppm. Assuming the carbon dioxide concentrations were at 900 ppmv prior to the Azolla Event they would have dropped to 430 ppmv, or 30 ppmv more than they are today, after the Azolla Event. This cooling trend at the end of the Early Eocene Climatic Optimum has also been proposed to have been caused by increased siliceous plankton productivity and marine carbon burial, which also helped draw carbon dioxide out of the atmosphere. Cooling after this event continued due to continual decrease in atmospheric carbon dioxide from organic productivity and weathering from mountain building.\nGlobal cooling continued until there was a major reversal from cooling to warming in the Bartonian. This warming event, signifying a sudden and temporary reversal of the cooling conditions, is known as the Middle Eocene Climatic Optimum (MECO). At around 41.5 Ma, stable isotopic analysis of samples from Southern Ocean drilling sites indicated a warming event for 600,000 years. A similar shift in carbon isotopes is known from the Northern Hemisphere in the Scaglia Limestones of Italy. Oxygen isotope analysis showed a large negative change in the proportion of heavier oxygen isotopes to lighter oxygen isotopes, which indicates an increase in global temperatures. The warming is considered to be primarily due to carbon dioxide increases, because carbon isotope signatures rule out major methane release during this short-term warming. A sharp increase in atmospheric carbon dioxide was observed with a maximum of 4,000 ppm: the highest amount of atmospheric carbon dioxide detected during the Eocene. Other studies suggest a more modest rise in carbon dioxide levels. The increase in atmospheric carbon dioxide has also been hypothesised to have been driven by increased seafloor spreading rates and metamorphic decarbonation reactions between Australia and Antarctica and increased amounts of volcanism in the region. One possible cause of atmospheric carbon dioxide increase could have been a sudden increase due to metamorphic release due to continental drift and collision of India with Asia and the resulting formation of the Himalayas; however, data on the exact timing of metamorphic release of atmospheric carbon dioxide is not well resolved in the data. Recent studies have mentioned, however, that the removal of the ocean between Asia and India could have released significant amounts of carbon dioxide. Another hypothesis still implicates a diminished negative feedback of silicate weathering as a result of continental rocks having become less weatherable during the warm Early and Middle Eocene, allowing volcanically released carbon dioxide to persist in the atmosphere for longer. Yet another explanation hypothesises that MECO warming was caused by the simultaneous occurrence of minima in both the 400 kyr and 2.4 Myr eccentricity cycles. During the MECO, sea surface temperatures in the Tethys Ocean jumped to 32-36 \u00b0C, and Tethyan seawater became more dysoxic. A decline in carbonate accumulation at ocean depths of greater than three kilometres took place synchronously with the peak of the MECO, signifying ocean acidification took place in the deep ocean. An abrupt decrease in lakewater salinity in western North America occurred during this warming interval. This warming is short lived, as benthic oxygen isotope records indicate a return to cooling at ~40 Ma.\nLate Eocene.\nAt the end of the Middle Eocene Climatic Optimum, cooling and the carbon dioxide drawdown continued through the late Eocene and into the Eocene\u2013Oligocene transition around 34 Ma. The post-MECO cooling brought with it a major aridification trend in Asia. The cooling during the initial stages of the opening of the Drake Passage ~38.5 Ma was not global, as evidenced by an absence of cooling in the North Atlantic. During the cooling period, benthic oxygen isotopes show the possibility of ice creation and ice increase during this later cooling. The end of the Eocene and beginning of the Oligocene is marked with the massive expansion of area of the Antarctic ice sheet that was a major step into the icehouse climate. Multiple proxies, such as oxygen isotopes and alkenones, indicate that at the Eocene\u2013Oligocene transition, the atmospheric carbon dioxide concentration had decreased to around 750\u2013800 ppm, approximately twice that of present levels. Along with the decrease of atmospheric carbon dioxide reducing the global temperature, orbital factors in ice creation can be seen with 100,000-year and 400,000-year fluctuations in benthic oxygen isotope records. Another major contribution to the expansion of the ice sheet was the creation of the Antarctic Circumpolar Current. The creation of the Antarctic circumpolar current would isolate the cold water around the Antarctic, which would reduce heat transport to the Antarctic along with creating ocean gyres that result in the upwelling of colder bottom waters. The issue with this hypothesis of the consideration of this being a factor for the Eocene-Oligocene transition is the timing of the creation of the circulation is uncertain. For Drake Passage, sediments indicate the opening occurred ~41 Ma while tectonics indicate that this occurred ~32 Ma. \nFlora.\nDuring the early-middle Eocene, forests covered most of the Earth including the poles. Tropical forests extended across much of modern Africa, South America, Central America, India, South-east Asia and China.\u00a0 Paratropical forests grew over North America, Europe and Russia, with broad-leafed evergreen and broad-leafed deciduous forests at higher latitudes.\nPolar forests were quite extensive. Fossils and even preserved remains of trees such as swamp cypress and dawn redwood from the Eocene have been found on Ellesmere Island in the Arctic. Even at that time, Ellesmere Island was only a few degrees in latitude further south than it is today. Fossils of subtropical and even tropical trees and plants from the Eocene also have been found in Greenland and Alaska. Tropical rainforests grew as far north as northern North America and Europe.\nPalm trees were growing as far north as Alaska and northern Europe during the early Eocene, although they became less abundant as the climate cooled. Dawn redwoods were far more extensive as well.\nThe earliest definitive \"Eucalyptus\" fossils were dated from 51.9 Mya, and were found in the Laguna del Hunco deposit in Chubut province in Argentina.\nCooling began mid-period, and by the end of the Eocene continental interiors had begun to dry, with forests thinning considerably in some areas. The newly evolved grasses were still confined to river banks and lake shores, and had not yet expanded into plains and savannas.\nThe cooling also brought seasonal changes. Deciduous trees, better able to cope with large temperature changes, began to overtake evergreen tropical species. By the end of the period, deciduous forests covered large parts of the northern continents, including North America, Eurasia and the Arctic, and rainforests held on only in equatorial South America, Africa, India and Australia.\nAntarctica began the Eocene fringed with a warm temperate to sub-tropical rainforest. Pollen found in Prydz Bay from the Eocene suggest taiga forest existed there. It became much colder as the period progressed; the heat-loving tropical flora was wiped out, and by the beginning of the Oligocene, the continent hosted deciduous forests and vast stretches of tundra.\nFauna.\nDuring the Eocene, plants and marine faunas became quite modern. Many modern bird orders first appeared in the Eocene. The Eocene oceans were warm and teeming with fish and other sea life.\nMammals.\nThe oldest known fossils of most of the modern mammal orders appear within a brief period during the early Eocene. At the beginning of the Eocene, several new mammal groups arrived in North America. These modern mammals, like artiodactyls, perissodactyls, and primates, had features like long, thin legs, feet, and hands capable of grasping, as well as differentiated teeth adapted for chewing. Dwarf forms reigned. All the members of the new mammal orders were small, under 10\u00a0kg; based on comparisons of tooth size, Eocene mammals were only 60% of the size of the primitive Palaeocene mammals that preceded them. They were also smaller than the mammals that followed them. It is assumed that the hot Eocene temperatures favored smaller animals that were better able to manage the heat.\nBoth groups of modern ungulates (hoofed animals) became prevalent because of a major radiation between Europe and North America, along with carnivorous ungulates like \"Mesonyx\". Early forms of many other modern mammalian orders appeared, including horses (most notably the \"Eohippus\"), bats, proboscidians (elephants), primates, rodents, and marsupials. Older primitive forms of mammals declined in variety and importance. Important Eocene land fauna fossil remains have been found in western North America, Europe, Patagonia, Egypt, and southeast Asia. Marine fauna are best known from South Asia and the southeast United States.\nEstablished megafauna of the Eocene include the \"Uintatherium\", \"Arsinoitherium\", and brontotheres, in which the former two, unlike the latter, did not belong to ungulates but groups that became extinct shortly after their establishments.\nLarge terrestrial mammalian predators began to take form as the terrestrial carnivores like the \"Hyaenodon\" and \"Daphoenus\" (the earliest lineage of a once-successful predatory family known as bear dogs). Entelodonts meanwhile established themselves as some of the largest omnivores. The first nimravids, including Dinictis, established themselves as amongst the first feliforms to appear. Their groups became highly successful and continued to live past the Eocene.\n\"Basilosaurus\" is a very well-known Eocene whale, but whales as a group had become very diverse during the Eocene, which is when the major transitions from being terrestrial to fully aquatic in cetaceans occurred. The first sirenians were evolving at this time, and would eventually evolve into the extant manatees and dugongs.\nIt is thought that millions of years after the Cretaceous-Paleogene extinction event, brain sizes of mammals now started to increase, \"likely driven by a need for greater cognition in increasingly complex environments\".\nBirds.\nEocene birds include some enigmatic groups with resemblances to modern forms, some of which continued from the Paleocene. Bird taxa of the Eocene include carnivorous psittaciforms, such as Messelasturidae, Halcyornithidae, large flightless forms such as \"Gastornis\" and \"Eleutherornis\", long legged falcon \"Masillaraptor\", ancient galliforms such as Gallinuloides, putative rail relatives of the family Songziidae, various pseudotooth birds such as \"Gigantornis\", the ibis relative \"Rhynchaeites\", primitive swifts of the genus \"Aegialornis\", and primitive penguins such as \"Archaeospheniscus\" and \"Inkayacu\".\nReptiles.\nReptile fossils from this time, such as fossils of pythons and turtles, are abundant.\nInsects and arachnids.\nSeveral rich fossil insect faunas are known from the Eocene, notably the Baltic amber found mainly along the south coast of the Baltic Sea, amber from the Paris Basin, France, the Fur Formation, Denmark, and the Bembridge Marls from the Isle of Wight, England. Insects found in Eocene deposits mostly belong to genera that exist today, though their range has often shifted since the Eocene. For instance the bibionid genus \"Plecia\" is common in fossil faunas from presently temperate areas, but only lives in the tropics and subtropics today. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9420", "revid": "45431165", "url": "https://en.wikipedia.org/wiki?curid=9420", "title": "Eindhoven", "text": "City and municipality in North Brabant, Netherlands\nEindhoven (] ()) is a city and municipality in the Netherlands, located in the southern province of North Brabant of which it is its largest and is also located in the Dutch part of the natural region the Campine. With a population of 238,326 on 1 January 2022, it is the fifth-largest city of the Netherlands and the largest outside the Randstad conurbation.\nEindhoven was originally located at the confluence of the Dommel and Gender. A municipality since the 13th century, Eindhoven witnessed rapid growth starting in the 1900s by textile and tobacco industries. Two well known companies: DAF Trucks and Philips were founded in the city; Philips would go on to become a major multinational conglomerate while based in Eindhoven. Apart from Philips, Eindhoven also contains the globally famous Design Academy Eindhoven.\nNeighbouring cities and towns include Son en Breugel, Nuenen, Geldrop-Mierlo, Helmond, Heeze-Leende, Waalre, Veldhoven, Eersel, Oirschot and Best. The agglomeration has a population of . The metropolitan area consists of inhabitants. The city region has a population of 753,426. The Brabantse Stedenrij combined metropolitan area has about two million inhabitants.\nEtymology.\nThe name may derive from the contraction of the regional words \"eind\" (meaning \"last\" or \"end\") and \"hove\" (or \"hoeve\", a section of some 14 hectares of land). Toponymically, \"eind\" occurs commonly as a prefix and postfix in local place- and street names. A \"hove\" comprised a parcel of land which a local lord might lease to private persons (such as farmers). Given that a string of such parcels existed around Woensel, the name \"Eindhoven\" may have originated with the meaning \"last hoves on the land of Woensel\".\nAnother explanation is that \"Eind\" is derived from \"Gender\", the city is located at the end of this little river. Genderhoven phonetically would have changed to Endehoven. 'Ende' is also the old spelling and pronunciation of the word 'eind', which would explain the change from 'Gender' to 'Eind'.\nHistory.\n13th\u201315th centuries.\nThe written history of Eindhoven started in 1232, when Duke Hendrik I of Brabant granted city rights to \"Eindhoven\", then a small town right on the confluence of the Dommel and Gender streams. At the time of granting of its charter, Eindhoven had approximately 170 houses enclosed by a rampart. Just outside the city walls stood a small castle. The city was also granted the right to organize a weekly market and the farmers in nearby villages were obliged to come to Eindhoven to sell their produce. Another factor in its establishment was its location on the trade route from Holland to Li\u00e8ge.\nAround 1388, the city's fortifications were strengthened further. And between 1413 and 1420, a new castle was built within the city walls. In 1486, Eindhoven was plundered and burned by troops from Guelders.\n16th\u201318th centuries.\nThe reconstruction of Eindhoven was finished in 1502, with a stronger rampart and a new castle. However, in 1543 it fell again, its defense works having been neglected due to poverty.\nA big fire in 1554 destroyed 75% of the houses but by 1560 these had been rebuilt with the help of William I of Orange. During the Dutch Revolt, Eindhoven changed hands between the Dutch and the Spanish several times during which it was burned down by renegade Spanish soldiers, until finally in 1583 it was captured once more by Spanish troops and its city walls were demolished.\nEindhoven did not become part of the Netherlands until 1629. During the French occupation, Eindhoven suffered again with many of its houses destroyed by the invading forces. Eindhoven remained a minor city after that until the start of the Industrial Revolution.\n19th century.\nThe Industrial Revolution of the 19th century provided a major growth impulse. Canals, roads and railroads were constructed. Eindhoven was connected to the major Zuid-Willemsvaart canal through the Eindhovens Kanaal branch in 1843 and was connected by rail to Tilburg, 's-Hertogenbosch, Venlo and Belgium between 1866 and 1870. Industrial activities initially centred around tobacco and textiles and boomed with the rise of lighting and electronics giant Philips, which was founded as a light bulb manufacturing company in Eindhoven in 1891.\nIndustrialisation brought population growth to Eindhoven. On the establishment of the Kingdom of the Netherlands in 1815, Eindhoven had 2,310 inhabitants.\n20th century.\nBy 1920, the population was 47,946; by 1925 it was 63,870 and in 1935 that had ballooned to 103,030. The explosive growth of industry in the region and the subsequent housing needs of workers called for radical changes in administration, as the City of Eindhoven was still confined to its medieval moat city limits. In 1920, the five neighbouring municipalities of Woensel (to the north), Tongelre (northeast and east), Stratum (southeast), Gestel en Blaarthem (southwest) and Strijp (west), which already bore the brunt of the housing needs and related problems, were incorporated into the new Groot-Eindhoven (\"Greater Eindhoven\") municipality. The prefix \"Groot-\" was later dropped.\nAfter the incorporation of 1920, the five former municipalities became districts of the Municipality of Eindhoven, with Eindhoven-Centrum (the City proper) forming the sixth. Since then, an additional seventh district has been formed by dividing the largest district, that of Woensel, into Woensel-Zuid and Woensel-Noord.\nThe early 20th century saw additions in technical industry with the advent of car and truck manufacturing company Van Doorne's Aanhangwagenfabriek (Trailer factory) (DAF) which was later renamed to Van Doorne's Automobiel Fabriek and the subsequent shift towards electronics and engineering, with the traditional tobacco and textile industries waning and finally disappearing in the 1970s.\nA first air raid in World War II was flown by the RAF on 6 December 1942 targeting the Philips factory downtown, in which 148 civilians died, even though the attack was carried out on a Sunday by low-flying Mosquito bombers. Large-scale air raids, including the bombing by the Luftwaffe on 19 September 1944 during Operation Market Garden, destroyed large parts of the city and killed 227 civilians while leaving 800 wounded. The reconstruction that followed left very little historical remains and the postwar reconstruction period saw drastic renovation plans in highrise style, some of which were implemented. At the time, there was little regard for historical heritage. During the 1960s, a new city hall was built and its Neo-gothic predecessor (1867) demolished to make way for a planned arterial road that never materialised.\nThe 1970s, 1980s, and 1990s saw large-scale housing developments in the districts of Woensel-Zuid and Woensel-Noord, making Eindhoven the fifth-largest city in the Netherlands.\n21st century.\nAt the start of the 21st century, a whole new housing development called Meerhoven was constructed at the site of the old airport of Welschap, west of Eindhoven. The airport itself, now called Eindhoven Airport, had moved earlier to a new location, paving the way for much-needed new houses. Meerhoven is part of the Strijp district and is partially built on lands annexed from the municipality of Veldhoven.\nGeography.\nThe villages and city that make up modern Eindhoven were originally built on sandy elevations between the Dommel, Gender and Tongelreep rivers. Beginning in the 19th century, the basins of the rivers themselves have also been used as housing land, resulting in occasional flooding in the city centre. Partly to reduce flooding, the bed of the Gender stream, which flowed directly through the city centre, was dammed off and filled up after the War, and the course of the Dommel was regulated. New ecological and socio-historical insights have led to parts of the Dommel's course being restored to their original states, and plans to have the Gender flow through the centre once again.\nThe large-scale housing developments of the 20th century saw residential areas being built on former agricultural lands and woods, former heaths that had been turned into cultivable lands in the 19th century.\nThe city is currently divided into seven districts:\nClimate.\nEindhoven has an oceanic climate with slightly warmer summers and colder winters than the coastal parts of the Netherlands. Its all-time record is set on 25 July 2019 and set on 13 January 1968, while winter lows have dipped below during extreme cold snaps. Although frosts are frequent in winter, there is no lasting snow cover in a normal winter due to the mild daytime temperatures.\nDemographics.\nPopulation.\nAs of 2021, the population of Eindhoven consisted of 235,691 people (according to AlleCijfers.nl). Of these, 38.5% or some 90,788 people were of foreign descent.\nPeople are classified as being of foreign descent when they were born outside of the Netherlands, or when at least one of their parents was born outside of the Netherlands.\nThe municipal agglomeration of Eindhoven (an administrative construct which includes only some of the surrounding towns and villages) has 327,245 inhabitants as of 1 January 2010.\nThe spoken language is a combination of Kempenlands (a Dutch dialect spoken in a large area east and south east of the city, including Arendonk and Lommel in Belgium) and North Meierijs (between the south of Den Bosch and into Eindhoven). Both dialects belong to the East Brabantian dialect group), which is very similar to colloquial Dutch).\nDistricts.\nOf all Eindhoven districts, the historical centre is by far the smallest in size and population, numbering only 5,419 in 2006. Woensel-Noord is the largest, having been the city's main area of expansion for several decades.\nPopulation figures for all districts, as of 1 January 2008, ranked by size:\nReligion.\nEindhoven is located in the southeast of the province of North Brabant. This area is historically Catholic and the population of Eindhoven was similarly mostly Catholic for a very long time until the late 1970s. However, the internationalizing influence of the university, Philips and other companies have created a more mixed population over the last few decades.\nReligion in Eindhoven (2015)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0 No religious denomination\n (45%)&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0 Catholic Church\n (36.9%)&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0 Protestant Church in the Netherlands\n (2.5%)&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Other Christian denominations (2.4%)&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0 Islam\n (8%)&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0 Hinduism\n (0.8%)&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0 Buddhism\n (0.5%)&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Other (3.9%)\nThe spiritual needs of the Eindhoven population are tended to by a steadily shrinking number of churches, two mosques and one synagogue.\nCrime.\nIn research by the Dutch newspaper Algemeen Dagblad based on the police's statistical data on crime rates, Eindhoven was found to have the highest crime rate in the Netherlands for 2006, 2007, 2009, and 2010. In 2011, Eindhoven has slipped down the list to number six.\nIn 2009, in the Eindhoven agglomeration, the following numbers of crimes were recorded:\nEconomy.\nEindhoven has grown from a little town in 1232 to one of the biggest cities in the Netherlands with over 240,000 inhabitants in 2022. Much of its growth is due to Philips, DAF Trucks and Brabantia. Among recent high-tech companies based in Eindhoven are NXP Semiconductors, Sendcloud, and Signify.\nAfter the resurrection of the Netherlands in 1815 and the end of the Belgian Revolution, Eindhoven was a small village of some 1250 people in an economically backward and mostly agricultural area. Cheap land, cheap labor and the existence of pre-industrial homesourcing (\"huisnijverheid\" in Dutch) made Eindhoven an attractive area for the developing industries which were being stimulated by the government of King William I. During the 19th century, Eindhoven grew into an industrial town with factories for textile weaving, cigar manufacturing, match making and hat making. Most of these industries disappeared again after World War II, though.\nIn 1891, brothers Gerard and Anton Philips founded the small light bulb factory that would grow into one of the largest electronics firms in the world. Philips' presence is probably the largest single contributing factor to the major growth of Eindhoven in the 20th century. It attracted and spun off many hi-tech companies, making Eindhoven a major technology and industrial hub. In 2005, a full third of the total amount of money spent on research in the Netherlands was spent in or around Eindhoven. A quarter of the jobs in the region are in technology and ICT, with companies such as FEI Company (once Philips Electron Optics), NXP Semiconductors (formerly Philips Semiconductors), ASML, ALTEN, Simac, Neways Electronics and the aforementioned Philips and DAF.\nEindhoven has long been a centre of cooperation between research institutes and industry. This tradition started with Philips (the NatLab was a physical expression of this) and has since expanded to large cooperative networks. The Eindhoven University of Technology hosts an incubator for technology startups and the NatLab has developed into the High Tech Campus Eindhoven. Also, TNO has opened a branch on the university campus. This tradition has also fostered inter-industry cooperation in the region; one example of this is the announcement in September 2010 of a new research lab for high-grade packaging materials, a cooperation of IPS Packaging and Thales Cryogenics.\nThis cooperative tradition has also developed into a different direction than the traditional technology research done at the university. Starting in 2002, the university, the Catharina hospital, Philips Medical and the University of Maastricht joined forces and started joint research into biomedical science, technology and engineering. Within Eindhoven, this research has been concentrated in a new university faculty (BioMedical Technology or BMT). This development has also made Eindhoven a biomedical technology hub within the country and its (European) region.\nPrime examples of industrial heritage in Eindhoven are the renovated Witte Dame (\"White Lady\") complex, a former Philips lamp factory; and the Admirant building (informally known as Bruine Heer or \"Brown Gentleman\" in reference to the Witte Dame across the street), the former Philips main offices. The Witte Dame currently houses the municipal library, the Design Academy and a selection of shops. The Admirant has been renovated into an Office building for small companies. Across the street from the Witte Dame and next to the Admirant is Philips' first light bulb factory (nicknamed Roze Baby, or \"Pink Baby\", in reference to its pink colour and much smaller size when compared to the \"White Lady\" and \"Brown Gentleman\"). The small building now houses the \"Centrum Kunstlicht in de Kunst\" (centre artificial light in art) and the \"Philips Incandescent Lamp Factory of 1891\" museum.\nKnowledge economy initiatives.\nDue to its high-tech environment, Eindhoven is part of several initiatives to develop, foster and increase a knowledge economy. Chief among these are:\nThe Intelligent Community Forum named the Eindhoven metro region the No. 21 intelligent community in 2008 and the No. 7 intelligent community in 2009 and 2010. In 2011, the ICF named Eindhoven the Intelligent Community of the Year. Since 2012, Eindhoven has vanished from the top 7 of intelligent communities.\nEIT Co-location.\nEindhoven is one of the co-location centres of the European Institute of Innovation and Technology (EIT). It hosts two Knowledge and Innovation Communities (KICs): Innoenergy (Sustainable Energy) and EIT ICT Labs (Information and Communication Technology). The co-locations are on the High Tech Campus Eindhoven.\nEducation.\nEindhoven, being a city with a 240,000+ population, is served by a large number of schools both at primary and secondary education levels. In addition, Eindhoven is a higher-education hub within the southern Netherlands, with several institutes of higher education that serve students from the extended region of North Brabant, Zeeland, Limburg and parts of the surrounding provinces.\nPrimary education.\nPrimary education is provided to the children aged 4 to 12 in Eindhoven through a large number of primary schools:\nSecondary education.\nSecondary education is provided to the children aged 12 to 18 in Eindhoven through several highschools:\nSpecial needs secondary education:\nHigher and adult education.\nEindhoven hosts four different public institutions for higher and adult education, as well as a number of private institutions offering courses and trainings. The public institutions hosted in Eindhoven are:\nThe Open University also has a study center in Eindhoven.\nAmong the private institutions is the Centrum voor Kunsten Eindhoven, which offers art-related courses to adults (including a DJ-education).\nPolitics.\nMunicipal council.\nThe municipal council is the legislative council at the municipal level in Eindhoven; its existence is mandated by the Constitution of the Netherlands. The Eindhoven city council consists of 45 elected representatives from the Eindhoven municipality. These are elected during municipal elections from candidates running in Eindhoven. Eindhoven politics consists of local branches of the national political parties and purely local parties with strictly local interests. The city council reflects this mix in its makeup.\nThe division of the municipal seats in the Eindhoven city council after the elections is shown below:\nMunicipal executive.\nAlder(wo)men.\nThe executive council in Dutch municipalities is called the \"College of the Mayor and Aldermen\" (Dutch: \"College van Burgemeester en Wethouders\" or \"College van B&amp;W\" for short). The mayor is appointed by the monarch, but the council of aldermen is composed as a result of the formation of a local coalition government. This coalition is formed in such a way as to be able to rely on a majority of the votes in the city council.\nIn May 2014, a coalition was formed between PvdA, D66, SP, and GreenLeft. Together they had 26 seats in the city council. The council of alder(wo)men consisted of the following people:\nIn May 2018, a coalition was formed existing of VVD, GreenLeft, PvdA, and CDA. They had 26 seats together. The alder(wo)men were:\nIn June 2022, a coalition has been formed existing of GreenLeft, CDA, PvdA, and D66, having 25 seats together. Their alder(wo)men have been:\nMayor.\nThe mayors of the Netherlands are not elected but appointed by the crown. Nevertheless, there has been a movement over the last few years to give the municipalities more say in who will be their mayor, which has resulted in consultative referendums being held in the larger cities to \"suggest\" a candidate for the post. This was also tried in Eindhoven.\nOn 23 January 2008, a referendum to elect a mayor was held in Eindhoven. This referendum, the second of its kind in the Netherlands, was attended by 24.6% of the inhabitants. This was less than the required 30% needed to make a referendum binding. Nevertheless, the city council would choose the winner of the referendum as the preferred candidate. The main reason for the low attendance was that the candidates, Leen Verbeek and Rob van Gijzel, were from the same party (PvdA). Rob van Gijzel won the referendum with 61.8% of the votes and was appointed the city's new mayor.\nThe mayor is the chairman of the Council of B&amp;W. He also has responsibility for a number of specific posts (like the aldermen). For example, in the executive council of 2014-2018 mayor Van Gijzel held responsibility for the post of communication.\nIf unavailable, the mayor is temporarily replaced by one of the aldermen.\nRob van Gijzel was succeeded by John Jorritsma (VVD) on 13 September 2016. Jorritsma has been succeeded by Jeroen Dijsselbloem (PvdA) on 13 September 2022.\nCulture and recreation.\nCulturally and recreationally, Eindhoven was formed by two forces:\nEindhoven is also known as the City of Light, due to Philips originating from there and because of several projects involving lighting up buildings of the city. During Carnival, Eindhoven is rechristened \"Lampegat\" (Hamlet of Lamps, although for the ironic purposes of carnival the translation \"Hole in the ground with lamps\" is closer to the mark); this refers again to the important role of Philips in the Eindhoven community.\nCultural institutions.\nThere are several cultural institutions in and around the city.\nMuseums.\nEindhoven was home to the Evoluon science museum, sponsored by Philips. The Evoluon building has evolved into a conference centre.\nOpen-air art.\nThe Eindhoven public space contains many forms of artistic expression (a book published by the Eindhoven tourist board records 550 as of 2001 and more have been added since), with high \"concentrations\" of them in the parks. The Stadswandelpark for instance, contains over 30 works of modern art. There are also several other works of art on permanent display throughout the city, such as \"Flying Pins\" (by Claes Oldenburg and Coosje van Bruggen, who considered the location on the southern stretch of the John F. Kennedylaan to be like a bowling alley) and \"Swing\" (a construct on the Karel de Grotelaan, which morphs into different geometric shapes as you move around it). There are also a number of statues of famous city inhabitants, such as Jan van Hooff (by Auke Hettema, 1992) and Frits Philips (by Kees Verkade) on the Market Square. There is a statue of Anton Philips in front of the central railway station.\nEindhoven is also, to some degree, open to forms of impromptu and alternative art. For example, the Berenkuil is a freezone for graffiti artists in the city.\nLight art.\nStrijp-S is a place for experimentation with LED lighting, which keeps the historic connection with Philips' past. Some light art includes the project Fakkel by Har Hollands. In the underground passage to NatLab artist Daan Roosegaarde installed his project Crystal.\nStrijp-S is a regular location for the light festival GLOW.\nMusic and theatre.\nThe Effenaar is a popular music venue and cultural center in Eindhoven, and is located at the Dommelstraat.\nIn 1992, the Muziekcentrum Frits Philips was opened as a stage for classical and popular music in Eindhoven, reviewed by critics as a concert hall with acoustics that rival the best halls in Europe. Before that, Philips sponsored the POC.\nParktheater Eindhoven is Eindhoven's stage for opera, cabaret, ballet etc. Opened in 1964, it has received over 250,000 visitors every year. With its 1,000 m2 it has one of the largest stages in the Netherlands. With a major renovation ending in 2007, the new Parktheater will receive an estimated 300,000 visitors a year.\nEindhoven's Plaza Futura is now a cinema featuring cultural movies, lectures and special cultural events.\nEspecially for students, Studium Generale Eindhoven organizes \"socially, culturally and intellectually formative events\". From within the student body, two Tunas provide entertainment from time to time at university and city events: Tuna Ciudad de Luz (\"Tuna of the City of Light\") and the ladies tuna La Tuni\u00f1a.\nThe general music and theatre scene in Eindhoven (in the broadest sense) is supported by a foundation called PopEi. The purpose of this foundation is to support artistic groups with facilities, especially rehearsal stages and areas (housed in the old Philips location of Strijp-S) but also storage facilities. PopEi also provides a working environment for groups (through cafeteria facilities in Strijp-S, so groups can have real working days) and provides some logistical support for organizing events.\nRecreation.\nEindhoven has a lively recreational scene. For going out, there are numerous bars on the Market square, Stratumseind (Stratum's End) which is the largest pub-street in the Netherlands, Dommelstraat, Wilhelmina square and throughout the rest of the city. In addition to the more culturally oriented Plaza Futura, there are three cinemas in the centre of town (\"Servicebioscoop Zien\", \"Vue\" and Path\u00e9 Eindhoven, which offers THX sound, IMAX screens and 3D movie viewing).\nEindhoven also hosts a large number of cultural and entertainment-oriented festivals. The biggest festivals in Eindhoven are:\nParks.\nEindhoven contains several parks and a lot of open, green space. Of the five largest cities in the Netherlands, it has the highest percentage of green area (encompassing about \u2153 of all public space). It is also the greenest of the five largest cities in North Brabant. The green area per house is about .\nSome of the major parks in Eindhoven are the Stadswandelpark, Genneper Parken, the Philips van Lenneppark, Philips de Jongh Wandelpark and the Henri Dunantpark. There is also a green area surrounding the Karpendonkse Plas (a water area). The combination of park area, water and general atmosphere got the Ooievaarsnest neighborhood elected the \"Best large-city neighborhood of the Netherlands\" by the NRC Handelsblad in 1997.\nAdult-orientated entertainment.\nThe centre of town features two casinos (one branch of Holland Casino and the independent Casino4Events). At the A67 a Jack's casino is located.\nThere is a red light district on the Baekelandplein, as well as four brothels throughout the city. There is also a blue movie theater.\nStrijp-S.\nThe old Philips factory complex has been transformed into a multi-purpose cultural and residential complex called Strijp-S. This includes conference and event space, space for concerts and events, art of lighting, space for sports such as BMX, bouldering, and more, a walking promenade, etc.\nMedia.\nEindhoven features several print media. The local newspaper, called the Eindhovens Dagblad, is a daily newspaper with over 110,000 subscribers in the Samenwerkingsverband Regio Eindhoven region. It has a national and international section, as well as a section dedicated to regional news; the editorial department is located in Eindhoven.\nIn addition to the newspaper, Eindhoven is served by a number of weekly door-to-door publications. Chief among these is \"Groot Eindhoven\" (which carries publications of the city council, as well as other articles and advertisements). Other than that there are \"de Trompetter\", \"de Weekendkrant\" and the \"ZondagsNieuws\". The first two are delivered midweek, the last two are weekend publications.\nThere are several regional and municipal radio stations. The local radio station is Studio040, whereas Omroep Brabant and RoyaalFM provide regional radio.\nLocal television is provided by Studio040. Omroep Brabant broadcasts regionally from its television studio in Son.\nInternet, television and telephone connectivity is available via cable television, optic fiber and ADSL.\nTransport.\nAir traffic.\nEindhoven Airport is the closest airport, located approximately from the town centre. The airport serves as a military air base and a civilian commercial airport. Eindhoven Airport is the second-busiest in the Netherlands (after Schiphol). Ryanair serves London Stansted Airport, Dublin, Kyiv, Rome, Milan, Pisa, Bordeaux, Marseille, Glasgow, Madrid, Valencia, Stockholm, Kaunas, Malta, Sofia and Barcelona. Wizz air serves Belgrade, Brno, Bucharest-Otopeni, Budapest, Cluj-Napoca, Debrecen, Gda\u0144sk, Katowice, Prague, Riga, Sofia, Timi\u0219oara, Vilnius, Wroc\u0142aw. In the summer season, Reykjav\u00edk is served with 2 weekly flights operated by Iceland Express. Transavia services Alicante, Antalya, Athens, Bodrum, Corfu, Dalaman, Faro, Gran Canaria, Innsbruck, M\u00e1laga, Majorca, Munich, Prague, Rhodes and Salzburg, though some destinations are served only seasonally. Eindhoven Airport served more than 6.2\u00a0million passengers in 2018.\nRail traffic.\nEindhoven is a rail transport hub. Eindhoven Centraal railway station is the main station in Eindhoven. It has connections in the directions of:\nEindhoven Centraal is served by both intercity and local services while the smaller station, Eindhoven Strijp-S is only served by local trains. Towards 's-Hertogenbosch, Utrecht and Amsterdam trains run every ten minutes, on every day of the week. Eindhoven Stadion is a small station that serves Philips Stadion in the event of football matches or other special events at the stadium. It is located 900m west of the main station.\nUp until World War II, a train service connected Amsterdam to Li\u00e8ge via Eindhoven and Valkenswaard, but the service was discontinued and the line broken up. Recently, talks have resumed to have a service to Neerpelt, Belgium via Weert.\nRoads and highways.\nThe A2/E25 motorway from Amsterdam to Luxembourg passes Eindhoven to the west and south of the city. The A2 connects to the highway A58 to Tilburg and Breda just north of the city. Just south of Eindhoven, the A2 connects to the A67 / E34 between Antwerp and Duisburg. In 2006, the A50 was completed connecting Eindhoven to Nijmegen and Zwolle.\nLocal public transit.\nThe public transport of Eindhoven consists of more than 20 city bus lines, which also serve neighbouring villages such as Veldhoven, Geldrop and Nuenen. Nine of these buslines (400\u2013408) are marketed as high quality public transport and run with 43 electric articulated buses. Two specially built separated busways (HOV1 &amp; HOV2) are used by lines 400 to 408. Line 401 to the airport runs almost completely on separated busways. Apart from the city lines there are some 30 regional and rush-hour lines.\nBicycle infrastructure.\nAkin to all large Dutch cities, Eindhoven has an extensive network of bicycle paths. Since 2012, the Eindhoven bicycle path network has incorporated the Hovenring.\nMedical care.\nEindhoven has two hospitals in three locations: the Catharina Hospital and the M\u00e1xima Medisch Centrum, which has a branch in Woensel-Zuid (the old Diaconessenhuis) and one in Veldhoven (the old Sint Joseph Hospital). These three have an extensive cooperation and have divided specialties among each other. Emergency medicine, for example, is concentrated in the MMC Veldhoven branch and the Catharina Hospital, the MMC Eindhoven branch has no emergency department. Cardiac procedures are done in the Catharina.\nCatharina is also an academic and research hospital and participates in a shared research program with Philips Medical, the Eindhoven University of Technology and the Maastricht University into biomedical science, technology and engineering.\nPeople.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n- Anita Dillen, (born 1959), socialite, former executive, secretary of ABN Amro\n- Coen Dillen, (born 1926), former PSV Eindhoven footballer\n- Cor Dillen, (born 1920), former Philips CEO\n- Hank Dillen, (born 1947), Philips executive in USA\n- Pieter Johannes Dillen (born 1899), Painter, socialite\nTwin towns \u2013 sister cities.\nEindhoven is twinned with:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n Media related to at Wikimedia Commons\n travel guide from Wikivoyage"}
{"id": "9421", "revid": "7196877", "url": "https://en.wikipedia.org/wiki?curid=9421", "title": "Helsing\u00f8r", "text": "Helsing\u00f8r ( , ]), classically known in English as Elsinore ( ), is a city in eastern Denmark. Helsing\u00f8r Municipality had a population of 62,686 on 1 January 2018. Helsing\u00f8r and Helsingborg in Sweden together form the northern reaches of the \u00d8resund Region, centered on Copenhagen and Malm\u00f6. The HH Ferry route connects Helsing\u00f8r with Helsingborg, 4\u00a0km (2.5 miles) across the \u00d8resund.\nIts castle Kronborg was used by William Shakespeare as the setting for his play \"Hamlet.\"\nHistory.\nThe name \"Helsing\u00f8r\" has been believed to be derived from the word \"hals\" meaning \"neck\" or \"narrow strait,\" referring to the narrowest point of the \n\"\u00d8resund\" (\u00d8re Sound) between what is now Helsing\u00f8r and Helsingborg, Sweden. \nThe people were mentioned as \"Helsinger\" (which may mean \"the people of the strait\") for the first time in King Valdemar the Victorious's \"Liber Census Dani\u00e6\" from 1231 (not to be confused with the Helsings of H\u00e4lsingland in Sweden). \nPlace names show that the Helsinger may have had their main fort at Helsingborg and a fortified landing place at Helsing\u00f8r, to control the ferry route across the strait. The particularly-19th-century tradition to explain toponymies, place names, with features of the landscape does not necessarily exclude the much older tradition of reading place names as eponymous. Although an obscure legendary character, or several, Helsing is quite abundantly present in traces of lost legends in the Nordic countries.\nAlthough probably not the first Helsing, one of the three sons of Gandalf Alfgeirsson (the antagonist of Halfdan the Black, who was father of King Harald Fairhair, the semi-legendary, historical first king of a feudalist Norway) is called Helsing. He was brother to Hake and Hysing Gandalfson. Also Helsingfors/Helsinki in Finland and H\u00e4lsingland in Norrland, Sweden, refers to Helsing, as \"the Land of the Helsing/Helsinger,\" which makes the landscape-theory of the name of Helsing\u00f8r less likely.\nHelsing\u00f8r as it is known today was founded in the 1420s by Danish King Eric of Pomerania. He established the Sound Dues in 1429, which made all foreign ships passing through the strait pay a toll, which constituted up to two-thirds of Denmark's state income. With the income, Eric built the Krogen Castle Krogen, which was expanded in the 1580s and renamed Kronborg. All ships had to stop in Helsing\u00f8r to get their cargo taxed and pay a toll to the Danish Crown, which generated a significant trade for the town. In 1672, Helsing\u00f8r had grown to be the third-largest town in Denmark. \nJohan Isaksson Pontanus (\"Rerum Danicarum Historica\", 1631) attributes a long and partially-fictitious history to Helsing\u00f8r.\nThe Sound Dues were abolished in 1857 with the Copenhagen Convention in which all naval nations agreed to pay a one-time fee.\nThe oldest known fortified building of Helsing\u00f8r is \"Flynderborg\", an early medieval fortress on a hill just south of the mediaeval city.\nAround 1200, the first church, Saint Olaf's Church, was built. \nA number of convents once surrounded the church, but now all that remains is the church building, today the cathedral of the Diocese of Helsing\u00f8r. The oldest parts of the cathedral of Helsing\u00f8r date back to the 13th century and show that the fishing village, as Helsing\u00f8r was then, had grown to a town of importance.\nDuring World War II, Helsing\u00f8r was among the most important transport points for the rescue of Denmark's Jewish population during the Holocaust. Adolf Hitler had ordered that all Danish Jews were to be arrested and deported to the concentration camps on Rosh HaShanah, the Jewish New Year, which fell on 2 October 1943. When Georg Ferdinand Duckwitz, a diplomatic attach\u00e9 of Nazi Germany to Denmark, received word of the order on 28 September 1943, he shared it with political and Jewish community leaders. Using the name Elsinore Sewing Club (Danish: \"Helsing\u00f8r Syklub\") as a cover for messages, the Danish population formed an underground railroad of sorts that moved Jews away from the closely watched Copenhagen docks to spots further away, especially Helsing\u00f8r, just two miles across the \u00d8resund to Helsingborg, in neutral Sweden. Hundreds of civilians hid their fellow Danish Jewish citizens in their houses, farm lofts and churches until they could board them onto Danish fishing boats, personal pleasure boats and ferry boats. Over the course of three nights, Danes had smuggled over 7,200 Jews and 680 non-Jews (family members of Jews or political activists) across the \u00d8resund to safety in Helsingborg and Malm\u00f6 in Sweden.\nTransport.\nThe car ferry line between Helsing\u00f8r and Helsingborg, Scania, Sweden is the busiest in the world with more than 70 departures in each direction every day. The route is known as the HH Ferry route and has been sailed by several shipping lines throughout history. The car ferry terminal is connected to the town's main railway station. From the station, trains depart to Copenhagen every 20 minutes. Trains also depart to Hiller\u00f8d and Gilleleje. There are another six stations or train stops within the city and connected suburbs. Apart from \"Helsing\u00f8r Station and Ferry Terminal\" also \"Snekkersten station\", \"Esperg\u00e6rde station\", \"Mordrup station\" and the train stops at the line to Gilleleje, \"Gr\u00f8nnehave\", \"Marienlyst\" and \"H\u00f8jstrup\".\nThe E47 motorway towards Copenhagen begins just outside the city limits. The town and surrounding areas also have a network of local and regional buses.\nIndustrialisation.\nFor a century the or Elsinore shipyard was a prominent landmark, which covered the whole area between the town and Kronborg Castle. It was founded in 1882. At its height in 1957, it had 3,600 employees. The last ship left the shipyard in 1983 and it closed the same year following substantial losses.\nThe brewery, founded in 1840, was the second brewery in Denmark to ship bottled beer, just three years after Carlsberg. The last beer was brewed at in Helsing\u00f8r in 1998. Carlsberg continues to brew beer under the Wiibroe \u00c5rgangs\u00f8l label.\nPost-industrialisation.\nAfter the end of the industrial era, the town of Helsing\u00f8r had to redefine itself, and came up with an ambitious project: Kulturhavn Kronborg, literally \"Culture-harbour of Kronborg\". It officially opened on 26 May 2013, intended to appeal to tourists with an interest in culture. The main attraction of Kulturhavn Kronborg is Kronborg Castle, a UNESCO World Heritage Site. Besides the historical attractions of the site, William Shakespeare's play \"Hamlet\" has been performed annually in its courtyard since 1937. There is a longstanding tradition of performing the play in English, and notable actors in the title role have included Laurence Olivier, John Gielgud, Christopher Plummer, Derek Jacobi, and in 2009 Jude Law. At the heart of Kulturhavn Kronborg lies kulturv\u00e6rftet or The Culture Yard, a new cultural centre and a public library located in the old . It opened in 2010. The former dry dock now houses the Danish Maritime Museum.\nIn the centre of the harbour basin stands the polished steel sculpture \"Han\" (\"He\") by artist duo Elmgreen and Dragset, commissioned by the City of Helsing\u00f8r in 2012. It was inaugurated by then Minister of culture, Uffe Elb\u00e6k, in June 2012. It is seen as the counterpart (and even little brother) to Edvard Eriksen's world-famous \"The Little Mermaid\" statue in Copenhagen, and has caused both praise and protests among locals.\nThe Swedish city of Helsingborg lies a short distance across the \u00d8resund from Helsing\u00f8r, approximately . European route E55 joins the two cities; ferries connect the two sides.\nMusic.\nDieterich Buxtehude organist and composer of the Baroque period. \nHe was born Diderich Buxtehude presumably in Helsingborg, he serving as organist from 1660 to 1668 in Helsing\u00f8r as his father that held the position as organist at St. Olaf's cathedral.\nDiderich Buxtehude compositions and style became of significant influence, among others on his student Johann Sebastian Bach.\nArchitecture.\nThe new Danish Maritime Museum was designed by Danish prize-winning architects Bjarke Ingels Group (BIG).\nJ\u00f8rn Utzon lived in Helsing\u00f8r in his youth because his father was an engineer at . Utzon designed The Kingo Houses (1956\u201360) and The Hammersh\u00f8j Care Centre (1962) in the city. The project was completed by Birger Schmidt (1966) after Utzon moved to Sydney to work on the Sydney Opera House.\nDistricts.\nCentrum\nTwin towns \u2013 sister cities.\nHelsing\u00f8r practices twinning on the municipal level. For the twin towns, see twin towns of Helsing\u00f8r Municipality.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9422", "revid": "43558034", "url": "https://en.wikipedia.org/wiki?curid=9422", "title": "European route E4", "text": "Road in trans-European E-road network\n&lt;templatestyles src=\"Infobox road/styles.css\" /&gt;\nEuropean route E4 passes from north to south through Sweden from the border with Finland, with a total length of . The Finnish part lies entirely within Tornio in northern Finland, and is only long. The Swedish part traverses most of Sweden except the extreme north and the west coast region, and is commonly considered the highway backbone of Sweden, since it passes in the vicinity of many of its largest cities and through the capital Stockholm. In particular, it is the mainline road used by most vehicle traffic, both cars and lorries, between the north (Norrland) and south of Sweden or beyond.\nFrom Haparanda on the Finnish border, it stretches south along the Gulf of Bothnia to G\u00e4vle, then on a more inland route southwards. It ends in Helsingborg in Sweden, at the port for the ferry to Helsing\u00f8r in Denmark. The route intersects with European route E6 just outside Helsingborg, which continues to Trelleborg on the southern coast of Sweden.\nHistory and naming.\nThe International E-road network convention was signed in 1950, with E4 routed Lisbon-Madrid-Barcelona-Nimes-Geneva-Basel-Frankfurt-Hamburg-Helsing\u00f8r-Stockholm-Haparanda-Helsinki. The part in Sweden was signposted E4 in 1962. Until 1962, the road Helsingborg\u2013Stockholm was called highway 1, and Stockholm\u2013Haparanda highway 13.\nUnder the new system of European routes which was decided in 1975, but introduced in Sweden in 1992, it was planned to have been a part of E55, but it remains in the pre-1992 designation (E4) within Sweden, because the expenses connected with re-signing this long road portion would be too great. Besides the signs along the road, there are thousands of signs, especially in cities, showing how to reach the E4 road. The road is now fully authorised as E4 by the relevant authority, not as E55.\nRoute.\nNorth of G\u00e4vle the road is of mixed standard. Depending on the fashion at the time of construction, it is either a single standard carriageway road, usually wide, or a 2+1 road, a wide road with two lanes in one direction and one in the other with a steel wire barrier in between, or sometimes a motorway with two lanes in each direction. North of Sundsvall, the road passes through several of the larger cities as city streets. \nSouth of G\u00e4vle, the road becomes an almost continuous motorway, with the only non-motorway part being a long section past Ljungby, currently a 2+1 limited-access road. Upgrade to motorway standard will start in 2018. Construction was restarted in 2022, with the expectation to finish it in 2024. With the exception of the Ljungby bypass, the final stretch of the motorway to be opened was the road between Uppsala and Mehedeby, which was inaugurated on 17 October 2007. South of G\u00e4vle, the speed limit is on 60% and on 30% of the road. North of G\u00e4vle there are varying speed limits, with as the most common. The speed limits on the main roads in Sweden were changed on many stretches in October 2008, which saw the introduction of the 120\u00a0km/h limit.\nThe E4 is the fastest road to go from Germany/Denmark to areas north of the Arctic Circle, including places in Norway such as Troms\u00f8 or the North Cape.\nThe route passes through or nearby the cities\nTornio,\nHaparanda,\nLule\u00e5,\nPite\u00e5,\nSkellefte\u00e5,\nUme\u00e5,\n\u00d6rnsk\u00f6ldsvik,\nH\u00e4rn\u00f6sand,\nSundsvall,\nHudiksvall,\nS\u00f6derhamn,\nG\u00e4vle,\nUppsala,\nStockholm,\nS\u00f6dert\u00e4lje,\nNyk\u00f6ping,\nNorrk\u00f6ping,\nLink\u00f6ping,\nJ\u00f6nk\u00f6ping,\nV\u00e4rnamo,\nLjungby,\nand Helsingborg.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9424", "revid": "46091747", "url": "https://en.wikipedia.org/wiki?curid=9424", "title": "Ericsson", "text": "Swedish multinational networking and telecommunications company\n (lit.\u2009'Telephone Stock Company of LM Ericsson'), commonly known as Ericsson, is a Swedish multinational networking and telecommunications company headquartered in Stockholm. The company sells infrastructure, software, and services in information and communications technology for telecommunications service providers and enterprises, including, among others, 3G, 4G, and 5G equipment, and Internet Protocol (IP) and optical transport systems. The company employs around 100,000 people and operates in more than 180 countries. Ericsson has over 57,000 granted patents.\nEricsson has been a major contributor to the development of the telecommunications industry and is one of the leaders in 5G.\nThe company was founded in 1876 by Lars Magnus Ericsson and is jointly controlled by the Wallenberg family through its holding company Investor AB, and the universal bank Handelsbanken through its investment company Industriv\u00e4rden. The Wallenbergs and the Handelsbanken sphere acquired their voting-strong A-shares, and thus the control of Ericsson, after the fall of the Kreuger empire in the early 1930s.\nEricsson is the inventor of Bluetooth technology.\nHistory.\nFoundation.\nLars Magnus Ericsson began his association with telephones in his youth as an instrument maker. He worked for a firm that made telegraph equipment for the Swedish government agency Telegrafverket. In 1876, at the age of 30, he started a telegraph repair shop with help from his friend Carl Johan Andersson in central Stockholm and repaired foreign-made telephones. In 1878, Ericsson began making and selling his telephone equipment. His telephones were not technically innovative. In 1878, he agreed to supply telephones and switchboards to Sweden's first telecommunications operating company, Stockholms Allm\u00e4nna Telefonaktiebolag.\nInternational expansion.\nAs production grew in the late 1890s, and the Swedish market seemed to be reaching saturation, Ericsson expanded into foreign markets through a number of agents. The UK (Ericsson Telephones Ltd.) and Russia were early markets, where factories were later established to improve the chances of gaining local contracts and augment the output of the Swedish factory. In the UK, the National Telephone Company was a major customer; by 1897 sold 28% of its output in the UK. The Nordic countries were also Ericsson customers; they were encouraged by the growth of telephone services in Sweden.\nOther countries and colonies were exposed to Ericsson products through the influence of their parent countries. These included Australia and New Zealand, which by the late 1890s were Ericsson's largest non-European markets. Mass production techniques were now firmly established; telephones were losing some of their ornate finish and decoration.\nDespite their successes elsewhere, Ericsson did not make significant sales in the United States. The Bell Group, Kellogg and Automatic Electric dominated the market. Ericsson eventually sold its U.S. assets. Sales in Mexico led to inroads into South American countries. South Africa and China were also generating significant sales. With his company now multinational, Lars Ericsson stepped down from the company in 1901.\nAutomatic equipment.\nEricsson ignored the growth of automatic telephony in the United States and concentrated on manual exchange designs. Their first dial telephone was produced in 1921, although sales of the early automatic switching systems were slow until the equipment had proven itself on the world's markets. Telephones of this period had a simpler design and finish, and many of the early automatic desk telephones in Ericsson's catalogues were magneto styles with a dial on the front and appropriate changes to the electronics. Elaborate decals decorated the cases. World War I, the subsequent Great Depression and the loss of its Russian assets after the Revolution slowed the company's development while sales to other countries fell by about half.\nShareholding changes.\nThe acquisition of other telecommunications companies put pressure on Ericsson's finances; in 1925, Karl Fredric Wincrantz took control of the company by acquiring most of the shares. Wincrantz was partly funded by Ivar Kreuger, an international financier. The company was renamed \"Telefonaktiebolaget L M Ericsson\". Kreuger started showing interest in the company, being a major owner of Wincrantz holding companies.\nWallenberg era begins.\nEricsson was saved from bankruptcy and closure with the help of banks including Stockholms Enskilda Bank (now Skandinaviska Enskilda Banken) and other Swedish investment banks controlled by the Wallenberg family, and some Swedish government backing. Marcus Wallenberg Jr. negotiated a deal with several Swedish banks to rebuild Ericsson financially. The banks gradually increased their possession of LM Ericsson \"A\" shares, while ITT was still the largest shareholder. In 1960, the Wallenberg family bought ITT's shares in Ericsson, and has since controlled the company.\nMarket development.\nIn the 1920s and 1930s, the world telephone markets were being organized and stabilized by many governments. The fragmented town-by-town systems serviced by small, private companies that had evolved were integrated and offered for lease to a single company. Ericsson obtained some leases, which represented further sales of equipment to the growing networks. Ericsson got almost one-third of its sales under the control of its telephone operating companies.\nFurther development.\nEricsson introduced the world's first fully automatic mobile telephone system, MTA, in 1956. It released one of the world's first hands-free speaker telephones in the 1960s. In 1954, it released the Ericofon. Ericsson crossbar switching equipment was used in telephone administrations in many countries. In 1983 the company introduced the ERIPAX suite of network products and services.\nEmergence of the Internet (1995\u20132003).\nIn the 1990s, during the emergence of the Internet, Ericsson was regarded as slow to realize its potential and falling behind in the area of IP technology. But the company had established an Internet project in 1995 called Infocom Systems to exploit opportunities leading from fixed-line telecom and IT. CEO Lars Ramqvist wrote in the 1996 annual report that in all three of its business areas \u2013 Mobile Telephones and Terminals, Mobile Systems, and Infocom Systems \u2013 \"we will expand our operations as they relate to customer service and Internet Protocol (IP) access (Internet and intranet access)\".\nThe growth of GSM, which became a \"de facto\" world standard, combined with Ericsson's other mobile standards, such as D-AMPS and PDC, meant that by the start of 1997, Ericsson had an estimated 40% share of the world's mobile market, with around 54 million subscribers. There were also around 188\u00a0million AXE lines in place or on order in 117 countries. Telecom and chip companies worked in the 1990s to provide Internet access over mobile telephones. Early versions such as Wireless Application Protocol (WAP) used packet data over the existing GSM network, in a form known as GPRS (General Packet Radio Service), but these services, known as 2.5G, were fairly rudimentary and did not achieve much mass-market success.\nThe International Telecommunication Union (ITU) had prepared the specifications for a 3G mobile service that included several technologies. Ericsson pushed hard for the WCDMA (wideband CDMA) form based on the GSM standard and began testing it in 1996. Japanese operator NTT Docomo signed deals to partner with Ericsson and Nokia, who came together in 1997 to support WCDMA over rival standards. DoCoMo was the first operator with a live 3G network, using its own version of WCDMA called FOMA. Ericsson was a significant developer of the WCDMA version of GSM, while US-based chip developer Qualcomm promoted the alternative system CDMA2000, building on the popularity of CDMA in the US market. This resulted in a patent infringement lawsuit that was resolved in March 1999 when the two companies agreed to pay each other royalties for the use of their respective technologies and Ericsson purchased Qualcomm's wireless infrastructure business and some R&amp;D resources.\nEricsson issued a profit warning in March 2001. Over the coming year, sales to operators halved. Mobile telephones became a burden; the company's telephones unit made a loss of SEK 24 billion in 2000. A fire in a Philips chip factory in New Mexico in March 2000 caused severe disruption to Ericsson's phone production, dealing a \"coup de gr\u00e2ce\" to Ericsson's mobile phone hopes. Mobile phones would be spun off into a joint venture with Sony, Sony Ericsson Mobile Communications, in October 2001.\nEricsson launched several rounds of restructuring, refinancing and job-cutting; during 2001, staff numbers fell from 107,000 to 85,000. A further 20,000 went the next year, and 11,000 more in 2003. A new rights issue raised SEK 30\u00a0billion to keep the company afloat. The company had survived as mobile Internet started growing. With record profits, it was in better shape than many of its competitors.\nRebuilding and growing (2003\u20132018).\nThe emergence of full mobile Internet began a period of growth for the global telecom industry, including Ericsson. After the launch of 3G services in 2003, people started to access the Internet using their telephones.\nEricsson was working on ways to improve WCDMA as operators were buying and rolling it out; it was the first generation of 3G access. New advances included IMS (IP Multimedia Subsystem) and the next evolution of WCDMA, called High-Speed Packet Access (HSPA). It was initially deployed in the download version called HSDPA; the technology spread from the first test calls in the US in late 2005 to 59 commercial networks in September 2006. HSPA would provide the world's first mobile broadband.\nIn July 2016, Hans Vestberg stepped down as Ericsson's CEO after heading the company for six years. Jan Frykhammar, who has been working for the company since 1991 will be stepping in as interim CEO as Ericsson searches for a full-time replacement. On 16 January 2017, following Ericsson's announcement on 26 October 2016, new CEO B\u00f6rje Ekholm started and interim CEO Jan Frykhammar stepped down the following day.\nIn June 2018, Ericsson, Inc. and Ericsson AB have agreed to pay $145,893 to settle potential civil liability for an apparent violation of the International Emergency Economic Powers Act (IEEPA) and the Sudanese Sanctions Regulations, 31 C.F.R. part 538 (SSR).1\nAcquisitions and cooperation.\nAround 2000, companies and governments began to push for standards for mobile Internet. In May 2000, the European Commission created the Wireless Strategic Initiative, a consortium of four telecommunications suppliers in Europe \u2013 Ericsson, Nokia, Alcatel (France) and Siemens (Germany) \u2013 to develop and test new prototypes for advanced wireless communications systems. Later that year, the consortium partners invited other companies to join them in a Wireless World Research Forum in 2001. In December 1999, Microsoft\nand Ericsson announced a strategic partnership to combine the former's web browser and server software with the latter's mobile-internet technologies. In 2000, the Dot-com bubble burst with marked economic implications for Sweden. Ericsson, the world's largest producer of mobile telecommunications equipment, shed thousands of jobs, as did the country's Internet consulting firms and dot-com start-ups. In the same year, Intel, the world's largest semiconductor chip manufacturer, signed a $1.5\u00a0billion deal to supply flash memory to Ericsson over the next three years.\nThe short-lived joint venture called Ericsson Microsoft Mobile Venture, owned 70/30 percent by Ericsson and Microsoft, respectively, ended in October 2001 when Ericsson announced it would absorb the former joint venture and adopt a licensing agreement with Microsoft instead. The same month, Ericsson announced the launch of Sony Ericsson, a joint venture mobile telephone business, together with Sony. Sony Ericsson remained in operation until February 2012, when Sony bought out Ericsson's share; Ericsson said it wanted to focus on the global wireless market as a whole.\nLower stock prices and job losses affected many telecommunications companies in 2001. The major equipment manufacturers \u2013 Motorola (U.S.), Lucent Technologies (U.S.), Cisco Systems (U.S.), Marconi (UK), Siemens (Germany), Nokia (Finland), as well as Ericsson \u2013 all announced job cuts in their home countries and subsidiaries around the world. Ericsson's workforce worldwide fell during 2001 from 107,000 to 85,000.\nIn September 2001, Ericsson purchased the remaining shares in EHPT from Hewlett-Packard. Founded in 1993, Ericsson Hewlett Packard Telecom (EHPT) was a joint venture made up of 60% Ericsson interests and 40% Hewlett-Packard interests.\nIn 2002, ICT investor losses topped $2\u00a0trillion and share prices fell by 95% until August that year. More than half a million people lost their jobs in the global telecom industry over the two years. The collapse of U.S. carrier WorldCom, with more than $107\u00a0billion in assets, was the biggest in U.S. history. The sector's problems caused bankruptcies and job losses, and led to changes in the leadership of several major companies. Ericsson made 20,000 more staff redundant and raised about $3\u00a0billion from its shareholders. In June 2002, Infineon Technologies (then the sixth-largest semiconductor supplier and a subsidiary of Siemens) bought Ericsson's microelectronics unit for $400\u00a0million.\nEricsson was an official backer in the 2005 launch of the .mobi top-level domain created specifically for the mobile internet.\nCo-operation with Hewlett-Packard did not end with EHPT; in 2003 Ericsson outsourced its IT to HP, which included Managed Services, Help Desk Support, Data Center Operations, and HP Utility Data Center. The contract was extended in 2008. In October 2005, Ericsson acquired the bulk of the troubled UK telecommunications manufacturer Marconi Company, including its brand name that dates back to the creation of the original Marconi Company by the \"father of radio\" Guglielmo Marconi. In September 2006, Ericsson sold the greater part of its defense business Ericsson Microwave Systems, which mainly produced sensor and radar systems, to Saab AB, which renamed the company to Saab Microwave Systems.\nIn 2007, Ericsson acquired carrier edge-router maker Redback Networks, and then Entrisphere, a US-based company providing fiber-access technology. In September 2007, Ericsson acquired an 84% interest in German customer-care and billing software firm LHS, a stake later raised to 100%. In 2008, Ericsson sold its enterprise PBX division to Aastra Technologies, and acquired Tandberg Television, the television technology division of Norwegian company Tandberg. ==\nIn 2009, Ericsson bought the CDMA2000 and LTE business of Nortel's carrier networks division for US$1.18\u00a0billion; Bizitek, a Turkish business support systems integrator; the Estonian manufacturing operations of electronic manufacturing company Elcoteq; and completed its acquisition of LHS. Acquisitions in 2010 included assets from the Strategy and Technology Group of inCode, a North American business and consulting-services company; Nortel's majority shareholding (50% plus one share) in LG-Nortel, a joint venture between LG Electronics and Nortel Networks providing sales, R&amp;D and industrial capacity in South Korea, now known as Ericsson-LG; further Nortel carrier-division assets, relating from Nortel's GSM business in the United States and Canada; Optimi Corporation, a U.S.\u2013Spanish telecommunications vendor specializing in network optimization and management; and Pride, a consulting and systems-integration company operating in Italy.\nIn 2011, Ericsson acquired manufacturing and research facilities, and staff from the Guangdong Nortel Telecommunication Equipment Company (GDNT) as well as Nortel's Multiservice Switch business. Ericsson acquired U.S. company Telcordia Technologies in January 2012, an operations and business support systems (OSS/BSS) company. In March, Ericsson announced it was buying the broadcast-services division of Technicolor, a media broadcast technology company. In April 2012 Ericsson completed the acquisition of BelAir Networks a strong Wi-Fi network technology company.\nOn 3 May 2013, Ericsson announced it would divest its power cable operations to Danish company NKT Holding. On 1 July 2013, Ericsson announced it would acquire the media management company Red Bee Media, subject to regulatory approval. The acquisition was completed on 9 May 2014. In September 2013, Ericsson completed its acquisition of Microsoft's Mediaroom business and televisions services, originally announced in April the same year. The acquisition makes Ericsson the largest provider of IPTV and multi-screen services in the world, by market share; it was renamed Ericsson Mediaroom. In September 2014, Ericsson acquired majority stake in Apcera for cloud policy compliance. In October 2015, Ericsson completed the acquisition of Envivio, a software encoding company. In April 2016, Ericsson acquired Polish and Ukrainian operations of software development company Ericpol, a long-time supplier to Ericsson. Approximately 2,300 Ericpol employees joined Ericsson, bringing software development competence in radio, cloud, and IP.\nOn 20 June 2017, Bloomberg disclosed that Ericsson hired Morgan Stanley to explore the sale of its media businesses. The Red Bee Media business was kept in-house as an independent subsidiary company, as no suitable buyer was found, but a 51% stake of the remainder of the Media Solution division was sold to private equity firm One Equity Partners, the new company being named MediaKind. The transaction was completed on 31 January 2019. In February 2018, Ericsson acquired the location-based mobile data management platform Placecast. Ericsson has since integrated Placecast's platform and capabilities with its programmatic mobile ad subsidiary, Emodo. In May 2018, SoftBank partnered with Ericsson to trial new radio technology. In September 2020, Ericsson acquired US-based carrier equipment manufacturer Cradlepoint for $1.1 billion.\nIn November 2021, Ericsson announced it had reached an agreement to acquire Vonage for $6.2 billion. The acquisition completed in July 2022.\nCorporate governance.\nAs of 2016[ [update]], members of the board of directors of LM Ericsson were: Leif Johansson, Jacob Wallenberg, Kristin S. Rinne, Helena Stjernholm, Sukhinder Singh Cassidy, B\u00f6rje Ekholm, Ulf J. Johansson, Mikael L\u00e4nnqvist, Zlatko Hadzic, Kjell-\u00c5ke Soting, Nora Denzel, Kristin Skogen Lund, Pehr Claesson, Karin \u00c5berg and Roger Svensson.\nResearch and development.\nEricsson has structured its R&amp;D in three levels depending on when products or technologies will be introduced to customers and users. Its research and development organization is part of 'Group Function Technology' and addresses several facets of network architecture: wireless access networks; radio access technologies; broadband technologies; packet technologies; multimedia technologies; services software; EMF safety and sustainability; security; and global services. The head of research since 2012 is Sara Mazur.\nGroup Function Technology holds research co-operations with several major universities and research institutes including Lund University in Sweden, E\u00f6tv\u00f6s Lor\u00e1nd University in Hungary and Beijing Institute of Technology in China. Ericsson also holds research co-operations within several European research programs such as GigaWam and OASE. Ericsson holds 33,000 granted patents and is the number-one holder of GSM/GPRS/EDGE, WCDMA/HSPA, and LTE essential patents. In 2021, the WIPO's annual World Intellectual Property Indicators report ranked Ericsson's number of patent applications published under the PCT System as 6th in the world, with 1,989 patent applications being published during 2020. This position is up from their previous ranking as 7th in 2019 with 1,698 applications.\nEricsson hosts a developer program called Ericsson Developer Connection designed to encourage development of applications and services. Ericsson also has an open innovation initiative for beta applications and beta API's &amp; tools called Ericsson Labs. The company hosts several internal innovation competitions among its employees.\nIn May 2022, it was announced that Ericsson and Intel are pooling R&amp;D excellence to create high-performing Cloud RAN solutions. The organisations have pooled to launch a tech hub in California, USA. The hub focuses on the benefits that Ericsson Cloud RAN and Intel technology can bring to: improving energy efficiency and network performance, reducing time to market, and monetizing new business opportunities such as enterprise applications.\nProducts and services.\nEricsson's business includes technology research, development, network systems and software development, and running operations for telecom service providers. and software Ericsson offers end-to-end services for all major mobile communication standards, and has three main business units.\nBusiness Area Networks.\nBusiness Area Networks, previously called Business Unit Networks, develop network infrastructure for communication needs over mobile and fixed connections. Its products include radio base stations, radio network controllers, mobile switching centers and service application nodes. Operators use Ericsson products to migrate from 2G to 3G and, most recently, to 4G networks.\nThe company's network division has been described as a driver in the development of 2G, 3G, 4G/LTE and 5G technology, and the evolution towards all-IP, and it develops and deploys advanced LTE systems, but it is still developing the older GSM, WCDMA, and CDMA technologies. The company's networks portfolio also includes microwave transport, Internet Protocol (IP) networks, fixed-access services for copper and fiber, and mobile broadband modules, several levels of fixed broadband access, radio access networks from small pico cells to high-capacity macro cells and controllers for radio base stations.\nNetwork services.\nEricsson's network rollout services employ in-house capabilities, subcontractors and central resources to make changes to live networks. Services such as technology deployment, network transformation, support services and network optimization are also provided.\nBusiness Area Digital Services.\nThis unit provides core networks, Operations Support Systems such as network management and analytics, and Business Support Systems such as billing and mediation. Within the Digital Services unit, there is an m-Commerce offering, which focuses on service providers and facilitates their working with financial institutions and intermediaries. Ericsson has announced m-commerce deals with Western Union and African wireless carrier MTN.\nBusiness Area Managed Services.\nThe unit is active in 180 countries; it supplies managed services, systems integration, consulting, network rollout, design and optimization, broadcast services, learning services and support.\nThe company also works with television and media, public safety, and utilities. Ericsson claims to manage networks that serve more than 1\u00a0billion subscribers worldwide, and to support customer networks that serve more than 2.5\u00a0billion subscribers.\nBroadcast services.\nEricsson's Broadcast Services unit was evolved into a unit called Red Bee Media, which has been spun out into a joint venture. It deals with the playout of live and pre-recorded, commercial and public service television programmes, including presentation (continuity announcements), trailers, and ancillary access services such as closed-caption subtitles, audio description and in-vision sign language interpreters. Its media management services consist of Managed Media Preparation and Managed Media Internet Delivery.\nDivested businesses.\nSony Ericsson Mobile Communications AB (Sony Ericsson) was a joint venture with Sony that merged the previous mobile telephone operations of both companies. It manufactured mobile telephones, accessories and personal computer (PC) cards. Sony Ericsson was responsible for product design and development, marketing, sales, distribution and customer services. On 16 February 2012, Sony announced it had completed the full acquisition of Sony Ericsson, after which it changed name to Sony Mobile Communications, and nearly a year later it moved headquarters from Sweden to Japan.\nMobile phones.\nAs a joint venture with Sony, Ericsson's mobile telephone production was moved into the company Sony Ericsson in 2001. The following is a list of mobile phones marketed under the brand name Ericsson.\nEricsson Mobile Platforms.\nEricsson Mobile Platforms existed for eight years; on 12 February 2009, Ericsson announced it would be merged with the mobile platform company of STMicroelectronics, ST-NXP Wireless, to create a 50/50 joint venture owned by Ericsson and STMicroelectronics.\nThis joint venture was divested in 2013 and remaining activities can be found in Ericsson Modems and STMicroelectronics. Ericsson Mobile Platform ceased being a legal entity early 2009.\nEricsson Enterprise.\nStarting in 1983 Ericsson Enterprise provided communications systems and services for businesses, public entities and educational institutions. It produced products for voice over Internet protocol (VoIP)-based private branch exchanges (PBX), wireless local area networks (WLAN), and mobile intranets.\nEricsson Enterprise operated mainly from Sweden but also operated through regional units and other partners/distributors. In 2008 it was sold to Aastra.\nCorruption.\nOn 7 December 2019, Ericsson agreed to pay more than $1.2 billion (\u20ac1.09 billion) to settle U.S. Department of Justice FCPA criminal and civil investigations into foreign corruption. US authorities accused the company of conducting a campaign of corruption between 2000 and 2016 across China, Indonesia, Vietnam, Kuwait and Djibouti. Ericsson admitted to paying bribes, falsifying books and records and failing to implement reasonable internal accounting controls in an attempt to strengthen its position in the telecommunications industry.\nIn 2022, an internal investigation into corruption inside the company was leaked by the International Consortium of Investigative Journalists. It detailed corruption in at least 10 countries. Ericsson has admitted \"serious breaches of compliance rules\".\nThe leak also revealed that some subcontractors working on behalf of Ericsson paid bribes to the Islamic State in order to continue operating the telecom network in occupied regions of Iraq.\nSee also.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9425", "revid": "1154852918", "url": "https://en.wikipedia.org/wiki?curid=9425", "title": "Ethology", "text": "Scientific objective study of animal behaviour\nEthology is a branch of zoology that studies animal behavior, usually with a scientific focus on behaviour under natural conditions, and viewing behaviour as an evolutionarily adaptive trait. Behaviourism as a term also describes the scientific and objective study of animal behavior, usually referring to measured responses to stimuli or to trained behavioral responses in a laboratory context, without a particular emphasis on evolutionary adaptivity. Throughout history, different naturalists have studied aspects of animal behaviour. Ethology has its scientific roots in the work of Charles Darwin and of American and German ornithologists of the late 19th and early 20th century, including Charles O. Whitman, Oskar Heinroth, and Wallace Craig. The modern discipline of ethology is generally considered to have begun during the 1930s with the work of Dutch biologist Nikolaas Tinbergen and Austrian biologists Konrad Lorenz and Karl von Frisch, the three recipients of the 1973 Nobel Prize in Physiology or Medicine. Ethology combines laboratory and field science, with a strong relation to some other disciplines such as neuroanatomy, ecology, and evolutionary biology. Ethologists typically show interest in a behavioral process rather than in a particular animal group, and often study one type of behavior, such as aggression, in a number of unrelated species.\nEthology is a rapidly growing field. Since the dawn of the 21st century researchers have re-examined and reached new conclusions in many aspects of animal communication, emotions, culture, learning and sexuality that the scientific community long thought it understood. New fields, such as neuroethology, have developed.\nUnderstanding ethology or animal behavior can be important in animal training. Considering the natural behaviors of different species or breeds enables trainers to select the individuals best suited to perform the required task. It also enables trainers to encourage the performance of naturally occurring behaviors and the discontinuance of undesirable behaviors.\nEtymology.\nThe term \"ethology\" derives from the Greek language: \u1f26\u03b8\u03bf\u03c2, \"ethos\" meaning \"character\" and , \"-logia\" meaning \"the study of\". The term was first popularized by American myrmecologist (a person who studies ants) William Morton Wheeler in 1902.\nHistory.\nThe beginnings of ethology.\nBecause ethology is considered a topic of biology, ethologists have been concerned particularly with the evolution of behaviour and its understanding in terms of natural selection. In one sense, the first modern ethologist was Charles Darwin, whose 1872 book \"The Expression of the Emotions in Man and Animals\" influenced many ethologists. He pursued his interest in behaviour by encouraging his prot\u00e9g\u00e9 George Romanes, who investigated animal learning and intelligence using an anthropomorphic method, anecdotal cognitivism, that did not gain scientific support.\nOther early ethologists, such as Eug\u00e8ne Marais, Charles O. Whitman, Oskar Heinroth, Wallace Craig and Julian Huxley, instead concentrated on behaviours that can be called instinctive, or natural, in that they occur in all members of a species under specified circumstances. Their beginning for studying the behaviour of a new species was to construct an ethogram (a description of the main types of behaviour with their frequencies of occurrence). This provided an objective, cumulative database of behaviour, which subsequent researchers could check and supplement.\nGrowth of the field.\nDue to the work of Konrad Lorenz and Niko Tinbergen, ethology developed strongly in continental Europe during the years prior to World War II. After the war, Tinbergen moved to the University of Oxford, and ethology became stronger in the UK, with the additional influence of William Thorpe, Robert Hinde, and Patrick Bateson at the Sub-department of Animal Behaviour of the University of Cambridge. In this period, too, ethology began to develop strongly in North America.\nLorenz, Tinbergen, and von Frisch were jointly awarded the Nobel Prize in Physiology or Medicine in 1973 for their work of developing ethology.\nEthology is now a well-recognized scientific discipline, and has a number of journals covering developments in the subject, such as \"Animal Behaviour\", \"Animal Welfare\", \"Applied Animal Behaviour Science\", \"Animal Cognition\", \"Behaviour\", \"Behavioral Ecology\" and \"Ethology: International Journal of Behavioural Biology\". In 1972, the International Society for Human Ethology was founded to promote exchange of knowledge and opinions concerning human behaviour gained by applying ethological principles and methods and published their journal, \"The Human Ethology Bulletin\". In 2008, in a paper published in the journal \"Behaviour\", ethologist Peter Verbeek introduced the term \"Peace Ethology\" as a sub-discipline of Human Ethology that is concerned with issues of human conflict, conflict resolution, reconciliation, war, peacemaking, and peacekeeping behaviour.\nSocial ethology and recent developments.\nIn 1972, the English ethologist John H. Crook distinguished comparative ethology from social ethology, and argued that much of the ethology that had existed so far was really comparative ethology\u2014examining animals as individuals\u2014whereas, in the future, ethologists would need to concentrate on the behaviour of social groups of animals and the social structure within them.\nE. O. Wilson's book \"\" appeared in 1975, and since that time, the study of behaviour has been much more concerned with social aspects. It has also been driven by the stronger, but more sophisticated, Darwinism associated with Wilson, Robert Trivers, and W. D. Hamilton. The related development of behavioural ecology has also helped transform ethology. Furthermore, a substantial rapprochement with comparative psychology has occurred, so the modern scientific study of behaviour offers a more or less seamless spectrum of approaches: from animal cognition to more traditional comparative psychology, ethology, sociobiology, and behavioural ecology. In 2020, Tobias Starzak and Albert Newen from the Institute of Philosophy II at the Ruhr University Bochum postulated that animals may have beliefs.\nRelationship with comparative psychology.\nComparative psychology also studies animal behavior, but, as opposed to ethology, is construed as a sub-topic of psychology rather than as one of biology. Historically, where comparative psychology has included research on animal behavior in the context of what is known about human psychology, ethology involves research on animal behavior in the context of what is known about animal anatomy, physiology, neurobiology, and phylogenetic history. Furthermore, early comparative psychologists concentrated on the study of learning and tended to research behavior in artificial situations, whereas early ethologists concentrated on behavior in natural situations, tending to describe it as instinctive.\nThe two approaches are complementary rather than competitive, but they do result in different perspectives, and occasionally conflicts of opinion about matters of substance. In addition, for most of the twentieth century, comparative psychology developed most strongly in North America, while ethology was stronger in Europe. From a practical standpoint, early comparative psychologists concentrated on gaining extensive knowledge of the behavior of very few species. Ethologists were more interested in understanding behavior across a wide range of species to facilitate principled comparisons across taxonomic groups. Ethologists have made much more use of such cross-species comparisons than comparative psychologists have.\nInstinct.\n\"Webster's Dictionary\" defines instinct as \"A largely inheritable and unalterable tendency of an organism to make a complex and specific response to environmental stimuli without involving reason\".\nFixed action patterns.\nAn important development, associated with the name of Konrad Lorenz though probably due more to his teacher, Oskar Heinroth, was the identification of fixed action patterns. Lorenz popularized these as instinctive responses that would occur reliably in the presence of identifiable stimuli called sign stimuli or \"releasing stimuli\". Fixed action patterns are now considered to be instinctive behavioural sequences that are relatively invariant within the species and that almost inevitably run to completion.\nOne example of a releaser is the beak movements of many bird species performed by newly hatched chicks, which stimulates the mother to regurgitate food for her offspring. Other examples are the classic studies by Tinbergen on the egg-retrieval behaviour and the effects of a \"supernormal stimulus\" on the behaviour of graylag geese.\nOne investigation of this kind was the study of the waggle dance (\"dance language\") in bee communication by Karl von Frisch.\nLearning.\nHabituation.\nHabituation is a simple form of learning and occurs in many animal taxa. It is the process whereby an animal ceases responding to a stimulus. Often, the response is an innate behavior. Essentially, the animal learns not to respond to irrelevant stimuli. For example, prairie dogs (\"Cynomys ludovicianus\") give alarm calls when predators approach, causing all individuals in the group to quickly scramble down burrows. When prairie dog towns are located near trails used by humans, giving alarm calls every time a person walks by is expensive in terms of time and energy. Habituation to humans is therefore an important adaptation in this context.\nAssociative learning.\nAssociative learning in animal behavior is any learning process in which a new response becomes associated with a particular stimulus. The first studies of associative learning were made by Russian physiologist Ivan Pavlov, who observed that dogs trained to associate food with the ringing of a bell would salivate on hearing the bell.\nImprinting.\nImprinting enables the young to discriminate the members of their own species, vital for reproductive success. This important type of learning only takes place in a very limited period of time. Konrad Lorenz observed that the young of birds such as geese and chickens followed their mothers spontaneously from almost the first day after they were hatched, and he discovered that this response could be imitated by an arbitrary stimulus if the eggs were incubated artificially and the stimulus were presented during a critical period that continued for a few days after hatching.\nCultural learning.\nImitation.\nImitation is an advanced behavior whereby an animal observes and exactly replicates the behavior of another.\nThe National Institutes of Health reported that capuchin monkeys preferred the company of researchers who imitated them to that of researchers who did not. The monkeys not only spent more time with their imitators but also preferred to engage in a simple task with them even when provided with the option of performing the same task with a non-imitator. Imitation has been observed in recent research on chimpanzees; not only did these chimps copy the actions of another individual, when given a choice, the chimps preferred to imitate the actions of the higher-ranking elder chimpanzee as opposed to the lower-ranking young chimpanzee.\nStimulus and local enhancement.\nThere are various ways animals can learn using observational learning but without the process of imitation. One of these is \"stimulus enhancement\" in which individuals become interested in an object as the result of observing others interacting with the object. Increased interest in an object can result in object manipulation which allows for new object-related behaviours by trial-and-error learning. Haggerty (1909) devised an experiment in which a monkey climbed up the side of a cage, placed its arm into a wooden chute, and pulled a rope in the chute to release food. Another monkey was provided an opportunity to obtain the food after watching a monkey go through this process on four occasions. The monkey performed a different method and finally succeeded after trial-and-error. Another example familiar to some cat and dog owners is the ability of their animals to open doors. The action of humans operating the handle to open the door results in the animals becoming interested in the handle and then by trial-and-error, they learn to operate the handle and open the door.\nIn local enhancement, a demonstrator attracts an observer's attention to a particular location. Local enhancement has been observed to transmit foraging information among birds, rats and pigs. The stingless bee (\"Trigona corvina\") uses local enhancement to locate other members of their colony and food resources.\nSocial transmission.\nA well-documented example of social transmission of a behaviour occurred in a group of macaques on Hachijojima Island, Japan. The macaques lived in the inland forest until the 1960s, when a group of researchers started giving them potatoes on the beach: soon, they started venturing onto the beach, picking the potatoes from the sand, and cleaning and eating them. About one year later, an individual was observed bringing a potato to the sea, putting it into the water with one hand, and cleaning it with the other. This behaviour was soon expressed by the individuals living in contact with her; when they gave birth, this behaviour was also expressed by their young - a form of social transmission.\nTeaching.\nTeaching is a highly specialized aspect of learning in which the \"teacher\" (demonstrator) adjusts their behaviour to increase the probability of the \"pupil\" (observer) achieving the desired end-result of the behaviour. For example, orcas are known to intentionally beach themselves to catch pinniped prey. Mother orcas teach their young to catch pinnipeds by pushing them onto the shore and encouraging them to attack the prey. Because the mother orca is altering her behaviour to help her offspring learn to catch prey, this is evidence of teaching. Teaching is not limited to mammals. Many insects, for example, have been observed demonstrating various forms of teaching to obtain food. Ants, for example, will guide each other to food sources through a process called \"tandem running,\" in which an ant will guide a companion ant to a source of food. It has been suggested that the pupil ant is able to learn this route to obtain food in the future or teach the route to other ants. This behaviour of teaching is also exemplified by crows, specifically New Caledonian crows. The adults (whether individual or in families) teach their young adolescent offspring how to construct and utilize tools. For example, \"Pandanus\" branches are used to extract insects and other larvae from holes within trees.\nMating and the fight for supremacy.\nIndividual reproduction is the most important phase in the proliferation of individuals or genes within a species: for this reason, there exist complex mating rituals, which can be very complex even if they are often regarded as fixed action patterns. The stickleback's complex mating ritual, studied by Tinbergen, is regarded as a notable example.\nOften in social life, animals fight for the right to reproduce, as well as social supremacy. A common example of fighting for social and sexual supremacy is the so-called pecking order among poultry. Every time a group of poultry cohabitate for a certain time length, they establish a pecking order. In these groups, one chicken dominates the others and can peck without being pecked. A second chicken can peck all the others except the first, and so on. Chickens higher in the pecking order may at times be distinguished by their healthier appearance when compared to lower level chickens. While the pecking order is establishing, frequent and violent fights can happen, but once established, it is broken only when other individuals enter the group, in which case the pecking order re-establishes from scratch.\nLiving in groups.\nSeveral animal species, including humans, tend to live in groups. Group size is a major aspect of their social environment. Social life is probably a complex and effective survival strategy. It may be regarded as a sort of symbiosis among individuals of the same species: a society is composed of a group of individuals belonging to the same species living within well-defined rules on food management, role assignments and reciprocal dependence.\nWhen biologists interested in evolution theory first started examining social behaviour, some apparently unanswerable questions arose, such as how the birth of sterile castes, like in bees, could be explained through an evolving mechanism that emphasizes the reproductive success of as many individuals as possible, or why, amongst animals living in small groups like squirrels, an individual would risk its own life to save the rest of the group. These behaviours may be examples of altruism. Of course, not all behaviours are altruistic, as indicated by the table below. For example, revengeful behaviour was at one point claimed to have been observed exclusively in \"Homo sapiens\". However, other species have been reported to be vengeful including chimpanzees, as well as anecdotal reports of vengeful camels.\nAltruistic behaviour has been explained by the gene-centred view of evolution.\nBenefits and costs of group living.\nOne advantage of group living can be decreased predation. If the number of predator attacks stays the same despite increasing prey group size, each prey may have a reduced risk of predator attacks through the dilution effect. Further, according to the selfish herd theory, the fitness benefits associated with group living vary depending on the location of an individual within the group. The theory suggests that conspecifics positioned at the centre of a group will reduce the likelihood predations while those at the periphery will become more vulnerable to attack. Additionally, a predator that is confused by a mass of individuals can find it more difficult to single out one target. For this reason, the zebra's stripes offer not only camouflage in a habitat of tall grasses, but also the advantage of blending into a herd of other zebras. In groups, prey can also actively reduce their predation risk through more effective defence tactics, or through earlier detection of predators through increased vigilance.\nAnother advantage of group living can be an increased ability to forage for food. Group members may exchange information about food sources between one another, facilitating the process of resource location. Honeybees are a notable example of this, using the waggle dance to communicate the location of flowers to the rest of their hive. Predators also receive benefits from hunting in groups, through using better strategies and being able to take down larger prey.\nSome disadvantages accompany living in groups. Living in close proximity to other animals can facilitate the transmission of parasites and disease, and groups that are too large may also experience greater competition for resources and mates.\nGroup size.\nTheoretically, social animals should have optimal group sizes that maximize the benefits and minimize the costs of group living. However, in nature, most groups are stable at slightly larger than optimal sizes. Because it generally benefits an individual to join an optimally-sized group, despite slightly decreasing the advantage for all members, groups may continue to increase in size until it is more advantageous to remain alone than to join an overly full group.\nTinbergen's four questions for ethologists.\nNiko Tinbergen argued that ethology always needed to include four kinds of explanation in any instance of behaviour:\nThese explanations are complementary rather than mutually exclusive\u2014all instances of behaviour require an explanation at each of these four levels. For example, the function of eating is to acquire nutrients (which ultimately aids survival and reproduction), but the immediate cause of eating is hunger (causation). Hunger and eating are evolutionarily ancient and are found in many species (evolutionary history), and develop early within an organism's lifespan (development). It is easy to confuse such questions\u2014for example, to argue that people eat because they're hungry and not to acquire nutrients\u2014without realizing that the reason people experience hunger is because it causes them to acquire nutrients.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9426", "revid": "41438237", "url": "https://en.wikipedia.org/wiki?curid=9426", "title": "Electromagnetic radiation", "text": "Waves of the electromagnetic field\nIn physics, electromagnetic radiation (EMR) consists of waves of the electromagnetic (EM) field, which propagate through space and carry momentum and electromagnetic radiant energy. Types of EMR include radio waves, microwaves, infrared, (visible) light, ultraviolet, X-rays, and gamma rays, all of which are part of the electromagnetic spectrum.\nClassically, electromagnetic radiation consists of electromagnetic waves, which are synchronized oscillations of electric and magnetic fields. Depending on the frequency of oscillation, different wavelengths of electromagnetic spectrum are produced. In a vacuum, electromagnetic waves travel at the speed of light, commonly denoted \"c\". In homogeneous, isotropic media, the oscillations of the two fields are perpendicular to each other and perpendicular to the direction of energy and wave propagation, forming a transverse wave. The position of an electromagnetic wave within the electromagnetic spectrum can be characterized by either its frequency of oscillation or its wavelength. Electromagnetic waves of different frequency are called by different names since they have different sources and effects on matter. In order of increasing frequency and decreasing wavelength these are: radio waves, microwaves, infrared radiation, visible light, ultraviolet radiation, X-rays and gamma rays.\nElectromagnetic waves are emitted by electrically charged particles undergoing acceleration, and these waves can subsequently interact with other charged particles, exerting force on them. EM waves carry energy, momentum and angular momentum away from their source particle and can impart those quantities to matter with which they interact. Electromagnetic radiation is associated with those EM waves that are free to propagate themselves (\"radiate\") without the continuing influence of the moving charges that produced them, because they have achieved sufficient distance from those charges. Thus, EMR is sometimes referred to as the far field. In this language, the near field refers to EM fields near the charges and current that directly produced them, specifically electromagnetic induction and electrostatic induction phenomena.\nIn quantum mechanics, an alternate way of viewing EMR is that it consists of photons, uncharged elementary particles with zero rest mass which are the quanta of the electromagnetic field, responsible for all electromagnetic interactions. Quantum electrodynamics is the theory of how EMR interacts with matter on an atomic level. Quantum effects provide additional sources of EMR, such as the transition of electrons to lower energy levels in an atom and black-body radiation. The energy of an individual photon is quantized and is greater for photons of higher frequency. This relationship is given by Planck's equation \"E\" = \"hf\", where \"E\" is the energy per photon, \"f\" is the frequency of the photon, and \"h\" is Planck's constant. A single gamma ray photon, for example, might carry ~100,000 times the energy of a single photon of visible light.\nThe effects of EMR upon chemical compounds and biological organisms depend both upon the radiation's power and its frequency. EMR of visible or lower frequencies (i.e., visible light, infrared, microwaves, and radio waves) is called \"non-ionizing radiation\", because its photons do not individually have enough energy to ionize atoms or molecules, or break chemical bonds. The effects of these radiations on chemical systems and living tissue are caused primarily by heating effects from the combined energy transfer of many photons. In contrast, high frequency ultraviolet, X-rays and gamma rays are called \"ionizing radiation\", since individual photons of such high frequency have enough energy to ionize molecules or break chemical bonds. These radiations have the ability to cause chemical reactions and damage living cells beyond that resulting from simple heating, and can be a health hazard.\nPhysics.\nTheory.\nMaxwell's equations.\nJames Clerk Maxwell derived a wave form of the electric and magnetic equations, thus uncovering the wave-like nature of electric and magnetic fields and their symmetry. Because the speed of EM waves predicted by the wave equation coincided with the measured speed of light, Maxwell concluded that light itself is an EM wave. Maxwell's equations were confirmed by Heinrich Hertz through experiments with radio waves.\nNear and far fields.\nMaxwell's equations established that some charges and currents (\"sources\") produce a local type of electromagnetic field near them that does not radiate. Currents directly produce a magnetic field, but it is of a magnetic dipole type that dies out with distance from the current. In a similar manner, moving charges pushed apart in a conductor by a changing electrical potential (such as in an antenna) produce an electric dipole type electrical field, but this also declines with distance. These fields make up the near-field near the EMR source. Neither of these behaviours are responsible for EM radiation. Instead, they cause electromagnetic field behaviour that only efficiently transfers power to a receiver very close to the source, such as the magnetic induction inside a transformer. Typically, near-fields have a powerful effect on their own sources, causing an increased \"load\" (decreased electrical reactance) in the source or transmitter, whenever energy is withdrawn from the EM field by a receiver. Otherwise, these fields do not \"propagate\" freely out into space, carrying their energy away without distance-limit, but rather oscillate, returning their energy to the transmitter if it is not received by a receiver.\nBy contrast, the EM far-field is composed of \"radiation\" that is free of the transmitter in the sense that (unlike the case in an electrical transformer) the transmitter requires the same power to send these changes in the fields out, whether the signal is immediately picked up or not. This distant part of the electromagnetic field \"is\" \"electromagnetic radiation\" (also called the far-field). The far-fields propagate (radiate) without allowing the transmitter to affect them. This causes them to be independent in the sense that their existence and their energy, after they have left the transmitter, is completely independent of both transmitter and receiver. Due to conservation of energy, the amount of power passing through any spherical surface drawn around the source is the same. Because such a surface has an area proportional to the square of its distance from the source, the power density of EM radiation from an isotropic source decreases with the inverse square of the distance from the source; this is called the inverse-square law. This is in contrast to dipole parts of the EM field close to the source (the near-field), which vary in intensity according to an inverse cube power law, and thus do \"not\" transport a conserved amount of energy over distances, but instead fade with distance, with its energy (as noted) rapidly returning to the transmitter or absorbed by a nearby receiver (such as a transformer secondary coil).\nIn the Li\u00e9nard\u2013Wiechert potential formulation of the electric and magnetic fields due to motion of a single particle (according to Maxwell's equations), the terms associated with acceleration of the particle are those that are responsible for the part of the field that is regarded as electromagnetic radiation. By contrast, the term associated with the changing static electric field of the particle and the magnetic term that results from the particle's uniform velocity, are both associated with the electromagnetic near-field, and do not comprise EM radiation.\nProperties.\nElectric and magnetic fields obey the properties of superposition. Thus, a field due to any particular particle or time-varying electric or magnetic field contributes to the fields present in the same space due to other causes. Further, as they are vector fields, all magnetic and electric field vectors add together according to vector addition. For example, in optics two or more coherent light waves may interact and by constructive or destructive interference yield a resultant irradiance deviating from the sum of the component irradiances of the individual light waves.\nThe electromagnetic fields of light are not affected by traveling through static electric or magnetic fields in a linear medium such as a vacuum. However, in nonlinear media, such as some crystals, interactions can occur between light and static electric and magnetic fields\u2014these interactions include the Faraday effect and the Kerr effect.\nIn refraction, a wave crossing from one medium to another of different density alters its speed and direction upon entering the new medium. The ratio of the refractive indices of the media determines the degree of refraction, and is summarized by Snell's law. Light of composite wavelengths (natural sunlight) disperses into a visible spectrum passing through a prism, because of the wavelength-dependent refractive index of the prism material (dispersion); that is, each component wave within the composite light is bent a different amount.\nEM radiation exhibits both wave properties and particle properties at the same time (see wave-particle duality). Both wave and particle characteristics have been confirmed in many experiments. Wave characteristics are more apparent when EM radiation is measured over relatively large timescales and over large distances while particle characteristics are more evident when measuring small timescales and distances. For example, when electromagnetic radiation is absorbed by matter, particle-like properties will be more obvious when the average number of photons in the cube of the relevant wavelength is much smaller than 1. It is not so difficult to experimentally observe non-uniform deposition of energy when light is absorbed, however this alone is not evidence of \"particulate\" behavior. Rather, it reflects the quantum nature of \"matter\". Demonstrating that the light itself is quantized, not merely its interaction with matter, is a more subtle affair.\nSome experiments display both the wave and particle natures of electromagnetic waves, such as the self-interference of a single photon. When a single photon is sent through an interferometer, it passes through both paths, interfering with itself, as waves do, yet is detected by a photomultiplier or other sensitive detector only once.\nA quantum theory of the interaction between electromagnetic radiation and matter such as electrons is described by the theory of quantum electrodynamics.\nElectromagnetic waves can be polarized, reflected, refracted, diffracted or interfere with each other.\nWave model.\n In homogeneous, isotropic media, electromagnetic radiation is a transverse wave, meaning that its oscillations are perpendicular to the direction of energy transfer and travel. It comes from the following equations:formula_1These equations predicate that any electromagnetic wave must be a transverse wave, where the electric field E and the magnetic field B are both perpendicular to the direction of wave propagation.\nThe electric and magnetic parts of the field in an electromagnetic wave stand in a fixed ratio of strengths to satisfy the two Maxwell equations that specify how one is produced from the other. In dissipation-less (lossless) media, these E and B fields are also in phase, with both reaching maxima and minima at the same points in space (see illustrations). In the far-field EM radiation which is described by the two source-free Maxwell curl operator equations, a time-change in one type of field is proportional to the curl of the other. These derivatives require that the E and B fields in EMR are in-phase (see mathematics section below).\nAn important aspect of light's nature is its frequency. The frequency of a wave is its rate of oscillation and is measured in hertz, the SI unit of frequency, where one hertz is equal to one oscillation per second. Light usually has multiple frequencies that sum to form the resultant wave. Different frequencies undergo different angles of refraction, a phenomenon known as dispersion.\nA monochromatic wave (a wave of a single frequency) consists of successive troughs and crests, and the distance between two adjacent crests or troughs is called the wavelength. Waves of the electromagnetic spectrum vary in size, from very long radio waves longer than a continent to very short gamma rays smaller than atom nuclei. Frequency is inversely proportional to wavelength, according to the equation:\nformula_2\nwhere \"v\" is the speed of the wave (\"c\" in a vacuum or less in other media), \"f\" is the frequency and \u03bb is the wavelength. As waves cross boundaries between different media, their speeds change but their frequencies remain constant.\nElectromagnetic waves in free space must be solutions of Maxwell's electromagnetic wave equation. Two main classes of solutions are known, namely plane waves and spherical waves. The plane waves may be viewed as the limiting case of spherical waves at a very large (ideally infinite) distance from the source. Both types of waves can have a waveform which is an arbitrary time function (so long as it is sufficiently differentiable to conform to the wave equation). As with any time function, this can be decomposed by means of Fourier analysis into its frequency spectrum, or individual sinusoidal components, each of which contains a single frequency, amplitude and phase. Such a component wave is said to be \"monochromatic\". A monochromatic electromagnetic wave can be characterized by its frequency or wavelength, its peak amplitude, its phase relative to some reference phase, its direction of propagation, and its polarization.\nInterference is the superposition of two or more waves resulting in a new wave pattern. If the fields have components in the same direction, they constructively interfere, while opposite directions cause destructive interference. An example of interference caused by EMR is electromagnetic interference (EMI) or as it is more commonly known as, radio-frequency interference (RFI). Additionally, multiple polarization signals can be combined (i.e. interfered) to form new states of polarization, which is known as parallel polarization state generation.\nThe energy in electromagnetic waves is sometimes called radiant energy.\nParticle model and quantum theory.\nAn anomaly arose in the late 19th century involving a contradiction between the wave theory of light and measurements of the electromagnetic spectra that were being emitted by thermal radiators known as black bodies. Physicists struggled with this problem unsuccessfully for many years, and it later became known as the ultraviolet catastrophe. In 1900, Max Planck developed a new theory of black-body radiation that explained the observed spectrum. Planck's theory was based on the idea that black bodies emit light (and other electromagnetic radiation) only as discrete bundles or packets of energy. These packets were called quanta. In 1905, Albert Einstein proposed that light quanta be regarded as real particles. Later the particle of light was given the name photon, to correspond with other particles being described around this time, such as the electron and proton. A photon has an energy, \"E\", proportional to its frequency, \"f\", by\n formula_3\nwhere \"h\" is Planck's constant, formula_4 is the wavelength and \"c\" is the speed of light. This is sometimes known as the Planck\u2013Einstein equation. In quantum theory (see first quantization) the energy of the photons is thus directly proportional to the frequency of the EMR wave.\nLikewise, the momentum \"p\" of a photon is also proportional to its frequency and inversely proportional to its wavelength:\n formula_5\nThe source of Einstein's proposal that light was composed of particles (or could act as particles in some circumstances) was an experimental anomaly not explained by the wave theory: the photoelectric effect, in which light striking a metal surface ejected electrons from the surface, causing an electric current to flow across an applied voltage. Experimental measurements demonstrated that the energy of individual ejected electrons was proportional to the \"frequency\", rather than the \"intensity\", of the light. Furthermore, below a certain minimum frequency, which depended on the particular metal, no current would flow regardless of the intensity. These observations appeared to contradict the wave theory, and for years physicists tried in vain to find an explanation. In 1905, Einstein explained this puzzle by resurrecting the particle theory of light to explain the observed effect. Because of the preponderance of evidence in favor of the wave theory, however, Einstein's ideas were met initially with great skepticism among established physicists. Eventually Einstein's explanation was accepted as new particle-like behavior of light was observed, such as the Compton effect.\nAs a photon is absorbed by an atom, it excites the atom, elevating an electron to a higher energy level (one that is on average farther from the nucleus). When an electron in an excited molecule or atom descends to a lower energy level, it emits a photon of light at a frequency corresponding to the energy difference. Since the energy levels of electrons in atoms are discrete, each element and each molecule emits and absorbs its own characteristic frequencies. Immediate photon emission is called fluorescence, a type of photoluminescence. An example is visible light emitted from fluorescent paints, in response to ultraviolet (blacklight). Many other fluorescent emissions are known in spectral bands other than visible light. Delayed emission is called phosphorescence.\nWave\u2013particle duality.\nThe modern theory that explains the nature of light includes the notion of wave\u2013particle duality.\nWave and particle effects of electromagnetic radiation.\nTogether, wave and particle effects fully explain the emission and absorption spectra of EM radiation. The matter-composition of the medium through which the light travels determines the nature of the absorption and emission spectrum. These bands correspond to the allowed energy levels in the atoms. Dark bands in the absorption spectrum are due to the atoms in an intervening medium between source and observer. The atoms absorb certain frequencies of the light between emitter and detector/eye, then emit them in all directions. A dark band appears to the detector, due to the radiation scattered out of the light beam. For instance, dark bands in the light emitted by a distant star are due to the atoms in the star's atmosphere. A similar phenomenon occurs for emission, which is seen when an emitting gas glows due to excitation of the atoms from any mechanism, including heat. As electrons descend to lower energy levels, a spectrum is emitted that represents the jumps between the energy levels of the electrons, but lines are seen because again emission happens only at particular energies after excitation. An example is the emission spectrum of nebulae. Rapidly moving electrons are most sharply accelerated when they encounter a region of force, so they are responsible for producing much of the highest frequency electromagnetic radiation observed in nature.\nThese phenomena can aid various chemical determinations for the composition of gases lit from behind (absorption spectra) and for glowing gases (emission spectra). Spectroscopy (for example) determines what chemical elements comprise a particular star. Spectroscopy is also used in the determination of the distance of a star, using the red shift.\nPropagation speed.\nWhen any wire (or other conducting object such as an antenna) conducts alternating current, electromagnetic radiation is propagated at the same frequency as the current. \nAs a wave, light is characterized by a velocity (the speed of light), wavelength, and frequency. As particles, light is a stream of photons. Each has an energy related to the frequency of the wave given by Planck's relation \"E = hf\", where \"E\" is the energy of the photon, \"h\" is Planck's constant, 6.626 \u00d7 10\u221234 J\u00b7s, and \"f\" is the frequency of the wave.\nIn a medium (other than vacuum), velocity factor or refractive index are considered, depending on frequency and application. Both of these are ratios of the speed in a medium to speed in a vacuum.\nHistory of discovery.\nElectromagnetic radiation of wavelengths other than those of visible light were discovered in the early 19th century. The discovery of infrared radiation is ascribed to astronomer William Herschel, who published his results in 1800 before the Royal Society of London. Herschel used a glass prism to refract light from the Sun and detected invisible rays that caused heating beyond the red part of the spectrum, through an increase in the temperature recorded with a thermometer. These \"calorific rays\" were later termed infrared.\nIn 1801, German physicist Johann Wilhelm Ritter discovered ultraviolet in an experiment similar to Herschel's, using sunlight and a glass prism. Ritter noted that invisible rays near the violet edge of a solar spectrum dispersed by a triangular prism darkened silver chloride preparations more quickly than did the nearby violet light. Ritter's experiments were an early precursor to what would become photography. Ritter noted that the ultraviolet rays (which at first were called \"chemical rays\") were capable of causing chemical reactions.\nIn 1862\u201364 James Clerk Maxwell developed equations for the electromagnetic field which suggested that waves in the field would travel with a speed that was very close to the known speed of light. Maxwell therefore suggested that visible light (as well as invisible infrared and ultraviolet rays by inference) all consisted of propagating disturbances (or radiation) in the electromagnetic field. Radio waves were first produced deliberately by Heinrich Hertz in 1887, using electrical circuits calculated to produce oscillations at a much lower frequency than that of visible light, following recipes for producing oscillating charges and currents suggested by Maxwell's equations. Hertz also developed ways to detect these waves, and produced and characterized what were later termed radio waves and microwaves.\nWilhelm R\u00f6ntgen discovered and named X-rays. After experimenting with high voltages applied to an evacuated tube on 8 November 1895, he noticed a fluorescence on a nearby plate of coated glass. In one month, he discovered X-rays' main properties.\nThe last portion of the EM spectrum to be discovered was associated with radioactivity. Henri Becquerel found that uranium salts caused fogging of an unexposed photographic plate through a covering paper in a manner similar to X-rays, and Marie Curie discovered that only certain elements gave off these rays of energy, soon discovering the intense radiation of radium. The radiation from pitchblende was differentiated into alpha rays (alpha particles) and beta rays (beta particles) by Ernest Rutherford through simple experimentation in 1899, but these proved to be charged particulate types of radiation. However, in 1900 the French scientist Paul Villard discovered a third neutrally charged and especially penetrating type of radiation from radium, and after he described it, Rutherford realized it must be yet a third type of radiation, which in 1903 Rutherford named gamma rays. In 1910 British physicist William Henry Bragg demonstrated that gamma rays are electromagnetic radiation, not particles, and in 1914 Rutherford and Edward Andrade measured their wavelengths, finding that they were similar to X-rays but with shorter wavelengths and higher frequency, although a 'cross-over' between X and gamma rays makes it possible to have X-rays with a higher energy (and hence shorter wavelength) than gamma rays and vice versa. The origin of the ray differentiates them, gamma rays tend to be natural phenomena originating from the unstable nucleus of an atom and X-rays are electrically generated (and hence man-made) unless they are as a result of bremsstrahlung X-radiation caused by the interaction of fast moving particles (such as beta particles) colliding with certain materials, usually of higher atomic numbers.\nElectromagnetic spectrum.\nEM radiation (the designation 'radiation' excludes static electric and magnetic and near fields) is classified by wavelength into radio, microwave, infrared, visible, ultraviolet, X-rays and gamma rays. Arbitrary electromagnetic waves can be expressed by Fourier analysis in terms of sinusoidal monochromatic waves, which in turn can each be classified into these regions of the EMR spectrum.\nFor certain classes of EM waves, the waveform is most usefully treated as \"random\", and then spectral analysis must be done by slightly different mathematical techniques appropriate to random or stochastic processes. In such cases, the individual frequency components are represented in terms of their \"power\" content, and the phase information is not preserved. Such a representation is called the power spectral density of the random process. Random electromagnetic radiation requiring this kind of analysis is, for example, encountered in the interior of stars, and in certain other very wideband forms of radiation such as the Zero point wave field of the electromagnetic vacuum.\nThe behavior of EM radiation and its interaction with matter depends on its frequency, and changes qualitatively as the frequency changes. Lower frequencies have longer wavelengths, and higher frequencies have shorter wavelengths, and are associated with photons of higher energy. There is no fundamental limit known to these wavelengths or energies, at either end of the spectrum, although photons with energies near the Planck energy or exceeding it (far too high to have ever been observed) will require new physical theories to describe.\nRadio and microwave.\nWhen radio waves impinge upon a conductor, they couple to the conductor, travel along it and induce an electric current on the conductor surface by moving the electrons of the conducting material in correlated bunches of charge. Such effects can cover macroscopic distances in conductors (such as radio antennas), since the wavelength of radio waves is long.\nElectromagnetic radiation phenomena with wavelengths ranging from as long as one meter to as short as one millimeter are called microwaves; with frequencies between 300\u00a0MHz (0.3\u00a0GHz) and 300\u00a0GHz.\nAt radio and microwave frequencies, EMR interacts with matter largely as a bulk collection of charges which are spread out over large numbers of affected atoms. In electrical conductors, such induced bulk movement of charges (electric currents) results in absorption of the EMR, or else separations of charges that cause generation of new EMR (effective reflection of the EMR). An example is absorption or emission of radio waves by antennas, or absorption of microwaves by water or other molecules with an electric dipole moment, as for example inside a microwave oven. These interactions produce either electric currents or heat, or both.\nInfrared.\nLike radio and microwave, infrared (IR) also is reflected by metals (and also most EMR, well into the ultraviolet range). However, unlike lower-frequency radio and microwave radiation, Infrared EMR commonly interacts with dipoles present in single molecules, which change as atoms vibrate at the ends of a single chemical bond. It is consequently absorbed by a wide range of substances, causing them to increase in temperature as the vibrations dissipate as heat. The same process, run in reverse, causes bulk substances to radiate in the infrared spontaneously (see thermal radiation section below).\nInfrared radiation is divided into spectral subregions. While different subdivision schemes exist, the spectrum is commonly divided as near-infrared (0.75\u20131.4 \u03bcm), short-wavelength infrared (1.4\u20133 \u03bcm), mid-wavelength infrared (3\u20138 \u03bcm), long-wavelength infrared (8\u201315 \u03bcm) and far infrared (15\u20131000 \u03bcm).\nVisible light.\nNatural sources produce EM radiation across the spectrum. EM radiation with a wavelength between approximately 400 nm and 700\u00a0nm is directly detected by the human eye and perceived as visible light. Other wavelengths, especially nearby infrared (longer than 700\u00a0nm) and ultraviolet (shorter than 400\u00a0nm) are also sometimes referred to as light.\nAs frequency increases into the visible range, photons have enough energy to change the bond structure of some individual molecules. It is not a coincidence that this happens in the visible range, as the mechanism of vision involves the change in bonding of a single molecule, retinal, which absorbs a single photon. The change in retinal causes a change in the shape of the rhodopsin protein it is contained in, which starts the biochemical process that causes the retina of the human eye to sense the light.\nPhotosynthesis becomes possible in this range as well, for the same reason. A single molecule of chlorophyll is excited by a single photon. In plant tissues that conduct photosynthesis, carotenoids act to quench electronically excited chlorophyll produced by visible light in a process called non-photochemical quenching, to prevent reactions that would otherwise interfere with photosynthesis at high light levels.\nAnimals that detect infrared make use of small packets of water that change temperature, in an essentially thermal process that involves many photons.\nInfrared, microwaves and radio waves are known to damage molecules and biological tissue only by bulk heating, not excitation from single photons of the radiation.\nVisible light is able to affect only a tiny percentage of all molecules. Usually not in a permanent or damaging way, rather the photon excites an electron which then emits another photon when returning to its original position. This is the source of color produced by most dyes. Retinal is an exception. When a photon is absorbed, the retinal permanently changes structure from cis to trans, and requires a protein to convert it back, i.e. reset it to be able to function as a light detector again.\nLimited evidence indicate that some reactive oxygen species are created by visible light in skin, and that these may have some role in photoaging, in the same manner as ultraviolet A.\nUltraviolet.\nAs frequency increases into the ultraviolet, photons now carry enough energy (about three electron volts or more) to excite certain doubly bonded molecules into permanent chemical rearrangement. In DNA, this causes lasting damage. DNA is also indirectly damaged by reactive oxygen species produced by ultraviolet A (UVA), which has energy too low to damage DNA directly. This is why ultraviolet at all wavelengths can damage DNA, and is capable of causing cancer, and (for UVB) skin burns (sunburn) that are far worse than would be produced by simple heating (temperature increase) effects. This property of causing molecular damage that is out of proportion to heating effects, is characteristic of all EMR with frequencies at the visible light range and above. These properties of high-frequency EMR are due to quantum effects that permanently damage materials and tissues at the molecular level.\nAt the higher end of the ultraviolet range, the energy of photons becomes large enough to impart enough energy to electrons to cause them to be liberated from the atom, in a process called photoionisation. The energy required for this is always larger than about 10 electron volt (eV) corresponding with wavelengths smaller than 124\u00a0nm (some sources suggest a more realistic cutoff of 33\u00a0eV, which is the energy required to ionize water). This high end of the ultraviolet spectrum with energies in the approximate ionization range, is sometimes called \"extreme UV.\" Ionizing UV is strongly filtered by the Earth's atmosphere.\nX-rays and gamma rays.\nElectromagnetic radiation composed of photons that carry minimum-ionization energy, or more, (which includes the entire spectrum with shorter wavelengths), is therefore termed ionizing radiation. (Many other kinds of ionizing radiation are made of non-EM particles). Electromagnetic-type ionizing radiation extends from the extreme ultraviolet to all higher frequencies and shorter wavelengths, which means that all X-rays and gamma rays qualify. These are capable of the most severe types of molecular damage, which can happen in biology to any type of biomolecule, including mutation and cancer, and often at great depths below the skin, since the higher end of the X-ray spectrum, and all of the gamma ray spectrum, penetrate matter.\nAtmosphere and magnetosphere.\nMost UV and X-rays are blocked by absorption first from molecular nitrogen, and then (for wavelengths in the upper UV) from the electronic excitation of dioxygen and finally ozone at the mid-range of UV. Only 30% of the Sun's ultraviolet light reaches the ground, and almost all of this is well transmitted.\nVisible light is well transmitted in air, as it is not energetic enough to excite nitrogen, oxygen, or ozone, but too energetic to excite molecular vibrational frequencies of water vapor.\nAbsorption bands in the infrared are due to modes of vibrational excitation in water vapor. However, at energies too low to excite water vapor, the atmosphere becomes transparent again, allowing free transmission of most microwave and radio waves. \nFinally, at radio wavelengths longer than 10 m or so (about 30\u00a0MHz), the air in the lower atmosphere remains transparent to radio, but plasma in certain layers of the ionosphere begins to interact with radio waves (see skywave). This property allows some longer wavelengths (100 m or 3\u00a0MHz) to be reflected and results in shortwave radio beyond line-of-sight. However, certain ionospheric effects begin to block incoming radiowaves from space, when their frequency is less than about 10\u00a0MHz (wavelength longer than about 30 m).\nThermal and electromagnetic radiation as a form of heat.\nThe basic structure of matter involves charged particles bound together. When electromagnetic radiation impinges on matter, it causes the charged particles to oscillate and gain energy. The ultimate fate of this energy depends on the context. It could be immediately re-radiated and appear as scattered, reflected, or transmitted radiation. It may get dissipated into other microscopic motions within the matter, coming to thermal equilibrium and manifesting itself as thermal energy, or even kinetic energy, in the material. With a few exceptions related to high-energy photons (such as fluorescence, harmonic generation, photochemical reactions, the photovoltaic effect for ionizing radiations at far ultraviolet, X-ray and gamma radiation), absorbed electromagnetic radiation simply deposits its energy by heating the material. This happens for infrared, microwave and radio wave radiation. Intense radio waves can thermally burn living tissue and can cook food. In addition to infrared lasers, sufficiently intense visible and ultraviolet lasers can easily set paper afire.\nIonizing radiation creates high-speed electrons in a material and breaks chemical bonds, but after these electrons collide many times with other atoms eventually most of the energy becomes thermal energy all in a tiny fraction of a second. This process makes ionizing radiation far more dangerous per unit of energy than non-ionizing radiation. This caveat also applies to UV, even though almost all of it is not ionizing, because UV can damage molecules due to electronic excitation, which is far greater per unit energy than heating effects.\nInfrared radiation in the spectral distribution of a black body is usually considered a form of heat, since it has an equivalent temperature and is associated with an entropy change per unit of thermal energy. However, \"heat\" is a technical term in physics and thermodynamics and is often confused with thermal energy. Any type of electromagnetic energy can be transformed into thermal energy in interaction with matter. Thus, \"any\" electromagnetic radiation can \"heat\" (in the sense of increase the thermal energy temperature of) a material, when it is absorbed.\nThe inverse or time-reversed process of absorption is thermal radiation. Much of the thermal energy in matter consists of random motion of charged particles, and this energy can be radiated away from the matter. The resulting radiation may subsequently be absorbed by another piece of matter, with the deposited energy heating the material.\nThe electromagnetic radiation in an opaque cavity at thermal equilibrium is effectively a form of thermal energy, having maximum radiation entropy.\nBiological effects.\nBioelectromagnetics is the study of the interactions and effects of EM radiation on living organisms. The effects of electromagnetic radiation upon living cells, including those in humans, depends upon the radiation's power and frequency. For low-frequency radiation (radio waves to visible light) the best-understood effects are those due to radiation power alone, acting through heating when radiation is absorbed. For these thermal effects, frequency is important as it affects the intensity of the radiation and penetration into the organism (for example, microwaves penetrate better than infrared). It is widely accepted that low frequency fields that are too weak to cause significant heating could not possibly have any biological effect.\nSome research suggests that weaker \"non-thermal\" electromagnetic fields (including weak ELF magnetic fields, although the latter does not strictly qualify as EM radiation) and modulated RF and microwave fields can have biological effects, though the significance of this is unclear.\nThe World Health Organization has classified radio frequency electromagnetic radiation as Group 2B \u2013 possibly carcinogenic. This group contains possible carcinogens such as lead, DDT, and styrene. For example, epidemiological studies looking for a relationship between cell phone use and brain cancer development have been largely inconclusive, save to demonstrate that the effect, if it exists, cannot be a large one.\nAt higher frequencies (visible and beyond), the effects of individual photons begin to become important, as these now have enough energy individually to directly or indirectly damage biological molecules. All UV frequencies have been classed as Group 1 carcinogens by the World Health Organization. Ultraviolet radiation from sun exposure is the primary cause of skin cancer.\nThus, at UV frequencies and higher (and probably somewhat also in the visible range), electromagnetic radiation does more damage to biological systems than simple heating predicts. This is most obvious in the \"far\" (or \"extreme\") ultraviolet. UV, with X-ray and gamma radiation, are referred to as ionizing radiation due to the ability of photons of this radiation to produce ions and free radicals in materials (including living tissue). Since such radiation can severely damage life at energy levels that produce little heating, it is considered far more dangerous (in terms of damage-produced per unit of energy, or power) than the rest of the electromagnetic spectrum.\nUse as a weapon.\nThe heat ray is an application of EMR that makes use of microwave frequencies to create an unpleasant heating effect in the upper layer of the skin. A publicly known heat ray weapon called the Active Denial System was developed by the US military as an experimental weapon to deny the enemy access to an area. A death ray is a theoretical weapon that delivers heat ray based on electromagnetic energy at levels that are capable of injuring human tissue. An inventor of a death ray, Harry Grindell Matthews, claimed to have lost sight in his left eye while working on his death ray weapon based on a microwave magnetron from the 1920s (a normal microwave oven creates a tissue damaging cooking effect inside the oven at around 2 kV/m).\nDerivation from electromagnetic theory.\nElectromagnetic waves are predicted by the classical laws of electricity and magnetism, known as Maxwell's equations. There are nontrivial solutions of the homogeneous Maxwell's equations (without charges or currents), describing \"waves\" of changing electric and magnetic fields. Beginning with Maxwell's equations in free space:\nwhere\nBesides the trivial solution\nformula_15\nuseful solutions can be derived with the following vector identity, valid for all vectors formula_16 in some vector field:\nformula_17\nTaking the curl of the second Maxwell equation (2) yields:\nEvaluating the left hand side of (5) with the above identity and simplifying using (1), yields:\nEvaluating the right hand side of (5) by exchanging the sequence of derivations and inserting the fourth Maxwell equation (4), yields:\nCombining (6) and (7) again, gives a vector-valued differential equation for the electric field, solving the homogeneous Maxwell equations:\nformula_18\nTaking the curl of the fourth Maxwell equation (4) results in a similar differential equation for a magnetic field solving the homogeneous Maxwell equations:\nformula_19\nBoth differential equations have the form of the general wave equation for waves propagating with speed formula_20 where formula_21 is a function of time and location, which gives the amplitude of the wave at some time at a certain location:\nformula_22 is a unit vector in the direction of propagation, and formula_23 is a position vector. formula_24 is a generic solution to the wave equation. In other words,\nformula_25\nfor a generic wave traveling in the formula_26 direction.\nFrom the first of Maxwell's equations, we get\nformula_27\nThus,\nformula_28\nwhich implies that the electric field is orthogonal to the direction the wave propagates. The second of Maxwell's equations yields the magnetic field, namely,\nformula_29\nThus,\nformula_30\nThe remaining equations will be satisfied by this choice of formula_31.\nThe electric and magnetic field waves in the far-field travel at the speed of light. They have a special restricted orientation and proportional magnitudes, formula_32, which can be seen immediately from the Poynting vector. The electric field, magnetic field, and direction of wave propagation are all orthogonal, and the wave propagates in the same direction as formula_33. Also, E and B far-fields in free space, which as wave solutions depend primarily on these two Maxwell equations, are in-phase with each other. This is guaranteed since the generic wave solution is first order in both space and time, and the curl operator on one side of these equations results in first-order spatial derivatives of the wave solution, while the time-derivative on the other side of the equations, which gives the other field, is first-order in time, resulting in the same phase shift for both fields in each mathematical operation.\nFrom the viewpoint of an electromagnetic wave traveling forward, the electric field might be oscillating up and down, while the magnetic field oscillates right and left. This picture can be rotated with the electric field oscillating right and left and the magnetic field oscillating down and up. This is a different solution that is traveling in the same direction. This arbitrariness in the orientation with respect to propagation direction is known as polarization. On a quantum level, it is described as photon polarization. The direction of the polarization is defined as the direction of the electric field.\nMore general forms of the second-order wave equations given above are available, allowing for both non-vacuum propagation media and sources. Many competing derivations exist, all with varying levels of approximation and intended applications. One very general example is a form of the electric field equation, which was factorized into a pair of explicitly directional wave equations, and then efficiently reduced into a single uni-directional wave equation by means of a simple slow-evolution approximation.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9428", "revid": "30746614", "url": "https://en.wikipedia.org/wiki?curid=9428", "title": "Ernest Hemingway", "text": "American author and journalist (1899\u20131961)\nErnest Miller Hemingway (; July 21, 1899\u00a0\u2013 July 2, 1961) was an American novelist, short-story writer, and journalist. His economical and understated style\u2014which included his iceberg theory\u2014had a strong influence on 20th-century fiction, while his adventurous lifestyle and public image brought him admiration from later generations. Hemingway produced most of his work between the mid-1920s and the mid-1950s, and he was awarded the 1954 Nobel Prize in Literature. He published seven novels, six short-story collections, and two nonfiction works. Three of his novels, four short-story collections, and three nonfiction works were published posthumously. Many of his works are considered classics of American literature.\nHemingway was raised in Oak Park, Illinois. After high school, he was a reporter for a few months for \"The Kansas City Star\" before leaving for the Italian Front to enlist as an ambulance driver in World War I. In 1918, he was seriously wounded and returned home. His wartime experiences formed the basis for his novel \"A Farewell to Arms\" (1929).\nIn 1921, he married Hadley Richardson, the first of four wives. They moved to Paris, where he worked as a foreign correspondent for the \"Toronto Star\" and fell under the influence of the modernist writers and artists of the 1920s' \"Lost Generation\" expatriate community. Hemingway's debut novel \"The Sun Also Rises\" was published in 1926. He divorced Richardson in 1927, and married Pauline Pfeiffer. They divorced after he returned from the Spanish Civil War (1936\u20131939), which he covered as a journalist and which was the basis for his novel \"For Whom the Bell Tolls\" (1940). Martha Gellhorn became his third wife in 1940. He and Gellhorn separated after he met Mary Welsh in London during World War II. Hemingway was present with Allied troops as a journalist at the Normandy landings and the liberation of Paris.\nHe maintained permanent residences in Key West, Florida (in the 1930s) and in Cuba (in the 1940s and 1950s). On a 1954 trip to Africa, he was seriously injured in two plane accidents on successive days, leaving him in pain and ill health for much of the rest of his life. In 1959, he bought a house in Ketchum, Idaho, where, in mid-1961, he died by suicide.\nLife.\nEarly life.\nErnest Miller Hemingway was born on July 21, 1899, in Oak Park, Illinois, an affluent suburb just west of Chicago, to Clarence Edmonds Hemingway, a physician, and Grace Hall Hemingway, a musician. His parents were well-educated and well-respected in Oak Park, a conservative community about which resident Frank Lloyd Wright said, \"So many churches for so many good people to go to.\" When Clarence and Grace Hemingway married in 1896, they lived with Grace's father, Ernest Miller Hall, after whom they named their first son, the second of their six children. His sister Marcelline preceded him in 1898, followed by Ursula in 1902, Madelaine in 1904, Carol in 1911, and Leicester in 1915. Grace followed the Victorian convention of not differentiating children's clothing by gender. With only a year separating the two, Ernest and Marcelline resembled one-another strongly. Grace wanted them to appear as twins, so in Ernest's first three years she kept his hair long and dressed both children in similarly frilly feminine clothing.\nHemingway's mother, a well-known musician in the village, taught her son to play the cello despite his refusal to learn; though later in life he admitted the music lessons contributed to his writing style, evidenced for example in the \"contrapuntal structure\" of \"For Whom the Bell Tolls\". As an adult Hemingway professed to hate his mother, although biographer Michael S. Reynolds points out that he shared similar energies and enthusiasms.\nEach summer the family traveled to Windemere on Walloon Lake, near Petoskey, Michigan. There young Ernest joined his father and learned to hunt, fish, and camp in the woods and lakes of Northern Michigan, early experiences that instilled a life-long passion for outdoor adventure and living in remote or isolated areas.\nHemingway attended Oak Park and River Forest High School in Oak Park from 1913 until 1917. He was an accomplished athlete involved with a number of sports, including boxing, track and field, water polo, and football. He performed in the school orchestra for two years with his sister Marcelline, and received good grades in English classes. During his last two years at high school he edited the \"Trapeze\" and \"Tabula\" (the school's newspaper and yearbook), where he imitated the language of sportswriters and used the pen name Ring Lardner Jr.\u2014a nod to Ring Lardner of the \"Chicago Tribune\" whose byline was \"Line O'Type\". Like Mark Twain, Stephen Crane, Theodore Dreiser, and Sinclair Lewis, Hemingway was a journalist before becoming a novelist. After leaving high school he went to work for \"The Kansas City Star\" as a cub reporter. Although he stayed there for only six months, he relied on the \"Star\"'s style guide as a foundation for his writing, such as \"Use short sentences. Use short first paragraphs. Use vigorous English. Be positive, not negative.\"\nWorld War I.\nIn December 1917, after being rejected by the U.S. Army for poor eyesight, Hemingway responded to a Red Cross recruitment effort and signed on to be an ambulance driver in Italy, In May 1918, he sailed from New York, and arrived in Paris as the city was under bombardment from German artillery. That June he arrived at the Italian Front. On his first day in Milan, he was sent to the scene of a munitions factory explosion to join rescuers retrieving the shredded remains of female workers. He described the incident in his 1932 non-fiction book \"Death in the Afternoon\": \"I remember that after we searched quite thoroughly for the complete dead we collected fragments.\" A few days later, he was stationed at Fossalta di Piave.\nOn July 8, he was seriously wounded by mortar fire, having just returned from the canteen bringing chocolate and cigarettes for the men at the front line. Despite his wounds, Hemingway assisted Italian soldiers to safety, for which he was decorated with the Italian War Merit Cross, the \"Croce al Merito di Guerra\". He was still only 18 at the time. Hemingway later said of the incident: \"When you go to war as a boy you have a great illusion of immortality. Other people get killed; not you\u00a0... Then when you are badly wounded the first time you lose that illusion and you know it can happen to you.\" He sustained severe shrapnel wounds to both legs, underwent an immediate operation at a distribution center, and spent five days at a field hospital before he was transferred for recuperation to the Red Cross hospital in Milan. He spent six months at the hospital, where he met and formed a strong friendship with \"Chink\" Dorman-Smith that lasted for decades and shared a room with future American foreign service officer, ambassador, and author Henry Serrano Villard.\nWhile recuperating he fell in love with Agnes von Kurowsky, a Red Cross nurse seven years his senior. When Hemingway returned to the United States in January 1919, he believed Agnes would join him within months and the two would marry. Instead, he received a letter in March with her announcement that she was engaged to an Italian officer. Biographer Jeffrey Meyers writes Agnes's rejection devastated and scarred the young man; in future relationships, Hemingway followed a pattern of abandoning a wife before she abandoned him.\nToronto and Chicago.\nHemingway returned home early in 1919 to a time of readjustment. Before the age of 20, he had gained from the war a maturity that was at odds with living at home without a job and with the need for recuperation. As Reynolds explains, \"Hemingway could not really tell his parents what he thought when he saw his bloody knee.\" He was not able to tell them how scared he had been \"in another country with surgeons who could not tell him in English if his leg was coming off or not.\"\nIn September, he took a fishing and camping trip with high-school friends to the back-country of Michigan's Upper Peninsula. The trip became the inspiration for his short story \"Big Two-Hearted River\", in which the semi-autobiographical character Nick Adams takes to the country to find solitude after returning from war. A family friend offered him a job in Toronto, and with nothing else to do, he accepted. Late that year he began as a freelancer and staff writer for the \"Toronto Star Weekly\". He returned to Michigan the following June and then moved to Chicago in September 1920 to live with friends, while still filing stories for the \"Toronto Star\". In Chicago, he worked as an associate editor of the monthly journal \"Cooperative Commonwealth\", where he met novelist Sherwood Anderson.\nWhen St. Louis native Hadley Richardson came to Chicago to visit the sister of Hemingway's roommate, Hemingway became infatuated. He later claimed, \"I knew she was the girl I was going to marry.\" Hadley, red-haired, with a \"nurturing instinct\", was eight years older than Hemingway. Despite the age difference, Hadley, who had grown up with an overprotective mother, seemed less mature than usual for a young woman her age. Bernice Kert, author of \"The Hemingway Women\", claims Hadley was \"evocative\" of Agnes, but that Hadley had a childishness that Agnes lacked. The two corresponded for a few months and then decided to marry and travel to Europe. They wanted to visit Rome, but Sherwood Anderson convinced them to visit Paris instead, writing letters of introduction for the young couple. They were married on September 3, 1921; two months later Hemingway was hired as a foreign correspondent for the \"Toronto Star\", and the couple left for Paris. Of Hemingway's marriage to Hadley, Meyers claims: \"With Hadley, Hemingway achieved everything he had hoped for with Agnes: the love of a beautiful woman, a comfortable income, a life in Europe.\"\nParis.\nCarlos Baker, Hemingway's first biographer, believes that while Anderson suggested Paris because \"the monetary exchange rate\" made it an inexpensive place to live, more importantly it was where \"the most interesting people in the world\" lived. In Paris, Hemingway met American writer and art collector Gertrude Stein, Irish novelist James Joyce, American poet Ezra Pound (who \"could help a young writer up the rungs of a career\") and other writers.\nThe Hemingway of the early Paris years was a \"tall, handsome, muscular, broad-shouldered, brown-eyed, rosy-cheeked, square-jawed, soft-voiced young man.\" He and Hadley lived in a small walk-up at 74 rue du Cardinal Lemoine in the Latin Quarter, and he worked in a rented room in a nearby building. Stein, who was the bastion of modernism in Paris, became Hemingway's mentor and godmother to his son Jack; she introduced him to the expatriate artists and writers of the Montparnasse Quarter, whom she referred to as the \"Lost Generation\"\u2014a term Hemingway popularized with the publication of \"The Sun Also Rises\". A regular at Stein's salon, Hemingway met influential painters such as Pablo Picasso, Joan Mir\u00f3, and Juan Gris. He eventually withdrew from Stein's influence, and their relationship deteriorated into a literary quarrel that spanned decades. While living in Paris in 1922, Hemingway befriended artist Henry Strater who painted two portraits of him.\nEzra Pound met Hemingway by chance at Sylvia Beach's bookshop Shakespeare and Company in 1922. The two toured Italy in 1923 and lived on the same street in 1924. They forged a strong friendship, and in Hemingway, Pound recognized and fostered a young talent. Pound introduced Hemingway to James Joyce, with whom Hemingway frequently embarked on \"alcoholic sprees\".\nDuring his first 20 months in Paris, Hemingway filed 88 stories for the \"Toronto Star\" newspaper. He covered the Greco-Turkish War, where he witnessed the burning of Smyrna, and wrote travel pieces such as \"Tuna Fishing in Spain\" and \"Trout Fishing All Across Europe: Spain Has the Best, Then Germany\".\nHemingway was devastated on learning that Hadley had lost a suitcase filled with his manuscripts at the Gare de Lyon as she was traveling to Geneva to meet him in December 1922. In the following September the couple returned to Toronto, where their son John Hadley Nicanor was born on October 10, 1923. During their absence, Hemingway's first book, \"Three Stories and Ten Poems\", was published. Two of the stories it contained were all that remained after the loss of the suitcase, and the third had been written early the previous year in Italy. Within months a second volume, \"in our time\" (without capitals), was published. The small volume included six vignettes and a dozen stories Hemingway had written the previous summer during his first visit to Spain, where he discovered the thrill of the \"corrida\". He missed Paris, considered Toronto boring, and wanted to return to the life of a writer, rather than live the life of a journalist.\nHemingway, Hadley and their son (nicknamed Bumby) returned to Paris in January 1924 and moved into a new apartment on the rue Notre-Dame des Champs. Hemingway helped Ford Madox Ford edit \"The Transatlantic Review\", which published works by Pound, John Dos Passos, Baroness Elsa von Freytag-Loringhoven, and Stein, as well as some of Hemingway's own early stories such as \"Indian Camp\". When \"In Our Time\" was published in 1925, the dust jacket bore comments from Ford. \"Indian Camp\" received considerable praise; Ford saw it as an important early story by a young writer, and critics in the United States praised Hemingway for reinvigorating the short story genre with his crisp style and use of declarative sentences. Six months earlier, Hemingway had met F. Scott Fitzgerald, and the pair formed a friendship of \"admiration and hostility\". Fitzgerald had published \"The Great Gatsby\" the same year: Hemingway read it, liked it, and decided his next work had to be a novel.\nWith his wife Hadley, Hemingway first visited the Festival of San Ferm\u00edn in Pamplona, Spain, in 1923, where he became fascinated by bullfighting. It is at this time that he began to be referred to as \"Papa\", even by much older friends. Hadley would much later recall that Hemingway had his own nicknames for everyone and that he often did things for his friends; she suggested that he liked to be looked up to. She did not remember precisely how the nickname came into being; however, it certainly stuck. The Hemingways returned to Pamplona in 1924 and a third time in June 1925; that year they brought with them a group of American and British expatriates: Hemingway's Michigan boyhood friend Bill Smith, Donald Ogden Stewart, Lady Duff Twysden (recently divorced), her lover Pat Guthrie, and Harold Loeb. A few days after the fiesta ended, on his birthday (July 21), he began to write the draft of what would become \"The Sun Also Rises\", finishing eight weeks later. A few months later, in December 1925, the Hemingways left to spend the winter in Schruns, Austria, where Hemingway began revising the manuscript extensively. Pauline Pfeiffer joined them in January and against Hadley's advice, urged Hemingway to sign a contract with Scribner's. He left Austria for a quick trip to New York to meet with the publishers, and on his return, during a stop in Paris, began an affair with Pfeiffer, before returning to Schruns to finish the revisions in March. The manuscript arrived in New York in April; he corrected the final proof in Paris in August 1926, and Scribner's published the novel in October.\n\"The Sun Also Rises\" epitomized the post-war expatriate generation, received good reviews and is \"recognized as Hemingway's greatest work\". Hemingway himself later wrote to his editor Max Perkins that the \"point of the book\" was not so much about a generation being lost, but that \"the earth abideth forever\"; he believed the characters in \"The Sun Also Rises\" may have been \"battered\" but were not lost.\nHemingway's marriage to Hadley deteriorated as he was working on \"The Sun Also Rises\". In early 1926, Hadley became aware of his affair with Pfeiffer, who came to Pamplona with them that July. On their return to Paris, Hadley asked for a separation; in November she formally requested a divorce. They split their possessions while Hadley accepted Hemingway's offer of the proceeds from \"The Sun Also Rises\". The couple were divorced in January 1927, and Hemingway married Pfeiffer in May.\nPfeiffer, who was from a wealthy Catholic Arkansas family, had moved to Paris to work for \"Vogue\" magazine. Before their marriage, Hemingway converted to Catholicism. They honeymooned in Le Grau-du-Roi, where he contracted anthrax, and he planned his next collection of short stories, \"Men Without Women\", which was published in October 1927, and included his boxing story \"Fifty Grand\". \"Cosmopolitan\" magazine editor-in-chief Ray Long praised \"Fifty Grand\", calling it, \"one of the best short stories that ever came to my hands\u00a0... the best prize-fight story I ever read\u00a0... a remarkable piece of realism.\"\nBy the end of the year Pauline, who was pregnant, wanted to move back to America. John Dos Passos recommended Key West, and they left Paris in March 1928. Hemingway suffered a severe injury in their Paris bathroom when he pulled a skylight down on his head thinking he was pulling on a toilet chain. This left him with a prominent forehead scar, which he carried for the rest of his life. When Hemingway was asked about the scar, he was reluctant to answer. After his departure from Paris, Hemingway \"never again lived in a big city\".\nKey West and the Caribbean.\nHemingway and Pauline traveled to Kansas City, where their son Patrick was born on June 28, 1928. Pauline had a difficult delivery; Hemingway fictionalized a version of the event as a part of \"A Farewell to Arms\". After Patrick's birth, Pauline and Hemingway traveled to Wyoming, Massachusetts, and New York. In the winter, he was in New York with Bumby, about to board a train to Florida, when he received a cable telling him that his father had killed himself. Hemingway was devastated, having earlier written to his father telling him not to worry about financial difficulties; the letter arrived minutes after the suicide. He realized how Hadley must have felt after her own father's suicide in 1903, and he commented, \"I'll probably go the same way.\"\nUpon his return to Key West in December, Hemingway worked on the draft of \"A Farewell to Arms\" before leaving for France in January. He had finished it in August but delayed the revision. The serialization in \"Scribner's Magazine\" was scheduled to begin in May, but as late as April, Hemingway was still working on the ending, which he may have rewritten as many as seventeen times. The completed novel was published on September 27. Biographer James Mellow believes \"A Farewell to Arms\" established Hemingway's stature as a major American writer and displayed a level of complexity not apparent in \"The Sun Also Rises\". (The story was turned into a play by war veteran Laurence Stallings that was the basis for the film starring Gary Cooper.) In Spain in mid-1929, Hemingway researched his next work, \"Death in the Afternoon\". He wanted to write a comprehensive treatise on bullfighting, explaining the \"toreros\" and \"corridas\" complete with glossaries and appendices, because he believed bullfighting was \"of great tragic interest, being literally of life and death.\"\nDuring the early 1930s, Hemingway spent his winters in Key West and summers in Wyoming, where he found \"the most beautiful country he had seen in the American West\" and hunted deer, elk, and grizzly bear. He was joined there by Dos Passos, and in November 1930, after bringing Dos Passos to the train station in Billings, Montana, Hemingway broke his arm in a car accident. The surgeon tended the compound spiral fracture and bound the bone with kangaroo tendon. Hemingway was hospitalized for seven weeks, with Pauline tending to him; the nerves in his writing hand took as long as a year to heal, during which time he suffered intense pain.\nHis third child, Gloria Hemingway, was born a year later on November 12, 1931, in Kansas City as \"Gregory Hancock Hemingway\". Pauline's uncle bought the couple a house in Key West with a carriage house, the second floor of which was converted into a writing studio. While in Key West, Hemingway frequented the local bar Sloppy Joe's. He invited friends\u2014including Waldo Peirce, Dos Passos, and Max Perkins\u2014to join him on fishing trips and on an all-male expedition to the Dry Tortugas. Meanwhile, he continued to travel to Europe and to Cuba, and\u2014although in 1933 he wrote of Key West, \"We have a fine house here, and kids are all well\"\u2014Mellow believes he \"was plainly restless\".\nIn 1933, Hemingway and Pauline went on safari to Kenya. The 10-week trip provided material for \"Green Hills of Africa\", as well as for the short stories \"The Snows of Kilimanjaro\" and \"The Short Happy Life of Francis Macomber\". The couple visited Mombasa, Nairobi, and Machakos in Kenya; then moved on to Tanganyika Territory, where they hunted in the Serengeti, around Lake Manyara, and west and southeast of present-day Tarangire National Park. Their guide was the noted \"white hunter\" Philip Percival who had guided Theodore Roosevelt on his 1909 safari. During these travels, Hemingway contracted amoebic dysentery that caused a prolapsed intestine, and he was evacuated by plane to Nairobi, an experience reflected in \"The Snows of Kilimanjaro\". On Hemingway's return to Key West in early 1934, he began work on \"Green Hills of Africa\", which he published in 1935 to mixed reviews.\nHemingway bought a boat in 1934, named it the \"Pilar\", and began sailing the Caribbean. In 1935 he first arrived at Bimini, where he spent a considerable amount of time. During this period he also worked on \"To Have and Have Not\", published in 1937 while he was in Spain, the only novel he wrote during the 1930s.\nSpanish Civil War.\nIn 1937, Hemingway left for Spain to cover the Spanish Civil War for the North American Newspaper Alliance (NANA), despite Pauline's reluctance to have him working in a war zone. He and Dos Passos both signed on to work with Dutch filmmaker Joris Ivens as screenwriters for \"The Spanish Earth\". Dos Passos left the project after the execution of Jos\u00e9 Robles, his friend and Spanish translator, which caused a rift between the two writers.\nHemingway was joined in Spain by journalist and writer Martha Gellhorn, whom he had met in Key West a year earlier. Like Hadley, Martha was a St. Louis native, and like Pauline, she had worked for \"Vogue\" in Paris. Of Martha, Kert explains, \"she never catered to him the way other women did\". In July 1937 he attended the Second International Writers' Congress, the purpose of which was to discuss the attitude of intellectuals to the war, held in Valencia, Barcelona and Madrid and attended by many writers including Andr\u00e9 Malraux, Stephen Spender and Pablo Neruda. Late in 1937, while in Madrid with Martha, Hemingway wrote his only play, \"The Fifth Column\", as the city was being bombarded by Francoist forces. He returned to Key West for a few months, then back to Spain twice in 1938, where he was present at the Battle of the Ebro, the last republican stand, and he was among the British and American journalists who were some of the last to leave the battle as they crossed the river.\nCuba.\nIn early 1939, Hemingway crossed to Cuba in his boat to live in the Hotel Ambos Mundos in Havana. This was the separation phase of a slow and painful split from Pauline, which began when Hemingway met Martha Gellhorn. Martha soon joined him in Cuba, and they rented \"Finca Vig\u00eda\" (\"Lookout Farm\"), a property from Havana. Pauline and the children left Hemingway that summer, after the family was reunited during a visit to Wyoming; when his divorce from Pauline was finalized, he and Martha were married on November 20, 1940, in Cheyenne, Wyoming.\nHemingway moved his primary summer residence to Ketchum, Idaho, just outside the newly built resort of Sun Valley, and moved his winter residence to Cuba. He had been disgusted when a Parisian friend allowed his cats to eat from the table, but he became enamored of cats in Cuba and kept dozens of them on the property. Descendants of his cats live at his Key West home.\nGellhorn inspired him to write his most famous novel, \"For Whom the Bell Tolls\", which he began in March 1939 and finished in July 1940. It was published in October 1940. His pattern was to move around while working on a manuscript, and he wrote \"For Whom the Bell Tolls\" in Cuba, Wyoming, and Sun Valley. It became a Book-of-the-Month Club choice, sold half a million copies within months, was nominated for a Pulitzer Prize and, in the words of Meyers, \"triumphantly re-established Hemingway's literary reputation\".\nIn January 1941, Martha was sent to China on assignment for \"Collier's\" magazine. Hemingway went with her, sending in dispatches for the newspaper \"PM\", but in general he disliked China. \nA 2009 book by former KGB officer Alexander Vassiliev suggests during that period he may have been recruited to work for NKVD \"on ideological grounds\" under the code name \"Argo\". \nThey returned to Cuba before the declaration of war by the United States that December, when he convinced the Cuban government to help him refit the \"Pilar\", which he intended to use to ambush German submarines off the coast of Cuba.\nWorld War II.\nHemingway was in Europe from May 1944 to March 1945. When he arrived in London, he met \"Time\" magazine correspondent Mary Welsh, with whom he became infatuated. Martha had been forced to cross the Atlantic in a ship filled with explosives because Hemingway refused to help her get a press pass on a plane, and she arrived in London to find him hospitalized with a concussion from a car accident. She was unsympathetic to his plight; she accused him of being a bully and told him that she was \"through, absolutely finished\". The last time that Hemingway saw Martha was in March 1945 as he was preparing to return to Cuba, and their divorce was finalized later that year. Meanwhile, he had asked Mary Welsh to marry him on their third meeting.\nHemingway accompanied the troops to the Normandy Landings wearing a large head bandage, according to Meyers, but he was considered \"precious cargo\" and not allowed ashore. The landing craft came within sight of Omaha Beach before coming under enemy fire and turning back. Hemingway later wrote in \"Collier's\" that he could see \"the first, second, third, fourth and fifth waves of [landing troops] lay where they had fallen, looking like so many heavily laden bundles on the flat pebbly stretch between the sea and first cover\". Mellow explains that, on that first day, none of the correspondents were allowed to land and Hemingway was returned to the \"Dorothea Dix\".\nLate in July, he attached himself to \"the 22nd Infantry Regiment commanded by Col. Charles \"Buck\" Lanham, as it drove toward Paris\", and Hemingway became de facto leader to a small band of village militia in Rambouillet outside of Paris. Paul Fussell remarks: \"Hemingway got into considerable trouble playing infantry captain to a group of Resistance people that he gathered because a correspondent is not supposed to lead troops, even if he does it well.\" This was in fact in contravention of the Geneva Convention, and Hemingway was brought up on formal charges; he said that he \"beat the rap\" by claiming that he only offered advice.\nOn August 25, he was present at the liberation of Paris as a journalist; contrary to the Hemingway legend, he was not the first into the city, nor did he liberate the Ritz. In Paris, he visited Sylvia Beach and Pablo Picasso with Mary Welsh, who joined him there; in a spirit of happiness, he forgave Gertrude Stein. Later that year, he observed heavy fighting in the Battle of H\u00fcrtgen Forest. On December 17, 1944, he had himself driven to Luxembourg in spite of illness to cover The Battle of the Bulge. As soon as he arrived, however, Lanham handed him to the doctors, who hospitalized him with pneumonia; he recovered a week later, but most of the fighting was over.\nIn 1947, Hemingway was awarded a Bronze Star for his bravery during World War II. He was recognized for having been \"under fire in combat areas in order to obtain an accurate picture of conditions\", with the commendation that \"through his talent of expression, Mr. Hemingway enabled readers to obtain a vivid picture of the difficulties and triumphs of the front-line soldier and his organization in combat\".\nCuba and the Nobel Prize.\nHemingway said he \"was out of business as a writer\" from 1942 to 1945 during his residence in Cuba. In 1946 he married Mary, who had an ectopic pregnancy five months later. The Hemingway family suffered a series of accidents and health problems in the years following the war: in a 1945 car accident, he \"smashed his knee\" and sustained another \"deep wound on his forehead\"; Mary broke first her right ankle and then her left in successive skiing accidents. A 1947 car accident left Patrick with a head wound and severely ill. Hemingway sank into depression as his literary friends began to die: in 1939 William Butler Yeats and Ford Madox Ford; in 1940 F. Scott Fitzgerald; in 1941 Sherwood Anderson and James Joyce; in 1946 Gertrude Stein; and the following year in 1947, Max Perkins, Hemingway's long-time Scribner's editor, and friend. During this period, he suffered from severe headaches, high blood pressure, weight problems, and eventually diabetes\u2014much of which was the result of previous accidents and many years of heavy drinking. Nonetheless, in January 1946, he began work on \"The Garden of Eden\", finishing 800 pages by June. During the post-war years, he also began work on a trilogy tentatively titled \"The Land\", \"The Sea\" and \"The Air\", which he wanted to combine in one novel titled \"The Sea Book\". However, both projects stalled, and Mellow says that Hemingway's inability to continue was \"a symptom of his troubles\" during these years.\nIn 1948, Hemingway and Mary traveled to Europe, staying in Venice for several months. While there, Hemingway fell in love with the then 19-year-old Adriana Ivancich. The platonic love affair inspired the novel \"Across the River and into the Trees\", written in Cuba during a time of strife with Mary, and published in 1950 to negative reviews. The following year, furious at the critical reception of \"Across the River and Into the Trees\", he wrote the draft of \"The Old Man and the Sea\" in eight weeks, saying that it was \"the best I can write ever for all of my life\". \"The Old Man and the Sea\" became a book-of-the-month selection, made Hemingway an international celebrity, and won the Pulitzer Prize in May 1953, a month before he left for his second trip to Africa.\nIn January 1954, while in Africa, Hemingway was almost fatally injured in two successive plane crashes. He chartered a sightseeing flight over the Belgian Congo as a Christmas present to Mary. On their way to photograph Murchison Falls from the air, the plane struck an abandoned utility pole and \"crash landed in heavy brush\". Hemingway's injuries included a head wound, while Mary broke two ribs. The next day, attempting to reach medical care in Entebbe, they boarded a second plane that exploded at take-off, with Hemingway suffering burns and another concussion, this one serious enough to cause leaking of cerebral fluid. They eventually arrived in Entebbe to find reporters covering the story of Hemingway's death. He briefed the reporters and spent the next few weeks recuperating and reading his erroneous obituaries. Despite his injuries, Hemingway accompanied Patrick and his wife on a planned fishing expedition in February, but pain caused him to be irascible and difficult to get along with. When a bushfire broke out, he was again injured, sustaining second-degree burns on his legs, front torso, lips, left hand and right forearm. Months later in Venice, Mary reported to friends the full extent of Hemingway's injuries: two cracked discs, a kidney and liver rupture, a dislocated shoulder and a broken skull. The accidents may have precipitated the physical deterioration that was to follow. After the plane crashes, Hemingway, who had been \"a thinly controlled alcoholic throughout much of his life, drank more heavily than usual to combat the pain of his injuries.\"\nIn October 1954, Hemingway received the Nobel Prize in Literature. He modestly told the press that Carl Sandburg, Isak Dinesen and Bernard Berenson deserved the prize, but he gladly accepted the prize money. Mellow says Hemingway \"had coveted the Nobel Prize\", but when he won it, months after his plane accidents and the ensuing worldwide press coverage, \"there must have been a lingering suspicion in Hemingway's mind that his obituary notices had played a part in the academy's decision.\" Because he was suffering pain from the African accidents, he decided against traveling to Stockholm. Instead he sent a speech to be read, defining the writer's life:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Writing, at its best, is a lonely life. Organizations for writers palliate the writer's loneliness but I doubt if they improve his writing. He grows in public stature as he sheds his loneliness and often his work deteriorates. For he does his work alone and if he is a good enough writer he must face eternity, or the lack of it, each day.\nFrom the end of the year in 1955 to early 1956, Hemingway was bedridden. He was told to stop drinking to mitigate liver damage, advice he initially followed but then disregarded. In October 1956, he returned to Europe and met Basque writer Pio Baroja, who was seriously ill and died weeks later. During the trip, Hemingway became sick again and was treated for \"high blood pressure, liver disease, and arteriosclerosis\".\nIn November 1956, while staying in Paris, he was reminded of trunks he had stored in the Ritz Hotel in 1928 and never retrieved. Upon re-claiming and opening the trunks, Hemingway discovered they were filled with notebooks and writing from his Paris years. Excited about the discovery, when he returned to Cuba in early 1957, he began to shape the recovered work into his memoir \"A Moveable Feast\". By 1959 he ended a period of intense activity: he finished \"A Moveable Feast\" (scheduled to be released the following year); brought \"True at First Light\" to 200,000 words; added chapters to \"The Garden of Eden\"; and worked on \"Islands in the Stream\". The last three were stored in a safe deposit box in Havana, as he focused on the finishing touches for \"A Moveable Feast\". Author Michael Reynolds claims it was during this period that Hemingway slid into depression, from which he was unable to recover.\nThe Finca Vig\u00eda became crowded with guests and tourists, as Hemingway, beginning to become unhappy with life there, considered a permanent move to Idaho. In 1959 he bought a home overlooking the Big Wood River, outside Ketchum, and left Cuba\u2014although he apparently remained on easy terms with the Castro government, telling \"The New York Times\" he was \"delighted\" with Castro's overthrow of Batista. He was in Cuba in November 1959, between returning from Pamplona and traveling west to Idaho, and the following year for his 61st birthday; however, that year he and Mary decided to leave after hearing the news that Castro wanted to nationalize property owned by Americans and other foreign nationals. On July 25, 1960, the Hemingways left Cuba for the last time, leaving art and manuscripts in a bank vault in Havana. After the 1961 Bay of Pigs Invasion, the Finca Vig\u00eda was expropriated by the Cuban government, complete with Hemingway's collection of \"four to six thousand books\". President Kennedy arranged for Mary Hemingway to travel to Cuba where she met Fidel Castro and obtained her husband's papers and painting in return for donating Finca Vig\u00eda to Cuba.\nIdaho and suicide.\nHemingway continued to rework the material that was published as \"A Moveable Feast\" through the 1950s. In mid-1959, he visited Spain to research a series of bullfighting articles commissioned by \"Life\" magazine. \"Life\" wanted only 10,000\u00a0words, but the manuscript grew out of control. He was unable to organize his writing for the first time in his life, so he asked A. E. Hotchner to travel to Cuba to help him. Hotchner helped him trim the \"Life\" piece down to 40,000 words, and Scribner's agreed to a full-length book version (\"The Dangerous Summer\") of almost 130,000 words. Hotchner found Hemingway to be \"unusually hesitant, disorganized, and confused\", and suffering badly from failing eyesight.\nHemingway and Mary left Cuba for the last time on July 25, 1960. He set up a small office in his New York City apartment and attempted to work, but he left soon after. He then traveled alone to Spain to be photographed for the front cover of \"Life\" magazine. A few days later, the news reported that he was seriously ill and on the verge of dying, which panicked Mary until she received a cable from him telling her, \"Reports false. Enroute Madrid. Love Papa.\" He was, in fact, seriously ill, and believed himself to be on the verge of a breakdown. Feeling lonely, he took to his bed for days, retreating into silence, despite having the first installments of \"The Dangerous Summer\" published in \"Life\" in September 1960 to good reviews. In October, he left Spain for New York, where he refused to leave Mary's apartment, presuming that he was being watched. She quickly took him to Idaho, where physician George Saviers met them at the train.\nHemingway was constantly worried about money and his safety. He worried about his taxes and that he would never return to Cuba to retrieve the manuscripts that he had left in a bank vault. He became paranoid, thinking that the FBI was actively monitoring his movements in Ketchum. The FBI had opened a file on him during World War II, when he used the \"Pilar\" to patrol the waters off Cuba, and J. Edgar Hoover had an agent in Havana watch him during the 1950s. Unable to care for her husband, Mary had Saviers fly Hemingway to the Mayo Clinic in Minnesota at the end of November for hypertension treatments, as he told his patient. The FBI knew that Hemingway was at the Mayo Clinic, as an agent later documented in a letter written in January 1961.\nHemingway was checked in under Saviers's name to maintain anonymity. Meyers writes that \"an aura of secrecy surrounds Hemingway's treatment at the Mayo\" but confirms that he was treated with electroconvulsive therapy (ECT) as many as 15 times in December 1960 and was \"released in ruins\" in January 1961. Reynolds gained access to Hemingway's records at the Mayo, which document ten ECT sessions. The doctors in Rochester told Hemingway the depressive state for which he was being treated may have been caused by his long-term use of Reserpine and Ritalin. Of the ECT therapy, Hemingway told Hotchner, \"What is the sense of ruining my head and erasing my memory, which is my capital, and putting me out of business? It was a brilliant cure, but we lost the patient.\"\nHemingway was back in Ketchum in April 1961, three months after being released from the Mayo Clinic, when Mary \"found Hemingway holding a shotgun\" in the kitchen one morning. She called Saviers, who sedated him and admitted him to the Sun Valley Hospital and once the weather cleared Saviers flew again to Rochester with his patient. Hemingway underwent three electroshock treatments during that visit. He was released at the end of June and was home in Ketchum on June 30. Two days later he \"quite deliberately\" shot himself with his favorite shotgun in the early morning hours of July 2, 1961. He had unlocked the basement storeroom where his guns were kept, gone upstairs to the front entrance foyer, and shot himself with the \"double-barreled shotgun that he had used so often it might have been a friend\", which was purchased from Abercrombie &amp; Fitch.\nMary was sedated and taken to the hospital, returning home the next day where she cleaned the house and saw to the funeral and travel arrangements. Bernice Kert writes that it \"did not seem to her a conscious lie\" when she told the press that his death had been accidental. In a press interview five years later, Mary confirmed that he had shot himself.\nFamily and friends flew to Ketchum for the funeral, officiated by the local Catholic priest, who believed that the death had been accidental. An altar boy fainted at the head of the casket during the funeral, and Hemingway's brother Leicester wrote: \"It seemed to me Ernest would have approved of it all.\" He is buried in the Ketchum cemetery.\nHemingway's behavior during his final years had been similar to that of his father before he killed himself; his father may have had hereditary hemochromatosis, whereby the excessive accumulation of iron in tissues culminates in mental and physical deterioration. Medical records made available in 1991 confirmed that Hemingway had been diagnosed with hemochromatosis in early 1961. His sister Ursula and his brother Leicester also killed themselves. Hemingway's health was further complicated by heavy drinking throughout most of his life.\nA memorial to Hemingway just north of Sun Valley is inscribed on the base with a eulogy Hemingway had written for a friend several decades earlier:\n\"Best of all he loved the fall\"\n\"the leaves yellow on cottonwoods\"\n\"leaves floating on trout streams\"\n\"and above the hills\"\n\"the high blue windless skies\"\n...\"Now he will be a part of them forever.\"\nWriting style.\n\"The New York Times\" wrote in 1926 of Hemingway's first novel, \"No amount of analysis can convey the quality of \"The Sun Also Rises\". It is a truly gripping story, told in a lean, hard, athletic narrative prose that puts more literary English to shame.\" \"The Sun Also Rises\" is written in the spare, tight prose that made Hemingway famous, and, according to James Nagel, \"changed the nature of American writing\". In 1954, when Hemingway was awarded the Nobel Prize for Literature, it was for \"his mastery of the art of narrative, most recently demonstrated in \"The Old Man and the Sea\", and for the influence that he has exerted on contemporary style.\"\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIf a writer of prose knows enough of what he is writing about he may omit things that he knows and the reader, if the writer is writing truly enough, will have a feeling of those things as strongly as though the writer had stated them. The dignity of movement of an ice-berg is due to only one-eighth of it being above water. A writer who omits things because he does not know them only makes hollow places in his writing.\n \u2014Ernest Hemingway in \"Death in the Afternoon\"\nHenry Louis Gates believes Hemingway's style was fundamentally shaped \"in reaction to [his] experience of world war\". After World War\u00a0I, he and other modernists \"lost faith in the central institutions of Western civilization\" by reacting against the elaborate style of 19th-century writers and by creating a style \"in which meaning is established through dialogue, through action, and silences\u2014a fiction in which nothing crucial\u2014or at least very little\u2014is stated explicitly.\"\nBecause he began as a writer of short stories, Baker believes Hemingway learned to \"get the most from the least, how to prune language, how to multiply intensities and how to tell nothing but the truth in a way that allowed for telling more than the truth.\" Hemingway called his style the iceberg theory: the facts float above water; the supporting structure and symbolism operate out of sight. The concept of the iceberg theory is sometimes referred to as the \"theory of omission\". Hemingway believed the writer could describe one thing (such as Nick Adams fishing in \"Big Two-Hearted River\") though an entirely different thing occurs below the surface (Nick Adams concentrating on fishing to the extent that he does not have to think about anything else). Paul Smith writes that Hemingway's first stories, collected as \"In Our Time\", showed he was still experimenting with his writing style, and when he wrote about Spain or other countries he incorporated foreign words into the text, which sometimes appears directly in the other language (in italics, as occurs in \"The Old Man and the Sea\") or in English as literal translations. He also often used bilingual puns and crosslingual wordplay as stylistic devices. In general, he avoided complicated syntax. About 70 percent of the sentences are simple sentences without subordination\u2014a simple childlike grammar structure.\nJackson Benson believes Hemingway used autobiographical details as framing devices about life in general\u2014not only about his life. For example, Benson postulates that Hemingway used his experiences and drew them out with \"what if\" scenarios: \"what if I were wounded in such a way that I could not sleep at night? What if I were wounded and made crazy, what would happen if I were sent back to the front?\" Writing in \"The Art of the Short Story\", Hemingway explains: \"A few things I have found to be true. If you leave out important things or events that you know about, the story is strengthened. If you leave or skip something because you do not know it, the story will be worthless. The test of any story is how very good the stuff that you, not your editors, omit.\"\nThe simplicity of the prose is deceptive. Zoe Trodd believes Hemingway crafted skeletal sentences in response to Henry James's observation that World War\u00a0I had \"used up words\". Hemingway offers a \"multi-focal\" photographic reality. His iceberg theory of omission is the foundation on which he builds. The syntax, which lacks subordinating conjunctions, creates static sentences. The photographic \"snapshot\" style creates a collage of images. Many types of internal punctuation (colons, semicolons, dashes, parentheses) are omitted in favor of short declarative sentences. The sentences build on each other, as events build to create a sense of the whole. Multiple strands exist in one story; an \"embedded text\" bridges to a different angle. He also uses other cinematic techniques of \"cutting\" quickly from one scene to the next; or of \"splicing\" a scene into another. Intentional omissions allow the reader to fill the gap, as though responding to instructions from the author and create three-dimensional prose.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIn the late summer that year we lived in a house in a village that looked across the river and the plain to the mountains. In the bed of the river there were pebbles and boulders, dry and white in the sun, and the water was clear and swiftly moving and blue in the channels. Troops went by the house and down the road and the dust they raised powdered the trees.\n \u2014Opening passage of \"A Farewell to Arms\" showing Hemingway's use of the word \"and\"\nHemingway habitually used the word \"and\" in place of commas. This use of polysyndeton may serve to convey immediacy. Hemingway's polysyndetonic sentence\u2014or in later works his use of subordinate clauses\u2014uses conjunctions to juxtapose startling visions and images. Benson compares them to haikus. Many of Hemingway's followers misinterpreted his lead and frowned upon all expression of emotion; Saul Bellow satirized this style as \"Do you have emotions? Strangle them.\" However, Hemingway's intent was not to eliminate emotion, but to portray it more scientifically. Hemingway thought it would be easy, and pointless, to describe emotions; he sculpted collages of images in order to grasp \"the real thing, the sequence of motion and fact which made the emotion and which would be as valid in a year or in ten years or, with luck and if you stated it purely enough, always\". This use of an image as an objective correlative is characteristic of Ezra Pound, T. S. Eliot, James Joyce, and Marcel Proust. Hemingway's letters refer to Proust's \"Remembrance of Things Past\" several times over the years, and indicate he read the book at least twice.\nThemes.\nHemingway's writing includes themes of love, war, travel, wilderness, and loss. Critic Leslie Fiedler sees the theme he defines as \"The Sacred Land\"\u2014the American West\u2014extended in Hemingway's work to include mountains in Spain, Switzerland and Africa, and to the streams of Michigan. The American West is given a symbolic nod with the naming of the \"Hotel Montana\" in \"The Sun Also Rises\" and \"For Whom the Bell Tolls\". According to Stoltzfus and Fiedler, in Hemingway's work, nature is a place for rebirth and rest; and it is where the hunter or fisherman might experience a moment of transcendence at the moment they kill their prey. Nature is where men exist without women: men fish; men hunt; men find redemption in nature. Although Hemingway does write about sports, such as fishing, Carlos Baker notes the emphasis is more on the athlete than the sport. At its core, much of Hemingway's work can be viewed in the light of American naturalism, evident in detailed descriptions such as those in \"Big Two-Hearted River\".\nHemingway often wrote about Americans abroad. In \"Hemingway\u2019s Expatriate Nationalism\", Jeffrey Herlihy describes \"Hemingway's Transnational Archetype\" as one that involves characters who are \"multilingual and bicultural, and have integrated new cultural norms from the host community into their daily lives by the time plots begin.\" In this way, \"foreign scenarios, far from being mere exotic backdrops or cosmopolitan milieus, are motivating factors in-character action.\" Donald Monk comments that Hemingway's use of \"expatriation comes to be not so much a psychological as a metaphysical reality. It guarantees his world-view of his heroes, based on a type of rootless outsider.\"\nFiedler believes Hemingway inverts the American literary theme of the evil \"Dark Woman\" versus the good \"Light Woman\". The dark woman\u2014Brett Ashley of \"The Sun Also Rises\"\u2014is a goddess; the light woman\u2014Margot Macomber of \"The Short Happy Life of Francis Macomber\"\u2014is a murderess. Robert Scholes says early Hemingway stories, such as \"A Very Short Story\", present \"a male character favorably and a female unfavorably\". According to Rena Sanderson, early Hemingway critics lauded his male-centric world of masculine pursuits, and the fiction divided women into \"castrators or love-slaves\". Feminist critics attacked Hemingway as \"public enemy number one\", although more recent re-evaluations of his work \"have given new visibility to Hemingway's female characters (and their strengths) and have revealed his own sensitivity to gender issues, thus casting doubts on the old assumption that his writings were one-sidedly masculine.\" Nina Baym believes that Brett Ashley and Margot Macomber \"are the two outstanding examples of Hemingway's 'bitch women.'\"\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe world breaks everyone and afterward many are strong in the broken places. But those that will not break it kills. It kills the very good and the very gentle and the very brave impartially. If you are none of these you can be sure it will kill you too but there will be no special hurry.\n\u2014Ernest Hemingway in \"A Farewell to Arms\"\nThe theme of women and death is evident in stories as early as \"Indian Camp\". The theme of death permeates Hemingway's work. Young believes the emphasis in \"Indian Camp\" was not so much on the woman who gives birth or the father who kills himself, but on Nick Adams who witnesses these events as a child, and becomes a \"badly scarred and nervous young man\". Hemingway sets the events in \"Indian Camp\" that shape the Adams persona. Young believes \"Indian Camp\" holds the \"master key\" to \"what its author was up to for some thirty-five years of his writing career\". Stoltzfus considers Hemingway's work to be more complex with a representation of the truth inherent in existentialism: if \"nothingness\" is embraced, then redemption is achieved at the moment of death. Those who face death with dignity and courage live an authentic life. Francis Macomber dies happy because the last hours of his life are authentic; the bullfighter in the corrida represents the pinnacle of a life lived with authenticity. In his paper \"The Uses of Authenticity: Hemingway and the Literary Field\", Timo M\u00fcller writes that Hemingway's fiction is successful because the characters live an \"authentic life\", and the \"soldiers, fishers, boxers and backwoodsmen are among the archetypes of authenticity in modern literature\".\nThe theme of emasculation is prevalent in Hemingway's work, notably in \"God Rest You Merry, Gentlemen\" and \"The Sun Also Rises\". Emasculation, according to Fiedler, is a result of a generation of wounded soldiers; and of a generation in which women such as Brett gained emancipation. This also applies to the minor character, Frances Clyne, Cohn's girlfriend in the beginning of \"The Sun Also Rises\". Her character supports the theme not only because the idea was presented early on in the novel but also the impact she had on Cohn in the start of the book while only appearing a small number of times. In \"God Rest You Merry, Gentlemen\", the emasculation is literal, and related to religious guilt. Baker believes Hemingway's work emphasizes the \"natural\" versus the \"unnatural\". In \"An Alpine Idyll\" the \"unnaturalness\" of skiing in the high country late spring snow is juxtaposed against the \"unnaturalness\" of the peasant who allowed his wife's dead body to linger too long in the shed during the winter. The skiers and peasant retreat to the valley to the \"natural\" spring for redemption.\nDescriptions of food and drink feature prominently in many of Hemingway's works. In the short story \"Big Two-Hearted River\" Hemingway describes a hungry Nick Adams cooking a can of pork and beans and a can of spaghetti over a fire in a heavy cast iron pot. The primitive act of preparing the meal in solitude is a restorative act and one of Hemingway's narratives of post-war integration.\nSusan Beegel reports that Charles Stetler and Gerald Locklin read Hemingway's \"The Mother of a Queen\" as both misogynistic and homophobic, and Ernest Fontana thought that a \"horror of homosexuality\" drove the short story \"A Pursuit Race\". Beegel found that \"despite the academy's growing interest in multiculturalism ... during the 1980s ... critics interested in multiculturalism tended to ignore the author as 'politically incorrect.'\", listing just two \"apologetic articles on [his] handling of race\". Barry Gross, comparing Jewish characters in literature of the period, commented that \"Hemingway never lets the reader forget that Cohn is a Jew, not an unattractive character who happens to be a Jew but a character who is unattractive because he is a Jew.\"\nInfluence and legacy.\nHemingway's legacy to American literature is his style: writers who came after him either emulated or avoided it. After his reputation was established with the publication of \"The Sun Also Rises\", he became the spokesperson for the post-World War\u00a0I generation, having established a style to follow. His books were burned in Berlin in 1933, \"as being a monument of modern decadence\", and disavowed by his parents as \"filth\". Reynolds asserts the legacy is that \"[Hemingway] left stories and novels so starkly moving that some have become part of our cultural heritage.\"\nBenson believes the details of Hemingway's life have become a \"prime vehicle for exploitation\", resulting in a Hemingway industry. Hemingway scholar Hallengren believes the \"hard-boiled style\" and the machismo must be separated from the author himself. Benson agrees, describing him as introverted and private as J. D. Salinger, although Hemingway masked his nature with braggadocio. During World War\u00a0II, Salinger met and corresponded with Hemingway, whom he acknowledged as an influence. In a letter to Hemingway, Salinger claimed their talks \"had given him his only hopeful minutes of the entire war\" and jokingly \"named himself national chairman of the Hemingway Fan Clubs\".\nThe extent of his influence is seen from the enduring and varied tributes to Hemingway and his works. 3656 Hemingway, a minor planet discovered in 1978 by Soviet astronomer Nikolai Chernykh, was named for Hemingway, and in 2009, a crater on Mercury was also named in his honor. \"The Kilimanjaro Device\" by Ray Bradbury featured Hemingway being transported to the top of Mount Kilimanjaro, while the 1993 motion picture \"Wrestling Ernest Hemingway\" explored the friendship of two retired men, played by Robert Duvall and Richard Harris, in a seaside Florida town. His influence is further evident from the many restaurants bearing his name and the proliferation of bars called \"Harry's\", a nod to the bar in \"Across the River and Into the Trees\". Hemingway's son Jack (Bumby) promoted a line of furniture honoring his father, Montblanc created a Hemingway fountain pen, and multiple lines of clothing inspired by Hemingway have been produced. In 1977, the International Imitation Hemingway Competition was created to acknowledge his distinct style and the comical efforts of amateur authors to imitate him; entrants are encouraged to submit one \"really good page of really bad Hemingway\" and the winners are flown to Harry's Bar in Italy.\nMary Hemingway established the Hemingway Foundation in 1965, and in the 1970s she donated her husband's papers to the John F. Kennedy Library. In 1980, a group of Hemingway scholars gathered to assess the donated papers, subsequently forming the Hemingway Society, \"committed to supporting and fostering Hemingway scholarship\", publishing \"The Hemingway Review\". Numerous awards have been established in Hemingway's honor to recognize significant achievement in the arts and culture, including the Hemingway Foundation/PEN Award and the Hemingway Award.\nIn 2012, he was inducted into the Chicago Literary Hall of Fame.\nAlmost exactly 35 years after Hemingway's death, on July 1, 1996, his granddaughter Margaux Hemingway died in Santa Monica, California. Margaux was a supermodel and actress, co-starring with her younger sister Mariel in the 1976 movie \"Lipstick\". Her death was later ruled a death by suicide.\nThree houses associated with Hemingway are listed on the U.S. National Register of Historic Places: the Ernest Hemingway Cottage on Walloon Lake, Michigan, designated in 1968; the Ernest Hemingway House in Key West, designated in 1968; and the Ernest and Mary Hemingway House in Ketchum, designated in 2015. Hemingway's childhood home in Oak Park and his Havana residence were also converted into museums.\nOn April 5, 2021, \"Hemingway\", a three-episode, six-hour documentary, a recapitulation of Hemingway's life, labors, and loves, debuted on the Public Broadcasting System. It was co-produced and directed by Ken Burns and Lynn Novick.\nSelected works.\nThe following is the list of books that Ernest Hemingway completed during his lifetime. While much of his work was published posthumously, they were finished without his supervision, unlike the works listed below.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9429", "revid": "36112485", "url": "https://en.wikipedia.org/wiki?curid=9429", "title": "Young and Innocent", "text": "1937 film by Alfred Hitchcock\nYoung and Innocent, released in the US as The Girl Was Young, is a 1937 British crime thriller film directed by Alfred Hitchcock and starring Nova Pilbeam and Derrick De Marney. Based on the 1936 novel \"A Shilling for Candles\" by Josephine Tey, the film is about a young man on the run from a murder charge who enlists the help of a woman who must put herself at risk for his cause. An elaborately staged crane shot Hitchcock devised, which appears towards the end of the film, identifies the real murderer.\nPlot.\nOn a stormy night, at a retreat on the English coast, Christine Clay (Pamela Carme), a successful actress, argues passionately with her jealous ex-husband Guy (George Curzon). Not accepting her Reno divorce as valid, he accuses her of having an affair. Finally, she slaps him and he leaves the room. While they had been arguing, his eyes twitched violently; they continue to do so when, once outside, he turns angrily to look at the closed door behind him.\nThe next morning, Robert Tisdall (Derrick De Marney) happens to be walking along the seaside when Christine's dead body washes ashore. He recognizes her, and runs for help. Two young women arrive just in time to see him racing away from the corpse. The police quickly decide that Tisdall is the only suspect. Christine was strangled with the belt from a raincoat; his raincoat is missing and he says it was recently stolen. He admits knowing the victim for three years since he sold her a story but the authorities assume the two have been having an affair. When they learn that she has left him money in her will (unbeknownst to him), they feel they have hit upon a motive and Tisdall is arrested.\nScotland Yard detectives grill him all night. The next morning, he faints and is revived with the aid of Erica Burgoyne (Nova Pilbeam), daughter of the local police Chief Constable. Tisdall is assigned an incompetent solicitor, and is taken into court for his formal arraignment. Doubting if his innocence will ever be established, he takes advantage of overcrowding in the courthouse to escape, wearing the solicitor's eyeglasses as a disguise. He gets away by riding on the running board of Erica's Morris car, revealing himself to her after the car runs out of petrol.\nHe helps push the car to a filling station, pays for petrol, and convinces her to give him a ride. Though she is initially fearful and unsure about her passenger, Erica eventually becomes convinced of his innocence and decides to help him in any way that she can. They are eventually spotted together, forcing both to stay on the run from the police. Tisdall tries to prove his innocence by tracking down the stolen coat: if it still has its belt, the one found next to Christine's body must not be his.\nThe duo succeed in tracing Tisdall's coat to Old Will (Edward Rigby), a homeless, but sociable, china-mender. But Will was not the thief; he was given the coat by a man with \"twitchy eyes\", and with its belt already missing.\nAfter becoming separated from the others, Erica is taken in by the police. Upon realizing that his daughter has fully allied herself with a murder suspect, her father chooses to resign his position as Chief Constable rather than arrest her for assisting a felon. Though mutually undeclared, by this point she and Tisdall are in love, Tisdall sneaks into their house to see her, intending to surrender and assert he kidnapped her, to save her honour and her father's reputation. But she mentions that the coat had a box of matches from the Grand Hotel in a pocket. As Tisdall has never been there, he surmises perhaps the murderer has a connection to the hotel.\nThe following evening, Erica and Will go to the hotel together, hoping to find him. In a memorably long, continuous sequence, the camera pans right from their entrance to the hotel and then moves forward from the very back of the hotel ballroom, finally focusing in extreme closeup on the drummer in a dance band performing in blackface. His eyes are twitching. He is Guy, the murderer.\nRecognizing Old Will in the audience, and seeing policemen nearby (who have actually followed Will hoping he'll lead them to Tisdall), Guy performs poorly due to fear. He is berated by the conductor and, during a break, takes medicine to try to control the twitching, but it makes him very sleepy. Eventually, in mid-performance, Guy passes out, drawing the attention of Erica and the police. Immediately after being revived and confronted, he confesses his crime and begins laughing hysterically.\nReunited once again with Tisdall, Erica then tells her father that she thinks it is time they invited him to their home for dinner.\nMain cast.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReception.\n\"Variety\" called the film a \"Pleasing, artless vehicle\" for Nova Pilbeam, who was \"charming\" in her role and concluded, \"If the pic is not Hitchcock's best effort, it is by no means unworthy of him.\" Frank Nugent of \"The New York Times\" called it a \"crisply paced, excellently performed film.\" \"The Monthly Film Bulletin\" wrote, \"Innumerable small touches show Hitchcock's keen and penetrating observation and his knowledge of human nature. Comedy, romance, and thrills are skilfully blended.\" \"Harrison's Reports\" wrote, \"Good melodramatic entertainment. Because of the novelty of the story, the interesting plot developments, and the expert direction by Alfred Hitchcock, one's attention is held from the beginning to the end.\" John Mosher of \"The New Yorker\" wrote that it was \"rather exasperating and disappointing to me. It begins with a smart murder, but wanders off through the English rural landscape in a fashion so lacking in that sound common sense we like in our mysteries, or like to feel is there anyhow, that one's interest fades away.\"\nAggregator Rotten Tomatoes reports 100% approval of \"Young and Innocent\", with an average rating of 7.6/10.\nChanges from the novel.\nSignificant changes were made in adapting the book for the film. The novel is a whodunit centred on the Scotland Yard inspector, who is Tey's regular character Alan Grant. The storyline involving Robert Tisdall, Erica Burgoyne, and the missing coat is similar to the film story, but in the novel it is only a subplot and ends part way through the book when Erica finds the coat and it is intact. Grant then focuses on other suspects, none of whom (including the actual murderer in the novel) appear in the film. Christine Clay in the novel is not divorced, but is in an unconventional marriage to an aristocrat.\nHitchcock's cameo.\nAlfred Hitchcock's cameo is a signature occurrence in most of his films. He can be seen outside the courthouse, holding a camera, at 14 minutes into the film.\nCopyright and home video status.\n\"Young and Innocent\", like all of Hitchcock's British films, is copyrighted worldwide but has been heavily bootlegged for home video. Despite this, licensed releases have appeared on Blu-ray, DVD and video on demand services worldwide from the likes of Network Distributing in the UK, MGM and The Criterion Collection in the US, and others.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9430", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9430", "title": "Things Turn Sour", "text": ""}
{"id": "9431", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9431", "title": "The Endless Dark Nothingness", "text": ""}
{"id": "9432", "revid": "14471692", "url": "https://en.wikipedia.org/wiki?curid=9432", "title": "The Time in Between", "text": "2005 novel by David Bergen\nThe Time in Between is a novel by Canadian author David Bergen. It deals with a man, who mysteriously returns to Vietnam, where he had been a soldier earlier in his life, followed by his children, who also go to Vietnam to search for him. The novel was the recipient of the Scotiabank Giller Prize and the McNally Robinson Book of the Year Award in 2005.\nPlot.\nCharles Boatman, an army veteran suddenly disappears and his daughter Ada and her younger brother Jon on finding some clues go looking out for him in Danang, Vietnam. The novel mixes various stories from different timeframes narrating Charles's days in Washington when he was young. He married Sara and had daughter Ada while living in Fraser Valley of British Columbia. He gets posted in the wartime era to Vietnam and serves there and upon arrival discovers his wife's infidelity. Sara dies early and by then they also had a son Jon. Charles keeps getting nightmares of his Vietnam days on how he killed an innocent civilian boy in one of the operations and this keeps haunting him. On the other hand, Ada is on a mission to find her father and is helped by a local guy Yen who becomes her guide and guardian in the new country. She engages in a sexual relationship with an older man, Hoang Vu who is an artist by profession. Jon indulges in the nightlife of Vietnam, and Ada keeps getting closer to her father as she travels across the country. Charles discovers author Dang Tho's novel chronicling wartime and this helps him find some peace.\nPublication and development.\nThe book is author David Bergen's fifth novel. Although generally called a war novel, the author states that he \"[doesn't] see \"The Time in Between\" as a war novel\". The book was released as Audio book by Blackstone Audio in December 2005 and was narrated by Anna Fields, better known as Kate Fleming.\nReviews and reception.\n\"Kirkus reviews\" called the novel a \"beautifully composed, unflinching and harrowing story\". Nicholas Dinka in their \"Quill &amp; Quire\" review mentions that the novel has \"much decency and intelligence\" and both the stories of the novel are \"entirely plausible\" but criticises for \"remarkable dourness of its prose\". While Dennis Lythgoe of \"Deseret News\" noted that \"Bergen's book lives and breathes the Vietnam experience\"; Ron Charles in his \"The Washington Post\" review mentioned that \"Bergen's ability to dramatize trauma-induced disaffection is undeniable; whether readers will want to sink down that hole with his characters is less clear\". Irene Wanner of \"The Seattle Times\" appreciated the novel for its writing.\nThe novel won the Scotiabank Giller Prize in 2005 while being nominated along with \"Luck\" (by Joan Barfoot), \"Sweetness in the Belly\" (by Camilla Gibb), \"Alligator\" (by Lisa Moore), and \"A Wall of Light\" (by Edeet Ravel). The judges Warren Cariou, Elizabeth Hay, and Richard B. Wright noted \"\"The Time in Between\" explores our need to understand the relationship between love and duty...[] This is a subtle and elegantly written novel by an author in complete command of his talent\". It also won the McNally Robinson Book of the Year Award in 2005. Bergen had earlier won the award in 1996 for \"A Year of Lesser\" and later again won in 2009 for \"The Retreat\". Dan Zigmond of \"SFGate\" reviews the novel as \"a rich and rewarding novel\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9433", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=9433", "title": "Spain in Flames", "text": "Spain in Flames is a 1937 compilation film made by Helen van Dongen during the Spanish Civil War. Hal Erickson has written that the film \"... is remarkable in its willingness to offer both sides of the conflict -- though its sympathies are firmly with the Loyalists.\" The film consists of two parts. The first, \"The Fight for Freedom\", was based on film footage from a Spanish government documentary \"Spain and the Fight for Freedom\". A foreword by the then Spanish Ambassador to the United States, Fernando de los R\u00edos, began one of the film's screenings in New York in 1937.\nThe second part, \"They Shalt Not Pass\", was based on a short film \"No Pasaran!\" done by the Artkino Film Company of the Soviet Union, where van Dongen was working at the time the film was made. John Dos Passos narrated parts of the film, and the commentary was written by Dos Passos, Ernest Hemingway, Archibald MacLeish, and Prudencio de Pareda. Erickson writes that, \"The horrendous images of battlefield carnage, not to mention the close-ups of suffering and dying Spanish children, still pack a wallop when seen today.\"\nLater, Hemingway, Dos Passos, Lillian Hellman and others founded the company Contemporary Historians, which produced another film called \"The Spanish Earth\" (1937), directed by Joris Ivens and edited by van Dongen.\n\"Spain in Flames\" was banned in New Brunswick, New Jersey and Waterbury, Connecticut. A screening of the film, accompanied by a speech from Granville Hicks, was also banned in Provincetown, Massachusetts.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9434", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9434", "title": "Ernest Hemingway/For Whom the Bell Tolls", "text": ""}
{"id": "9435", "revid": "39761822", "url": "https://en.wikipedia.org/wiki?curid=9435", "title": "Frederic Henry", "text": ""}
{"id": "9436", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9436", "title": "Ernest Hemingway/Robert Jordan", "text": ""}
{"id": "9437", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9437", "title": "Famous at Twenty-Five Thirty a Master", "text": ""}
{"id": "9438", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9438", "title": "From Boy to Man Hemingways First World War", "text": ""}
{"id": "9439", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9439", "title": "From Reality to Fiction A Farewell to Arms", "text": ""}
{"id": "9440", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9440", "title": "Sure Shots The Second World War", "text": ""}
{"id": "9441", "revid": "45076379", "url": "https://en.wikipedia.org/wiki?curid=9441", "title": "The Downward Spiral", "text": "The Downward Spiral is the second studio album by American industrial rock band Nine Inch Nails, released on March 8, 1994, by Nothing Records in the United States and Island Records in Europe. It is a concept album detailing the self-destruction of a man from the beginning of his misanthropic \"downward spiral\" to his suicidal breaking point. The album was a commercial success and established Nine Inch Nails as a reputable force in the 1990s music scene, with its sound being widely imitated, and the band receiving media attention and multiple honors.\nBand frontman Trent Reznor had moved to 10050 Cielo Drive in Benedict Canyon, Los Angeles, the site of the murder of actress Sharon Tate by members of the Manson Family in 1969; it was transformed into a studio for recording the \"Broken\" EP (1992) and subsequently \"The Downward Spiral\". The album features elements of industrial rock, techno, metal and ambient soundscapes, in contrast to the band's synth-pop-influenced debut album \"Pretty Hate Machine\" (1989). Reznor was strongly influenced by David Bowie's \"Low\" and Pink Floyd's \"The Wall\" for their themes of introspection and dissociation, and their focus on texture and space.\n\"The Downward Spiral\" has been regarded by music critics and audiences as one of the most important albums of the 1990s, and was praised for its abrasive and eclectic nature and dark themes, although it was sensationalized by social conservatives for some of its lyrics. The album spawned two lead singles, \"March of the Pigs\" and \"Closer\", in addition to the promotional singles \"Piggy\" and \"Hurt\". The lead singles were accompanied by music videos, with the former shot twice and the latter being heavily censored. A remix album titled \"Further Down the Spiral\" was released in 1995.\nWriting and recording.\nReznor conceived of \"The Downward Spiral\" after Nine Inch Nails' run in the lineup of the Lollapalooza festival tour, feeling increasingly alienated and disinterested. The band's concerts were known for their radical onstage dynamic in which members acted aggressively, injured themselves, destroyed instruments and polluted stages. Reznor had begun to feud with TVT Records, resulting in him co-founding Nothing Records with his then-manager John Malm, Jr. as a subsidiary of Interscope. Simultaneously, he began fleshing out the concept for \"The Downward Spiral\", focusing on the life and death of a misanthropic man who rebels against humanity, and kills God before attempting suicide. Reznor frequently struggled with drug addiction and depression, and the themes of the album gradually allegorized his living situation. His peers at some point recommended him the antidepressant Prozac, but he declined to be medicated.\nReznor wanted the album's sound to diverge from the abrasion of \"Broken\", emphasizing mood, texture, restraint and subtlety, although he was unsure about its musical direction. The album's production was decided on to aim for \"full range\" sound, and he focused on texture and space, avoiding conventional usage of guitars or synthesizers with a recognizable sound palette. Subsequently, he mainly worked with a Macintosh computer, using music editor programs on the computer to analyze and invert frequencies in tracks as a form of sound design.\nReznor searched for and moved to 10050 Cielo Drive in 1992 for recording \"Broken\" and \"The Downward Spiral\", a decision made against his initial choice to record the album in New Orleans. 10050 Cielo Drive is referred to as the \"Tate House\" since Sharon Tate was murdered by members of the Manson Family in 1969; Reznor named the studio \"Le Pig\" after the message that was scrawled on the front door with Tate's blood by her murderers, and stayed there with Malm for 18 months. He called his first night in 10050 Cielo Drive \"terrifying\" because he already knew it and read books related to the incident. Reznor chose the Tate house to calibrate his engineering skills and the band bought a large console and two Studer machines as resources, a move that he believed was cheaper than renting.\nReznor collaborated with Jane's Addiction and Porno for Pyros drummer Stephen Perkins, progressive rock guitarist Adrian Belew, and Nine Inch Nails drummer Chris Vrenna. Belew's first visit to the studio involved playing the guitar parts in \"Mr. Self-Destruct\", and he was told to play freely, think on reacting to melodies, concentrate on rhythm, and use noise. This approach improved Reznor's confidence in the instrument: he found it to be more expressive than the keyboard due to the interface. Belew praised Reznor for his \"command of technology,\" and commented that the music of Nine Inch Nails made innovations \"that are in [his] realm.\" Vrenna and Perkins played drum parts recorded live in the studio; the tracks were rendered into looped samples. Reznor took a similar approach to recording guitar parts: he would tape 20- to 25-minute-long sessions of himself playing guitars on a hard disc recorder with the Studio Vision sequencer.\nReznor frequently sampled excerpts from his guitar session tracks and processed them to sporadic and expressive points to convey the album's themes, also doing the same with drum parts. Digidesign's TurboSynth and Zoom 9030 effects unit were used extensively to process guitar tracks, often in conjunction with a Marshall JMP-1 preamp; Zoom 9030 was also used to distort vocals. Acoustic drums in various settings, as well as Roland's TR-808 and R-70 drum machines were sampled through multiple Akai S1000s and a Kurzweil K2000. Additionally, Vrenna had compiled various movie samples on Digital Audio Tapes for Reznor to sample, which were gradually identified by fans in the decades following the album's release. Other equipments and software Reznor used for recording the album include Oberheim OB-Mx, Minimoog, Prophet VS keyboard, Eventide H3000 Harmonizer, Pro Tools and various Jackson and Gibson guitars.\nIn December 1993, Reznor was confronted by Patti Tate, who asked if he was exploiting Sharon Tate's death in the house. Reznor responded that he was interested in the house as her death happened there. He later made a statement about this encounter during a 1997 interview with \"Rolling Stone\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;While I was working on \"[The] Downward Spiral\", I was living in the house where Sharon Tate was killed. Then one day I met her sister [Patti Tate]. It was a random thing, just a brief encounter. And she said: 'Are you exploiting my sister's death by living in her house?' For the first time, the whole thing kind of slapped me in the face. I said, 'No, it's just sort of my own interest in American folklore. I'm in this place where a weird part of history occurred.' I guess it never really struck me before, but it did then. She lost her sister from a senseless, ignorant situation that I don't want to support. When she was talking to me, I realized for the first time, 'What if it was my sister?' I thought, 'Fuck Charlie Manson.' I went home and cried that night. It made me see there's another side to things, you know?\nBritish producer and engineer Flood, known for engineering and producing U2 and Depeche Mode albums, was employed as co-producer on \"The Downward Spiral\"; it became his last collaboration with Nine Inch Nails due to creative differences. For instance, a \"very dangerously self-destructive\" yet humorous short song written for the album, \"Just Do It\", was not included in the final version, criticized by Flood who said that Reznor had \"gone too far.\" Reznor completed the last song written for the album, \"Big Man with a Gun\", in late 1993. After the album's recording, Reznor moved out and the house was demolished shortly thereafter. \"The Downward Spiral\" entered its mixing and mastering processes, done at the Record Plant and A&amp;M Studios with Alan Moulder, who subsequently took on more extensive production duties for future album releases.\nMusic and lyrics.\nNumerous layers of metaphors are present throughout \"The Downward Spiral\", leaving it open to wide interpretation. The album relays nihilism and is defined by a prominent theme of self-abuse and self-control. It is a semi-autobiographical concept album, in which the overarching plot follows the protagonist's descent into madness in his own inner solipsistic world through a metaphorical \"downward spiral\", dealing with religion, dehumanization, violence, disease, society, drugs, sex, and finally, suicide. Reznor described the concept as consisting of \"someone who sheds everything around them to a potential nothingness, but through career, religion, relationship, belief and so on.\" Media journalists like \"The New York Times\" writer Jon Pareles noted the album's theme of angst had already been used by grunge bands like Nirvana, and that Nine Inch Nails' depiction was more generalized.\nUsing elements of genres such as techno, dance, electronic, heavy metal, and hard rock, \"The Downward Spiral\" is considered an industrial rock, alternative rock, industrial metal, industrial, and art rock album. Reznor regularly uses noise and distortion in his song arrangements that do not follow verse\u2013chorus form, and incorporates dissonance with chromatic melody or harmony (or both). The treatment of metal guitars in \"Broken\" is carried over to \"The Downward Spiral\", which includes innovative techniques such as expanded song structures and unconventional time signatures. The album features a wide range of textures and moods to illustrate the mental progress of the central protagonist. Reznor's singing follows a similar pattern from beginning to end, frequently moving from whispers to screams. These techniques are all used in the song \"Hurt\", which features a highly dissonant tritone played on guitar during the verses, a B5#11, emphasized when Reznor sings the eleventh note on the word \"I\" every time the B/E# dyad is played.\n\"Mr. Self Destruct\", a song about a powerful person, follows a build-up sampled from the 1971 film \"THX 1138\" with an \"industrial roar\" and is accompanied by an audio loop of a pinion rotating. \"The Becoming\" expresses the state of being dead and the protagonist's transformation into a non-human organism. \"Closer\" concludes with a chromatic piano motif: The melody is introduced during the second verse of \"Piggy\" on organ, then reappears in power chords at drop D tuning throughout the chorus of \"Heresy\", and recurs for the final time on \"The Downward Spiral\". The album was chiefly inspired by David Bowie's \"Low\", an experimental rock album which Reznor related to on songwriting, mood, and structures, as well as progressive rock group Pink Floyd's \"The Wall\", a concept album featuring themes of abuse, isolation, and mental instability.\nPackaging.\n\"Committere\", an installation featuring artwork and sketches for \"The Downward Spiral\", \"Closer\" and \"March of the Pigs\" by Russell Mills was displayed at the Glasgow School of Art. Mills explained the ideas and materials that made up the painting (titled \"Wound\") that was used for the album's cover art:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I had been thinking about making works that dealt with layers, physically, materially and conceptually. I wanted to produce works that were about both exposure and revealing and at the same dealt with closure and covering. Given the nature of the lyrics and the power of the music I was working with, I felt justified in attempting to make works that alluded to the apparently contradictory imagery of pain and healing. I wanted to make beautiful surfaces that partially revealed the visceral rawness of open wounds beneath. The mixed media work 'Wound' was the first piece I tackled in this vein (no pun intended) and it became the cover of the album. It is made of plaster, acrylics, oils, rusted metals, insects, moths, blood (mine), wax, varnishes, and surgical bandaging on a wooden panel.\nPromotion.\nSingles.\n\"March of the Pigs\" and \"Closer\" were released as singles; two other songs, \"Hurt\" and \"Piggy\", were issued to radio without a commercial single release. \"March of the Pigs\" has an unusual meter, alternating three bars of 7/8 time with one of 8/8. The song's music video was directed by Peter Christopherson and was shot twice; the first version scrapped due to Reznor's involvement, and the released second version being a live performance.\n\"Closer\" features a heavily modified bass drum sample from the Iggy Pop song \"Nightclubbing\" from his album \"The Idiot\". Lyrically, it is a meditation on self-hatred and obsession, but to Reznor's dismay, the song was widely misinterpreted as a lust anthem due to its chorus, which included the line \"I wanna fuck you like an animal\". The music video for \"Closer\" was directed by Mark Romanek and received frequent rotation on MTV, though the network heavily censored the original version, which they perceived to be too graphic. The video shows events in a laboratory dealing with religion, sexuality, animal cruelty, politics, and terror; controversial imagery included a nude bald woman with a crucifix mask, a monkey tied to a cross, a pig's head spinning on a machine, a diagram of a vulva, Reznor wearing an S&amp;M mask while swinging in shackles, and of him wearing a ball gag. A radio edit that partially censored the song's explicit lyrics also received extensive airtime. The video has since been made part of the permanent collection of the Museum of Modern Art in New York City.\n\"Piggy\" uses \"nothing can stop me now\", a line that recurs in \"Ruiner\" and \"Big Man with a Gun\". The frantic drumming on the song's outro is Reznor's only attempt at performing drums on the record, and one of the few \"live\" drum performances on the album. He had stated that the recording was from him testing the microphone setup in studio, but he liked the sound too much not to include it. It was released as a promotional single in December 1994 and reached the Top 20 on the \"Billboard\" Modern Rock Tracks chart.\nReleased in 1995, \"Hurt\" clearly includes references to self-harm and heroin addiction.\nTour.\nThe Nine Inch Nails live band embarked on the Self Destruct tour in support of \"The Downward Spiral\". Chris Vrenna and James Woolley performed drums and keyboards respectively, Robin Finck replaced Richard Patrick on guitar and bassist Danny Lohner was added to the line-up. The stage set-up consisted of dirty curtains which would be pulled down and up for visuals shown during songs such as \"Hurt\". The back of the stage was littered with darker and standing lights, along with very few actual ones. The tour debuted the band's grungy and messy image in which they would come out in ragged clothes slathered in corn starch. The concerts were violent and chaotic, with band members often injuring themselves. They would frequently destroy their instruments at the end of concerts, attack each other, and stage-dive into the crowd.\nThe tour included a set at Woodstock '94 broadcast on pay-per-view and seen in as many as 24\u00a0million homes. The band being covered in mud was a result of pre-concert backstage play, contrary to the belief that it was an attention-grabbing ploy, thus making it difficult for Reznor to navigate the stage: Reznor pushed Lohner into the mud pit as the concert began and saw mud from his hair entering his eyes while performing. Nine Inch Nails was widely proclaimed to have \"stolen the show\" from its popular contemporaries, mostly classic rock bands, and its fan base expanded. The band received considerable mainstream success thereafter, performing with significantly higher production values and the addition of various theatrical visual elements. Its performance of \"Happiness in Slavery\" from the Woodstock concert earned the group a Grammy Award for Best Metal Performance in 1995. \"Entertainment Weekly\" commented about the band's Woodstock '94 performance: \"Reznor unstrings rock to its horrifying, melodramatic core\u2014an experience as draining as it is exhilarating\". Despite this acclaim, Reznor attributed his dislike of the concert to its technical difficulties.\nThe main leg of the tour featured Marilyn Manson as the supporting act, who featured bassist Jeordie White (then playing under the pseudonym \"Twiggy Ramirez\"); White later played bass with Nine Inch Nails from 2005 to 2007. After another tour leg supporting the remix album \"Further Down the Spiral\", Nine Inch Nails contributed to the Alternative Nation Festival in Australia and subsequently embarked on the Dissonance Tour, which included 26 separate performances with co-headliner David Bowie on his Outside Tour. Nine Inch Nails was the opening act for the tour, and its set transitioned into Bowie's set with joint performances of both bands' songs. However, the crowds reportedly did not respond positively to the pairing due to their creative differences. Despite this, in a 2012 \"Rolling Stone\" readers' poll, the tour (pairing Nine Inch Nails with Bowie) was named one of the top 10 opening acts in rock history.\nThe tour concluded with \"Nights of Nothing\", a three-night showcase of performances from Nothing Records bands Marilyn Manson, Prick, Meat Beat Manifesto, and Pop Will Eat Itself, which ended with an 80-minute set from Nine Inch Nails. \"Kerrang!\" described the Nine Inch Nails set during the Nights of Nothing showcase as \"tight, brash and dramatic\", but was disappointed at the lack of new material. On the second of the three nights, Richard Patrick was briefly reunited with the band and contributed guitar to a performance of \"Head Like a Hole\". After the Self Destruct tour, Chris Vrenna, member of the live band since 1988 and frequent contributor to Nine Inch Nails studio recordings, left the act permanently to pursue a career in producing and to form Tweaker.\nRelease and reception.\n\"The Downward Spiral\"'s release date was delayed at various times to slow down Reznor's intended pace of the album's recording. The first delay caused the process of setting up Le Pig to take longer than he expected, and its release was postponed again as he was educating himself different ways to write songs that did not resemble those on \"Broken\" and \"Pretty Hate Machine\". He considered delivering the album to Interscope in early 1993, only to experience a writer's block as he was unable to produce any satisfactory material. Interscope grew impatient and concerned with this progress, but Reznor was not forced by their demands of expediency despite crediting the label for giving him creative freedom. He told rock music producer Rick Rubin that his motivation for creating the album was to get it finished, thus Rubin responded that Reznor might not do so until he makes music that is allowed to be heard. Reznor realized that he was in the most fortunate situation he imagined when the album was recorded with a normal budget, \"cool\" equipment, and a studio to work at.\nReleased on March 8, 1994, to instant success, \"The Downward Spiral\" debuted at number two on the US \"Billboard\" 200, selling nearly 119,000 copies in its first week. On October 28, 1998, the Recording Industry Association of America (RIAA) certified the album quadruple platinum, and by December 2011, it had sold 3.7\u00a0million copies in the United States. The album peaked at number nine on the UK Albums Chart, and on July 22, 2013, it was certified gold by the British Phonographic Industry (BPI), denoting shipments in excess of 100,000 copies in the United Kingdom. It reached number 13 on the Canadian \"RPM\" albums chart and received a triple platinum certification from the Canadian Recording Industry Association (CRIA) for shipping 200,000 copies in Canada. A group of early listeners of the album viewed it as \"commercial suicide\", but Reznor did not make it for profit as his goal was to slightly broaden Nine Inch Nails' scope. Reznor felt that the finished product he delivered to Interscope was complete and faithful to his vision and thought its commercial potential was limited, but after its release he was surprised by the success and received questions about a follow-up single with a music video to be shown on MTV. The album has since sold over four million copies worldwide.\nMany music critics and audiences praised \"The Downward Spiral\" for its abrasive, eclectic nature and dark themes and commented on the concept of a destruction of a man. \"The New York Times\" writer Jon Pareles' review of the album found the music to be highly abrasive. Pareles asserted that unlike other electro-industrial groups like Ministry and Nitzer Ebb, \"Reznor writes full-fledged tunes\" with stronger use of melodies than riffs. He noticed criticisms of Nine Inch Nails from industrial purists for popularizing the genre and the album's transgression. \"Village Voice\" critic Robert Christgau gave it an \"honorable mention\" in his capsule review column and summed the record up as, \"musically, Hieronymus Bosch as postindustrial atheist; lyrically, Transformers as kiddie porn.\" Jonathan Gold, writing for \"Rolling Stone\", likened the album to cyberpunk fiction. \"Entertainment Weekly\" reviewer Tom Sinclair commented: \"Reznor's pet topics (sex, power, S&amp;M, hatred, transcendence) are all here, wrapped in hooks that hit your psyche with the force of a blowtorch.\"\nAccolades.\n\"The Downward Spiral\" has been listed on several publications' best album lists. In 2003, the album was ranked number 200 on \"Rolling Stone\" magazine's list of The 500 Greatest Albums of All Time, then was re-ranked 201 in a 2012 revised list. The \"Rolling Stone\" staff wrote: \"Holing up in the one-time home of Manson-family victim Sharon Tate, Trent Reznor made an overpowering meditation on NIN's central theme: control.\" It moved up to 122 on the magazine's revised list in 2020. The album was placed 10th on \"Spin\"'s \"125 Best Albums of the Past 25 Years\" list; the \"Spin\" staff quoted Ann Powers' review that appreciated its bleak, aggressive style. It was ranked number 488 in the book \"The Top 500 Heavy Metal Albums of All Time\" by heavy metal music critic Martin Popoff. In 2001, \"Q\" named \"The Downward Spiral\" as one of the \"50 Heaviest Albums of All Time\"; in 2010, the album was ranked number 102 on their \"250 Best Albums of Q's Lifetime (1986\u20132011)\" list. \"The Downward Spiral\" was featured in Robert Dimery's book \"1001 Albums You Must Hear Before You Die\". In May 2014, \"Loudwire\" placed \"The Downward Spiral\" at number two on its \"10 Best Hard Rock Albums of 1994\" list. In July 2014, \"Guitar World\" placed \"The Downward Spiral\" at number 43 in their \"Superunknown: 50 Iconic Albums That Defined 1994\" list.\nLegacy.\nThe immediate success of \"The Downward Spiral\" established Nine Inch Nails as a reputable force in the 1990s. The band's image and musical style became so recognizable that a Gatorade commercial featured a remix of \"Down in It\" without their involvement. Reznor felt uncomfortable with the media hype and success the band earned, received false reports of his death, depression, and was falsely reported to have had a relationship with serial killer Jeffrey Dahmer, and was depicted as a sex icon due to his visual appearance. Nine Inch Nails received several honors, including Grammy Award nominations for Best Alternative Performance for \"The Downward Spiral\" and Best Rock Song for \"Hurt\". After the release of \"The Downward Spiral\", many bands such as Gravity Kills, Stabbing Westward, Filter, and M\u00f6tley Cr\u00fce made albums that imitated the sound of Nine Inch Nails.\nReznor interpreted \"The Downward Spiral\" as an extension of himself that \"became the truth fulfilling itself,\" as he experienced personal and social issues presented in the album after its release. He had already struggled with social anxiety disorder and depression and started his abuse of narcotics including cocaine while he went on an alcohol binge. Around this time, his studio perfectionism, struggles with addiction, and bouts of writer's block prolonged the production of \"The Fragile\", and Reznor completed rehabilitation from drugs in 2001.\nOne year after \"The Downward Spiral\"\u2019s release, the band released an accompanying remix album titled \"Further Down the Spiral\". It features contributions from Coil with Danny Hyde, J. G. Thirlwell, electronic musician Aphex Twin, producer Rick Rubin, and Jane's Addiction guitarist Dave Navarro. The album peaked at number 23 on the \"Billboard\" 200 and received mixed reviews. \"Recoiled\", a remix EP of \"Gave Up\", \"Closer\", \"The Downward Spiral\", and \"Eraser\" by Coil, was released on February 24, 2014, via British record label Cold Spring.\nRetrospective reviews regard \"The Downward Spiral\" as one of the most important albums of the 1990s and Reznor's greatest work. The 2004 edition of \"The New Rolling Stone Album Guide\" gave the album five out of five stars and called it \"a powerful statement, and one of the landmark albums of the Nineties.\" Writing for \"Entertainment Weekly\", Kyle Anderson remembered watching the music video of \"Closer\" on MTV as an adolescent and expressed that the album changed his perception of popular music from that of songs heard on the radio to albums with cover art. \"Stereogum\"'s Tom Breihan remains favorable toward the album since influenced youth culture, with teenagers wearing ripped fish nets on their arms. The album was also included in the book \"1001 Albums You Must Hear Before You Die\". According to Acclaimed Music, it is the 162nd most acclaimed album, based on appearances in critics' all-time lists.\nControversies.\n\"Big Man with a Gun\" lyrics.\n\"The Downward Spiral\"'s emphasis on transgressive themes drew criticism from American social conservatives. Senator Bob Dole, then the head of the Republican Party, sharply denounced Time Warner, the former owner of Interscope's former parent company Warner Music Group, after a meeting between Michael J. Fuchs (head of WMG), William Bennett, and C. Delores Tucker. During the meeting, Tucker and Bennett demanded that Fuchs recite lyrics from \"Big Man with a Gun\". Interscope had previously been blamed for releasing gangsta rap albums by rappers such as Dr. Dre, Tupac Shakur and Snoop Dogg that were deemed objectionable. Reznor called Tucker (who erroneously referred to Nine Inch Nails as a gangsta rap act) \"such a fucking idiot\", and claimed that the song was actually a satire of the gangsta rap genre as a whole and was originally about madness. Reznor conceded \"The Downward Spiral\" could be \"harmful, through implying and subliminally suggesting things\", whereas hardcore hip hop could be \"cartoonish\". Robert Bork also repeatedly referenced \"Big Man with a Gun\" in his book \"Slouching Toward Gomorrah\" as evidence of a cultural decline. The book also incorrectly states that it is a rap song.\nAlleged contribution to the Columbine shooting.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nAnother form of the Downward Spiral\u00a0... deeper &amp; deeper it goes. to cuddle w. her, to be one w. her, to love; just laying there. I need a gun. This is a weird entry\u00a0... I should feel happy, but shit brought me down.\nDylan Klebold from one of his journals two years before the shooting.\nBefore the Columbine High School massacre, perpetrator Dylan Klebold referenced lyrics from Nine Inch Nails songs multiple times in his journal. Klebold heavily identified with the protagonist of \"The Downward Spiral\" as a symbol of his own depression. On May 4, 1999, a hearing on the marketing and distribution practices of violent content to minors by the television, music, film, and video game industries was conducted before the United States Senate Committee on Commerce, Science and Transportation. The committee heard testimony from cultural observers, professors, and mental health professionals, that included conservative William Bennett and the Archbishop of Denver, Reverend Charles J. Chaput. Participants criticized the album, Nine Inch Nails' label-mate Marilyn Manson, and the 1999 film \"The Matrix\" for their alleged contribution to the environment that made incidents like Columbine possible. The committee requested that the Federal Trade Commission and the United States Department of Justice investigate the entertainment industry's marketing practices to minors.\niPhone application refusal.\nIn 2009, Apple rejected a proposal for a Nine Inch Nails iPhone software application, citing objectionable content in the title track. Days later, Apple reversed the decision, but refused to explain its reasoning.\nTrack listing.\nOriginal release.\nNotes\nDeluxe edition (Halo 8 DE).\nTo mark the album's tenth anniversary, \"The Downward Spiral\" was re-released on November 23, 2004, in high-resolution SACD and DualDisc formats. Disc one of the album's deluxe edition re-release is nearly identical to the original version; track anomalies such as sounds from previous tracks creeping up on start of tracks are fixed, and it includes a stereo and multi-channel SACD layer. The second bonus disc is a collection of remixes and B-sides and also includes a stereo SACD layer in addition to the Redbook CD layer. The last three tracks on the bonus disc are previously unreleased demo recordings from the original album.\n\"DualDisc\" (Halo 8 DVD-A)\nThe DualDisc edition of \"The Downward Spiral\" contains the same CD content on Side A as the Deluxe Edition, with a DVD-Audio layer on Side B. When played on DVD-Video players a Dolby Digital 5.1 multi-channel or Dolby Digital 2.0 stereo mix of \"The Downward Spiral\" can be selected, along with videos of \"March of the Pigs\", \"Hurt\" and an uncensored video of \"Closer\". There is also an interactive discography and an image gallery. High resolution 24-bit/48\u00a0kHz 5.1 Surround sound and stereo versions of \"The Downward Spiral\" can be played on a DVD-Audio player, allowing the user a similar high fidelity experience as the SACD layer of the Deluxe Edition. The DualDisc release does not contain the additional B-sides and demo tracks.\nPersonnel.\nCredits adapted from the liner notes of \"The Downward Spiral\".\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9442", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9442", "title": "Violence and Redemption", "text": ""}
{"id": "9443", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9443", "title": "Why It Went Wrong", "text": ""}
{"id": "9444", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9444", "title": "Ernest Hemingway/Bibliography", "text": ""}
{"id": "9447", "revid": "1719098", "url": "https://en.wikipedia.org/wiki?curid=9447", "title": "Egyptian Lover", "text": "American rapper\nGregory James Broussard (born August 31, 1963), better known by his stage name Egyptian Lover, is an American musician, vocalist, producer and DJ, and was a part of the L.A. dance music, electro, and rap scene in the early 1980s.\nHistory.\nThe Egyptian Lover was born in Los Angeles, California, and started out there as a DJ with Uncle Jamm's Army, DJing dances as large as the L.A. Sports Arena with 10,000 people. He began recording around Los Angeles in 1982 as a member of the Radio Crew, as well as Uncle Jamm's Army. Members of Uncle Jamm's Army and the World Class Wreckin' Cru, including Dr. Dre, The Unknown DJ, Egyptian Lover, Ice-T and Kid Frost would later go on to help define the early West Coast Hip-Hop sound throughout the 1980s.\nMost of the Egyptian Lover's successful recordings were 12\" singles. \"Egypt, Egypt\" was one of the most popular, which was called part of the \"b-boy canon.\" He eventually released some of the earliest rap LPs, but they were less popular commercially than his singles. On the strength of an alternate mix of his most popular single \"Egypt, Egypt\", 1984's \"On the Nile\" was moderately successful, reaching the Billboard Top 200. It was called \"one of the first hip-hop records to come out of the left coast\". He also collaborated with several other hip-hop and dance music artists. After a break in the early 1990s, Egyptian Lover returned in 1994 with \"Back from the Tomb\", his first full-length album in over ten years.\nThe Egyptian Lover also established his own record company, Egyptian Empire Records, which included artists such as Rodney O &amp; Joe Cooley, 2 O'Clock &amp; Te &amp; Joezee.\nHis 2015 release, \"1984\", continues his tradition of using all analog equipment, including the Roland TR-808, along with much of the same gear used on his recordings of the 1980s. The name \"1984\" refers to his earlier albums. The album was recorded at Skip Saylor, Encore Studios, and at RUSK Studios, the same studio where \"On The Nile\" was recorded in 1984. It is widely available on double gatefold LP, CD and cassette tape.\nTouring.\nThe Egyptian Lover began touring again in 2004 throughout Europe, Asia, and North America. His performances often begin with mixing records on turntables before segueing into his original compositions.\nIn 2008, he supported M.I.A. in her People vs. Money Tour.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9448", "revid": "1037383974", "url": "https://en.wikipedia.org/wiki?curid=9448", "title": "Exhaust pipe", "text": ""}
{"id": "9449", "revid": "571203446", "url": "https://en.wikipedia.org/wiki?curid=9449", "title": "Electro funk", "text": ""}
{"id": "9450", "revid": "40561892", "url": "https://en.wikipedia.org/wiki?curid=9450", "title": "Electrical telegraph", "text": "Early system for transmitting text over wires\nElectrical telegraphs were point-to-point text messaging systems, primarily used from the 1840s until the late 20th century. It was the first electrical telecommunications system and the most widely used of a number of early messaging systems called \"telegraphs\", that were devised to communicate text messages quicker than physical transportation. Electrical telegraphy can be considered to be the first example of electrical engineering. \nText telegraphy consisted of two or more geographically separated stations, called telegraph offices. The offices were connected by wires, usually supported overhead on utility poles. Many different electrical telegraph systems were invented, but the ones that became widespread fit into two broad categories. The first category consists of needle telegraphs in which a needle pointer is made to move electromagnetically with an electric current sent down the telegraph line. Early systems used multiple needles requiring multiple wires. The first commercial system, and the most widely used needle telegraph, was the Cooke and Wheatstone telegraph, invented in 1837. The second category consists of armature systems in which the current activates a telegraph sounder which makes a click. The archetype of this category was the Morse system, invented by Samuel Morse in 1838. In 1865, the Morse system became the standard for international communication using a modified code developed for German railways.\nElectrical telegraphs were used by the emerging railway companies to develop train control systems, minimizing the chances of trains colliding with each other. This was built around the signalling block system with signal boxes along the line communicating with their neighbouring boxes by telegraphic sounding of single-stroke bells and three-position needle telegraph instruments.\nIn the 1840s, the electrical telegraph superseded optical telegraph systems, becoming the standard way to send urgent messages. By the latter half of the century, most developed nations had created commercial telegraph networks with local telegraph offices in most cities and towns, allowing the public to send messages called telegrams addressed to any person in the country, for a fee. \nBeginning in 1850, submarine telegraph cables allowed for the first rapid communication between continents. Electrical telegraph networks permitted people and commerce to transmit messages across both continents and oceans almost instantly, with widespread social and economic impacts. Circa 1894, the electric telegraph led to Guglielmo Marconi's invention of wireless telegraphy, the first means of radiowave telecommunication. \nIn the early 20th century, manual telegraphy was slowly replaced by teleprinter networks. Increasing use of the telephone pushed telegraphy into a few specialist uses. Use by the general public was mainly special occasion telegram greetings. The rise of the Internet and usage of email in the 1990s largely put an end to dedicated telegraphy networks.\nHistory.\nPrecursors.\nPrior to the electric telegraph, visual systems were used, including beacons, smoke signals, flag semaphore, and optical telegraphs for visual signals to communicate over distances of land. \nAn auditory predecessor was West African talking drums. In the 19th century, Yoruba drummers used talking drums to mimic human tonal language to communicate complex messages - usually regarding news of birth, ceremonies, and military conflict - over 4-5 mile distances.\nEarly work.\nFrom early studies of electricity, electrical phenomena were known to travel with great speed, and many experimenters worked on the application of electricity to communications at a distance. All the known effects of electricity\u2014such as sparks, electrostatic attraction, chemical changes, electric shocks, and later electromagnetism\u2014were applied to the problems of detecting controlled transmissions of electricity at various distances.\nIn 1753, an anonymous writer in the \"Scots Magazine\" suggested an electrostatic telegraph. Using one wire for each letter of the alphabet, a message could be transmitted by connecting the wire terminals in turn to an electrostatic machine, and observing the deflection of pith balls at the far end. The writer has never been positively identified, but the letter was signed C.M. and posted from Renfrew leading to a Charles Marshall of Renfrew being suggested. Telegraphs employing electrostatic attraction were the basis of early experiments in electrical telegraphy in Europe, but were abandoned as being impractical and were never developed into a useful communication system.\nIn 1774, Georges-Louis Le Sage realised an early electric telegraph. The telegraph had a separate wire for each of the 26 letters of the alphabet and its range was only between two rooms of his home.\nIn 1800, Alessandro Volta invented the voltaic pile, providing a continuous current of electricity for experimentation. This became a source of a low-voltage current that could be used to produce more distinct effects, and which was far less limited than the momentary discharge of an electrostatic machine, which with Leyden jars were the only previously known man-made sources of electricity.\nAnother very early experiment in electrical telegraphy was an \"electrochemical telegraph\" created by the German physician, anatomist and inventor Samuel Thomas von S\u00f6mmering in 1809, based on an earlier, less robust design of 1804 by Spanish polymath and scientist Francisco Salva Campillo. Both their designs employed multiple wires (up to 35) to represent almost all Latin letters and numerals. Thus, messages could be conveyed electrically up to a few kilometers (in von S\u00f6mmering's design), with each of the telegraph receiver's wires immersed in a separate glass tube of acid. An electric current was sequentially applied by the sender through the various wires representing each letter of a message; at the recipient's end, the currents electrolysed the acid in the tubes in sequence, releasing streams of hydrogen bubbles next to each associated letter or numeral. The telegraph receiver's operator would watch the bubbles and could then record the transmitted message. This is in contrast to later telegraphs that used a single wire (with ground return).\nHans Christian \u00d8rsted discovered in 1820 that an electric current produces a magnetic field that will deflect a compass needle. In the same year Johann Schweigger invented the galvanometer, with a coil of wire around a compass, that could be used as a sensitive indicator for an electric current. Also that year, Andr\u00e9-Marie Amp\u00e8re suggested that telegraphy could be achieved by placing small magnets under the ends of a set of wires, one pair of wires for each letter of the alphabet. He was apparently unaware of Schweigger's invention at the time, which would have made his system much more sensitive. In 1825, Peter Barlow tried Amp\u00e8re's idea but only got it to work over and declared it impractical. In 1830 William Ritchie improved on Amp\u00e8re's design by placing the magnetic needles inside a coil of wire connected to each pair of conductors. He successfully demonstrated it, showing the feasibility of the electromagnetic telegraph, but only within a lecture hall.\nIn 1825, William Sturgeon invented the electromagnet, with a single winding of uninsulated wire on a piece of varnished iron, which increased the magnetic force produced by electric current. Joseph Henry improved it in 1828 by placing several windings of insulated wire around the bar, creating a much more powerful electromagnet which could operate a telegraph through the high resistance of long telegraph wires. During his tenure at The Albany Academy from 1826 to 1832, Henry first demonstrated the theory of the 'magnetic telegraph' by ringing a bell through of wire strung around the room in 1831.\nIn 1835, Joseph Henry and Edward Davy independently invented the mercury dipping electrical relay, in which a magnetic needle is dipped into a pot of mercury when an electric current passes through the surrounding coil. In 1837, Davy invented the much more practical metallic make-and-break relay which became the relay of choice in telegraph systems and a key component for periodically renewing weak signals. Davy demonstrated his telegraph system in Regent's Park in 1837 and was granted a patent on 4 July 1838. Davy also invented a printing telegraph which used the electric current from the telegraph signal to mark a ribbon of calico infused with potassium iodide and calcium hypochlorite.\nFirst working systems.\nThe first working telegraph was built by the English inventor Francis Ronalds in 1816 and used static electricity. At the family home on Hammersmith Mall, he set up a complete subterranean system in a long trench as well as an long overhead telegraph. The lines were connected at both ends to revolving dials marked with the letters of the alphabet and electrical impulses sent along the wire were used to transmit messages. Offering his invention to the Admiralty in July 1816, it was rejected as \"wholly unnecessary\". His account of the scheme and the possibilities of rapid global communication in \"Descriptions of an Electrical Telegraph and of some other Electrical Apparatus\" was the first published work on electric telegraphy and even described the risk of signal retardation due to induction. Elements of Ronalds' design were utilised in the subsequent commercialisation of the telegraph over 20 years later.\nThe Schilling telegraph, invented by Baron Schilling von Canstatt in 1832, was an early needle telegraph. It had a transmitting device that consisted of a keyboard with 16 black-and-white keys. These served for switching the electric current. The receiving instrument consisted of six galvanometers with magnetic needles, suspended from silk threads. The two stations of Schilling's telegraph were connected by eight wires; six were connected with the galvanometers, one served for the return current and one for a signal bell. When at the starting station the operator pressed a key, the corresponding pointer was deflected at the receiving station. Different positions of black and white flags on different disks gave combinations which corresponded to the letters or numbers. Pavel Schilling subsequently improved its apparatus by reducing the number of connecting wires from eight to two.\nOn 21 October 1832, Schilling managed a short-distance transmission of signals between two telegraphs in different rooms of his apartment. In 1836, the British government attempted to buy the design but Schilling instead accepted overtures from Nicholas\u00a0I of Russia. Schilling's telegraph was tested on a experimental underground and underwater cable, laid around the building of the main Admiralty in Saint Petersburg and was approved for a telegraph between the imperial palace at Peterhof and the naval base at Kronstadt. However, the project was cancelled following Schilling's death in 1837. Schilling was also one of the first to put into practice the idea of the binary system of signal transmission. His work was taken over and developed by Moritz von Jacobi who invented telegraph equipment that was used by Tsar Alexander III to connect the Imperial palace at Tsarskoye Selo and Kronstadt Naval Base.\nIn 1833, Carl Friedrich Gauss, together with the physics professor Wilhelm Weber in G\u00f6ttingen installed a wire above the town's roofs. Gauss combined the Poggendorff-Schweigger multiplicator with his magnetometer to build a more sensitive device, the galvanometer. To change the direction of the electric current, he constructed a commutator of his own. As a result, he was able to make the distant needle move in the direction set by the commutator on the other end of the line.\nAt first, Gauss and Weber used the telegraph to coordinate time, but soon they developed other signals and finally, their own alphabet. The alphabet was encoded in a binary code that was transmitted by positive or negative voltage pulses which were generated by means of moving an induction coil up and down over a permanent magnet and connecting the coil with the transmission wires by means of the commutator. The page of Gauss' laboratory notebook containing both his code and the first message transmitted, as well as a replica of the telegraph made in the 1850s under the instructions of Weber are kept in the faculty of physics at the University of G\u00f6ttingen, in Germany.\nGauss was convinced that this communication would be a help to his kingdom's towns. Later in the same year, instead of a voltaic pile, Gauss used an induction pulse, enabling him to transmit seven letters a minute instead of two. The inventors and university did not have the funds to develop the telegraph on their own, but they received funding from Alexander von Humboldt. Carl August Steinheil in Munich was able to build a telegraph network within the city in 1835\u20131836. He installed a telegraph line along the first German railroad in 1835. Steinheil built a telegraph along the Nuremberg - F\u00fcrth railway line in 1838, the first earth-return telegraph put into service.\nBy 1837, William Fothergill Cooke and Charles Wheatstone had co-developed a telegraph system which used a number of needles on a board that could be moved to point to letters of the alphabet. Any number of needles could be used, depending on the number of characters it was required to code. In May 1837 they patented their system. The patent recommended five needles, which coded twenty of the alphabet's 26 letters.\nSamuel Morse independently developed and patented a recording electric telegraph in 1837. Morse's assistant Alfred Vail developed an instrument that was called the register for recording the received messages. It embossed dots and dashes on a moving paper tape by a stylus which was operated by an electromagnet. Morse and Vail developed the Morse code signalling alphabet. The first telegram in the United States was sent by Morse on 11 January 1838, across of wire at Speedwell Ironworks near Morristown, New Jersey, although it was only later, in 1844, that he sent the message \"WHAT HATH GOD WROUGHT\" over the from the Capitol in Washington to the old Mt. Clare Depot in Baltimore.\nCommercial telegraphy.\nCooke and Wheatstone system.\nThe first commercial electrical telegraph was the Cooke and Wheatstone system. A demonstration four-needle system was installed on the Euston to Camden Town section of Robert Stephenson's London and Birmingham Railway in 1837 for signalling rope-hauling of locomotives. It was rejected in favour of pneumatic whistles. Cooke and Wheatstone had their first commercial success with a system installed on the Great Western Railway over the from Paddington station to West Drayton in 1838. This was a five-needle, six-wire system. A major advantage of this system was it displayed the letter being sent so operators did not need to learn a code. This system suffered from failing insulation on the underground cables. When the line was extended to Slough in 1843, the telegraph was converted to a one-needle, two-wire system with uninsulated wires on poles. The cost of installing wires was ultimately more economically significant than the cost of training operators. The one-needle telegraph proved highly successful on British railways, and 15,000 sets were still in use at the end of the nineteenth century. Some remained in service in the 1930s. The Electric Telegraph Company, the world's first public telegraphy company was formed in 1845 by financier John Lewis Ricardo and Cooke.\nWheatstone ABC telegraph.\nWheatstone developed a practical alphabetical system in 1840 called the A.B.C. System, used mostly on private wires. This consisted of a \"communicator\" at the sending end and an \"indicator\" at the receiving end. The communicator consisted of a circular dial with a pointer and the 26 letters of the alphabet (and four punctuation marks) around its circumference. Against each letter was a key that could be pressed. A transmission would begin with the pointers on the dials at both ends set to the start position. The transmitting operator would then press down the key corresponding to the letter to be transmitted. In the base of the communicator was a magneto actuated by a handle on the front. This would be turned to apply an alternating voltage to the line. Each half cycle of the current would advance the pointers at both ends by one position. When the pointer reached the position of the depressed key, it would stop and the magneto would be disconnected from the line. The communicator's pointer was geared to the magneto mechanism. The indicator's pointer was moved by a polarised electromagnet whose armature was coupled to it through an escapement. Thus the alternating line voltage moved the indicator's pointer on to the position of the depressed key on the communicator. Pressing another key would then release the pointer and the previous key, and re-connect the magneto to the line. These machines were very robust and simple to operate, and they stayed in use in Britain until well into the 20th century.\nMorse system.\nThe Morse system uses a single wire between offices. At the sending station, an operator taps on a switch called a telegraph key, spelling out text messages in Morse code. Originally, the armature was intended to make marks on paper tape, but operators learned to interpret the clicks and it was more efficient to write down the message directly.\nIn 1851, a conference in Vienna of countries in the German-Austrian Telegraph Union (which included many central European countries) adopted the Morse telegraph as the system for international communications. The international Morse code adopted was considerably modified from the original American Morse code, and was based on a code used on Hamburg railways (Gerke, 1848). A common code was a necessary step to allow direct telegraph connection between countries. With different codes, additional operators were required to translate and retransmit the message. In 1865, a conference in Paris adopted Gerke's code as the International Morse code and was henceforth the international standard. The US, however, continued to use American Morse code internally for some time, hence international messages required retransmission in both directions.\nIn the United States, the Morse/Vail telegraph was quickly deployed in the two decades following the first demonstration in 1844. The overland telegraph connected the west coast of the continent to the east coast by 24 October 1861, bringing an end to the Pony Express.\nFoy\u2013Breguet system.\nFrance was slow to adopt the electrical telegraph, because of the extensive optical telegraph system built during the Napoleonic era. There was also serious concern that an electrical telegraph could be quickly put out of action by enemy saboteurs, something that was much more difficult to do with optical telegraphs which had no exposed hardware between stations. The Foy-Breguet telegraph was eventually adopted. This was a two-needle system using two signal wires but displayed in a uniquely different way to other needle telegraphs. The needles made symbols similar to the Chappe optical system symbols, making it more familiar to the telegraph operators. The optical system was decommissioned starting in 1846, but not completely until 1855. In that year the Foy-Breguet system was replaced with the Morse system.\nExpansion.\nAs well as the rapid expansion of the use of the telegraphs along the railways, they soon spread into the field of mass communication with the instruments being installed in post offices. The era of mass personal communication had begun. Telegraph networks were expensive to build, but financing was readily available, especially from London bankers. By 1852, National systems were in operation in major countries: \nThe New York and Mississippi Valley Printing Telegraph Company, for example, was created in 1852 in Rochester, New York and eventually became the Western Union Telegraph Company. Although many countries had telegraph networks, there was no \"worldwide\" interconnection. Message by post was still the primary means of communication to countries outside Europe.\nTelegraphy was introduced in Central Asia during the 1870s.\nTelegraphic improvements.\nA continuing goal in telegraphy was to reduce the cost per message by reducing hand-work, or increasing the sending rate. There were many experiments with moving pointers, and various electrical encodings. However, most systems were too complicated and unreliable. A successful expedient to reduce the cost per message was the development of telegraphese.\nThe first system that did not require skilled technicians to operate was Charles Wheatstone's ABC system in 1840 in which the letters of the alphabet were arranged around a clock-face, and the signal caused a needle to indicate the letter. This early system required the receiver to be present in real time to record the message and it reached speeds of up to 15 words a minute.\nIn 1846, Alexander Bain patented a chemical telegraph in Edinburgh. The signal current moved an iron pen across a moving paper tape soaked in a mixture of ammonium nitrate and potassium ferrocyanide, decomposing the chemical and producing readable blue marks in Morse code. The speed of the printing telegraph was 16 and a half words per minute, but messages still required translation into English by live copyists. Chemical telegraphy came to an end in the US in 1851, when the Morse group defeated the Bain patent in the US District Court.\nFor a brief period, starting with the New York\u2013Boston line in 1848, some telegraph networks began to employ sound operators, who were trained to understand Morse code aurally. Gradually, the use of sound operators eliminated the need for telegraph receivers to include register and tape. Instead, the receiving instrument was developed into a \"sounder\", an electromagnet that was energized by a current and attracted a small iron lever. When the sounding key was opened or closed, the sounder lever struck an anvil. The Morse operator distinguished a dot and a dash by the short or long interval between the two clicks. The message was then written out in long-hand.\nRoyal Earl House developed and patented a letter-printing telegraph system in 1846 which employed an alphabetic keyboard for the transmitter and automatically printed the letters on paper at the receiver, and followed this up with a steam-powered version in 1852. Advocates of printing telegraphy said it would eliminate Morse operators' errors. The House machine was used on four main American telegraph lines by 1852. The speed of the House machine was announced as 2600 words an hour.\nDavid Edward Hughes invented the printing telegraph in 1855; it used a keyboard of 26 keys for the alphabet and a spinning type wheel that determined the letter being transmitted by the length of time that had elapsed since the previous transmission. The system allowed for automatic recording on the receiving end. The system was very stable and accurate and became accepted around the world.\nThe next improvement was the Baudot code of 1874. French engineer \u00c9mile Baudot patented a printing telegraph in which the signals were translated automatically into typographic characters. Each character was assigned a five-bit code, mechanically interpreted from the state of five on/off switches. Operators had to maintain a steady rhythm, and the usual speed of operation was 30 words per minute.\nBy this point, reception had been automated, but the speed and accuracy of the transmission were still limited to the skill of the human operator. The first practical automated system was patented by Charles Wheatstone. The message (in Morse code) was typed onto a piece of perforated tape using a keyboard-like device called the 'Stick Punch'. The transmitter automatically ran the tape through and transmitted the message at the then exceptionally high speed of 70 words per minute.\nTeleprinters.\nAn early successful teleprinter was invented by Frederick G. Creed. In Glasgow he created his first keyboard perforator, which used compressed air to punch the holes. He also created a reperforator (receiving perforator) and a printer. The reperforator punched incoming Morse signals onto paper tape and the printer decoded this tape to produce alphanumeric characters on plain paper. This was the origin of the Creed High Speed Automatic Printing System, which could run at an unprecedented 200 words per minute. His system was adopted by the \"Daily Mail\" for daily transmission of the newspaper contents.\nWith the invention of the teletypewriter, telegraphic encoding became fully automated. Early teletypewriters used the ITA-1 Baudot code, a five-bit code. This yielded only thirty-two codes, so it was over-defined into two \"shifts\", \"letters\" and \"figures\". An explicit, unshared shift code prefaced each set of letters and figures. In 1901, Baudot's code was modified by Donald Murray.\nIn the 1930s, teleprinters were produced by Teletype in the US, Creed in Britain and Siemens in Germany.\nBy 1935, message routing was the last great barrier to full automation. Large telegraphy providers began to develop systems that used telephone-like rotary dialling to connect teletypewriters. These resulting systems were called \"Telex\" (TELegraph EXchange). Telex machines first performed rotary-telephone-style pulse dialling for circuit switching, and then sent data by ITA2. This \"type A\" Telex routing functionally automated message routing.\nThe first wide-coverage Telex network was implemented in Germany during the 1930s as a network used to communicate within the government.\nAt the rate of 45.45 (\u00b10.5%) baud \u2013 considered speedy at the time \u2013 up to 25 telex channels could share a single long-distance telephone channel by using \"voice frequency telegraphy multiplexing\", making telex the least expensive method of reliable long-distance communication.\nAutomatic teleprinter exchange service was introduced into Canada by CPR Telegraphs and CN Telegraph in July 1957 and in 1958, Western Union started to build a Telex network in the United States.\nThe harmonic telegraph.\nThe most expensive aspect of a telegraph system was the installation \u2013 the laying of the wire, which was often very long. The costs would be better covered by finding a way to send more than one message at a time through the single wire, thus increasing revenue per wire. Early devices included the duplex and the quadruplex which allowed, respectively, one or two telegraph transmissions in each direction. However, an even greater number of channels was desired on the busiest lines. In the latter half of the 1800s, several inventors worked towards creating a method for doing just that, including Charles Bourseul, Thomas Edison, Elisha Gray, and Alexander Graham Bell.\nOne approach was to have resonators of several different frequencies act as carriers of a modulated on-off signal. This was the harmonic telegraph, a form of frequency-division multiplexing. These various frequencies, referred to as harmonics, could then be combined into one complex signal and sent down the single wire. On the receiving end, the frequencies would be separated with a matching set of resonators.\nWith a set of frequencies being carried down a single wire, it was realized that the human voice itself could be transmitted electrically through the wire. This effort led to the invention of the telephone. (While the work toward packing multiple telegraph signals onto one wire led to telephony, later advances would pack multiple voice signals onto one wire by increasing the bandwidth by modulating frequencies much higher than human hearing. Eventually, the bandwidth was widened much further by using laser light signals sent through fiber optic cables. Fiber optic transmission can carry 25,000 telephone signals simultaneously down a single fiber.)\nOceanic telegraph cables.\nSoon after the first successful telegraph systems were operational, the possibility of transmitting messages across the sea by way of submarine communications cables was first proposed. One of the primary technical challenges was to sufficiently insulate the submarine cable to prevent the electric current from leaking out into the water. In 1842, a Scottish surgeon William Montgomerie introduced gutta-percha, the adhesive juice of the \"Palaquium gutta\" tree, to Europe. Michael Faraday and Wheatstone soon discovered the merits of gutta-percha as an insulator, and in 1845, the latter suggested that it should be employed to cover the wire which was proposed to be laid from Dover to Calais. Gutta-percha was used as insulation on a wire laid across the Rhine between Deutz and Cologne. In 1849, C. V. Walker, electrician to the South Eastern Railway, submerged a wire coated with gutta-percha off the coast from Folkestone, which was tested successfully.\nJohn Watkins Brett, an engineer from Bristol, sought and obtained permission from Louis-Philippe in 1847 to establish telegraphic communication between France and England. The first undersea cable was laid in 1850, connecting the two countries and was followed by connections to Ireland and the Low Countries.\nThe Atlantic Telegraph Company was formed in London in 1856 to undertake to construct a commercial telegraph cable across the Atlantic Ocean. It was successfully completed on 18 July 1866 by the ship SS \"Great Eastern\", captained by Sir James Anderson, after many mishaps along the away. John Pender, one of the men on the Great Eastern, later founded several telecommunications companies primarily laying cables between Britain and Southeast Asia. Earlier transatlantic submarine cables installations were attempted in 1857, 1858 and 1865. The 1857 cable only operated intermittently for a few days or weeks before it failed. The study of underwater telegraph cables accelerated interest in mathematical analysis of very long transmission lines. The telegraph lines from Britain to India were connected in 1870. (Those several companies combined to form the \"Eastern Telegraph Company\" in 1872.) The HMS \"Challenger\" expedition in 1873\u20131876 mapped the ocean floor for future underwater telegraph cables.\nAustralia was first linked to the rest of the world in October 1872 by a submarine telegraph cable at Darwin. This brought news reports from the rest of the world. The telegraph across the Pacific was completed in 1902, finally encircling the world.\nFrom the 1850s until well into the 20th century, British submarine cable systems dominated the world system. This was set out as a formal strategic goal, which became known as the All Red Line. In 1896, there were thirty cable laying ships in the world and twenty-four of them were owned by British companies. In 1892, British companies owned and operated two-thirds of the world's cables and by 1923, their share was still 42.7 percent.\nCable and Wireless Company.\nCable &amp; Wireless was a British telecommunications company that traced its origins back to the 1860s, with Sir John Pender as the founder, although the name was only adopted in 1934. It was formed from successive mergers including: \nTelegraphy and longitude.\nMain article \u00a7 Section: .\nThe telegraph was very important for sending time signals to determine longitude, providing greater accuracy than previously available. Longitude was measured by comparing local time (for example local noon occurs when the sun is at its highest above the horizon) with absolute time (a time that is the same for an observer anywhere on earth). If the local times of two places differ by one hour, the difference in longitude between them is 15\u00b0 (360\u00b0/24h). Before telegraphy, absolute time could be obtained from astronomical events, such as eclipses, occultations or lunar distances, or by transporting an accurate clock (a chronometer) from one location to the other.\nThe idea of using the telegraph to transmit a time signal for longitude determination was suggested by Fran\u00e7ois Arago to Samuel Morse in 1837, and the first test of this idea was made by Capt. Wilkes of the U.S. Navy in 1844, over Morse's line between Washington and Baltimore. The method was soon in practical use for longitude determination, in particular by the U.S. Coast Survey, and over longer and longer distances as the telegraph network spread across North America and the world, and as technical developments improved accuracy and productivity\nThe \"telegraphic longitude net\" soon became worldwide. Transatlantic links between Europe and North America were established in 1866 and 1870. The US\u00a0Navy extended observations into the West Indies and Central and South America with an additional transatlantic link from South America to Lisbon between 1874 and 1890. British, Russian and US observations created a chain from Europe through Suez, Aden, Madras, Singapore, China and Japan, to Vladivostok, thence to Saint Petersburg and back to Western Europe.\nAustralia was linked to Singapore via Java in 1871 and the web circled the globe in 1902 with the connection of Australia and New Zealand to Canada via the All Red Line. The double determination of longitudes from east to west and from west to east agreed within one second of arc (&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204415\u00a0second of time \u2013 less than 30\u00a0metres).\nTelegraphy in war.\nThe ability to send telegrams brought obvious advantages to those conducting war. Secret messages were encoded, so interception alone would not be sufficient for the opposing side to gain an advantage. There were also geographical constraints on intercepting the telegraph cables that improved security, however once radio telegraphy was developed interception became far more widespread.\nCrimean War.\nThe Crimean War was one of the first conflicts to use telegraphs and was one of the first to be documented extensively. In 1854, the government in London created a military Telegraph Detachment for the Army commanded by an officer of the Royal Engineers. It was to comprise twenty-five men from the Royal Corps of Sappers &amp; Miners trained by the Electric Telegraph Company to construct and work the first field electric telegraph.\nJournalistic recording of the war was provided by William Howard Russell (writing for \"The Times\" newspaper) with photographs by Roger Fenton. News from war correspondents kept the public of the nations involved in the war informed of the day-to-day events in a way that had not been possible in any previous war. After the French extended the telegraph to the coast of the Black Sea in late 1854, the news reached London in two days. When the British laid an underwater cable to the Crimean peninsula in April 1855, news reached London in a few hours. The daily news reports energised public opinion, which brought down the government and led to Lord Palmerston becoming prime minister.\nAmerican Civil War.\nDuring the American Civil War the telegraph proved its value as a tactical, operational, and strategic communication medium and an important contributor to Union victory. By contrast the Confederacy failed to make effective use of the South's much smaller telegraph network. Prior to the War the telegraph systems were primarily used in the commercial sector. Government buildings were not inter-connected with telegraph lines, but relied on runners to carry messages back and forth. Before the war the Government saw no need to connect lines within city limits, however, they did see the use in connections between cities. Washington D.C. being the hub of government, it had the most connections, but there were only a few lines running north and south out of the city. It wasn't until the Civil War that the government saw the true potential of the telegraph system. Soon after the shelling of Fort Sumter, the South cut telegraph lines running into D.C., which put the city in a state of panic because they feared an immediate Southern invasion.\nWithin 6 months of the start of the war, the U.S. Military Telegraph Corps (USMT) had laid approximately of line. By war's end they had laid approximately of line, 8,000 for military and 5,000 for commercial use, and had handled approximately 6.5\u00a0million messages. The telegraph was not only important for communication within the armed forces, but also in the civilian sector, helping political leaders to maintain control over their districts.\nEven before the war, the American Telegraph Company censored suspect messages informally to block aid to the secession movement. During the war, Secretary of War Simon Cameron, and later Edwin Stanton, wanted control over the telegraph lines to maintain the flow of information. Early in the war, one of Stanton's first acts as Secretary of War was to move telegraph lines from ending at McClellan's headquarters to terminating at the War Department. Stanton himself said \"[telegraphy] is my right arm\". Telegraphy assisted Northern victories, including the Battle of Antietam (1862), the Battle of Chickamauga (1863), and Sherman's March to the Sea (1864).\nThe telegraph system still had its flaws. The USMT, while the main source of telegraphers and cable, was still a civilian agency. Most operators were first hired by the telegraph companies and then contracted out to the War Department. This created tension between Generals and their operators. One source of irritation was that USMT operators did not have to follow military authority. Usually they performed without hesitation, but they were not required to, so Albert Myer created a U.S. Army Signal Corps in February 1863. As the new head of the Signal Corps, Myer tried to get all telegraph and flag signaling under his command, and therefore subject to military discipline. After creating the Signal Corps, Myer pushed to further develop new telegraph systems. While the USMT relied primarily on civilian lines and operators, the Signal Corp's new field telegraph could be deployed and dismantled faster than USMT's system.\nFirst World War.\nDuring World War I, Britain's telegraph communications were almost completely uninterrupted, while it was able to quickly cut Germany's cables worldwide. The British government censored telegraph cable companies in an effort to root out espionage and restrict financial transactions with Central Powers nations. British access to transatlantic cables and its codebreaking expertise led to the Zimmermann Telegram incident that contributed to the US joining the war. Despite British acquisition of German colonies and expansion into the Middle East, debt from the war led to Britain's control over telegraph cables to weaken while US control grew.\nSecond World War.\nWorld War II revived the 'cable war' of 1914\u20131918. In 1939, German-owned cables across the Atlantic were cut once again, and, in 1940, Italian cables to South America and Spain were cut in retaliation for Italian action against two of the five British cables linking Gibraltar and Malta. Electra House, Cable &amp; Wireless's head office and central cable station, was damaged by German bombing in 1941.\nResistance movements in occupied Europe sabotaged communications facilities such as telegraph lines, forcing the Germans to use wireless telegraphy, which could then be intercepted by Britain.\nThe Germans developed a highly complex teleprinter attachment (German: \"Schl\u00fcssel-Zusatz\", \"cipher attachment\") that was used for enciphering telegrams, using the Lorenz cipher, between German High Command (OKW) and the army groups in the field. These contained situation reports, battle plans, and discussions of strategy and tactics. Britain intercepted these signals, diagnosed how the encrypting machine worked, and decrypted a large amount of teleprinter traffic.\nEnd of the telegraph era.\nIn America, the end of the telegraph era can be associated with the fall of the Western Union Telegraph Company. Western Union was the leading telegraph provider for America and was seen as the best competition for the National Bell Telephone Company. Western Union and Bell were both invested in telegraphy and telephone technology. Western Union's decision to allow Bell to gain the advantage in telephone technology was the result of Western Union's upper management's failure to foresee the surpassing of the telephone over the, at the time, dominant telegraph system. Western Union soon lost the legal battle for the rights to their telephone copyrights. This led to Western Union agreeing to a lesser position in the telephone competition, which in turn led to the lessening of the telegraph.\nWhile the telegraph was not the focus of the legal battles that occurred around 1878, the companies that were affected by the effects of the battle were the main powers of telegraphy at the time. Western Union thought that the agreement of 1878 would solidify telegraphy as the long-range communication of choice. However, due to the underestimates of telegraph's future and poor contracts, Western Union found itself declining. AT&amp;T acquired working control of Western Union in 1909 but relinquished it in 1914 under threat of antitrust action. AT&amp;T bought Western Union's electronic mail and Telex businesses in 1990.\nAlthough commercial \"telegraph\" services are still available in many countries, transmission is usually done via a computer network rather than a dedicated wired connection.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9451", "revid": "44120587", "url": "https://en.wikipedia.org/wiki?curid=9451", "title": "Event", "text": "Event may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "9452", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=9452", "title": "Estruscan alphabet", "text": ""}
{"id": "9454", "revid": "770058", "url": "https://en.wikipedia.org/wiki?curid=9454", "title": "Establishing shot", "text": "Long shot that sets up the context for a scene in filmmaking and television production\nAn establishing shot in filmmaking and television production sets up, or establishes, the context for a scene by showing the relationship between its important figures and objects. It is generally a long or extreme-long shot at the beginning of a scene indicating where, and sometimes when, the remainder of the scene takes place.\nEstablishing shots were more common during the classical era of filmmaking than they are now. Today's filmmakers tend to skip the establishing shot in order to move the scene along more quickly, or merely mention the setting in on-screen text (as is done in the \"Law &amp; Order\" franchise). In addition, the expositional nature of the shot may be unsuitable to scenes in mysteries, where details are intentionally obscured or left out.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9455", "revid": "17678816", "url": "https://en.wikipedia.org/wiki?curid=9455", "title": "Etruscan language", "text": "Extinct language of ancient Italy\nEtruscan ( ) was the language of the Etruscan civilization in the ancient region of Etruria, in Etruria Padana and Etruria Campana in what is now Italy. Etruscan influenced Latin but was eventually completely superseded by it. The Etruscans left around 13,000 inscriptions that have been found so far, only a small minority of which are of significant length; some bilingual inscriptions with texts also in Latin, Greek, or Phoenician; and a few dozen purported loanwords. Attested from 700 BC to AD 50, the relation of Etruscan to other languages has been a source of long-running speculation and study, with it mostly being referred to as one of the Tyrsenian languages, at times as an isolate and a number of other less well-known theories.\nThe consensus among linguists and Etruscologists is that Etruscan was a Pre\u2013Indo-European and Paleo-European language, closely related to the Raetic language that was spoken in the Alps, and to the Lemnian language, attested in a few inscriptions on Lemnos.\nGrammatically, the language is agglutinating, with nouns and verbs showing suffixed inflectional endings and some gradation of vowels. Nouns show five cases, singular and plural numbers, with a gender distinction between animate and inanimate in pronouns.\nEtruscan appears to have had a cross-linguistically common phonological system, with four phonemic vowels and an apparent contrast between aspirated and unaspirated stops. The records of the language suggest that phonetic change took place over time, with the loss and then re-establishment of word-internal vowels, possibly due to the effect of Etruscan's word-initial stress.\nEtruscan religion influenced that of the Romans, and many of the few surviving Etruscan-language artifacts are of votive or religious significance. Etruscan was written in an alphabet derived from the Greek alphabet; this alphabet was the source of the Latin alphabet, as well as other alphabets in Italy and probably beyond. The Etruscan language is also believed to be the source of certain important cultural words of Western Europe such as \"military\" and \"person\", which do not have obvious Indo-European roots.\nHistory of Etruscan literacy.\nEtruscan literacy was widespread over the Mediterranean shores, as evidenced by about 13,000 inscriptions (dedications, epitaphs, etc.), most fairly short, but some of considerable length. They date from about 700 BC.\nThe Etruscans had a rich literature, as noted by Latin authors. Livy and Cicero were both aware that highly specialized Etruscan religious rites were codified in several sets of books written in Etruscan under the generic Latin title . The dealt with divination by reading entrails from a sacrificed animal, while the expounded the art of divination by observing lightning. A third set, the , might have provided a key to Etruscan civilization: its wider scope embraced Etruscan standards of social and political life, as well as ritual practices. According to the 4th-century Latin writer Maurus Servius Honoratus, a fourth set of Etruscan books existed; dealing with animal gods, but it is unlikely that any scholar living in that era could have read Etruscan. However, only one book (as opposed to inscription), the \"Liber Linteus\", survived, and only because the linen on which it was written was used as mummy wrappings.\nIn 30 BC, Livy noted that Etruscan was once widely taught to Roman boys, but had since become replaced by the teaching of only Greek, while Varro noted that works of theatre had once been composed in Etruscan.\nDemise.\nThe date of extinction for Etruscan is held by scholarship to have been either in the late first century BC, or the early first century AD. Freeman's analysis of inscriptional evidence would appear to imply that Etruscan was still flourishing in the 2nd century BC, still alive in the first century BC, and surviving in at least one location in the beginning of the first century AD; however, the replacement of Etruscan by Latin likely occurred earlier in southern regions closer to Rome.\nIn southern Etruria, the first Etruscan site to be Latinized was Veii, when it was destroyed and repopulated by Romans in 396 BC. Caere (Cerveteri), another southern Etruscan town on the coast 45 kilometers from Rome, appears to have shifted to Latin in the late 2nd century BC. In Tarquinia and Vulci, Latin inscriptions coexisted with Etruscan inscriptions in wall paintings and grave markers for centuries, from the 3rd century BC until the early 1st century BC, after which Etruscan is replaced by the exclusive use of Latin.\nIn northern Etruria, Etruscan inscriptions continue after they disappear in southern Etruria. At Clusium (Chiusi), tomb markings show mixed Latin and Etruscan in the first half of the 1st century BC, with cases where two subsequent generations are inscribed in Latin and then the third, youngest generation, surprisingly, is transcribed in Etruscan. At Perugia, monolingual monumental inscriptions in Etruscan are still seen in the first half of the 1st century BC, while the period of bilingual inscriptions appears to have stretched from the 3rd century to the late 1st century BC. The isolated last bilinguals are found at three northern sites. Inscriptions in Arezzo include one dated to 40 BC followed by two with slightly later dates, while in Volterra there is one dated to just after 40 BC and a final one dated to 10\u201320 AD; coins with written Etruscan near Saena have also been dated to 15 BC. Freeman notes that in rural areas the language may have survived a bit longer, and that a survival into the late 1st century AD and beyond \"cannot wholly be dismissed\", especially given the revelation of Oscan writing in Pompeii's walls.\nDespite the apparent extinction of Etruscan, it appears that Etruscan religious rites continued much later, continuing to use the Etruscan names of deities and possibly with some liturgical usage of the language. In late Republican and early Augustan times, various Latin sources including Cicero noted the esteemed reputation of Etruscan soothsayers. An episode where lightning struck an inscription with the name Caesar, turning it into Aesar, was interpreted to have been a premonition of the deification of Caesar because of the resemblance to Etruscan , meaning 'gods', although this indicates knowledge of a single word and not the language. Centuries later and long after Etruscan is thought to have died out, Ammianus Marcellinus reports that Julian the Apostate, the last pagan Emperor, apparently had Etruscan soothsayers accompany him on his military campaigns with books on war, lightning and celestial events, but the language of these books is unknown. According to Zosimus, when Rome was faced with destruction by Alaric in 408 AD, the protection of nearby Etruscan towns was attributed to Etruscan pagan priests who claimed to have summoned a raging thunderstorm, and they offered their services \"in the ancestral manner\" to Rome as well, but the devout Christians of Rome refused the offer, preferring death to help by pagans. Freeman notes that these events may indicate that a limited theological knowledge of Etruscan may have survived among the priestly caste much longer. One 19th-century writer argued in 1892 that Etruscan deities retained an influence on early modern Tuscan folklore.\nAround 180, the Latin author Aulus Gellius mentions Etruscan alongside the Gaulish language in an anecdote. Freeman notes that although Gaulish was clearly still alive during Gellius' time, his testimony may not indicate that Etruscan was still alive because the phrase could indicate a meaning of the sort of \"it's all Greek (incomprehensible) to me\".\nAt the time of its extinction, only a few educated Romans with antiquarian interests, such as Marcus Terentius Varro, could read Etruscan. The Roman emperor Claudius (10\u00a0BC \u2013 AD\u00a054) is considered to have possibly been able to read Etruscan, and authored a treatise on Etruscan history; a separate dedication made by Claudius implies a knowledge from \"diverse Etruscan sources\", but it is unclear if any were fluent speakers of Etruscan. Plautia Urgulanilla, the emperor's first wife, was Etruscan.\nEtruscan had some influence on Latin, as a few dozen Etruscan words and names were borrowed by the Romans, some of which remain in modern languages, among which are possibly 'vulture', 'trumpet', 'sheath', 'people'.\nGeographic distribution.\nInscriptions have been found in northwest and west-central Italy, in the region that even now bears the name of the Etruscan civilization, Tuscany (from Latin 'Etruscans'), as well as in modern Latium north of Rome, in today's Umbria west of the Tiber, in the Po Valley to the north of Etruria, and in Campania. This range may indicate a maximum Italian homeland where the language was at one time spoken.\nOutside Italy, inscriptions have been found in Corsica, Gallia Narbonensis, Greece, the Balkans. But by far, the greatest concentration is in Italy.\nClassification.\nTyrsenian family hypothesis.\nIn 1998, Helmut Rix put forward the view that Etruscan is related to other extinct languages such as Raetic, spoken in ancient times in the eastern Alps, and Lemnian, to which other scholars added Camunic language, spoken in the Central Alps.\nRix's Tyrsenian language family has gained widespread acceptance among scholars, being confirmed by Stefan Schumacher, Norbert Oettinger, Carlo De Simone, and Simona Marchesini. \nCommon features between Etruscan, Raetic, and Lemnian have been found in morphology, phonology, and syntax, but only a few lexical correspondences are documented, at least partly due to the scant number of Raetic and Lemnian texts. On the other hand, the Tyrsenian family, or Common Tyrrhenic, is often considered to be Paleo-European and to predate the arrival of Indo-European languages in southern Europe. Several scholars believe that the Lemnian language could have arrived in the Aegean Sea during the Late Bronze Age, when Mycenaean rulers recruited groups of mercenaries from Sicily, Sardinia and various parts of the Italian peninsula. Scholars such as Norbert Oettinger, Michel Gras and Carlo De Simone think that Lemnian is the testimony of an Etruscan commercial settlement on the island that took place before 700 BC, not related to the Sea Peoples.\nArcheogenetic studies.\nA 2021 archeogenetic analysis of Etruscan individuals, who lived between 800 BC and 1 BC, concluded that the Etruscans were autochthonous and genetically similar to the Early Iron Age Latins, and that the Etruscan language, and therefore the other languages of the Tyrrhenian family, may be a surviving language of the ones that were widespread in Europe from at least the Neolithic period before the arrival of the Indo-European languages, as already argued by German geneticist Johannes Krause who concluded that it is likely that the Etruscan language (as well as Basque, Paleo-Sardinian and Minoan) \"developed on the continent in the course of the Neolithic Revolution\". The lack of recent Anatolian-related admixture and Iranian-related ancestry among the Etruscans, who genetically joined firmly to the European cluster, might also suggest that the presence of a handful of inscriptions found at Lemnos, in a language related to Etruscan and Raetic, \"could represent population movements departing from the Italian peninsula\".\nSuperseded theories and fringe scholarship.\nOver the centuries many hypotheses on the Etruscan language have been developed, most of which have not been accepted or have been considered highly speculative since they were published. The major consensus among scholars is that the Etruscan, and therefore all the languages of the Tyrrhenian family, is neither Indo-European nor Semitic, and may be a Pre\u2013Indo-European and Paleo-European language. At present the major consensus is that Etruscan has only a kinship with the Raetic and Lemnian languages.\nPre-Greek substrate hypothesis.\nThe idea of a relation between the language of the Minoan Linear A scripts was taken into consideration as the main hypothesis by Michael Ventris before he discovered that, in fact, the language behind the later Linear B script was Mycenean, a Greek dialect. It has been proposed to possibly be part of a wider Paleo-European \"Aegean\" language family, which would also include Minoan, Eteocretan (possibly descended from Minoan) and Eteocypriot. This has been proposed by Giulio Mauro Facchetti, a researcher who has dealt with both Etruscan and Minoan, and supported by S. Yatsemirsky, referring to some similarities between Etruscan and Lemnian on one hand, and Minoan and Eteocretan on the other.\nIt has also been proposed that this language family is related to the pre-Indo-European languages of Anatolia, based upon place name analysis. The relationship between Etruscan and Minoan, and hypothetical unattested pre-Indo-European languages of Anatolia, is considered unfounded.\nAnatolian Indo-European family hypothesis.\nSome have suggested that Tyrsenian languages may yet be distantly related to early Indo-European languages, such as those of the Anatolian branch. More recently, Robert S. P. Beekes argued in 2002 that the people later known as the Lydians and Etruscans had originally lived in northwest Anatolia, with a coastline to the Sea of Marmara, whence they were driven by the Phrygians \"circa\" 1200 BC, leaving a remnant known in antiquity as the Tyrsenoi. A segment of this people moved south-west to Lydia, becoming known as the Lydians, while others sailed away to take refuge in Italy, where they became known as Etruscans. This account draws on the well-known story by Herodotus (I, 94) of the Lydian origin of the Etruscans or Tyrrhenians, famously rejected by Dionysius of Halicarnassus (book I), partly on the authority of Xanthus, a Lydian historian, who had no knowledge of the story, and partly on what he judged to be the different languages, laws, and religions of the two peoples. In 2006, Frederik Woudhuizen went further on Herodotus' traces, suggesting that Etruscan belongs to the Anatolian branch of the Indo-European family, specifically to Luwian. Woudhuizen revived a conjecture to the effect that the Tyrsenians came from Anatolia, including Lydia, whence they were driven by the Cimmerians in the early Iron Age, 750\u2013675 BC, leaving some colonists on Lemnos. He makes a number of comparisons of Etruscan to Luwian and asserts that Etruscan is modified Luwian. He accounts for the non-Luwian features as a Mysian influence: \"deviations from Luwian [...] may plausibly be ascribed to the dialect of the indigenous population of Mysia.\" According to Woudhuizen, the Etruscans were initially colonizing the Latins, bringing the alphabet from Anatolia. For historical, archaeological, genetic, and linguistic reasons, a relationship between Etruscan and the Indo-European Anatolian languages (Lydian or Luwian) and the idea that the Etruscans initially colonized the Latins, bringing the alphabet from Anatolia, have not been accepted, just as the Lydian origin story reported by Herodotus is no longer considered reliable.\nOther theories.\nThe interest in Etruscan antiquities and the Etruscan language found its modern origin in a book by a Renaissance Dominican friar, Annio da Viterbo, a cabalist and orientalist now remembered mainly for literary forgeries. In 1498, Annio published his antiquarian miscellany titled (in 17 volumes) where he put together a theory in which both the Hebrew and Etruscan languages were said to originate from a single source, the \"Aramaic\" spoken by Noah and his descendants, founders of the Etruscan city Viterbo.\nThe 19th century saw numerous attempts to reclassify Etruscan. Ideas of Semitic origins found supporters until this time. In 1858, the last attempt was made by Johann Gustav Stickel, Jena University in his . A reviewer concluded that Stickel brought forward every possible argument which would speak for that hypothesis, but he proved the opposite of what he had attempted to do. In 1861, Robert Ellis proposed that Etruscan was related to Armenian. Exactly 100 years later, a relationship with Albanian was to be advanced by Zecharia Mayani, a theory regarded today as disproven and discredited.\nSeveral theories from the late 19th and early 20th centuries connected Etruscan to Uralic or even Altaic languages. In 1874, the British scholar Isaac Taylor brought up the idea of a genetic relationship between Etruscan and Hungarian, of which also Jules Martha would approve in his exhaustive study (1913). In 1911, the French orientalist Baron Carra de Vaux suggested a connection between Etruscan and the Altaic languages. The Hungarian connection was revived by Mario Alinei, Emeritus Professor of Italian Languages at the University of Utrecht. Alinei's proposal has been rejected by Etruscan experts such as Giulio M. Facchetti, Finno-Ugric experts such as Angela Marcantonio, and by Hungarian historical linguists such as Bela Brogyanyi. Another proposal, pursued mainly by a few linguists from the former Soviet Union, suggested a relationship with Northeast Caucasian (or Nakh-Daghestanian) languages. None of these theories has been accepted nor enjoys consensus.\nWriting system.\nAlphabet.\nThe Latin script owes its existence to the Etruscan alphabet, which was adapted for Latin in the form of the Old Italic script. The Etruscan alphabet employs a Euboean variant of the Greek alphabet using the letter digamma and was in all probability transmitted through Pithecusae and Cumae, two Euboean settlements in southern Italy. This system is ultimately derived from West Semitic scripts.\nThe Etruscans recognized a 26-letter alphabet, which makes an early appearance incised for decoration on a small bucchero terracotta lidded vase in the shape of a cockerel at the Metropolitan Museum of Art, ca. 650\u2013600 BC. The full complement of 26 has been termed the model alphabet. The Etruscans did not use four letters of it, mainly because Etruscan did not have the voiced stops \"b\", \"d\" and \"g\"; the \"o\" was also not used. They innovated one letter for \"f\" (\ud800\udf1a).\nText.\nWriting was from right to left except in archaic inscriptions, which occasionally used boustrophedon. An example found at Cerveteri used left to right. In the earliest inscriptions, the words are continuous. From the 6th century BC, they are separated by a dot or a colon, which might also be used to separate syllables. Writing was phonetic; the letters represented the sounds and not conventional spellings. On the other hand, many inscriptions are highly abbreviated and often casually formed, so the identification of individual letters is sometimes difficult. Spelling might vary from city to city, probably reflecting differences of pronunciation.\nComplex consonant clusters.\nSpeech featured a heavy stress on the first syllable of a word, causing syncopation by weakening of the remaining vowels, which then were not represented in writing: \"Alcsntre\" for \"Alexandros\", \"Rasna\" for \"Rasena\". This speech habit is one explanation of the Etruscan \"impossible\" consonant clusters. Some of the consonants, especially resonants, however, may have been syllabic, accounting for some of the clusters (see below under Consonants). In other cases, the scribe sometimes inserted a vowel: Greek \"H\u0113rakl\u0113s\" became \"Hercle\" by syncopation and then was expanded to \"Herecele\". Pallottino regarded this variation in vowels as \"instability in the quality of vowels\" and accounted for the second phase (e.g. \"Herecele\") as \"vowel harmony, i.e., of the assimilation of vowels in neighboring syllables\".\nPhases.\nThe writing system had two historical phases: the archaic from the seventh to fifth centuries BC, which used the early Greek alphabet, and the later from the fourth to first centuries BC, which modified some of the letters. In the later period, syncopation increased.\nThe alphabet went on in modified form after the language disappeared. In addition to being the source of the Roman and early Oscan and Umbrian alphabets, it has been suggested that it passed northward into Veneto and from there through Raetia into the Germanic lands, where it became the Elder Futhark alphabet, the oldest form of the runes.\nCorpus.\nThe Etruscan corpus is edited in the \"Corpus Inscriptionum Etruscarum\" (CIE) and \"Thesaurus Linguae Etruscae\" (TLE).\nBilingual text.\nThe Pyrgi Tablets are a bilingual text in Etruscan and Phoenician engraved on three gold leaves, one for the Phoenician and two for the Etruscan. The Etruscan language portion has 16 lines and 37 words. The date is roughly 500 BC.\nThe tablets were found in 1964 by Massimo Pallottino during an excavation at the ancient Etruscan port of Pyrgi, now Santa Severa. The only new Etruscan word that could be extracted from close analysis of the tablets was the word for 'three', .\nLonger texts.\nAccording to Rix and his collaborators, only two unified (though fragmentary) long texts are available in Etruscan:\nSome additional longer texts are:\nInscriptions on monuments.\nThe main material repository of Etruscan civilization, from the modern perspective, is its tombs, all other public and private buildings having been dismantled and the stone reused centuries ago. The tombs are the main source of Etruscan portables, provenance unknown, in collections throughout the world. Their incalculable value has created a brisk black market in Etruscan \"objets d'art\" \u2013 and equally brisk law enforcement effort, as it is illegal to remove any objects from Etruscan tombs without authorization from the Italian government.\nThe magnitude of the task involved in cataloguing them means that the total number of tombs is unknown. They are of many types. Especially plentiful are the hypogeal or \"underground\" chambers or system of chambers cut into tuff and covered by a tumulus. The interior of these tombs represents a habitation of the living stocked with furniture and favorite objects. The walls may display painted murals, the predecessor of wallpaper. Tombs identified as Etruscan date from the Villanovan period to about 100 BC, when presumably the cemeteries were abandoned in favor of Roman ones. Some of the major cemeteries are as follows:\nInscriptions on portable objects.\nVotives.\n\"See\" Votive gifts.\nOne example of an early (pre-fifth century bce) votive inscription is on a bucchero oinochoe (wine vase): \"\u1e43i\u1e47i mulva\u1e47\u1ecbce venalia \u1e61larina\u1e61. en mipi kapi \u1e43i(r) \u1e47u\u1e47ai\" = \u201cVenalia \u1e60larina\u1e61 gave me. Do not touch me (?), I (am) \"nunai\" (an offering?).\" This seems to be a rare case from this early period of a female (Venalia) dedicating the votive.\nSpecula.\nA speculum is a circular or oval hand-mirror used predominantly by Etruscan women. is Latin; the Etruscan word is or . Specula were cast in bronze as one piece or with a tang into which a wooden, bone, or ivory handle fitted. The reflecting surface was created by polishing the flat side. A higher percentage of tin in the mirror improved its ability to reflect. The other side was convex and featured intaglio or cameo scenes from mythology. The piece was generally ornate.\nAbout 2,300 specula are known from collections all over the world. As they were popular plunderables, the provenance of only a minority is known. An estimated time window is 530\u2013100 BC. Most probably came from tombs.\nMany bear inscriptions naming the persons depicted in the scenes, so they are often called picture bilinguals. In 1979, Massimo Pallottino, then president of the \"Istituto di Studi Etruschi ed Italici\" initiated the Committee of the \"Corpus Speculorum Etruscanorum\", which resolved to publish all the specula and set editorial standards for doing so.\nSince then, the committee has grown, acquiring local committees and representatives from most institutions owning Etruscan mirror collections. Each collection is published in its own fascicle by diverse Etruscan scholars.\nCistae.\nA cista is a bronze container of circular, ovoid, or more rarely rectangular shape used by women for the storage of sundries. They are ornate, often with feet and lids to which figurines may be attached. The internal and external surfaces bear carefully crafted scenes usually from mythology, usually intaglio, or rarely part intaglio, part cameo.\nCistae date from the Roman Republic of the fourth and third centuries BC in Etruscan contexts. They may bear various short inscriptions concerning the manufacturer or owner or subject matter. The writing may be Latin, Etruscan, or both. Excavations at Praeneste, an Etruscan city which became Roman, turned up about 118 cistae, one of which has been termed \"the Praeneste cista\" or \"the Ficoroni cista\" by art analysts, with special reference to the one manufactured by Novios Plutius and given by Dindia Macolnia to her daughter, as the archaic Latin inscription says. All of them are more accurately termed \"the Praenestine cistae\".\nRings and ringstones.\nAmong the most plunderable portables from the Etruscan tombs of Etruria are the finely engraved gemstones set in patterned gold to form circular or ovoid pieces intended to go on finger rings. Around one centimeter in size, they are dated to the Etruscan apogee from the second half of the sixth to the first centuries BC. The two main theories of manufacture are native Etruscan and Greek. The materials are mainly dark red carnelian, with agate and sard entering usage from the third to the first centuries BC, along with purely gold finger rings with a hollow engraved bezel setting. The engravings, mainly cameo, but sometimes intaglio, depict scarabs at first and then scenes from Greek mythology, often with heroic personages called out in Etruscan. The gold setting of the bezel bears a border design, such as cabling.\nCoins.\nEtruscan-minted coins can be dated between the 5th and 3rd centuries BC. Use of the 'Chalcidian' standard, based on the silver unit of 5.8\u00a0grams, indicates that this custom, like the alphabet, came from Greece. Roman coinage later supplanted Etruscan, but the basic Roman coin, the \"sesterce\", is believed to have been based on the 2.5-denomination Etruscan coin. Etruscan coins have turned up in caches or individually in tombs and in excavations seemingly at random, and concentrated, of course, in Etruria.\nEtruscan coins were in gold, silver, and bronze, the gold and silver usually having been struck on one side only. The coins often bore a denomination, sometimes a minting authority name, and a cameo motif. Gold denominations were in units of silver; silver, in units of bronze. Full or abbreviated names are mainly Pupluna (Populonia), Vatl or Veltuna (Vetulonia), Velathri (Volaterrae), Velzu or Velznani (Volsinii) and Cha for Chamars (Camars). Insignia are mainly heads of mythological characters or depictions of mythological beasts arranged in a symbolic motif: Apollo, Zeus, Culsans, Athena, Hermes, griffin, gorgon, male sphinx, hippocamp, bull, snake, eagle, or other creatures which had symbolic significance.\nFunctional categories.\nWallace et alia include the following categories, based on the uses to which they were put, on their site: abecedaria (alphabets), artisans' texts, boundary markers, construction texts, dedications, didaskalia (instructional texts), funerary texts, legal texts, other/unclear texts, prohibitions, proprietary texts (indicating ownership), religious texts, tesserae hospitales (tokens that establish \"the claim of the bearer to hospitality when travelling\").\nPhonology.\nIn the tables below, conventional letters used for transliterating Etruscan are accompanied by likely pronunciation in symbols within the square brackets, followed by examples of the early Etruscan alphabet which would have corresponded to these sounds.\nVowels.\nThe Etruscan vowel system consisted of four distinct vowels. The vowels \"o\" and \"u\" appear to have not been phonetically distinguished based on the nature of the writing system, as only one symbol is used to cover both in loans from Greek (e.g. Greek &gt; Etruscan 'pitcher').\nBefore the front vowels \u27e8c\u27e9 is used, while \u27e8k\u27e9 and \u27e8q\u27e9 are used before respectively unrounded and rounded back vowels.\nConsonants.\nTable of consonants.\nEtruscan also might have had consonants \u02a7 and \u02a7\u02b0, as they might be represented in the writing by using two letters, like in the word ('great-nephew' or 'great-grandson'). However, this theory is not widely accepted.\nAbsence of voiced stops.\nThe Etruscan consonant system primarily distinguished between aspirated and non-aspirated stops. There were no voiced stops. When words from foreign languages were borrowed into Etruscan, voiced stops typically became unvoiced stops; one example is Greek , which became Etruscan and Latin . Such a lack of voiced stops is not particularly unusual; it is found e.g. in modern Icelandic, in Scottish Gaelic, and in most Chinese languages. Even in English, aspiration is often more important than voice in the distinction of fortis-lenis pairs.\nSyllabic theory.\nBased on standard spellings by Etruscan scribes of words without vowels or with unlikely consonant clusters (e.g. 'of this (gen.)' and 'freeman'), it is likely that /m n l r/ were sometimes syllabic sonorants (cf. English \"little, \"button). Thus /kl\u0329/ and /\u02c8l\u0251wtn\u0329/.\nRix postulates several syllabic consonants, namely /l, r, m, n/ and palatal /l\u02b2, r\u02b2, n\u02b2/ as well as a labiovelar spirant /x\u02b7/, and some scholars such as Mauro Cristofani also view the aspirates as palatal rather than aspirated but these views are not shared by most Etruscologists. Rix supports his theories by means of variant spellings such as \"/\", \"/\", \"/\".\nMorphology.\nEtruscan was an agglutinative language, varying the endings of nouns, adjectives, pronouns and verbs with discrete endings for each function. It also had adverbs and conjunctions, whose endings did not vary.\nNouns.\nEtruscan substantives had five cases\u2014nominative, accusative, genitive, dative, and locative\u2014and two numbers: singular and a plural. Not all five cases are attested for every word. Nouns merge the nominative and accusative; pronouns do not generally merge these. Gender appears in personal names (masculine and feminine) and in pronouns (animate and inanimate); otherwise, it is not marked.\nUnlike the Indo-European languages, Etruscan noun endings were more agglutinative, with some nouns bearing two or three agglutinated suffixes. For example, where Latin would have distinct nominative plural and dative plural endings, Etruscan would suffix the case ending to a plural marker: Latin nominative singular , 'son', plural , dative plural , but Etruscan , and . Moreover, Etruscan nouns could bear multiple suffixes from the case paradigm alone: that is, Etruscan exhibited \"Suffixaufnahme\". Pallottino calls this phenomenon \"morphological redetermination\", which he defines as \"the typical tendency ... to redetermine the syntactical function of the form by the superposition of suffixes.\" His example is , 'in the sanctuary of Juno', where\" -al\" is a genitive ending and \"-\u03b8i\" a locative.\nSteinbauer says of Etruscan, \"there can be more than one marker ... to design a case, and ... the same marker can occur for more than one case.\"\n Common nouns use the unmarked root. Names of males may end in \"-e\": (Hercules), (Achilles), (Titus); of females, in \"-i\", \"-a\", or \"-u\": (Juno), (Minerva), or . Names of gods may end in \"-s\": \",\" ; or they may be the unmarked stem ending in a vowel or consonant: (Apollo), (Bacchus), or .\n Pallottino defines two declensions based on whether the genitive ends in \"-s/-\u015b\" or \"-l\". In the \"-s\" group are most noun stems ending in a vowel or a consonant: \"/',\" \"/\". In the second are names of females ending in \"i\" and names of males that end \"s\", \"th\" or \"n\": \"/',\" \"/\"\",\" \"/\". After \"l\" or \"r\" \"-us\" instead of \"-s\" appears: \"/\". Otherwise, a vowel might be placed before the ending: instead of . \nAccording to Rex Wallace, \"A few nouns could be inflected with both types of endings without any difference in meaning. Consider, for example, the genitives 'fortress (?)' and . Why this should be the case is not clear.\"\n There is a patronymic ending: \"-sa\" or \"-isa\", 'son of', but the ordinary genitive might serve that purpose. In the genitive case, morphological redetermination becomes elaborate. Given two male names, \"Vel\" and \"Avle\", means 'Vel son of Avle'. This expression in the genitive become \"Vel-u\u015b Avles-la\". Pallottino's example of a three-suffix form is .\nPronouns.\nPersonal pronouns refer to persons; demonstrative pronouns point out English \"this\", \"that\", \"there\".\nPersonal.\nThe first-person personal pronoun has a nominative ('I') and an accusative ('me'). The third person has a personal form ('he' or 'she') and an inanimate ('it'). The second person is uncertain, but some, like the Bonfantes, have claimed a dative singular ('to thee') and an accusative singular ('thee').\nDemonstrative.\nThe demonstratives, and , are used without distinction for 'that' or 'this'. The nominative\u2013accusative singular forms are: \",\" \",\" \",\" \",\" ; the plural: \",\" . There is a genitive singular: \",\" \",\" and plural . The accusative singular: \",\" \",\" \",\" \",\" \",\" ; plural 'these/those'. Locative singular: ; plural .\nAdjectives.\nThough uninflected for number, adjectives were inflected for case, agreeing with their noun: 'good' versus genitive 'of (the) good...'\nAdjectives fall into a number of types formed from nouns with a suffix:\nAdverbs.\nAdverbs are unmarked: , 'again'; , 'now, here'; , 'at first' (compare 'one'). Most Indo-European adverbs are formed from the oblique cases, which become unproductive and descend to fixed forms. Cases such as the ablative are therefore called adverbial. If there is any such widespread system in Etruscan, it is not obvious from the relatively few surviving adverbs.\nThe negative adverb is (for examples, see below in Imperative moods) .\nConjunctions.\nThe two enclitic coordinate conjunctions \"\u2010ka/\u2010ca/\u2010c\" 'and' and \"-um/\u2010m\" 'and, but' coordinated phrases and clauses, but phrases could also be coordinated without any conjunction (asyndetic). \nVerbs.\nVerbs had an indicative mood, an imperative mood and others. Tenses were present and past. The past tense had an active voice and a passive voice.\nPresent active.\nEtruscan used a verbal root with a zero suffix or \"-a\" without distinction to number or person: \",\" , 'he, she, we, you, they make'.\nPast or preterite active.\nAdding the suffix to the verb root produces a third-person singular active, which has been called variously a \"past\", a \"preterite\", a \"perfect.\" In contrast to Indo-European, this form is not marked for person. Examples: 'gives, dedicates' versus 'gave, dedicated'; 'lives' versus 'lived'.\nPast passive.\nThe third-person past passive is formed with -che: , 'offers/offered/was offered'.\nImperative mood.\nThe imperative was formed with the simple, uninflected root of the verb: 'dedicate!', 'put!', 'speak!' and 'invoke!'). \nThe imperative 'take, steal' is found in so\u2010called anti\u2010theft inscriptions: \n (Cm 2.13; fifth century BCE)\n'I (am) the bowl of Cupe Althr\u0325na. Don\u2019t steal me!'\nOther modals.\nVerbs with the suffix \"\u2010a\" indicated the jussive mood, with the force of commanding, or exhorting (within a subjunctive framework).\n'No one should put/make (?) anything here ().'\nVerbs ending in \"\u2010ri\" referred to obligatory activities:\n'On September twenty six, victims must be offered (?) and sacrificed (?) to Nethuns.'\nParticiples.\nVerbs formed participles in a variety of ways, among the most frequently attested being \"-u\" in 'dead' from 'die'.\nParticiples could also be formed with \"\u2010\u03b8\". These referred to activities that were contemporaneous with that of the main verb: '(while) speaking', '(while) invoking', and '(while) pouring (?)'.\nPostpositions.\nTypical of SOV agglutinative languages, Etruscan had postpositions rather than prepositions, each governing a specific case.\nVocabulary.\nBorrowings from Etruscan.\nOnly a few hundred words of the Etruscan vocabulary are understood with some certainty. The exact count depends on whether the different forms and the expressions are included. Below is a table of some of the words grouped by topic.\nSome words with corresponding Latin or other Indo-European forms are likely loanwords to or from Etruscan. For example, 'nephew', is probably from Latin (Latin \",\" ; this is a cognate of German , Old Norse ). A number of words and names for which Etruscan origin has been proposed survive in Latin.\nAt least one Etruscan word has an apparent Semitic/Aramaic origin: 'girl', that could have been transmitted by Phoenicians or by the Greeks (Greek: ). The word 'house' is a false cognate to the Coptic 'house'.\nIn addition to words believed to have been borrowed into Etruscan from Indo-European or elsewhere, there is a corpus of words such as which seem to have been borrowed into Latin from the older Etruscan civilization as a superstrate influence. Some of these words still have widespread currency in English and Latin-influenced languages. Other words believed to have a possible Etruscan origin include:\nEtruscan vocabulary.\nNumerals.\nMuch debate has been carried out about a possible Indo-European origin of the Etruscan cardinals. In the words of Larissa Bonfante (1990), \"What these numerals show, beyond any shadow of a doubt, is the non-Indo-European nature of the Etruscan language\". Conversely, other scholars, including Francisco R. Adrados, Albert Carnoy, Marcello Durante, Vladimir Georgiev, Alessandro Morandi and Massimo Pittau, have proposed a close phonetic proximity of the first ten Etruscan numerals to the corresponding numerals in other Indo-European languages.\nThe lower Etruscan numerals are (G. Bonfante 2002:96):\nIt is unclear which of , , and are 7, 8 and 9. may also mean 'twelve', with for 'ten'.\nFor higher numbers, it has been determined that is 20, 30, 40, 50, 60, and and any two in the series 70\u201390. is 100 (clearly 10, just as Proto-Indo-European 100 is from 10). Further, mean 'once, twice, and thrice' respectively; and 'first' and 'third'; 'one by one', 'two by two'; and and are 'double' and 'quadruple'.\nSample texts.\nFrom Tabula Capuana:\n(/ indicates line break; text from Alessandro Morandi \"Epigrafia Italica\" Rome, 1982, p.40) \nFirst section probably for March (lines 1\u20137): \n \n \n \n \nStart of second section for April ()(starting on line 8):\n \n \n \n \nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9457", "revid": "8356162", "url": "https://en.wikipedia.org/wiki?curid=9457", "title": "Election", "text": "Process by which a population chooses the holder of a public office\nAn election is a formal group decision-making process by which a population chooses an individual or multiple individuals to hold public office.\nElections have been the usual mechanism by which modern representative democracy has operated since the 17th century. Elections may fill offices in the legislature, sometimes in the executive and judiciary, and for regional and local government. This process is also used in many other private and business organisations, from clubs to voluntary associations and corporations.\nThe global use of elections as a tool for selecting representatives in modern representative democracies is in contrast with the practice in the democratic archetype, ancient Athens, where the elections were considered an oligarchic institution and most political offices were filled using sortition, also known as allotment, by which officeholders were chosen by lot.\nElectoral reform describes the process of introducing fair electoral systems where they are not in place, or improving the fairness or effectiveness of existing systems. Psephology is the study of results and other statistics relating to elections (especially with a view to predicting future results). Election is the fact of electing, or being elected.\nTo \"elect\" means \"to select or make a decision\", and so sometimes other forms of ballot such as referendums are referred to as elections, especially in the United States.\nHistory.\nElections were used as early in history as ancient Greece and ancient Rome, and throughout the Medieval period to select rulers such as the Holy Roman Emperor (see imperial election) and the pope (see papal election).\nIn the Vedic period of India, the \"raja\" (king) of a \"ga\u1e47a\" (a tribal organization) was elected by the \"ga\u1e47a\". The \"raja\" always belonged to the Kshatriya varna (warrior class), and was typically a son of the previous \"raja\". However, the \"ga\u1e47a\" members had the final say in his elections. Even during the Sangam Period people elected their representatives by casting their votes and the ballot boxes (usually a pot) were tied by rope and sealed. After the election the votes were taken out and counted. The Pala King Gopala (ruled c.\u2009750s\u00a0\u2013 770s CE) in early medieval Bengal was elected by a group of feudal chieftains. Such elections were quite common in contemporary societies of the region. In the Chola Empire, around 920 CE, in Uthiramerur (in present-day Tamil Nadu), palm leaves were used for selecting the village committee members. The leaves, with candidate names written on them, were put inside a mud pot. To select the committee members, a young boy was asked to take out as many leaves as the number of positions available. This was known as the \"Kudavolai\" system.\nThe first recorded popular elections of officials to public office, by majority vote, where all citizens were eligible both to vote and to hold public office, date back to the Ephors of Sparta in 754 BC, under the mixed government of the Spartan Constitution. Athenian democratic elections, where all citizens could hold public office, were not introduced for another 247 years, until the reforms of Cleisthenes. Under the earlier Solonian Constitution (c.\u2009574 BC), all Athenian citizens were eligible to vote in the popular assemblies, on matters of law and policy, and as jurors, but only the three highest classes of citizens could vote in elections. Nor were the lowest of the four classes of Athenian citizens (as defined by the extent of their wealth and property, rather than by birth) eligible to hold public office, through the reforms of Solon. The Spartan election of the Ephors, therefore, also predates the reforms of Solon in Athens by approximately 180 years.\nQuestions of suffrage, especially suffrage for minority groups, have dominated the history of elections. Males, the dominant cultural group in North America and Europe, often dominated the and continue to do so in many countries. Early elections in countries such as the United Kingdom and the United States were dominated by landed or ruling class males. However, by 1920 all Western European and North American democracies had universal adult male suffrage (except Switzerland) and many countries began to consider women's suffrage. Despite legally mandated universal suffrage for adult males, political barriers were sometimes erected to prevent fair access to elections (see civil rights movement).\nContexts of elections.\nElections are held in a variety of political, organizational, and corporate settings. Many countries hold elections to select people to serve in their governments, but other types of organizations hold elections as well. For example, many corporations hold elections among shareholders to select a board of directors, and these elections may be mandated by corporate law. In many places, an election to the government is usually a competition among people who have already won a primary election within a political party. Elections within corporations and other organizations often use procedures and rules that are similar to those of governmental elections.\nElectorate.\nSuffrage.\nThe question of who may vote is a central issue in elections. The electorate does not generally include the entire population; for example, many countries prohibit those who are under the age of majority from voting. All jurisdictions require a minimum age for voting.\nIn Australia, Aboriginal people were not given the right to vote until 1962 (see 1967 referendum entry) and in 2010 the federal government removed the rights of prisoners serving for 3 years or more to vote (a large proportion of which were Aboriginal Australians).\nSuffrage is typically only for citizens of the country, though further limits may be imposed.\nHowever, in the European Union, one can vote in municipal elections if one lives in the municipality and is an EU citizen; the nationality of the country of residence is not required. \nIn some countries, voting is required by law. Eligible voters may be subject to punitive measures such as a fine for not casting a vote. In Western Australia, the penalty for a first time offender failing to vote is a $20.00 fine, which increases to $50.00 if the offender refused to vote prior.\nVoting population.\nHistorically the size of eligible voters, the electorate, was small having the size of groups or communities of privileged men like aristocrats and men of a city (citizens).\nWith the growth of the number of people with bourgeois citizen rights outside of cities, expanding the term citizen, the electorates grew to numbers beyond the thousands.\nElections with an electorate in the hundred thousands appeared in the final decades of the Roman Republic, by extending voting rights to citizens outside of Rome with the Lex Julia of 90 BC, reaching an electorate of 910,000 and estimated voter turnout of maximum 10% in 70 BC, only again comparable in size to the first elections of the United States. At the same time the Kingdom of Great Britain had in 1780 about 214,000 eligible voters, 3% of the whole population.\nCandidates.\nA representative democracy requires a procedure to govern nomination for political office. In many cases, nomination for office is mediated through preselection processes in organized political parties.\nNon-partisan systems tend to be different from partisan systems as concerns nominations. In a direct democracy, one type of non-partisan democracy, any eligible person can be nominated. Although elections were used in ancient Athens, in Rome, and in the selection of popes and Holy Roman emperors, the origins of elections in the contemporary world lie in the gradual emergence of representative government in Europe and North America beginning in the 17th century. In some systems no nominations take place at all, with voters free to choose any person at the time of voting\u2014with some possible exceptions such as through a minimum age requirement\u2014in the jurisdiction. In such cases, it is not required (or even possible) that the members of the electorate be familiar with all of the eligible persons, though such systems may involve indirect elections at larger geographic levels to ensure that some first-hand familiarity among potential electees can exist at these levels (i.e., among the elected delegates).\nElectoral systems.\nElectoral systems are the detailed constitutional arrangements and voting systems that convert the vote into a political decision. \nThe first step is for voters to cast the ballots, which may be simple single-choice ballots, but other types, such as multiple choice or ranked ballots may also be used. Then the votes are tallied, for which various vote counting systems may be used. and the voting system then determines the result on the basis of the tally. Most systems can be categorized as either proportional, majoritarian or mixed. Among the proportional systems, the most commonly used are party-list proportional representation (list PR) systems, among majoritarian are first-past-the-post electoral system (single winner plurality voting) and different methods of majority voting (such as the widely used two-round system). Mixed systems combine elements of both proportional and majoritarian methods, with some typically producing results closer to the former (mixed-member proportional) or the other (e.g. parallel voting). \nMany countries have growing electoral reform movements, which advocate systems such as approval voting, single transferable vote, instant runoff voting or a Condorcet method; these methods are also gaining popularity for lesser elections in some countries where more important elections still use more traditional counting methods.\nWhile openness and accountability are usually considered cornerstones of a democratic system, the act of casting a vote and the content of a voter's ballot are usually an important exception. The secret ballot is a relatively modern development, but it is now considered crucial in most free and fair elections, as it limits the effectiveness of intimidation.\nCampaigns.\nWhen elections are called, politicians and their supporters attempt to influence policy by competing directly for the votes of constituents in what are called campaigns. Supporters for a campaign can be either formally organized or loosely affiliated, and frequently utilize campaign advertising. It is common for political scientists to attempt to predict elections via political forecasting methods.\nThe most expensive election campaign included US$7 billion spent on the 2012 United States presidential election and is followed by the US$5 billion spent on the 2014 Indian general election.\nElection timing.\nThe nature of democracy is that elected officials are accountable to the people, and they must return to the voters at prescribed intervals to seek their mandate to continue in office. For that reason, most democratic constitutions provide that elections are held at fixed regular intervals. In the United States, elections for public offices are typically held between every two and six years in most states and at the federal level, with exceptions for elected judicial positions that may have longer terms of office. There is a variety of schedules, for example, presidents: the President of Ireland is elected every seven years, the President of Russia and the President of Finland every six years, the President of France every five years, President of the United States every four years.\nPre-decided or fixed election dates have the advantage of fairness and predictability. However, they tend to greatly lengthen campaigns, and make dissolving the legislature (parliamentary system) more problematic if the date should happen to fall at a time when dissolution is inconvenient (e.g. when war breaks out). Other states (e.g., the United Kingdom) only set maximum time in office, and the executive decides exactly when within that limit it will actually go to the polls. In practice, this means the government remains in power for close to its full term, and chooses an election date it calculates to be in its best interests (unless something special happens, such as a motion of no-confidence). This calculation depends on a number of variables, such as its performance in opinion polls and the size of its majority.\nRolling elections are elections in which all representatives in a body are elected, but these elections are spread over a period of time rather than all at once. Examples are the presidential primaries in the United States, Elections to the European Parliament (where, due to differing election laws in each member state, elections are held on different days of the same week) and, due to logistics, general elections in Lebanon and India. The voting procedure in the Legislative Assemblies of the Roman Republic are also a classical example.\nIn rolling elections, voters have information about previous voters' choices. While in the first elections, there may be plenty of hopeful candidates, in the last rounds consensus on one winner is generally achieved. In today's context of rapid communication, candidates can put disproportionate resources into competing strongly in the first few stages, because those stages affect the reaction of latter stages.\nNon-democratic elections.\nIn many of the countries with weak rule of law, the most common reason why elections do not meet international standards of being \"free and fair\" is interference from the incumbent government. Dictators may use the powers of the executive (police, martial law, censorship, physical implementation of the election mechanism, etc.) to remain in power despite popular opinion in favour of removal. Members of a particular faction in a legislature may use the power of the majority or supermajority (passing criminal laws, and defining the electoral mechanisms including eligibility and district boundaries) to prevent the balance of power in the body from shifting to a rival faction due to an election.\nNon-governmental entities can also interfere with elections, through physical force, verbal intimidation, or fraud, which can result in improper casting or counting of votes. Monitoring for and minimizing electoral fraud is also an ongoing task in countries with strong traditions of free and fair elections. Problems that prevent an election from being \"free and fair\" take various forms.\nLack of open political debate or an informed electorate.\nThe electorate may be poorly informed about issues or candidates due to lack of freedom of the press, lack of objectivity in the press due to state or corporate control, and/or lack of access to news and political media. Freedom of speech may be curtailed by the state, favouring certain viewpoints or state propaganda.\nUnfair rules.\nGerrymandering, exclusion of opposition candidates from eligibility for office, needlessly high restrictions on who may be a candidate, like ballot access rules, and manipulating thresholds for electoral success are some of the ways the structure of an election can be changed to favour a specific faction or candidate.\nInterference with campaigns.\nThose in power may arrest or assassinate candidates, suppress or even criminalize campaigning, close campaign headquarters, harass or beat campaign workers, or intimidate voters with violence. Foreign electoral intervention can also occur, with the United States interfering between 1946 and 2000 in 81 elections and Russia/USSR in 36.\nIn 2018 the most intense interventions, utilizing false information, were by China in Taiwan and by Russia in Latvia; the next highest levels were in Bahrain, Qatar and Hungary.\nTampering with the election mechanism.\nThis can include falsifying voter instructions,\nviolation of the secret ballot, ballot stuffing, tampering with voting machines,\ndestruction of legitimately cast ballots,\nvoter suppression, voter registration fraud, failure to validate voter residency, fraudulent tabulation of results, and use of physical force or verbal intimation at polling places. Other examples include persuading candidates not to run, such as through blackmailing, bribery, intimidation or physical violence.\nSham election.\nA sham election, or show election, is an election that is held purely for show; that is, without any significant political choice or real impact on the results of the election.\nSham elections are a common event in dictatorial regimes that feel the need to feign the appearance of public legitimacy. Published results usually show nearly 100% voter turnout and high support (typically at least 80%, and close to 100% in many cases) for the prescribed candidate(s) or for the referendum choice that favours the political party in power. Dictatorial regimes can also organize sham elections with results simulating those that might be achieved in democratic countries.\nSometimes, only one government-approved candidate is allowed to run in sham elections with no opposition candidates allowed, or opposition candidates are arrested on false charges (or even without any charges) before the election to prevent them from running.\nBallots may contain only one \"yes\" option, or in the case of a simple \"yes or no\" question, security forces often persecute people who pick \"no\", thus encouraging them to pick the \"yes\" option. In other cases, those who vote receive stamps in their passport for doing so, while those who did not vote (and thus do not receive stamps) are persecuted as enemies of the people.\nSham elections can sometimes backfire against the party in power, especially if the regime believes they are popular enough to win without coercion or fraud. The most famous example of this was the 1990 Myanmar general election, in which the government-sponsored National Unity Party suffered a landslide defeat to the opposition National League for Democracy and consequently, the results were annulled.\nExamples of sham elections include: the presidential and parliamentary elections of the Islamic Republic of Iran, the 1929 and 1934 elections in Fascist Italy, the 1942 general election in Imperial Japan, those in Nazi Germany, East Germany, the 1940 elections of Stalinist \"People's Parliaments\" to legitimise the Soviet occupation of Estonia, Latvia and Lithuania, the 1928, 1935, 1942, 1949, 1951 and 1958 elections in Portugal, the 1991 and 2019 Kazakh presidential elections, those in North Korea, the 1995 and 2002 presidential referendums in Saddam Hussein's Iraq and the 2021 Hong Kong legislative election.\nIn Mexico, all of the presidential elections from 1929 to 1982 are considered to be sham elections, as the Institutional Revolutionary Party (PRI) and its predecessors governed the country in a \"de facto\" single-party system without serious opposition, and they won all of the presidential elections in that period with more than 70% of the vote. The first seriously competitive presidential election in modern Mexican history was that of 1988, in which for the first time the PRI candidate faced two strong opposition candidates, though it is believed that the government rigged the result. The first fair election was held in 1994, though the opposition did not win until 2000.\nA predetermined conclusion is permanently established by the regime through suppression of the opposition, coercion of voters, vote rigging, reporting several votes received greater than the number of voters, outright lying, or some combination of these.\nIn an extreme example, Charles D. B. King of Liberia was reported to have won by 234,000 votes in the 1927 general election, a \"majority\" that was over fifteen times larger than the number of eligible voters.\nElections as aristocratic.\nScholars argue that the predominance of elections in modern liberal democracies masks the fact that they are actually aristocratic selection mechanisms that deny each citizen an equal chance of holding public office. Such views were expressed as early as the time of Ancient Greece by Aristotle. According to French political scientist Bernard Manin, the inegalitarian nature of elections stems from four factors: the unequal treatment of candidates by voters, the distinction of candidates required by choice, the cognitive advantage conferred by salience, and the costs of disseminating information. These four factors result in the evaluation of candidates based on voters' partial standards of quality and social saliency (for example, skin color and good looks). This leads to self-selection biases in candidate pools due to unobjective standards of treatment by voters and the costs (barriers to entry) associated with raising one's political profile. Ultimately, the result is the election of candidates who are superior (whether in actuality or as perceived within a cultural context) and \"objectively unlike\" the voters they are supposed to represent.\nAdditionally, evidence suggests that the concept of electing representatives was originally conceived to be \"different\" from democracy. Prior to the 18th century, some societies in Western Europe used sortition as a means to select rulers, a method which allowed regular citizens to exercise power, in keeping with understandings of democracy at the time. However, the idea of what constituted a legitimate government shifted in the 18th century to include consent, especially with the rise of the enlightenment. From this point onwards, sortition fell out of favor as a mechanism for selecting rulers. On the other hand, elections began to be seen as a way for the masses to express popular consent repeatedly, resulting in the triumph of the electoral process until the present day.\nThis conceptual misunderstanding of elections as open and egalitarian when they are not innately so may thus be a root cause of the problems in contemporary governance. Those in favor of this view argue that the modern system of elections was never meant to give ordinary citizens the chance to exercise power - merely privileging their right to consent to those who rule. Therefore, the representatives that modern electoral systems select for are too disconnected, unresponsive, and elite-serving. To deal with this issue, various scholars have proposed alternative models of democracy, many of which include a return to sortition-based selection mechanisms. The extent to which sortition should be the dominant mode of selecting rulers or instead be hybridised with electoral representation remains a topic of debate.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "9458", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9458", "title": "Executive power", "text": ""}
{"id": "9459", "revid": "754619", "url": "https://en.wikipedia.org/wiki?curid=9459", "title": "Enniskillen", "text": "Town in County Fermanagh, Northern Ireland\nEnniskillen ( , from , 'Ceithlenn's island') is the largest town in County Fermanagh, Northern Ireland. It is in the middle of the county, between the Upper and Lower sections of Lough Erne. It had a population of 13,823 at the 2011 Census. Enniskillen Castle was built in the 15th century as a stronghold of the Maguires, before coming under English control in the early 17th century. The castle and town were expanded during the Plantation of Ulster. It was the seat of local government for the former Fermanagh District Council, and is the county town of Fermanagh.\nToponymy.\nThe town's name comes from the . This refers to Cethlenn, a figure in Irish mythology who may have been a goddess. Local legend has it that Cethlenn was wounded in battle by an arrow and attempted to swim across the River Erne, which surrounds the island, but she never reached the other side, so the island was named in reference to her. It has been anglicised many ways over the centuries \u2013 \"Iniskellen\", \"Iniskellin\", \"Iniskillin\", \"Iniskillen\", \"Inishkellen\", \"Inishkellin\", \"Inishkillin\", \"Inishkillen\" and so on.\nHistory.\nThe town's oldest building is Enniskillen Castle, built by Hugh (Maguire) the Hospitable who died in 1428. An earthwork, the Skonce on the shore of Lough Erne, may be the remains of an earlier motte. The castle was the stronghold of the junior branch of the Maguires. The first watergate was built around 1580 by C\u00fa Chonnacht Maguire, though subsequent lowering of the level of the lough has left it without water. The strategic position of the castle made its capture important for the English in 1593, to support their plans for the control of Ulster. The castle was besieged three times in 1594\u201395. The English, led by a Captain Dowdall, captured it in February 1594. Maguire then laid siege to it, and defeated a relieving force at the Battle of the Ford of the Biscuits at Drumane Bridge on the Arney River. Although the defenders were relieved, Maguire gained possession of the castle from 1595 to 1598 and it was not finally captured by the English until 1607.\nThis was part of a wider campaign to bring the province of Ulster under English control; the final capture of Enniskillen Castle in 1607 was followed by the Plantation of Ulster, during which the lands of the native Irish were seized and handed over to planters loyal to the English Crown. The Maguires were supplanted by William Cole, originally from Devon, who was appointed by James I to build an English settlement there in 1612.\nCaptain Cole was installed as Constable and strengthened the castle wall and built a \"fair house\" on the old foundation as the centre point of the county town. The first Protestant parish church was erected on the hilltop in 1627. By 1630 the town had around 180 inhabitants, mostly comprising English and Scottish settlers. The Royal Free School of Fermanagh was moved onto the island in 1643. The first bridges were drawbridges; permanent bridges were not installed before 1688.\nBy 1689 the town had grown significantly. During the conflict which resulted from the ousting of King James II by his Protestant rival, William III, Enniskillen and Derry were the focus of Williamite resistance in Ireland, including the nearby Battle of Newtownbutler.\nEnniskillen and Derry were the two garrisons in Ulster that were not wholly loyal to James II, and it was the last town to fall before the siege of Derry. As a direct result of this conflict, Enniskillen developed not only as a market town but also as a garrison, which became home to two regiments.\nThe current site of Fermanagh College (now part of the South West College) was the former Enniskillen Gaol. Many people were tried and hanged in the square during the times of public execution. Part of the old Gaol is still used by the college. Enniskillen Town Hall was designed by William Scott and completed in 1901.\nMilitary history.\nEnniskillen is the site of the foundation of two British Army regiments:\nThe town's name (with the archaic spelling) continues to form part of the title to The Royal Irish Regiment (27th (Inniskilling) 83rd and 87th and Ulster Defence Regiment). Enniskillen Castle features on the cap badge of both regiments.\nThe Troubles.\nEnniskillen was the site of several events during The Troubles, the most notable being the Remembrance Day bombing in which 11 people were killed. Bill Clinton opened The Clinton Centre in 2002 on the site of the bombing. The Provisional Irish Republican Army claimed responsibility for the attack.\nAlleged sexual abuse and assault.\nIn 2019, at least nine men reported to the police and the press and said in public forums that, in the 1980s and 90s, when they were children, they were repeatedly molested and raped by a paedophile ring of at least 20 men in the Enniskillen area. Investigations are continuing.\nDemography.\nOn Census day (27 March 2011) there were 13,823 people living in Enniskillen (5,733 households), accounting for 0.76% of the NI total and representing an increase of 1.6% on the Census 2001 population of 13,599. Of these:\nPlaces of interest.\nChurches.\nThere are four churches in the town centre. These are:\nThere are several other churches outside the town centre.\nHistoric Buildings.\nSome of these buildings are outside the town.\nSports.\nAssociation football.\nThe town has two association football teams called Enniskillen Rangers and Enniskillen Town United F.C.\nEnniskillen Rangers are the current holders of the Irish Junior Cup, defeating Hill Street 5\u20131 on Monday, 1 May 2017. The match was played at the National Football Stadium at Windsor Park in Belfast. They play their home games at the Ball Range.\nEnniskillen Rangers have several notable former players including Sandy Fulton and Jim Cleary.\nEnniskillen Town United F.C. currently play in the Fermanagh &amp; Western 1st Division. Their most notable former player is Michael McGovern who currently plays for Norwich City F.C. At the moment, Enniskillen Town play their home games at The Lakeland Forum playing fields in Enniskillen.\nRugby.\nEnniskillen Rugby Football Club was founded in 1925 and plays its home games at Mullaghmeen. The club currently fields 4 senior men's teams, a senior ladies' team, a range of male and female youth teams, a vibrant mini section and a disability tag team called The Enniskillen Elks. Enniskillen XV won the Ulster Towns Cup in the 2018/19 season, defeating Ballyclare 19\u20130. The team currently play in Kukri Ulster Rugby Championship Division 1.\nThe rugby club was formed on 28 August 1925, when 37 attended a meeting in Enniskillen Town Hall. The name Enniskillen Rugby Club was agreed and the club adopted the rules of the Dublin University Football Club. The first match was played on 30 September 1925 against Ballyshannon in County Donegal.\nGaelic games.\nEnniskillen Gaels is a Gaelic Athletic Association club founded in 1927. It is based at Brewster Park, Enniskillen. The club has had success in both Gaelic football and hurling winning in both county and provincial competitions.\nInternational events.\nEnniskillen was the venue of the 39th G8 summit which was held on 17 and 18 June 2013. It was held at the Lough Erne Resort, a five-star hotel and golf resort on the shore of Lough Erne. The gathering was the biggest international diplomatic gathering ever held in Northern Ireland. Among the G8 leaders who attended were British Prime Minister David Cameron, United States President Barack Obama, German Chancellor Angela Merkel, and Russian President Vladimir Putin.\nIn the past, Enniskillen has hosted an array of international events, most notably stages of the World Waterski World Cup, annually from 2005 to 2007 at the Broadmeadow. Despite its success, Enniskillen was not chosen as a World Cup Stop for 2008.\nIn January 2009, Enniskillen hosted the ceremonial start of Rally Ireland 2009, the first stage of the WRC FIA World Rally Championship 2009 Calendar.\nEnniskillen has hosted the Happy Days arts festival since 2012, which celebrates \"the work and influence of Nobel Prize-winning writer Samuel Beckett\" and is the \"first annual, international, multi-arts festival to be held in Northern Ireland since the launch of the Ulster Bank Belfast Festival at Queen's in 1962\".\nEducation.\nThere are numerous schools and colleges in and around the Enniskillen area, from primary level to secondary level, including some further education colleges such as the technical college.\nTransport.\nRail \u2013 historic.\nRailway lines from Enniskillen railway station linked the town with Derry from 1854, Dundalk from 1861, Bundoran from 1868 and Sligo from 1882. By 1883 the Great Northern Railway (Ireland) absorbed all the lines except the Sligo, Leitrim and Northern Counties Railway, which remained independent throughout its existence. In October 1957 the Government of Northern Ireland closed the GNR line, which made it impossible for the SL&amp;NCR to continue and forced it also to close.\nRail \u2013 current.\nThe nearest railway station to Enniskillen is Sligo station which is served by multiple trains to Dublin Connolly and is operated by Iarnr\u00f3d \u00c9ireann. The Dublin-Sligo railway line has a two-hourly service run by Iarnr\u00f3d \u00c9ireann. A connecting bus from Sligo via Manorhamilton to Enniskillen is operated by Bus \u00c9ireann.\nBus.\nBus service to Enniskillen is provided by both Ulsterbus and Bus \u00c9ireann, from Enniskillen bus station. Number 261, 261b and X261 Goldline buses run from Belfast to Enniskillen. Bus \u00c9ireann Route 30 runs from Donegal to Dublin Airport/Dublin City via Enniskillen.\nAir.\nEnniskillen has a World War II-era airport, Enniskillen/St Angelo Airport. The airport had scheduled flights in the past but now serves mainly private traffic.\nRoad.\nThe town is on the main A4/N16 route linking Belfast and Sligo, and on the main Dublin to Ballyshannon route, the N3/A46/A509.\nTwinning.\nEnniskillen was originally twinned with Brackwede \u2013 a Bielefeld suburb \u2013 where the Inniskilling Dragoon Guards were stationed in the late 1950s when the twinning was initiated; however, this suburb was incorporated into Stadt Bielefeld in 1973, the city with which Enniskillen is now officially twinned.\nThough the twinning arrangements are still operational, at a meeting of the Regeneration and Community Committee, in February 2018, it was agreed that the twinning arrangements would be formally terminated at the end of the Council term in June 2018. However, Fermanagh and Omagh District Council still have plans to send representatives to Brackwede for the 60th-anniversary celebrations of the twinning. Therefore, the future of the twinning is now somewhat unclear.\nClimate.\nEnniskillen has a maritime climate with a narrow range of temperatures and rainfall. The nearest official Met Office weather station for which online records are available is at Lough Navar Forest, about northwest of Enniskillen. Data has also more recently been collected from Enniskillen/St Angelo Airport, under north of the town centre, which should in time give a more accurate representation of the climate of the Enniskillen area.\nThe absolute maximum temperature is , recorded during July 2006. In an 'average' year, the warmest day is and only 2.4 days a year should rise to or above. The respective absolute maximum for St Angelo is \nThe absolute minimum temperature is , recorded during January 1984. In an 'average' year, the coldest night should fall to . Lough Navar is a frosty location, with some 76 air frosts recorded in a typical year. It is likely that Enniskillen town centre is significantly less frosty than this. The absolute minimum at St Angelo is , reported during the record cold month of December 2010.\nThe warmest month on record at St Angelo was August 1995 with a mean temperature of (mean maximum , mean minimum ), while the coldest month was December 2010, with a mean temperature of (mean maximum , mean minimum ).\nRainfall is high, averaging over 1500\u00a0mm. 212 days of the year report at least 1\u00a0mm of precipitation, ranging from 15 days during April, May and June, to 20 days in October, November, December, January and March.\nThe K\u00f6ppen climate classification subtype for this climate is \"\" (Marine West Coast Climate/Oceanic climate).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9461", "revid": "1588193", "url": "https://en.wikipedia.org/wiki?curid=9461", "title": "Eric Raymond (disambiguation)", "text": "Eric S. Raymond (born 1957) is an American computer programmer and author.\nEric Raymond may also refer to:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "9463", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=9463", "title": "English language/British English", "text": ""}
{"id": "9464", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9464", "title": "Non-standard adjectives in the English language", "text": ""}
{"id": "9465", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=9465", "title": "English language/American English", "text": ""}
{"id": "9467", "revid": "847224", "url": "https://en.wikipedia.org/wiki?curid=9467", "title": "Longest word in English", "text": "List of longest words in the English language\nThe identity of the longest word in English depends on the definition of a word and of length.\nWords may be derived naturally from the language's roots or formed by coinage and construction. Additionally, comparisons are complicated because place names may be considered words, technical terms may be arbitrarily long, and the addition of suffixes and prefixes may extend the length of words to create grammatically correct but unused or novel words.\nThe \"length\" of a word may also be understood in multiple ways. Most commonly, length is based on orthography (conventional spelling rules) and counting the number of written letters. Alternate, but less common, approaches include phonology (the spoken language) and the number of phonemes (sounds).\nMajor dictionaries.\nThe longest word in any of the major English language dictionaries is \"pneumonoultramicroscopicsilicovolcanoconiosis\" (45 letters), a word that refers to a lung disease contracted from the inhalation of very fine silica particles, specifically from a volcano; medically, it is the same as silicosis. The word was deliberately coined to be the longest word in English, and has since been used in a close approximation of its originally intended meaning, lending at least some degree of validity to its claim.\nThe \"Oxford English Dictionary\" contains \"pseudopseudohypoparathyroidism\" (30 letters).\n\"Merriam-Webster's Collegiate Dictionary\" does not contain \"antidisestablishmentarianism\" (28 letters), as the editors found no widespread, sustained usage of the word in its original meaning. The longest word in that dictionary is \"electroencephalographically\" (27 letters).\nThe longest non-technical word in major dictionaries is \"flocci\u00adnauci\u00adnihili\u00adpili\u00adfication\" at 29 letters. Consisting of a series of Latin words meaning \"nothing\" and defined as \"the act of estimating something as worthless\"; its usage has been recorded as far back as 1741.\nRoss Eckler has noted that most of the longest English words are not likely to occur in general text, meaning non-technical present-day text seen by casual readers, in which the author did not specifically intend to use an unusually long word. According to Eckler, the longest words likely to be encountered in general text are \"deinstitutionalization\" and \"counterrevolutionaries\", with 22 letters each.\nA computer study of over a million samples of normal English prose found that the longest word one is likely to encounter on an everyday basis is \"uncharacteristically\", at 20 letters.\nThe word \"internationalization\" is abbreviated \"i18n\", the embedded number representing the number of letters between the first and the last.\nCreations of long words.\nCoinages.\nIn his play \"Assemblywomen\" (\"Ecclesiazousae\"), the ancient Greek comedic playwright Aristophanes created a word of 171 letters (183 in the transliteration below), which describes a dish by stringing together its ingredients:\nLopadotemachoselachogaleokranioleipsanodrimhypotrimmatosilphiokarabomelitokatakechymenokichlepikossyphophattoperisteralektryonoptekephalliokigklopeleiolagoiosiraiobaphetraganopterygon.\nHenry Carey's farce \"Chrononhotonthologos\" (1743) holds the opening line: \"Aldiborontiphoscophornio! Where left you Chrononhotonthologos?\"\nThomas Love Peacock put these creations into the mouth of the phrenologist Mr. Cranium in his 1816 book \"Headlong Hall\": \"osteosarchaematosplanchnochondroneuromuelous\" (44 characters) and \"osseocarnisanguineoviscericartilaginonervomedullary\" (51 characters).\nJames Joyce made up nine 100-letter words plus one 101-letter word in his novel \"Finnegans Wake\", the most famous of which is Bababadalgharaghtakamminarronnkonnbronntonnerronntuonnthunntrovarrhounawnskawntoohoohoordenenthurnuk. Appearing on the first page, it allegedly represents the symbolic thunderclap associated with the fall of Adam and Eve. As it appears nowhere else except in reference to this passage, it is generally not accepted as a real word. Sylvia Plath made mention of it in her semi-autobiographical novel \"The Bell Jar\", when the protagonist was reading \"Finnegans Wake\".\n\"Supercalifragilisticexpialidocious\", the 34-letter title of a song from the movie \"Mary Poppins\", does appear in several dictionaries, but only as a proper noun defined in reference to the song title. The attributed meaning is \"a word that you say when you don't know what to say.\" The idea and invention of the word is credited to songwriters Robert and Richard Sherman.\nAgglutinative constructions.\nThe English language permits the legitimate extension of existing words to serve new purposes by the addition of prefixes and suffixes. This is sometimes referred to as agglutinative construction. This process can create arbitrarily long words: for example, the prefixes \"pseudo\" (false, spurious) and \"anti\" (against, opposed to) can be added as many times as desired. More familiarly, the addition of numerous \"great\"s to a relative, such as \"great-great-great-great-grandparent\", can produce words of arbitrary length. In musical notation, an 8192nd of a note may be called a \"semihemidemisemihemidemisemihemidemisemiquaver\".\n\"Antidisestablishmentarianism\" is the longest common example of a word formed by agglutinative construction.\nTechnical terms.\nA number of scientific naming schemes can be used to generate arbitrarily long words.\nThe IUPAC nomenclature for organic chemical compounds is open-ended, giving rise to the 189,819-letter chemical name \"Methionyl\u00adthreonylthreonyl\u200a.\u200a.\u200a.\u200aiso\u00adleucine\" for the protein also known as titin, which is involved in striated muscle formation. In nature, DNA molecules can be much bigger than protein molecules and therefore potentially be referred to with much longer chemical names. For example, the wheat chromosome 3B contains almost 1 billion base pairs, so the sequence of one of its strands, if written out in full like \"Adenilyl\u00adadenilyl\u00adguanilyl\u00adcystidylthymidyl\u200a.\u200a.\u200a.\u200a\", would be about 8billion letters long. The longest published word, \"Acetyl\u00adseryl\u00adtyrosyl\u00adseryliso\u200a.\u200a.\u200a.\u200aserine\", referring to the coat protein of a certain strain of tobacco mosaic virus (P03575), is 1,185 letters long, and appeared in the American Chemical Society's Chemical Abstracts Service in 1964 and 1966. In 1965, the Chemical Abstracts Service overhauled its naming system and started discouraging excessively long names. In 2011, a dictionary broke this record with a 1909-letter word describing the \"trpA\" protein (P0A877).\nJohn Horton Conway and Landon Curt Noll developed an open-ended system for naming powers of 10, in which one \"sexmillia\u00adquingent\u00adsexagin\u00adtillion\", coming from the Latin name for 6560, is the name for 103(6560+1) = 1019683. Under the long number scale, it would be 106(6560) = 1039360.\n\"&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Gammara\u00adcanthus\u00adkyto\u00addermo\u00adgammarus lori\u00adcato\u00adbaica\u00adlensis\" is sometimes cited as the longest binomial name\u2014it is a kind of amphipod. However, this name, proposed by B. Dybowski, was invalidated by the International Code of Zoological Nomenclature in 1929 after being petitioned by Mary J. Rathbun to take up the case.\n\"Myxococcus llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogochensis\" is the longest accepted binomial name for an organism. It is a bacterium found in soil collected at Llan\u00adfair\u00adpwll\u00adgwyn\u00adgyll\u00ad (discussed below). \"Parastratiosphecomyia stratiosphecomyioides\" is the longest accepted binomial name for any animal, or any organism visible with the naked eye. It is a species of soldier fly. The genus name \"Parapropalaehoplophorus\" (a fossil glyptodont, an extinct family of mammals related to armadillos) is two letters longer, but does not contain a similarly long species name.\n\"&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Aequeo\u00adsalino\u00adcalcalino\u00adceraceo\u00adaluminoso\u00adcupreo\u00advitriolic\", at 52 letters, describing the spa waters at Bath, England, is attributed to Dr. Edward Strother (1675\u20131737). The word is composed of the following elements:\nNotable long words.\nPlace names.\nThe longest officially recognized place name in an English-speaking country is (85 letters), which is a hill in New Zealand. The name is in the M\u0101ori language. A widely recognized version of the name is Taumata\u00adwhakatangihanga\u00adkoauau\u00ado\u00adtamatea\u00adturi\u00adpukaka\u00adpiki\u00admaunga\u00adhoro\u00adnuku\u00adpokai\u00adwhenua\u00adki\u00adtana\u00adtahu (85 letters), which appears on the signpost at the location (see the photo on this page). In M\u0101ori, the digraphs \"ng\" and \"wh\" are each treated as single letters.\nIn Canada, the longest place name is \"Dysart, Dudley, Harcourt, Guilford, Harburn, Bruton, Havelock, Eyre and Clyde\", a township in Ontario, at 61 letters or 68 non-space characters.\nThe 58-letter name \"Llan\u00adfair\u00adpwll\u00adgwyn\u00adgyll\u00adgogery\u00adchwyrn\u00addrob\u00adwlll\u00adlanty\u00adsilio\u00adgogo\u00adgoch\" is the name of a town on Anglesey, an island of Wales. In terms of the traditional Welsh alphabet, the name is only 51 letters long, as certain digraphs in Welsh are considered as single letters, for instance \"ll\", \"ng\" and \"ch\". It is generally agreed, however, that this invented name, adopted in the mid-19th century, was contrived solely to be the longest name of any town in Britain. The official name of the place is \"Llanfairpwllgwyngyll\", commonly abbreviated to \"Llanfairpwll\" or \"Llanfair PG\".\nThe longest non-contrived place name in the United Kingdom which is a single non-hyphenated word is Cottonshopeburnfoot (19 letters) and the longest which is hyphenated is Sutton-under-Whitestonecliffe (29 characters).\nThe longest place name in the United States (45 letters) is \"Char\u00adgogga\u00adgogg\u00adman\u00adchau\u00adggagogg\u00adchau\u00adbuna\u00adgunga\u00admaugg\", a lake in Webster, Massachusetts. It means \"Fishing Place at the Boundaries \u2013 Neutral Meeting Grounds\" and is sometimes facetiously translated as \"you fish your side of the water, I fish my side of the water, nobody fishes the middle\". The lake is also known as Webster Lake. The longest hyphenated names in the U.S. are \"Winchester-on-the-Severn\", a town in Maryland, and \"Washington-on-the-Brazos\", a notable place in Texas history. The longest single-word town names in the U.S. are Kleinfeltersville, Pennsylvania and Mooselookmeguntic, Maine.\nThe longest official geographical name in Australia is Ma\u00admungku\u00adkumpu\u00adrang\u00adkunt\u00adjunya. It has 26 letters and is a Pitjantjatjara word meaning \"where the Devil urinates\".\nLiechtenstein is the longest country name with single name in English. The second longest country name with single name in English is Turkmenistan. There are longer country names if one includes ones with spaces.\nPersonal names.\n\"Guinness World Records\" formerly contained a category for longest personal name used.\nLong birth names are often coined in protest of naming laws or for other personal reasons.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9469", "revid": "16185737", "url": "https://en.wikipedia.org/wiki?curid=9469", "title": "Eric S. Raymond", "text": "American computer programmer, author, and advocate for the open source movement\nEric Steven Raymond (born December 4, 1957), often referred to as ESR, is an American software developer, open-source software advocate, and author of the 1997 essay and 1999 book \"The Cathedral and the Bazaar\". He wrote a guidebook for the Roguelike game \"NetHack\". In the 1990s, he edited and updated the Jargon File, published as \"The New Hacker's Dictionary\".\nEarly life.\nRaymond was born in Boston, Massachusetts, in 1957 and lived in Venezuela as a child. His family moved to Pennsylvania in 1971. He developed cerebral palsy at birth; his weakened physical condition motivated him to go into computing.\nCareer.\nRaymond began his programming career writing proprietary software, between 1980 and 1985. In 1990, noting that the Jargon File had not been maintained since about 1983, he adopted it, but not without criticism; Paul Dourish maintains an archived original version of the Jargon File, because, he says, Raymond's updates \"essentially destroyed what held it together.\"\nIn 1996 Raymond took over development of the open-source email software \"popclient\", renaming it to Fetchmail. Soon after this experience, in 1997, he wrote the essay \"The Cathedral and the Bazaar\", detailing his thoughts on open-source software development and why it should be done as openly as possible (the \"bazaar\" approach). The essay was based in part on his experience in developing Fetchmail. He first presented his thesis at the annual Linux Kongress on May 27, 1997. He later expanded the essay into a book, \"The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary\", in 1999. The essay has been widely cited. The internal white paper by Frank Hecker that led to the release of the Mozilla (then Netscape) source code in 1998 cited \"The Cathedral and the Bazaar\" as \"independent validation\" of ideas proposed by Eric Hahn and Jamie Zawinski. Hahn would later describe the 1999 book as \"clearly influential\".\nFrom the late 1990s onward, due in part to the popularity of his essay, Raymond became a prominent voice in the open source movement. He co-founded the Open Source Initiative (OSI) in 1998, taking on the self-appointed role of ambassador of open source to the press, business and public. He remains active in OSI, but stepped down as president of the initiative in February 2005. In early March 2020, he was removed from two Open Source Initiative mailing lists due to posts that violated the OSI's Code of Conduct.\nIn 1998 Raymond received and published a Microsoft document expressing worry about the quality of rival open-source software. He named this document, together with others subsequently leaked, \"The Halloween Documents\".\nIn 2000\u20132002 he created Configuration Menu Language 2 (CML2), a source code configuration system; while originally intended for the Linux operating system, it was rejected by kernel developers. (Raymond attributed this rejection to \"kernel list politics\", but Linus Torvalds said in a 2007 mailing list post that as a matter of policy, the development team preferred more incremental changes.) Raymond's 2003 book \"The Art of Unix Programming\" discusses user tools for programming and other tasks.\nSome versions of \"NetHack\" still include Raymond's guide. He has also contributed code and content to the free software video game \"The Battle for Wesnoth\".\nRaymond is the main developer of NTPSec, a \"secure, hardened replacement\" for the Unix utility NTP.\nViews on open source.\nRaymond coined an aphorism he dubbed Linus's law, inspired by Linus Torvalds: \"Given enough eyeballs, all bugs are shallow\". It first appeared in his book \"The Cathedral and the Bazaar\".\nRaymond has refused to speculate on whether the \"bazaar\" development model could be applied to works such as books and music, saying that he does not want to \"weaken the winning argument for open-sourcing software by tying it to a potential loser\".\nRaymond has had a number of public disputes with other figures in the free software movement. As head of the Open Source Initiative, he argued that advocates should focus on the potential for better products. The \"very seductive\" moral and ethical rhetoric of Richard Stallman and the Free Software Foundation fails, he said, \"not because his principles are wrong, but because that kind of language ... simply does not persuade anybody\".\nIn a 2008 essay he defended programmers' right to issue work under proprietary licenses: \"I think that if a programmer wants to write a program and sell it, it's neither my business nor anyone else's but his customer's what the terms of sale are.\" In the same essay he said that the \"logic of the system\" puts developers into \"dysfunctional roles\", with bad code the result.\nPolitical beliefs and activism.\nRaymond is a member of the Libertarian Party and a gun rights advocate. He has endorsed the open source firearms organization Defense Distributed, calling them \"friends of freedom\" and writing \"I approve of any development that makes it more difficult for governments and criminals to monopolize the use of force. As 3D printers become less expensive and more ubiquitous, this could be a major step in the right direction.\"\nIn 2015 Raymond accused the Ada Initiative and other women in tech groups of attempting to entrap male open source leaders and accuse them of rape, saying \"Try to avoid even being alone, ever, because there is a chance that a 'women in tech' advocacy group is going to try to collect your scalp.\"\nRaymond has claimed that \"Gays experimented with unfettered promiscuity in the 1970s and got AIDS as a consequence\", and that \"Police who react to a random black male behaving suspiciously who might be in the critical age range as though he is an near-imminent lethal threat, are being rational, not racist.\" A progressive campaign, \"The Great Slate\", was successful in raising funds for candidates in part by asking for contributions from tech workers in return for not posting similar quotes by Raymond. Matasano Security employee and Great Slate fundraiser Thomas Ptacek said, \"I've been torturing Twitter with lurid Eric S. Raymond quotes for years. Every time I do, 20 people beg me to stop.\" It is estimated that, as of March 2018, over $30,000 has been raised in this way.\nReligious beliefs.\nRaymond describes himself as neo-pagan.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9471", "revid": "43184527", "url": "https://en.wikipedia.org/wiki?curid=9471", "title": "Externalization (psychology)", "text": "Concept in Freudian psychology\nPsychoanalysis.\nIn Freudian psychology, externalization (or externalisation) is a defense mechanism by which an individual projects their own internal characteristics onto the outside world, particularly onto other people. For example, a patient who is overly argumentative might instead perceive others as argumentative and themselves as blameless.\nLike other defense mechanisms, externalization is a protection against anxiety and is, therefore, part of a healthy, normally functioning mind. However, if taken to excess, it can lead to the development of a neurosis.\nNarrative therapy.\nMichael White states that the problem of the client is externalized, to alter the client's point of view.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9472", "revid": "1158262102", "url": "https://en.wikipedia.org/wiki?curid=9472", "title": "Euro", "text": "Currency of most countries in the European Union\nThe euro (symbol: \u20ac; code: EUR) is the official currency of 20 of the 27 member states of the European Union (EU). This group of states is known as the eurozone or, officially, the euro area, and includes about 344 million citizens as of 2023[ [update]]. The euro is divided into 100 cents.\nThe currency is also used officially by the institutions of the European Union, by four European microstates that are not EU members, the British Overseas Territory of Akrotiri and Dhekelia, as well as unilaterally by Montenegro and Kosovo. Outside Europe, a number of special territories of EU members also use the euro as their currency. Additionally, over 200\u00a0million people worldwide use currencies pegged to the euro.\nThe euro is the second-largest reserve currency as well as the second-most traded currency in the world after the United States dollar. As of \u00a02019,[ [update]] with more than \u20ac1.3\u00a0trillion in circulation, the euro has one of the highest combined values of banknotes and coins in circulation in the world.\nThe name \"euro\" was officially adopted on 16 December 1995 in Madrid. The euro was introduced to world financial markets as an accounting currency on 1 January 1999, replacing the former European Currency Unit (ECU) at a ratio of 1:1 (US$1.1743). Physical euro coins and banknotes entered into circulation on 1 January 2002, making it the day-to-day operating currency of its original members, and by March 2002 it had completely replaced the former currencies.\nBetween December 1999 and December 2002, the euro traded below the US dollar, but has since traded near parity with or above the US dollar, peaking at US$1.60 on 18 July 2008 and since then returning near to its original issue rate. On 13 July 2022, the two currencies hit parity for the first time in nearly two decades due in part to the 2022 Russian invasion of Ukraine.\nCharacteristics.\nAdministration.\nThe euro is managed and administered by the European Central Bank (ECB, Frankfurt am Main) and the Eurosystem, composed of the central banks of the eurozone countries. As an independent central bank, the ECB has sole authority to set monetary policy. The Eurosystem participates in the printing, minting and distribution of notes and coins in all member states, and the operation of the eurozone payment systems.\nThe 1992 Maastricht Treaty obliges most EU member states to adopt the euro upon meeting certain monetary and budgetary convergence criteria, although not all participating states have done so. Denmark has negotiated exemptions, while Sweden (which joined the EU in 1995, after the Maastricht Treaty was signed) turned down the euro in a non-binding referendum in 2003, and has circumvented the obligation to adopt the euro by not meeting the monetary and budgetary requirements. All nations that have joined the EU since 1993 have pledged to adopt the euro in due course. The Maastricht Treaty was later amended by the Treaty of Nice, which closed the gaps and loopholes in the Maastricht and Rome Treaties.\nEurozone members.\nThe 20 participating members are \n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nEU members not using the euro.\nThe EU member states not in the Eurozone are Bulgaria, Czech Republic, Denmark, Hungary, Poland, Romania, and Sweden.\nFuture eurozone members.\nThe government of Bulgaria aims for the Bulgarian lev to be replaced by the euro on 1 January 2025.\nThe Romanian government aims to replace the Romanian leu by the euro on 1 January 2026.\nEU members Czech Republic, Hungary, Poland, and Sweden are legally obligated to adopt the euro eventually, though they have no required date for adoption, and their governments do not currently have any plans for switching. Denmark has negotiated for the right to not be required to switch.\nOther users.\nMicrostates with a monetary agreement:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nEU special territories\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nUnilateral adopters \n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nPegged currencies.\nThe currency of a number of states is pegged to the euro. These states are:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCoins and banknotes.\nCoins.\nThe euro is divided into 100 cents (also referred to as \"euro cents\", especially when distinguishing them from other currencies, and referred to as such on the common side of all cent coins). In Community legislative acts the plural forms of \"euro\" and \"cent\" are spelled without the \"s\", notwithstanding normal English usage. Otherwise, normal English plurals are used, with many local variations such as \"centime\" in France.\nAll circulating coins have a \"common side\" showing the denomination or value, and a map in the background. Due to the linguistic plurality in the European Union, the Latin alphabet version of \"euro\" is used (as opposed to the less common Greek or Cyrillic) and Arabic numerals (other text is used on national sides in national languages, but other text on the common side is avoided). For the denominations except the 1-, 2- and 5-cent coins, the map only showed the 15 member states which were members when the euro was introduced. Beginning in 2007 or 2008 (depending on the country), the old map was replaced by a map of Europe also showing countries outside the EU. The 1-, 2- and 5-cent coins, however, keep their old design, showing a geographical map of Europe with the 15 member states of 2002 raised somewhat above the rest of the map. All common sides were designed by Luc Luycx. The coins also have a \"national side\" showing an image specifically chosen by the country that issued the coin. Euro coins from any member state may be freely used in any nation that has adopted the euro.\nThe coins are issued in denominations of \u20ac2, \u20ac1, 50c, 20c, 10c, 5c, 2c, and 1c. To avoid the use of the two smallest coins, some cash transactions are rounded to the nearest five cents in the Netherlands and Ireland (by voluntary agreement) and in Finland and Italy (by law). This practice is discouraged by the commission, as is the practice of certain shops of refusing to accept high-value euro notes.\nCommemorative coins with \u20ac2 face value have been issued with changes to the design of the national side of the coin. These include both commonly issued coins, such as the \u20ac2 commemorative coin for the fiftieth anniversary of the signing of the Treaty of Rome, and nationally issued coins, such as the coin to commemorate the 2004 Summer Olympics issued by Greece. These coins are legal tender throughout the eurozone. Collector coins with various other denominations have been issued as well, but these are not intended for general circulation, and they are legal tender only in the member state that issued them.\nCoin minting.\nA number of institutions are authorised to mint euro coins:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nBanknotes.\nThe design for the euro banknotes has common designs on both sides. The design was created by the Austrian designer Robert Kalina. Notes are issued in \u20ac500, \u20ac200, \u20ac100, \u20ac50, \u20ac20, \u20ac10, and \u20ac5. Each banknote has its own colour and is dedicated to an artistic period of European architecture. The front of the note features windows or gateways while the back has bridges, symbolising links between states in the union and with the future. While the designs are supposed to be devoid of any identifiable characteristics, the initial designs by Robert Kalina were of specific bridges, including the Rialto and the Pont de Neuilly, and were subsequently rendered more generic; the final designs still bear very close similarities to their specific prototypes; thus they are not truly generic. The monuments looked similar enough to different national monuments to please everyone.\nThe Europa series, or second series, consists of six denominations and no longer includes the \u20ac500 with issuance discontinued as of 27 April 2019. However, both the first and the second series of euro banknotes, including the \u20ac500, remain legal tender throughout the euro area.\nIn December 2021, the ECB announced its plans to redesign euro banknotes by 2024. A theme advisory group, made up of one member from each euro area country, was selected to submit theme proposals to the ECB. The proposals will be voted on by the public; a design competition will also be held.\nIssuing modalities for banknotes.\nSince 1 January 2002, the national central banks (NCBs) and the ECB have issued euro banknotes on a joint basis. Eurosystem NCBs are required to accept euro banknotes put into circulation by other Eurosystem members and these banknotes are not repatriated. The ECB issues 8% of the total value of banknotes issued by the Eurosystem. In practice, the ECB's banknotes are put into circulation by the NCBs, thereby incurring matching liabilities vis-\u00e0-vis the ECB. These liabilities carry interest at the main refinancing rate of the ECB. The other 92% of euro banknotes are issued by the NCBs in proportion to their respective shares of the ECB capital key, calculated using national share of European Union (EU) population and national share of EU GDP, equally weighted.\nBanknote printing.\nMember states are authorised to print or to commission bank note printing. As of November 2022[ [update]], these are the printers:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nPayments clearing, electronic funds transfer.\nCapital within the EU may be transferred in any amount from one state to another. All intra-Union transfers in euro are treated as domestic transactions and bear the corresponding domestic transfer costs. This includes all member states of the EU, even those outside the eurozone providing the transactions are carried out in euro. Credit/debit card charging and ATM withdrawals within the eurozone are also treated as domestic transactions; however paper-based payment orders, like cheques, have not been standardised so these are still domestic-based. The ECB has also set up a clearing system, TARGET, for large euro transactions.\nHistory.\nIntroduction.\nThe euro was established by the provisions in the 1992 Maastricht Treaty. To participate in the currency, member states are meant to meet strict criteria, such as a budget deficit of less than 3% of their GDP, a debt ratio of less than 60% of GDP (both of which were ultimately widely flouted after introduction), low inflation, and interest rates close to the EU average. In the Maastricht Treaty, the United Kingdom and Denmark were granted exemptions per their request from moving to the stage of monetary union which resulted in the introduction of the euro.\nThe name \"euro\" was officially adopted in Madrid on 16 December 1995. Belgian Esperantist Germain Pirlot, a former teacher of French and history, is credited with naming the new currency by sending a letter to then President of the European Commission, Jacques Santer, suggesting the name \"euro\" on 4 August 1995.\nDue to differences in national conventions for rounding and significant digits, all conversion between the national currencies had to be carried out using the process of triangulation via the euro. The \"definitive\" values of one euro in terms of the exchange rates at which the currency entered the euro are shown on the right.\nThe rates were determined by the Council of the European Union, based on a recommendation from the European Commission based on the market rates on 31 December 1998. They were set so that one European Currency Unit (ECU) would equal one euro. The European Currency Unit was an accounting unit used by the EU, based on the currencies of the member states; it was not a currency in its own right. They could not be set earlier, because the ECU depended on the closing exchange rate of the non-euro currencies (principally sterling) that day.\nThe procedure used to fix the conversion rate between the Greek drachma and the euro was different since the euro by then was already two years old. While the conversion rates for the initial eleven currencies were determined only hours before the euro was introduced, the conversion rate for the Greek drachma was fixed several months beforehand.\nThe currency was introduced in non-physical form (traveller's cheques, electronic transfers, banking, etc.) at midnight on 1 January 1999, when the national currencies of participating countries (the eurozone) ceased to exist independently. Their exchange rates were locked at fixed rates against each other. The euro thus became the successor to the European Currency Unit (ECU). The notes and coins for the old currencies, however, continued to be used as legal tender until new euro notes and coins were introduced on 1 January 2002.\nThe changeover period during which the former currencies' notes and coins were exchanged for those of the euro lasted about two months, until 28 February 2002. The official date on which the national currencies ceased to be legal tender varied from member state to member state. The earliest date was in Germany, where the mark officially ceased to be legal tender on 31 December 2001, though the exchange period lasted for two months more. Even after the old currencies ceased to be legal tender, they continued to be accepted by national central banks for periods ranging from several years to indefinitely (the latter for Austria, Germany, Ireland, Estonia and Latvia in banknotes and coins, and for Belgium, Luxembourg, Slovenia and Slovakia in banknotes only). The earliest coins to become non-convertible were the Portuguese escudos, which ceased to have monetary value after 31 December 2002, although banknotes remained exchangeable until 2022.\nCurrency sign.\nA special euro currency sign (\u20ac) was designed after a public survey had narrowed ten of the original thirty proposals down to two. The President of the European Commission at the time (Jacques Santer) and the European Commissioner with responsibility for the euro (Yves-Thibault de Silguy) then chose the winning design.\nRegarding the symbol, the European Commission stated on behalf of the European Union:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The symbol \u20ac is based on the Greek letter epsilon (\u0404), with the first letter in the word \"Europe\" and with 2 parallel lines signifying stability.\nThe European Commission also specified a euro logo with exact proportions. Placement of the currency sign relative to the numeric amount varies from state to state, but for texts in English published by EU institutions, the symbol (or the ISO-standard \"EUR\") should precede the amount.\nEurozone crisis.\nFollowing the U.S. financial crisis in 2008, fears of a sovereign debt crisis developed in 2009 among investors concerning some European states, with the situation becoming particularly tense in early 2010. Greece was most acutely affected, but fellow Eurozone members Cyprus, Ireland, Italy, Portugal, and Spain were also significantly affected. All these countries used EU funds except Italy, which is a major donor to the EFSF. To be included in the eurozone, countries had to fulfil certain convergence criteria, but the meaningfulness of such criteria was diminished by the fact it was not enforced with the same level of strictness among countries.\nAccording to the Economist Intelligence Unit in 2011, \"[I]f the [euro area] is treated as a single entity, its [economic and fiscal] position looks no worse and in some respects, rather better than that of the US or the UK\" and the budget deficit for the euro area as a whole is much lower and the euro area's government debt/GDP ratio of 86% in 2010 was about the same level as that of the United States. \"Moreover\", they write, \"private-sector indebtedness across the euro area as a whole is markedly lower than in the highly leveraged Anglo-Saxon economies\". The authors conclude that the crisis \"is as much political as economic\" and the result of the fact that the euro area lacks the support of \"institutional paraphernalia (and mutual bonds of solidarity) of a state\".\nThe crisis continued with S&amp;P downgrading the credit rating of nine euro-area countries, including France, then downgrading the entire European Financial Stability Facility (EFSF) fund.\nA historical parallel\u00a0\u2013 to 1931 when Germany was burdened with debt, unemployment and austerity while France and the United States were relatively strong creditors\u00a0\u2013 gained attention in summer 2012 even as Germany received a debt-rating warning of its own.\nDirect and indirect usage.\nAustria\nBelgium\nCroatia\nCyprus\nFinland\nEstonia\nFrance\nGreece\nGermany\nIreland\nItaly\nLatvia\nLithuania\nLux.\nMalta\nNetherlands\nPortugal\nSlovakia\nSlovenia\nSpain\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Eurozone members (20)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Monetary agreement (4)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Unilaterally adopted (2)\nAgreed direct usage with minting rights.\nThe euro is the sole currency of 20 EU member states: Austria, Belgium, Croatia, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal, Slovakia, Slovenia, and Spain. These countries constitute the \"eurozone\", some 347\u00a0million people in total as of 2023[ [update]]. According to bilateral agreements with the EU, the euro has also been designated as the sole and official currency in a further four European microstates awarded minting rights (Andorra, Monaco, San Marino and the Vatican City). With all but one (Denmark) EU members obliged to join when economic conditions permit, together with future members of the EU, the enlargement of the eurozone is set to continue.\nAgreed direct usage without minting rights.\nThe euro is also the sole currency in three overseas territories of France that are not themselves part of the EU, namely Saint Barth\u00e9lemy, Saint Pierre and Miquelon, and the French Southern and Antarctic Lands, as well as in the British Overseas Territory of Akrotiri and Dhekelia.\nUnilateral direct usage.\nThe euro has been adopted unilaterally as the sole currency of Montenegro and Kosovo. It has also been used as a foreign trading currency in Cuba since 1998, Syria since 2006, and Venezuela since 2018. In 2009, Zimbabwe abandoned its local currency and introduced major global convertible currencies instead, including the euro and the United States dollar. The direct usage of the euro outside of the official framework of the EU affects nearly 3\u00a0million people.\nCurrencies pegged to the euro.\nOutside the eurozone, two EU member states have currencies that are pegged to the euro, which is a precondition to joining the eurozone. The Danish krone and Bulgarian lev are pegged due to their participation in the ERM\u00a0II.\nAdditionally, a total of 21 countries and territories that do not belong to the EU have currencies that are directly pegged to the euro including 14 countries in mainland Africa (CFA franc), two African island countries (Comorian franc and Cape Verdean escudo), three French Pacific territories (CFP franc) and two Balkan countries, Bosnia and Herzegovina (Bosnia and Herzegovina convertible mark) and North Macedonia (Macedonian denar). On 1 January 2010, the dobra of S\u00e3o Tom\u00e9 and Pr\u00edncipe was officially linked with the euro. Additionally, the Moroccan dirham is tied to a basket of currencies, including the euro and the US dollar, with the euro given the highest weighting.\nThese countries generally had previously implemented a currency peg to one of the major European currencies (e.g. the French franc, Deutsche Mark or Portuguese escudo), and when these currencies were replaced by the euro their currencies became pegged to the euro. Pegging a country's currency to a major currency is regarded as a safety measure, especially for currencies of areas with weak economies, as the euro is seen as a stable currency, prevents runaway inflation, and encourages foreign investment due to its stability.\nIn total, as of 2013[ [update]], 182\u00a0million people in Africa use a currency pegged to the euro, 27\u00a0million people outside the eurozone in Europe, and another 545,000 people on Pacific islands.\nSince 2005, stamps issued by the Sovereign Military Order of Malta have been denominated in euros, although the Order's official currency remains the Maltese scudo. The Maltese scudo itself is pegged to the euro and is only recognised as legal tender within the Order.\nUse as reserve currency.\nSince its introduction, the euro has been the second most widely held international reserve currency after the U.S. dollar. The share of the euro as a reserve currency increased from 18% in 1999 to 27% in 2008. Over this period, the share held in U.S. dollar fell from 71% to 64% and that held in RMB fell from 6.4% to 3.3%. The euro inherited and built on the status of the Deutsche Mark as the second most important reserve currency. The euro remains underweight as a reserve currency in advanced economies while overweight in emerging and developing economies: according to the International Monetary Fund the total of euro held as a reserve in the world at the end of 2008 was equal to $1.1\u00a0trillion or \u20ac850\u00a0billion, with a share of 22% of all currency reserves in advanced economies, but a total of 31% of all currency reserves in emerging and developing economies.\nThe possibility of the euro becoming the first international reserve currency has been debated among economists. Former Federal Reserve Chairman Alan Greenspan gave his opinion in September 2007 that it was \"absolutely conceivable that the euro will replace the US dollar as reserve currency, or will be traded as an equally important reserve currency\". In contrast to Greenspan's 2007 assessment, the euro's increase in the share of the worldwide currency reserve basket has slowed considerably since 2007 and since the beginning of the worldwide credit crunch related recession and European sovereign-debt crisis.\nEconomics.\nOptimal currency area.\nIn economics, an optimum currency area, or region (OCA or OCR), is a geographical region in which it would maximise economic efficiency to have the entire region share a single currency. There are two models, both proposed by Robert Mundell: the stationary expectations model and the international risk sharing model. Mundell himself advocates the international risk sharing model and thus concludes in favour of the euro. However, even before the creation of the single currency, there were concerns over diverging economies. Before the late-2000s recession it was considered unlikely that a state would leave the euro or the whole zone would collapse. However the Greek government-debt crisis led to former British Foreign Secretary Jack Straw claiming the eurozone could not last in its current form. Part of the problem seems to be the rules that were created when the euro was set up. John Lanchester, writing for \"The New Yorker\", explains it: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The guiding principle of the currency, which opened for business in 1999, were supposed to be a set of rules to limit a country's annual deficit to three per cent of gross domestic product, and the total accumulated debt to sixty per cent of G.D.P. It was a nice idea, but by 2004 the two biggest economies in the euro zone, Germany and France, had broken the rules for three years in a row.\nTransaction costs and risks.\nThe most obvious benefit of adopting a single currency is to remove the cost of exchanging currency, theoretically allowing businesses and individuals to consummate previously unprofitable trades. For consumers, banks in the eurozone must charge the same for intra-member cross-border transactions as purely domestic transactions for electronic payments (e.g., credit cards, debit cards and cash machine withdrawals).\nFinancial markets on the continent are expected to be far more liquid and flexible than they were in the past. The reduction in cross-border transaction costs will allow larger banking firms to provide a wider array of banking services that can compete across and beyond the eurozone. However, although transaction costs were reduced, some studies have shown that risk aversion has increased during the last 40 years in the Eurozone.\nPrice parity.\nAnother effect of the common European currency is that differences in prices\u2014in particular in price levels\u2014should decrease because of the law of one price. Differences in prices can trigger arbitrage, i.e., speculative trade in a commodity across borders purely to exploit the price differential. Therefore, prices on commonly traded goods are likely to converge, causing inflation in some regions and deflation in others during the transition. Some evidence of this has been observed in specific eurozone markets.\nMacroeconomic stability.\nBefore the introduction of the euro, some countries had successfully contained inflation, which was then seen as a major economic problem, by establishing largely independent central banks. One such bank was the Bundesbank in Germany; the European Central Bank was modelled on the Bundesbank.\nThe euro has come under criticism due to its regulation, lack of flexibility and rigidity towards sharing member states on issues such as nominal interest rates.\nMany national and corporate bonds denominated in euro are significantly more liquid and have lower interest rates than was historically the case when denominated in national currencies. While increased liquidity may lower the nominal interest rate on the bond, denominating the bond in a currency with low levels of inflation arguably plays a much larger role. A credible commitment to low levels of inflation and a stable debt reduces the risk that the value of the debt will be eroded by higher levels of inflation or default in the future, allowing debt to be issued at a lower nominal interest rate.\nThere is also a cost in structurally keeping inflation lower than in the United States, United Kingdom, and China. The result is that seen from those countries, the euro has become expensive, making European products increasingly expensive for its largest importers; hence export from the eurozone becomes more difficult.\nIn general, those in Europe who own large amounts of euro are served by high stability and low inflation.\nA monetary union means states in that union lose the main mechanism of recovery of their international competitiveness by weakening (depreciating) their currency. When wages become too high compared to productivity in the exports sector, then these exports become more expensive and they are crowded out from the market within a country and abroad. This drives the fall of employment and output in the exports sector and fall of trade and current account balances. Fall of output and employment in the tradable goods sector may be offset by the growth of non-exports sectors, especially in construction and services. Increased purchases abroad and negative current account balances can be financed without a problem as long as credit is cheap. The need to finance trade deficit weakens currency, making exports automatically more attractive in a country and abroad. A state in a monetary union cannot use weakening of currency to recover its international competitiveness. To achieve this a state has to reduce prices, including wages (deflation). This could result in high unemployment and lower incomes as it was during the European sovereign-debt crisis.\nTrade.\nThe euro increased price transparency and stimulated cross-border trade. A 2009 consensus from the studies of the introduction of the euro concluded that it has increased trade within the eurozone by 5% to 10%, although one study suggested an increase of only 3% while another estimated 9 to 14%. However, a meta-analysis of all available studies suggests that the prevalence of positive estimates is caused by publication bias and that the underlying effect may be negligible. Although a more recent meta-analysis shows that publication bias decreases over time and that there are positive trade effects from the introduction of the euro, as long as results from before 2010 are taken into account. This may be because of the inclusion of the Financial crisis of 2007\u20132008 and ongoing integration within the EU. Furthermore, older studies accounting for time trend reflecting general cohesion policies in Europe that started before, and continue after implementing the common currency find no effect on trade. These results suggest that other policies aimed at European integration might be the source of observed increase in trade. According to Barry Eichengreen, studies disagree on the magnitude of the effect of the euro on trade, but they agree that it did have an effect.\nInvestment.\nPhysical investment seems to have increased by 5% in the eurozone due to the introduction. Regarding foreign direct investment, a study found that the intra-eurozone FDI stocks have increased by about 20% during the first four years of the EMU. Concerning the effect on corporate investment, there is evidence that the introduction of the euro has resulted in an increase in investment rates and that it has made it easier for firms to access financing in Europe. The euro has most specifically stimulated investment in companies that come from countries that previously had weak currencies. A study found that the introduction of the euro accounts for 22% of the investment rate after 1998 in countries that previously had a weak currency.\nInflation.\nThe introduction of the euro has led to extensive discussion about its possible effect on inflation. In the short term, there was a widespread impression in the population of the eurozone that the introduction of the euro had led to an increase in prices, but this impression was not confirmed by general indices of inflation and other studies. A study of this paradox found that this was due to an asymmetric effect of the introduction of the euro on prices: while it had no effect on most goods, it had an effect on cheap goods which have seen their price round up after the introduction of the euro. The study found that consumers based their beliefs on inflation of those cheap goods which are frequently purchased. It has also been suggested that the jump in small prices may be because prior to the introduction, retailers made fewer upward adjustments and waited for the introduction of the euro to do so.\nExchange rate risk.\nOne of the advantages of the adoption of a common currency is the reduction of the risk associated with changes in currency exchange rates. It has been found that the introduction of the euro created \"significant reductions in market risk exposures for nonfinancial firms both in and outside Europe\". These reductions in market risk \"were concentrated in firms domiciled in the eurozone and in non-euro firms with a high fraction of foreign sales or assets in Europe\".\nFinancial integration.\nThe introduction of the euro increased European financial integration, which helped stimulate growth of a European securities market (bond markets are characterized by economies of scale dynamics). According to a study on this question, it has \"significantly reshaped the European financial system, especially with respect to the securities markets [...] However, the real and policy barriers to integration in the retail and corporate banking sectors remain significant, even if the wholesale end of banking has been largely integrated.\" Specifically, the euro has significantly decreased the cost of trade in bonds, equity, and banking assets within the eurozone. On a global level, there is evidence that the introduction of the euro has led to an integration in terms of investment in bond portfolios, with eurozone countries lending and borrowing more between each other than with other countries. Financial integration made it cheaper for European companies to borrow. Banks, firms and households could also invest more easily outside of their own country, thus creating greater international risk-sharing.\nEffect on interest rates.\nAs of January 2014, and since the introduction of the euro, interest rates of most member countries (particularly those with a weak currency) have decreased. Some of these countries had the most serious sovereign financing problems.\nThe effect of declining interest rates, combined with excess liquidity continually provided by the ECB, made it easier for banks within the countries in which interest rates fell the most, and their linked sovereigns, to borrow significant amounts (above the 3% of GDP budget deficit imposed on the eurozone initially) and significantly inflate their public and private debt levels. Following the financial crisis of 2007\u20132008, governments in these countries found it necessary to bail out or nationalise their privately held banks to prevent systemic failure of the banking system when underlying hard or financial asset values were found to be grossly inflated and sometimes so nearly worthless there was no liquid market for them. This further increased the already high levels of public debt to a level the markets began to consider unsustainable, via increasing government bond interest rates, producing the ongoing European sovereign-debt crisis.\nPrice convergence.\nThe evidence on the convergence of prices in the eurozone with the introduction of the euro is mixed. Several studies failed to find any evidence of convergence following the introduction of the euro after a phase of convergence in the early 1990s. Other studies have found evidence of price convergence, in particular for cars. A possible reason for the divergence between the different studies is that the processes of convergence may not have been linear, slowing down substantially between 2000 and 2003, and resurfacing after 2003 as suggested by a recent study (2009).\nTourism.\nA study suggests that the introduction of the euro has had a positive effect on the amount of tourist travel within the EMU, with an increase of 6.5%.\nExchange rates.\nFlexible exchange rates.\nThe ECB targets interest rates rather than exchange rates and in general, does not intervene on the foreign exchange rate markets. This is because of the implications of the Mundell\u2013Fleming model, which implies a central bank cannot (without capital controls) maintain interest rate and exchange rate targets simultaneously, because increasing the money supply results in a depreciation of the currency. In the years following the Single European Act, the EU has liberalised its capital markets and, as the ECB has inflation targeting as its monetary policy, the exchange-rate regime of the euro is floating.\nAgainst other major currencies.\nThe euro is the second-most widely held reserve currency after the U.S. dollar. After its introduction on 4 January 1999 its exchange rate against the other major currencies fell reaching its lowest exchange rates in 2000 (3 May vs sterling, 25 October vs the U.S. dollar, 26 October vs Japanese yen). Afterwards it regained and its exchange rate reached its historical highest point in 2008 (15 July vs US dollar, 23 July vs Japanese yen, 29 December vs sterling). With the advent of the global financial crisis the euro initially fell, to regain later. Despite pressure due to the European sovereign-debt crisis the euro remained stable. In November 2011 the euro's exchange rate index\u00a0\u2013 measured against currencies of the bloc's major trading partners\u00a0\u2013 was trading almost two percent higher on the year, approximately at the same level as it was before the crisis kicked off in 2007. In mid July, 2022, the euro equalled the US dollar for a short period of time.\nPolitical considerations.\nBesides the economic motivations to the introduction of the euro, its creation was also partly justified as a way to foster a closer sense of joint identity between European citizens. Statements about this goal were for instance made by Wim Duisenberg, European Central Bank Governor, in 1998, Laurent Fabius, French Finance Minister, in 2000, and Romano Prodi, President of the European Commission, in 2002. However, 15 years after the introduction of the euro, a study found no evidence that it has had any effect on a shared sense of European identity.\n\"Euro\" in various languages.\nThe formal titles of the currency are \"euro\" for the major unit and \"cent\" for the minor (one-hundredth) unit and for official use in most eurozone languages; according to the ECB, all languages should use the same spelling for the nominative singular. This may contradict normal rules for word formation in some languages.\nBulgaria has negotiated an exception; \"euro\" in the Bulgarian Cyrillic alphabet is spelled e\u0432\u0440\u043e (\"evro\") and not e\u0443\u0440\u043e (\"euro\") in all official documents. In the Greek script the term \u03b5\u03c5\u03c1\u03ce (evr\u00f3) is used; the Greek \"cent\" coins are denominated in \u03bb\u03b5\u03c0\u03c4\u03cc/\u03ac (lept\u00f3/\u00e1). Official practice for English-language EU legislation is to use the words euro and cent as both singular and plural, although the European Commission's Directorate-General for Translation states that the plural forms \"euros\" and \"cents\" should be used in English.\nThe word 'euro' is pronounced differently according to pronunciation rules in the individual languages applied; in German ], in English , in French ], etc.\nIn summary:\nFor local phonetics, cent, use of plural and amount formatting (\u20ac6,00 or 6.00\u00a0\u20ac), see Language and the euro.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9474", "revid": "1160965427", "url": "https://en.wikipedia.org/wiki?curid=9474", "title": "European Central Bank", "text": "Prime component of the Eurosystem and the European System of Central Banks\nThe European Central Bank (ECB) is the prime component of the Eurosystem and the European System of Central Banks (ESCB) as well as one of seven institutions of the European Union. It is one of the world's most important central banks.\nThe ECB Governing Council makes monetary policy for the Eurozone and the European Union, administers the foreign exchange reserves of EU member states, engages in foreign exchange operations, and defines the intermediate monetary objectives and key interest rate of the EU. The ECB Executive Board enforces the policies and decisions of the Governing Council, and may direct the national central banks when doing so. The ECB has the exclusive right to authorise the issuance of euro banknotes. Member states can issue euro coins, but the volume must be approved by the ECB beforehand. The bank also operates the TARGET2 payments system.\nThe ECB was established by the Treaty of Amsterdam in May 1999 with the purpose of guaranteeing and maintaining price stability. On 1 December 2009, the Treaty of Lisbon became effective and the bank gained the official status of an EU institution. When the ECB was created, it covered a Eurozone of eleven members. Since then, Greece joined in January 2001, Slovenia in January 2007, Cyprus and Malta in January 2008, Slovakia in January 2009, Estonia in January 2011, Latvia in January 2014, Lithuania in January 2015 and Croatia in January 2023. The current President of the ECB is Christine Lagarde. Seated in Frankfurt, Germany, the bank formerly occupied the Eurotower prior to the construction of its new seat.\nThe ECB is directly governed by European Union law. Its capital stock, worth \u20ac11 billion, is owned by all 27 central banks of the EU member states as shareholders. The initial capital allocation key was determined in 1998 on the basis of the states' population and GDP, but the capital key has been readjusted since. Shares in the ECB are not transferable and cannot be used as collateral.\nHistory.\nEarly years of the ECB (1998\u20132007).\nThe European Central Bank is the \"de facto\" successor of the European Monetary Institute (EMI). The EMI was established at the start of the second stage of the EU's Economic and Monetary Union (EMU) to handle the transitional issues of states adopting the euro and prepare for the creation of the ECB and European System of Central Banks (ESCB). The EMI itself took over from the earlier European Monetary Cooperation Fund (EMCF).\nThe ECB formally replaced the EMI on 1 June 1998 by virtue of the Treaty on European Union (TEU, Treaty of Maastricht), however it did not exercise its full powers until the introduction of the euro on 1 January 1999, signalling the third stage of EMU. The bank was the final institution needed for EMU, as outlined by the EMU reports of Pierre Werner and President Jacques Delors. It was established on 1 June 1998 The first President of the Bank was Wim Duisenberg, the former president of the Dutch central bank and the European Monetary Institute. While Duisenberg had been the head of the EMI (taking over from Alexandre Lamfalussy of Belgium) just before the ECB came into existence, the French government wanted Jean-Claude Trichet, former head of the French central bank, to be the ECB's first president. The French argued that since the ECB was to be located in Germany, its president should be French. This was opposed by the German, Dutch and Belgian governments who saw Duisenberg as a guarantor of a strong euro. Tensions were abated by a gentleman's agreement in which Duisenberg would stand down before the end of his mandate, to be replaced by Trichet.\nTrichet replaced Duisenberg as president in November 2003. Until 2007, the ECB had very successfully managed to maintain inflation close but below 2%.\nThe ECB's response to the financial crises (2008\u20132014).\nThe European Central Bank underwent through a deep internal transformation as it faced the global financial crisis and the Eurozone debt crisis. \nEarly response to the Eurozone debt crisis.\nThe so-called \"European debt crisis\" began after Greece's new elected government uncovered the real level indebtedness and budget deficit and warned EU institutions of the imminent danger of a Greek sovereign default.\nForeseeing a possible sovereign default in the eurozone, the general public, international and European institutions, and the financial community reassessed the economic situation and creditworthiness of some Eurozone member states, in particular Southern countries. Consequently, sovereign bonds yields of several Eurozone countries started to rise sharply. This provoked a self-fulfilling panic on financial markets: the more Greek bonds yields rose, the more likely a default became possible, the more bond yields increased in turn.\nThis panic was also aggravated because of the inability of the ECB to react and intervene on sovereign bonds markets for two reasons. First, because the ECB's legal framework normally forbids the purchase of sovereign bonds (Article 123. TFEU), This prevented the ECB from implementing quantitative easing like the Federal Reserve and the Bank of England did as soon as 2008, which played an important role in stabilizing markets.\nSecondly, a decision by the ECB made in 2005 introduced a minimum credit rating (BBB-) for all Eurozone sovereign bonds to be eligible as collateral to the ECB's open market operations. This meant that if a private rating agencies were to downgrade a sovereign bond below that threshold, many banks would suddenly become illiquid because they would lose access to ECB refinancing operations. According to former member of the governing council of the ECB Athanasios Orphanides, this change in the ECB's collateral framework \"planted the seed\" of the euro crisis.\nFaced with those regulatory constraints, the ECB led by Jean-Claude Trichet in 2010 was reluctant to intervene to calm down financial markets. Up until 6 May 2010, Trichet formally denied at several press conferences the possibility of the ECB to embark into sovereign bonds purchases, even though Greece, Portugal, Spain and Italy faced waves of credit rating downgrades and increasing interest rate spreads.\nECB's market interventions (2010\u20132011).\nIn a remarkable u-turn, the ECB announced on 10 May 2010, the launch of a \"Securities Market Programme\" (SMP) which involved the discretionary purchase of sovereign bonds in secondary markets. Extraordinarily, the decision was taken by the Governing Council during a teleconference call only three days after the ECB's usual meeting of 6 May (when Trichet still denied the possibility of purchasing sovereign bonds). The ECB justified this decision by the necessity to \"address severe tensions in financial markets.\" The decision also coincided with the EU leaders decision of 10 May to establish the European Financial Stabilisation mechanism, which would serve as a crisis fighting fund to safeguard the euro area from future sovereign debt crisis.\nThe ECB's bond buying focused primarily on Spanish and Italian debt. They were intended to dampen international speculation against those countries, and thus avoid a contagion of the Greek crisis towards other Eurozone countries. The assumption is that speculative activity will decrease over time and the value of the assets increase.\nAlthough SMP did involve an injection of new money into financial markets, all ECB injections were \"sterilized\" through weekly liquidity absorption. So the operation was neutral for the overall money supply.\nIn September 2011, ECB's Board member J\u00fcrgen Stark, resigned in protest against the \"Securities Market Programme\" which involved the purchase of sovereign bonds from Southern member states, a move that he considered as equivalent to monetary financing, which is prohibited by the EU Treaty. The \"Financial Times Deutschland\" referred to this episode as \"the end of the ECB as we know it\", referring to its hitherto perceived \"hawkish\" stance on inflation and its historical Deutsche Bundesbank influence.\nAs of 18 June 2012, the ECB in total had spent \u20ac212.1bn (equal to 2.2% of the Eurozone GDP) for bond purchases covering outright debt, as part of the Securities Markets Programme. Controversially, the ECB made substantial profits out of SMP, which were largely redistributed to Eurozone countries. In 2013, the Eurogroup decided to refund those profits to Greece, however, the payments were suspended from 2014 until 2017 over the conflict between Yanis Varoufakis and ministers of the Eurogroup. In 2018, profits refunds were reinstalled by the Eurogroup. However, several NGOs complained that a substantial part of the ECB profits would never be refunded to Greece.\nRole in the Troika (2010\u20132015).\nThe ECB played a controversial role in the \"Troika\" by rejecting all forms of debt restructuring of public and private debts, forcing governments to adopt bailout programmes and structural reforms through secret letters to Italian, Spanish, Greek and Irish governments. It has further been accused of interfering in the Greek referendum of July 2015 by constraining liquidity to Greek commercial banks.\nIn November 2010, it became clear that Ireland would not be able to afford to bail out its failing banks, and Anglo Irish Bank in particular which needed around 30 billion euros, a sum the government obviously could not borrow from financial markets when its bond yields were soaring to comparable levels with the Greek bonds. Instead, the government issued a 31bn EUR \"promissory note\" (an IOU) to Anglo \u2013 which it had nationalized. In turn, the bank supplied the promissory note as collateral to the Central Bank of Ireland, so it could access emergency liquidity assistance (ELA). This way, Anglo was able to repay its bondholders. The operation became very controversial, as it basically shifted Anglo's private debts onto the government's balance sheet.\nIt became clear later that the ECB played a key role in making sure the Irish government did not let Anglo default on its debts, to avoid financial instability risks. On 15 October and 6 November 2010, the ECB President Jean-Claude Trichet sent two secret letters to the Irish finance Minister which essentially informed the Irish government of the possible suspension of ELA's credit lines, unless the government requested a financial assistance programme to the Eurogroup under the condition of further reforms and fiscal consolidation.\nOver 2012 and 2013, the ECB repeatedly insisted that the promissory note should be repaid in full, and refused the Government's proposal to swap the notes with a long-term (and less costly) bond until February 2013. In addition, the ECB insisted that no debt restructuring (or bail-in) should be applied to the nationalized banks' bondholders, a measure which could have saved Ireland 8 billion euros.\nIn April 2011, the ECB raised interest rates for the first time since 2008 from 1% to 1.25%, with a further increase to 1.50% in July 2011. However, in 2012\u20132013 the ECB sharply lowered interest rates to encourage economic growth, reaching the historically low 0.25% in November 2013. Soon after the rates were cut to 0.15%, then on 4 September 2014 the central bank reduced the rates by two-thirds from 0.15% to 0.05%. Recently, the interest rates were further reduced reaching 0.00%, the lowest rates on record.\nIn a report adopted on 13 March 2014, the European Parliament criticized the \"potential conflict of interest between the current role of the ECB in the Troika as 'technical advisor' and its position as a creditor of the four Member States, as well as its mandate under the Treaty\". The report was led by Austrian right-wing MEP Othmar Karas and French Socialist MEP Liem Hoang Ngoc.\nThe ECB's response under Mario Draghi (2012\u20132015).\nOn 1 November 2011, Mario Draghi replaced Jean-Claude Trichet as President of the ECB. This change in leadership also marks the start of a new era under which the ECB will become more and more interventionist and eventually ended the Eurozone sovereign debt crisis.\nDraghi's presidency started with the impressive launch of a new round of 1% interest loans with a term of three years (36 months) \u2013 the Long-term Refinancing operations (LTRO). Under this programme, 523 Banks tapped as much as \u20ac489.2 bn (US$640 bn). Observers were surprised by the volume of loans made when it was implemented. By far biggest amount of \u20ac325bn was tapped by banks in Greece, Ireland, Italy and Spain. Although those LTROs loans did not directly benefit EU governments, it effectively allowed banks to do a carry trade, by lending off the LTROs loans to governments with an interest margin. The operation also facilitated the rollover of \u20ac200bn of maturing bank debts in the first three months of 2012.\n\"Whatever it takes\" (26 July 2012).\nFacing renewed fears about sovereigns in the eurozone continued Mario Draghi made a decisive speech in London, by declaring that the ECB \"...is ready to do whatever it takes to preserve the Euro. And believe me, it will be enough.\" In light of slow political progress on solving the eurozone crisis, Draghi's statement has been seen as a key turning point in the eurozone crisis, as it was immediately welcomed by European leaders, and led to a steady decline in bond yields for eurozone countries, in particular Spain, Italy and France.\nFollowing up on Draghi's speech, on 6 September 2012 the ECB announced the Outright Monetary Transactions programme (OMT). Unlike the previous SMP programme, OMT has no ex-ante time or size limit. However, the activation of the purchases remains conditioned to the adherence by the benefitting country to an adjustment programme to the ESM. The program was adopted with near unanimity, the Bundesbank president Jens Weidmann being the sole member of the ECB's Governing Council to vote against it.\nEven if OMT was never actually implemented until today, it made the \"Whatever it takes\" pledge credible and significantly contributed to stabilizing financial markets and ending the sovereign debt crisis. According to various sources, the OMT programme and \"whatever it takes\" speeches were made possible because EU leaders previously agreed to build the banking union.\nLow inflation and quantitative easing (2015\u20132019).\nIn November 2014, the bank moved into its new premises, while the Eurotower building was dedicated to hosting the newly established supervisory activities of the ECB under the Single Supervisory Mechanism.\nAlthough the sovereign debt crisis was almost solved by 2014, the ECB started to face a repeated decline in the Eurozone inflation rate, indicating that the economy was going towards a deflation. Responding to this threat, the ECB announced on 4 September 2014 the launch of two bond buying purchases programmes: the Covered Bond Purchasing Programme (CBPP3) and Asset-Backed Securities Programme (ABSPP).\nOn 22 January 2015, the ECB announced an extension of those programmes within a full-fledge \"quantitative easing\" programme which also included sovereign bonds, to the tune of 60 billion euros per month up until at least September 2016. The programme was started on 9 March 2015.\nOn 8 June 2016, the ECB added corporate bonds to its asset purchases portfolio with the launch of the corporate sector purchase programme (CSPP). Under this programme, it conducted the net purchase of corporate bonds until January 2019 to reach about \u20ac177 billion. While the programme was halted for 11 months in January 2019, the ECB restarted net purchases in November 2019.\nAs of 2021, the size of the ECB's quantitative easing programme had reached 2947 billion euros.\nChristine Lagarde's era (2019\u2013 ).\nIn July 2019, EU leaders nominated Christine Lagarde to replace Mario Draghi as ECB President. Lagarde resigned from her position as managing director of the International Monetary Fund in July 2019 and formally took over the ECB's presidency on 1 November 2019.\nLagarde immediately signalled a change of style in the ECB's leadership. She embarked the ECB on a strategic review of the ECB's monetary policy strategy, an exercise the ECB had not done for 17 years. As part of this exercise, Lagarde committed the ECB to look into how monetary policy could contribute to address climate change, and promised that \"no stone would be left unturned.\" The ECB president also adopted a change of communication style, in particular in her use of social media to promote gender equality, and by opening dialogue with civil society stakeholders.\nResponse to the COVID-19 crisis.\nHowever, Lagarde's ambitions were quickly slowed down with the outbreak of the COVID-19 pandemic crisis.\nIn March 2020, the ECB responded quickly and boldly by launching a package of measures including a new asset purchase programme: the \u20ac1,350 billion Pandemic Emergency Purchase Programme (PEPP) which aimed to lower borrowing costs and increase lending in the euro area. The PEPP was extended to cover an additional \u20ac500 billion in December 2020. The ECB also re-launched more TLTRO loans to banks at historically low levels and record-high take-up (\u20ac1.3 trillion in June 2020). Lending by banks to SMEs was also facilitated by collateral easing measures, and other supervisory relaxations. The ECB also reactivated currency swap lines and enhanced existing swap lines with central banks across the globe.\nStrategy Review.\nAs a consequence of the COVID-19 crisis, the ECB extended the duration of the strategy review until September 2021. On 13 July 2021, the ECB presented the outcomes of the strategy review, with the main following announcements:\nThe ECB also said it would carry out another strategy review in 2025.\nMandate and inflation target.\nUnlike many other central banks, the ECB does not have a \"dual mandate\" where it has to pursue two equally important objectives such as price stability and full employment (like the US Federal Reserve System). The ECB has only one primary objective \u2013 price stability \u2013 subject to which it may pursue secondary objectives.\nPrimary mandate.\nThe primary objective of the European Central Bank, set out in Article 127(1) of the Treaty on the Functioning of the European Union, is to maintain price stability within the Eurozone. However the EU Treaties do not specify exactly how the ECB should pursue this objective. The European Central Bank has ample discretion over the way it pursues its price stability objective, as it can self-decide on the inflation target, and may also influence the way inflation is being measured.\nThe Governing Council in October 1998 defined price stability as inflation of under 2%, \"a year-on-year increase in the Harmonised Index of Consumer Prices (HICP) for the euro area of below 2%\" and added that price stability \"was to be maintained over the medium term\". In May 2003, following a thorough review of the ECB's monetary policy strategy, the Governing Council clarified that \"in the pursuit of price stability, it aims to maintain inflation rates below, but close to, 2% over the medium term\".\nSince 2016, the European Central Bank's president has further adjusted its communication, by introducing the notion of \"symmetry\" in its definition of its target, thus making it clear that the ECB should respond both to inflationary pressure to deflationary pressures. As Draghi once said \"symmetry meant not only that we would not accept persistently low inflation, but also that there was no cap on inflation at 2%.\"\nOn 8 July 2021, as a result of the strategic review led by the new president Christine Lagarde, the ECB officially abandoned the \"below but close to two per cent\" definition and adopted instead a 2% symmetric target.\nSecondary mandate.\nWithout prejudice to the objective of price stability, the Treaty (127 TFEU) also provides room for the ECB to pursue other objectives:Without prejudice to the objective of price stability, the ESCB shall support the general economic policies in the Union with a view to contributing to the achievement of the objectives of the Union as laid down in Article 3 of the Treaty on European Union.This legal provision is often considered to provide a \"secondary mandate\" to the ECB and offers ample justifications for the ECB to also prioritize other considerations such as full employment or environmental protection, which are mentioned in the Article 3 of the Treaty on the European Union. At the same time, economists and commentators are often divided on whether and how the ECB should pursue those secondary objectives, in particular the environmental impact. ECB official have also frequently pointed out the possible contradictions between those secondary objectives. To better guide the ECB's action on its secondary objectives, it has been suggested that closer consultation with the European Parliament would be warranted. In 2023, the ECB recognised the possible role of the European Parliament in the prioritisation of its secondary objectives.\nTasks.\nTo carry out its main mission, the ECB's tasks include:\nMonetary policy tools.\nThe principal monetary policy tool of the European central bank is collateralised borrowing or repo agreements. These tools are also used by the United States Federal Reserve Bank, but the Fed does more direct purchasing of financial assets than its European counterpart. The collateral used by the ECB is typically high quality public and private sector debt.\nAll lending to credit institutions must be collateralised as required by Article 18 of the Statute of the ESCB.\nThe criteria for determining \"high quality\" for public debt have been preconditions for membership in the European Union: total debt must not be too large in relation to a gross domestic product, for example, and deficits in any given year must not become too large. Though these criteria are fairly simple, a number of accounting techniques may hide the underlying reality of fiscal solvency\u2014or the lack of the same.\nDifference with US Federal Reserve.\nIn the United States Federal Reserve Bank, the Federal Reserve buys assets: typically, bonds issued by the Federal government. There is no limit on the bonds that it can buy and one of the tools at its disposal in a financial crisis is to take such extraordinary measures as the purchase of large amounts of assets such as commercial paper. The purpose of such operations is to ensure that adequate liquidity is available for the functioning of the financial system.\nThe Eurosystem, on the other hand, uses collateralized lending as a default instrument. There are about 1,500 eligible banks which may bid for short-term repo contracts. The difference is that banks in effect borrow cash from the ECB and must pay it back; the short durations allow interest rates to be adjusted continually. When the repo notes come due the participating banks bid again. An increase in the number of notes offered at auction allows an increase in liquidity in the economy. A decrease has the contrary effect. The contracts are carried on the asset side of the European Central Bank's balance sheet and the resulting deposits in member banks are carried as a liability. In layman's terms, the liability of the central bank is money, and an increase in deposits in member banks carried as a liability by the central bank, means that more money has been put into the economy.\nTo qualify for participation in the auctions, banks must be able to offer proof of appropriate collateral in the form of loans to other entities. These can be the public debt of member states, but a fairly wide range of private banking securities are also accepted. The fairly stringent membership requirements for the European Union, especially with regard to sovereign debt as a percentage of each member state's gross domestic product, are designed to ensure that assets offered to the bank as collateral are, at least in theory, all equally good, and all equally protected from the risk of inflation.\nOrganization.\nThe ECB has four decision-making bodies, that take all the decisions with the objective of fulfilling the ECB's mandate:\nDecision-making bodies.\nExecutive Board.\nThe Executive Board is responsible for the implementation of monetary policy (defined by the Governing Council) and the day-to-day running of the bank. It can issue decisions to national central banks and may also exercise powers delegated to it by the Governing Council. Executive Board members are assigned a portfolio of responsibilities by the President of the ECB. The executive board normally meets every Tuesday.\nIt is composed of the President of the Bank (currently Christine Lagarde), the vice-president (currently Luis de Guindos) and four other members. They are all appointed by the European Council for non-renewable terms of eight years. Members of the executive board of the ECB are appointed \"from among persons of recognised standing and professional experience in monetary or banking matters by common accord of the governments of the Member States at the level of Heads of State or Government, on a recommendation from the Council, after it has consulted the European Parliament and the Governing Council of the ECB\".\nJos\u00e9 Manuel Gonz\u00e1lez-P\u00e1ramo, a Spanish member of the executive board since June 2004, was due to leave the board in early June 2012, but no replacement had been named as of late May. The Spanish had nominated Barcelona-born Antonio S\u00e1inz de Vicu\u00f1a \u2013 an ECB veteran who heads its legal department \u2013 as Gonz\u00e1lez-P\u00e1ramo's replacement as early as January 2012, but alternatives from Luxembourg, Finland, and Slovenia were put forward and no decision made by May. After a long political battle and delays due to the European Parliament's protest over the lack of gender balance at the ECB, Luxembourg's Yves Mersch was appointed as Gonz\u00e1lez-P\u00e1ramo's replacement.\nIn December 2020, Frank Elderson succeeded to Yves Mersch at the ECB's board.\nGoverning Council.\nThe Governing Council is the main decision-making body of the Eurosystem. It comprises the members of the executive board (six in total) and the governors of the National Central Banks of the euro area countries (20 as of 2023).\nAccording to Article 284 of the TFEU, the President of the European Council and a representative from the European Commission may attend the meetings as observers, but they lack voting rights.\nSince January 2015, the ECB has published on its website a summary of the Governing Council deliberations (\"accounts\"). These publications came as a partial response to recurring criticism against the ECB's opacity. However, in contrast to other central banks, the ECB still does not disclose individual voting records of the governors seating in its council.\nGeneral Council.\nThe General Council is a body dealing with transitional issues of euro adoption, for example, fixing the exchange rates of currencies being replaced by the euro (continuing the tasks of the former EMI). It will continue to exist until all EU member states adopt the euro, at which point it will be dissolved. It is composed of the President and vice-president together with the governors of all of the EU's national central banks.\nSupervisory Board.\nThe supervisory board meets twice a month to discuss, plan and carry out the ECB's supervisory tasks. It proposes draft decisions to the Governing Council under the non-objection procedure. It is composed of Chair (appointed for a non-renewable term of five years), Vice-chair (chosen from among the members of the ECB's executive board) four ECB representatives and representatives of national supervisors. If the national supervisory authority designated by a Member State is not a national central bank (NCB), the representative of the competent authority can be accompanied by a representative from their NCB. In such cases, the representatives are together considered as one member for the purposes of the voting procedure.\nIt also includes the Steering Committee, which supports the activities of the supervisory board and prepares the Board's meetings. It is composed by the chair of the supervisory board, Vice-chair of the supervisory board, one ECB representative and five representatives of national supervisors. The five representatives of national supervisors are appointed by the supervisory board for one year based on a rotation system that ensures a fair representation of countries.\nCapital subscription.\nThe ECB is governed by European law directly, but its set-up resembles that of a corporation in the sense that the ECB has shareholders and stock capital. Its initial capital was supposed to be \u20ac5 billion and the initial capital allocation key was determined in 1998 on the basis of the member states' populations and GDP, but the key is adjustable. The euro area NCBs were required to pay their respective subscriptions to the ECB's capital in full. The NCBs of the non-participating countries have had to pay 7% of their respective subscriptions to the ECB's capital as a contribution to the operational costs of the ECB. As a result, the ECB was endowed with an initial capital of just under \u20ac4\u00a0billion. The capital is held by the national central banks of the member states as shareholders. Shares in the ECB are not transferable and cannot be used as collateral. The NCBs are the sole subscribers to and holders of the capital of the ECB.\nToday, ECB capital is about \u20ac11 billion, which is held by the national central banks of the member states as shareholders. The NCBs' shares in this capital are calculated using a capital key which reflects the respective member's share in the total population and gross domestic product of the EU. The ECB adjusts the shares every five years and whenever the number of contributing NCBs changes. The adjustment is made on the basis of data provided by the European Commission.\nAll national central banks (NCBs) that own a share of the ECB capital stock as of 1 February 2020 are listed below. Non-Euro area NCBs are required to pay up only a very small percentage of their subscribed capital, which accounts for the different magnitudes of Euro area and Non-Euro area total paid-up capital.\nReserves.\nIn addition to capital subscriptions, the NCBs of the member states participating in the euro area provided the ECB with foreign reserve assets equivalent to around \u20ac40\u00a0billion. The contributions of each NCB is in proportion to its share in the ECB's subscribed capital, while in return each NCB is credited by the ECB with a claim in euro equivalent to its contribution. 15% of the contributions was made in gold, and the remaining 85% in US dollars and UK pounds sterling.\nLanguages.\nThe internal working language of the ECB is English, and press conferences are held in English. External communications are handled flexibly: English is preferred (though not exclusively) for communication within the ESCB (i.e. with other central banks) and with financial markets; communication with other national bodies and with EU citizens is normally in their respective language, but the ECB website is predominantly English; official documents such as the Annual Report are in the official languages of the EU (generally English, German and French).\nIn 2022, the ECB publishes for the first time details on the nationality of its staff, revealing an over-representation of Germans and Italians along the ECB employees, including in management positions.\nIndependence.\nThe European Central Bank (and by extension, the Eurosystem) is often considered as the \"most independent central bank in the world\". In general terms, this means that the Eurosystem tasks and policies can be discussed, designed, decided and implemented in full autonomy, without pressure or need for instructions from any external body. The main justification for the ECB's independence is that such an institutional setup assists the maintenance of price stability.\nIn practice, the ECB's independence is pinned by four key principles:\nDemocratic accountability.\nIn return to its high degree of independence and discretion, the ECB is accountable to the European Parliament (and to a lesser extent to the European Court of Auditors, the European Ombudsman and the Court of Justice of the EU (CJEU)). Although no interinstitutional agreement exists between the European Parliament and the ECB to regulate the ECB's accountability framework, it has been inspired by a resolution of the European Parliament adopted in 1998 which was then informally agreed with the ECB and incorporated into the Parliament's rule of procedure. In 2021, the European Parliament's ECON Committee requested to start negotiations with the ECB to formalize and improve these accountability arrangements.\nThe accountability framework involves five main mechanisms:\nIn 2013, an interinstitutional agreement was reached between the ECB and the European Parliament in the context of the establishment of the ECB's Banking Supervision. This agreement sets broader powers to the European Parliament than the established practice on the monetary policy side of the ECB's activities. For example, under the agreement, the Parliament can veto the appointment of the chair and vice-chair of the ECB's supervisory board and may approve removals if requested by the ECB.\nTransparency.\nIn addition to its independence, the ECB is subject to limited transparency obligations in contrast to EU Institutions standards and other major central banks. Indeed, as pointed out by Transparency International, \"The Treaties establish transparency and openness as principles of the EU and its institutions. They do, however, grant the ECB a partial exemption from these principles. According to Art. 15(3) TFEU, the ECB is bound by the EU's transparency principles \"only when exercising [its] administrative tasks\" (the exemption \u2013 which leaves the term \"administrative tasks\" undefined \u2013 equally applies to the Court of Justice of the European Union and to the European Investment Bank).\"\nIn practice, there are several concrete examples where the ECB is less transparent than other institutions:\nLocation.\nThe bank is based in Ostend (East End), Frankfurt am Main. The city is the largest financial centre in the Eurozone and the bank's location in it is fixed by the Amsterdam Treaty. The bank moved to a new purpose-built headquarters in 2014, designed by a Vienna-based architectural office, Coop Himmelbau. The building is approximately tall and is to be accompanied by other secondary buildings on a landscaped site on the site of the former wholesale market in the eastern part of Frankfurt am Main. The main construction on a 120,000 m2 total site area began in October 2008, and it was expected that the building would become an architectural symbol for Europe. While it was designed to accommodate double the number of staff who operated in the former Eurotower, that building has been retained by the ECB, owing to more space being required since it took responsibility for banking supervision.\nDebates surrounding the ECB.\nDebates on ECB independence.\nThe debate on the independence of the ECB finds its origins in the preparatory stages of the construction of the EMU. The German government agreed to go ahead if certain crucial guarantees were respected, such as a European Central Bank independent of national governments and shielded from political pressure along the lines of the German central bank. The French government, for its part, feared that this independence would mean that politicians would no longer have any room for manoeuvre in the process. A compromise was then reached by establishing a regular dialogue between the ECB and the Council of Finance Ministers of the euro area, the Eurogroupe.\nArguments in favour of independence.\nThere is strong consensus among economists on the value of central bank independence from politics. The rationale behind are both empirical and theoretical. On the theoretical side, it's believed that time inconsistency suggests the existence of political business cycles where elected officials might take advantage of policy surprises to secure reelection. The politician up to the election will therefore be incentivized to introduce expansionary monetary policies, reducing unemployment in the short run. These effects will be most likely temporary. By contrast, in the long run, it will increase inflation, with unemployment returning to the natural rate negating the positive effect. Furthermore, the credibility of the central bank will deteriorate, making it more difficult to answer the market. Additionally, empirical work has been done that defined and measured central bank independence (CBI), looking at the relationship of CBI with inflation.\nThe arguments against too much independence.\nAn independence that would be the source of a democratic deficit..\nDemystify the independence of central bankers: According to Christopher Adolph (2009), the alleged neutrality of central bankers is only a legal fa\u00e7ade and not an indisputable fact. To achieve this, the author analyses the professional careers of central bankers and mirrors them with their respective monetary decision-making. To explain the results of his analysis, he utilizes he uses the \"\"principal-agent\" theory. To explain that in order to create a new entity, one needs a delegator or \"principal\" (in this case the heads of state or government of the euro area) and a delegate or \"agent\" (in this case the ECB). In his illustration, he describes the financial community as a \"shadow principale\"\" \u00a0which influences the choice of central bankers thus indicating that the central banks indeed act as interfaces between the financial world and the States. It is therefore not surprising, still according to the author, to regain their influence and preferences in the appointment of central bankers, presumed conservative, neutral and impartial according to the model of the Independent Central Bank (ICB), which eliminates this famous \"temporal inconsistency\". Central bankers had a professional life before joining the central bank and their careers will most likely continue after their tenure. They are ultimately human beings. Therefore, for the author, central bankers have interests of their own, based on their past careers and their expectations after joining the ECB, and try to send messages to their future potential employers.\nThe crisis: an opportunity to impose its will and extend its powers:\n\u2013 \"Its participation in the troika\": Thanks to its three factors which explain its independence, the ECB took advantage of this crisis to implement, through its participation in the troika, the famous structural reforms in the Member States aimed at making, more flexible the various markets, particularly the labour market, which are still considered too rigid under the ordoliberal concept.\n- \"Macro-prudential supervision\" : At the same time, taking advantage of the reform of the financial supervision system, the Frankfurt Bank has acquired new responsibilities, such as macro-prudential supervision, in other words, supervision of the provision of financial services.\n-\"Take liberties with its mandate to save the Euro\" : Paradoxically, the crisis undermined the ECB's ordoliberal discourse \"because some of its instruments, which it had to implement, deviated significantly from its principles. It then interpreted the paradigm with enough flexibly to adapt its original reputation to these new economic conditions. It was forced to do so as a last resort to save its one and only raison d'\u00eatre: the euro. This Independent was thus obliged to be pragmatic by departing from the spirit of its statutes, which is unacceptable to the hardest supporters of ordoliberalism, which will lead to the resignation of the two German leaders present within the ECB: the governor of the Bundesbank, Jens WEIDMANN and the member of the executive board of the ECB, J\u00fcrgen STARK.\n\u2013 \"Regulation of the financial system\" : The delegation of this new function to the ECB was carried out with great simplicity and with the consent of European leaders, because neither the Commission nor the Member States really wanted to obtain the monitoring of financial abuses throughout the area. In other words, in the event of a new financial crisis, the ECB would be the perfect scapegoat.\n- \"Capturing exchange rate policy\" : The event that will most mark the definitive politicization of the ECB is, of course, the operation launched in January 2015: the quantitative easing (QE) operation. Indeed, the Euro is an overvalued currency on the world markets against the dollar and the Euro zone is at risk of deflation. In addition, Member States find themselves heavily indebted, partly due to the rescue of their national banks. The ECB, as the guardian of the stability of the euro zone, is deciding to gradually buy back more than EUR 1 100 billion Member States' public debt. In this way, money is injected back into the economy, the euro depreciates significantly, prices rise, the risk of deflation is removed, and Member States reduce their debts. However, the ECB has just given itself the right to direct the exchange rate policy of the euro zone without this being granted by the Treaties or with the approval of European leaders, and without public opinion or the public arena being aware of this.\nIn conclusion, for those in favour of a framework for ECB independence, there is a clear concentration of powers. In the light of these facts, it is clear that the ECB is no longer the simple guardian of monetary stability in the euro area, but has become, over the course of the crisis, a \"multi-competent economic player, at ease in this role that no one, especially not the agnostic governments of the euro Member States, seems to have the idea of challenging\". This new political super-actor, having captured many spheres of competence and a very strong influence in the economic field in the broad sense (economy, finance, budget...).\u00a0 This new political super-actor can no longer act alone and refuse a counter-power, consubstantial to our liberal democracies. Indeed, the status of independence which the ECB enjoys by essence should not exempt it from a real responsibility regarding the democratic process.\nThe arguments in favour of a counter power.\nIn the aftermath of the euro area crisis, several proposals for a countervailing power were put forward, to deal with criticisms of a democratic deficit. For the German economist German Issing (2001) the ECB as a democratic responsibility and should be more transparent. According to him, this transparency could bring several advantages as the improvement of efficiency and credibility by giving the public adequate information. Others think that the ECB should have a closer relationship with the European Parliament which could play a major role in the evaluation of the democratic responsibility of the ECB. The development of new institutions or the creation of a minister is another solution proposed:\nA minister for the Eurozone ?\nThe idea of a eurozone finance minister is regularly raised and supported by certain political figures, including Emmanuel Macron, as well as former German Chancellor Angela Merkel, former President of the ECB Jean-Claude Trichet and former European Commissioner Pierre Moscovici. For the latter, this position would bring \"more democratic legitimacy\" and \"more efficiency\" to European politics. In his view, it is a question of merging the powers of Commissioner for the Economy and Finance with those of the President of the Eurogroup.\nThe main task of this minister would be to \"represent a strong political authority protecting the economic and budgetary interests of the euro area as a whole, and not the interests of individual Member States\". According to the Jacques Delors Institute, its competencies could be as follows:\nFor Jean-Claude Trichet, this minister could also rely on the Eurogroup working group for the preparation and follow-up of meetings in eurozone format, and on the Economic and Financial Committee for meetings concerning all Member States. He would also have under his authority a General Secretariat of the Treasury of the euro area, whose tasks would be determined by the objectives of the budgetary union currently being set up \nThis proposal was nevertheless rejected in 2017 by the Eurogroup, its president, Jeroen Dijsselbloem, spoke of the importance of this institution in relation to the European Commission.\nTowards democratic institutions ?\nThe absence of democratic institutions such as a Parliament or a real government is a regular criticism of the ECB in its management of the euro area, and many proposals have been made in this respect, particularly after the economic crisis, which would have shown the need to improve the governance of the euro area. For Mo\u00efse Sidiropoulos, a professor in economy: \"The crisis in the euro zone came as no surprise, because the euro remains an unfinished currency, a stateless currency with a fragile political legitimacy\".\nFrench economist Thomas Piketty wrote on his blog in 2017 that it was essential to equip the eurozone with democratic institutions. An economic government could for example enable it to have a common budget, common taxes and borrowing and investment capacities. Such a government would then make the euro area more democratic and transparent by avoiding the opacity of a council such as the Eurogroup.\nNevertheless, according to him \"there is no point in talking about a government of the eurozone if we do not say to which democratic body this government will be accountable\", a real parliament of the eurozone to which a finance minister would be accountable seems to be the real priority for the economist, who also denounces the lack of action in this area.\nThe creation of a sub-committee within the current European Parliament was also mentioned, in the model of the Eurogroup, which is currently an under-formation of the ECOFIN Committee. This would require a simple amendment to the rules of procedure and would avoid a competitive situation between two separate parliamentary assemblies. The former President of the European Commission had, moreover, stated on this subject that he had \"no sympathy for the idea of a specific Eurozone Parliament\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9476", "revid": "32694456", "url": "https://en.wikipedia.org/wiki?curid=9476", "title": "Electron", "text": "Elementary particle with negative charge\nThe electron (' or ') is a subatomic particle with a negative one elementary electric charge. Electrons belong to the first generation of the lepton particle family, and are generally thought to be elementary particles because they have no known components or substructure. The electron's mass is approximately 1/1836 that of the proton. Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value, expressed in units of the reduced Planck constant, \u0127. Being fermions, no two electrons can occupy the same quantum state, per the Pauli exclusion principle. Like all elementary particles, electrons exhibit properties of both particles and waves: They can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a longer de Broglie wavelength for a given energy.\nElectrons play an essential role in numerous physical phenomena, such as electricity, magnetism, chemistry, and thermal conductivity; they also participate in gravitational, electromagnetic, and weak interactions. Since an electron has charge, it has a surrounding electric field; if that electron is moving relative to an observer, the observer will observe it to generate a magnetic field. Electromagnetic fields produced from other sources will affect the motion of an electron according to the Lorentz force law. Electrons radiate or absorb energy in the form of photons when they are accelerated.\nLaboratory instruments are capable of trapping individual electrons as well as electron plasma by the use of electromagnetic fields. Special telescopes can detect electron plasma in outer space. Electrons are involved in many applications, such as tribology or frictional charging, electrolysis, electrochemistry, battery technologies, electronics, welding, cathode-ray tubes, photoelectricity, photovoltaic solar panels, electron microscopes, radiation therapy, lasers, gaseous ionization detectors, and particle accelerators.\nInteractions involving electrons with other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between the positive protons within atomic nuclei and the negative electrons without allows the composition of the two known as atoms. Ionization or differences in the proportions of negative electrons versus positive nuclei changes the binding energy of an atomic system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding. In 1838, British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms. Irish physicist George Johnstone Stoney named this charge 'electron' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897 during the cathode-ray tube experiment. Electrons can also participate in nuclear reactions, such as nucleosynthesis in stars, where they are known as beta particles. Electrons can be created through beta decay of radioactive isotopes and in high-energy collisions, for instance, when cosmic rays enter the atmosphere. The antiparticle of the electron is called the positron; it is identical to the electron, except that it carries electrical charge of the opposite sign. When an electron collides with a positron, both particles can be annihilated, producing gamma ray photons.\nHistory.\nDiscovery of effect of electric force.\nThe ancient Greeks noticed that amber attracted small objects when rubbed with fur. Along with lightning, this phenomenon is one of humanity's earliest recorded experiences with electricity. In his 1600 treatise , the English scientist William Gilbert coined the Neo-Latin term , to refer to those substances with property similar to that of amber which attract smaller objects after being rubbed. Both \"electric\" and \"electricity\" are derived from the Latin ' (also the root of the alloy of the same name), which came from the Greek word for amber, (').\nDiscovery of two kinds of charges.\nIn the early 1700s, French chemist Charles Fran\u00e7ois du Fay found that if a charged gold-leaf is repulsed by glass rubbed with silk, then the same charged gold-leaf is attracted by amber rubbed with wool. From this and other results of similar types of experiments, du Fay concluded that electricity consists of two electrical fluids, \"vitreous\" fluid from glass rubbed with silk and \"resinous\" fluid from amber rubbed with wool. These two fluids can neutralize each other when combined. American scientist Ebenezer Kinnersley later also independently reached the same conclusion. A decade later Benjamin Franklin proposed that electricity was not from different types of electrical fluid, but a single electrical fluid showing an excess (+) or deficit (\u2212). He gave them the modern charge nomenclature of positive and negative respectively. Franklin thought of the charge carrier as being positive, but he did not correctly identify which situation was a surplus of the charge carrier, and which situation was a deficit.\nBetween 1838 and 1851, British natural philosopher Richard Laming developed the idea that an atom is composed of a core of matter surrounded by subatomic particles that had unit electric charges. Beginning in 1846, German physicist Wilhelm Eduard Weber theorized that electricity was composed of positively and negatively charged fluids, and their interaction was governed by the inverse square law. After studying the phenomenon of electrolysis in 1874, Irish physicist George Johnstone Stoney suggested that there existed a \"single definite quantity of electricity\", the charge of a monovalent ion. He was able to estimate the value of this elementary charge \"e\" by means of Faraday's laws of electrolysis. However, Stoney believed these charges were permanently attached to atoms and could not be removed. In 1881, German physicist Hermann von Helmholtz argued that both positive and negative charges were divided into elementary parts, each of which \"behaves like atoms of electricity\".\nStoney initially coined the term \"electrolion\" in 1881. Ten years later, he switched to \"electron\" to describe these elementary charges, writing in 1894: \"... an estimate was made of the actual amount of this most remarkable fundamental unit of electricity, for which I have since ventured to suggest the name \"electron\"\". A 1906 proposal to change to \"electrion\" failed because Hendrik Lorentz preferred to keep \"electron\". The word \"electron\" is a combination of the words \"electric\" and \"ion\". The suffix -\"on\" which is now used to designate other subatomic particles, such as a proton or neutron, is in turn derived from electron.\nDiscovery of free electrons outside matter.\nWhile studying electrical conductivity in rarefied gases in 1859, the German physicist Julius Pl\u00fccker observed the radiation emitted from the cathode caused phosphorescent light to appear on the tube wall near the cathode; and the region of the phosphorescent light could be moved by application of a magnetic field. In 1869, Pl\u00fccker's student Johann Wilhelm Hittorf found that a solid body placed in between the cathode and the phosphorescence would cast a shadow upon the phosphorescent region of the tube. Hittorf inferred that there are straight rays emitted from the cathode and that the phosphorescence was caused by the rays striking the tube walls. In 1876, the German physicist Eugen Goldstein showed that the rays were emitted perpendicular to the cathode surface, which distinguished between the rays that were emitted from the cathode and the incandescent light. Goldstein dubbed the rays cathode rays. Decades of experimental and theoretical research involving cathode rays were important in J. J. Thomson's eventual discovery of electrons.\nDuring the 1870s, the English chemist and physicist Sir William Crookes developed the first cathode-ray tube to have a high vacuum inside. He then showed in 1874 that the cathode rays can turn a small paddle wheel when placed in their path. Therefore, he concluded that the rays carried momentum. Furthermore, by applying a magnetic field, he was able to deflect the rays, thereby demonstrating that the beam behaved as though it were negatively charged. In 1879, he proposed that these properties could be explained by regarding cathode rays as composed of negatively charged gaseous molecules in a fourth state of matter in which the mean free path of the particles is so long that collisions may be ignored.\nThe German-born British physicist Arthur Schuster expanded upon Crookes's experiments by placing metal plates parallel to the cathode rays and applying an electric potential between the plates. The field deflected the rays toward the positively charged plate, providing further evidence that the rays carried negative charge. By measuring the amount of deflection for a given electric and magnetic field, in 1890 Schuster was able to estimate the charge-to-mass ratio of the ray components. However, this produced a value that was more than a thousand times greater than what was expected, so little credence was given to his calculations at the time. This is because it was assumed that the charge carriers were much heavier hydrogen or nitrogen atoms. Schuster's estimates would subsequently turn out to be largely correct.\nIn 1892 Hendrik Lorentz suggested that the mass of these particles (electrons) could be a consequence of their electric charge.\nWhile studying naturally fluorescing minerals in 1896, the French physicist Henri Becquerel discovered that they emitted radiation without any exposure to an external energy source. These radioactive materials became the subject of much interest by scientists, including the New Zealand physicist Ernest Rutherford who discovered they emitted particles. He designated these particles alpha and beta, on the basis of their ability to penetrate matter. In 1900, Becquerel showed that the beta rays emitted by radium could be deflected by an electric field, and that their mass-to-charge ratio was the same as for cathode rays. This evidence strengthened the view that electrons existed as components of atoms.\nIn 1897, the British physicist J. J. Thomson, with his colleagues John S. Townsend and H. A. Wilson, performed experiments indicating that cathode rays really were unique particles, rather than waves, atoms or molecules as was believed earlier. Thomson made good estimates of both the charge \"e\" and the mass \"m\", finding that cathode ray particles, which he called \"corpuscles\", had perhaps one thousandth of the mass of the least massive ion known: hydrogen. He showed that their charge-to-mass ratio, \"e\"/\"m\", was independent of cathode material. He further showed that the negatively charged particles produced by radioactive materials, by heated materials and by illuminated materials were universal. The name electron was adopted for these particles by the scientific community, mainly due to the advocation by G. F. FitzGerald, J. Larmor, and H. A. Lorentz. In the same year Emil Wiechert and Walter Kaufmann also calculated the e/m ratio but they failed short of interpreting their results while J. J. Thomson would subsequently in 1899 give estimates for the electron charge and mass as well: e~ esu and m~ g\nThe electron's charge was more carefully measured by the American physicists Robert Millikan and Harvey Fletcher in their oil-drop experiment of 1909, the results of which were published in 1911. This experiment used an electric field to prevent a charged droplet of oil from falling as a result of gravity. This device could measure the electric charge from as few as 1\u2013150 ions with an error margin of less than 0.3%. Comparable experiments had been done earlier by Thomson's team, using clouds of charged water droplets generated by electrolysis, and in 1911 by Abram Ioffe, who independently obtained the same result as Millikan using charged microparticles of metals, then published his results in 1913. However, oil drops were more stable than water drops because of their slower evaporation rate, and thus more suited to precise experimentation over longer periods of time.\nAround the beginning of the twentieth century, it was found that under certain conditions a fast-moving charged particle caused a condensation of supersaturated water vapor along its path. In 1911, Charles Wilson used this principle to devise his cloud chamber so he could photograph the tracks of charged particles, such as fast-moving electrons.\nAtomic theory.\nBy 1914, experiments by physicists Ernest Rutherford, Henry Moseley, James Franck and Gustav Hertz had largely established the structure of an atom as a dense nucleus of positive charge surrounded by lower-mass electrons. In 1913, Danish physicist Niels Bohr postulated that electrons resided in quantized energy states, with their energies determined by the angular momentum of the electron's orbit about the nucleus. The electrons could move between those states, or orbits, by the emission or absorption of photons of specific frequencies. By means of these quantized orbits, he accurately explained the spectral lines of the hydrogen atom. However, Bohr's model failed to account for the relative intensities of the spectral lines and it was unsuccessful in explaining the spectra of more complex atoms.\nChemical bonds between atoms were explained by Gilbert Newton Lewis, who in 1916 proposed that a covalent bond between two atoms is maintained by a pair of electrons shared between them. Later, in 1927, Walter Heitler and Fritz London gave the full explanation of the electron-pair formation and chemical bonding in terms of quantum mechanics. In 1919, the American chemist Irving Langmuir elaborated on the Lewis's static model of the atom and suggested that all electrons were distributed in successive \"concentric (nearly) spherical shells, all of equal thickness\". In turn, he divided the shells into a number of cells each of which contained one pair of electrons. With this model Langmuir was able to qualitatively explain the chemical properties of all elements in the periodic table, which were known to largely repeat themselves according to the periodic law.\nIn 1924, Austrian physicist Wolfgang Pauli observed that the shell-like structure of the atom could be explained by a set of four parameters that defined every quantum energy state, as long as each state was occupied by no more than a single electron. This prohibition against more than one electron occupying the same quantum energy state became known as the Pauli exclusion principle. The physical mechanism to explain the fourth parameter, which had two distinct possible values, was provided by the Dutch physicists Samuel Goudsmit and George Uhlenbeck. In 1925, they suggested that an electron, in addition to the angular momentum of its orbit, possesses an intrinsic angular momentum and magnetic dipole moment. This is analogous to the rotation of the Earth on its axis as it orbits the Sun. The intrinsic angular momentum became known as spin, and explained the previously mysterious splitting of spectral lines observed with a high-resolution spectrograph; this phenomenon is known as fine structure splitting.\nQuantum mechanics.\nIn his 1924 dissertation \"\" (Research on Quantum Theory), French physicist Louis de Broglie hypothesized that all matter can be represented as a de Broglie wave in the manner of light. That is, under the appropriate conditions, electrons and other matter would show properties of either particles or waves. The corpuscular properties of a particle are demonstrated when it is shown to have a localized position in space along its trajectory at any given moment. The wave-like nature of light is displayed, for example, when a beam of light is passed through parallel slits thereby creating interference patterns. In 1927, George Paget Thomson and Alexander Reid discovered the interference effect was produced when a beam of electrons was passed through thin celluloid foils and later metal films, and by American physicists Clinton Davisson and Lester Germer by the reflection of electrons from a crystal of nickel. Alexander Reid, who was Thomson's graduate student, performed the first experiments but he died soon after in a motorcycle accident and is rarely mentioned.\nDe Broglie's prediction of a wave nature for electrons led Erwin Schr\u00f6dinger to postulate a wave equation for electrons moving under the influence of the nucleus in the atom. In 1926, this equation, the Schr\u00f6dinger equation, successfully described how electron waves propagated. Rather than yielding a solution that determined the location of an electron over time, this wave equation also could be used to predict the probability of finding an electron near a position, especially a position near where the electron was bound in space, for which the electron wave equations did not change in time. This approach led to a second formulation of quantum mechanics (the first by Heisenberg in 1925), and solutions of Schr\u00f6dinger's equation, like Heisenberg's, provided derivations of the energy states of an electron in a hydrogen atom that were equivalent to those that had been derived first by Bohr in 1913, and that were known to reproduce the hydrogen spectrum. Once spin and the interaction between multiple electrons were describable, quantum mechanics made it possible to predict the configuration of electrons in atoms with atomic numbers greater than hydrogen.\nIn 1928, building on Wolfgang Pauli's work, Paul Dirac produced a model of the electron\u00a0\u2013 the Dirac equation, consistent with relativity theory, by applying relativistic and symmetry considerations to the hamiltonian formulation of the quantum mechanics of the electro-magnetic field. In order to resolve some problems within his relativistic equation, Dirac developed in 1930 a model of the vacuum as an infinite sea of particles with negative energy, later dubbed the Dirac sea. This led him to predict the existence of a positron, the antimatter counterpart of the electron. This particle was discovered in 1932 by Carl Anderson, who proposed calling standard electrons \"negatrons\" and using \"electron\" as a generic term to describe both the positively and negatively charged variants.\nIn 1947, Willis Lamb, working in collaboration with graduate student Robert Retherford, found that certain quantum states of the hydrogen atom, which should have the same energy, were shifted in relation to each other; the difference came to be called the Lamb shift. About the same time, Polykarp Kusch, working with Henry M. Foley, discovered the magnetic moment of the electron is slightly larger than predicted by Dirac's theory. This small difference was later called anomalous magnetic dipole moment of the electron. This difference was later explained by the theory of quantum electrodynamics, developed by Sin-Itiro Tomonaga, Julian Schwinger and\nRichard Feynman in the late 1940s.\nParticle accelerators.\nWith the development of the particle accelerator during the first half of the twentieth century, physicists began to delve deeper into the properties of subatomic particles. The first successful attempt to accelerate electrons using electromagnetic induction was made in 1942 by Donald Kerst. His initial betatron reached energies of 2.3\u00a0MeV, while subsequent betatrons achieved 300\u00a0MeV. In 1947, synchrotron radiation was discovered with a 70\u00a0MeV electron synchrotron at General Electric. This radiation was caused by the acceleration of electrons through a magnetic field as they moved near the speed of light.\nWith a beam energy of 1.5\u00a0GeV, the first high-energy\nparticle collider was ADONE, which began operations in 1968. This device accelerated electrons and positrons in opposite directions, effectively doubling the energy of their collision when compared to striking a static target with an electron. The Large Electron\u2013Positron Collider (LEP) at CERN, which was operational from 1989 to 2000, achieved collision energies of 209\u00a0GeV and made important measurements for the Standard Model of particle physics.\nConfinement of individual electrons.\nIndividual electrons can now be easily confined in ultra small (\"L\" = 20 nm, \"W\" = 20 nm) CMOS transistors operated at cryogenic temperature over a range of \u2212269\u00a0\u00b0C (4\u00a0K) to about \u2212258\u00a0\u00b0C (15\u00a0K). The electron wavefunction spreads in a semiconductor lattice and negligibly interacts with the valence band electrons, so it can be treated in the single particle formalism, by replacing its mass with the effective mass tensor.\nCharacteristics.\nClassification.\nIn the Standard Model of particle physics, electrons belong to the group of subatomic particles called leptons, which are believed to be fundamental or elementary particles. Electrons have the lowest mass of any charged lepton (or electrically charged particle of any type) and belong to the first-generation of fundamental particles. The second and third generation contain charged leptons, the muon and the tau, which are identical to the electron in charge, spin and interactions, but are more massive. Leptons differ from the other basic constituent of matter, the quarks, by their lack of strong interaction. All members of the lepton group are fermions, because they all have half-odd integer spin; the electron has spin .\nFundamental properties.\nThe invariant mass of an electron is approximately \u00a0kilograms, or \u00a0atomic mass units. Due to mass\u2013energy equivalence, this corresponds to a rest energy of . The ratio between the mass of a proton and that of an electron is about 1836. Astronomical measurements show that the proton-to-electron mass ratio has held the same value, as is predicted by the Standard Model, for at least half the age of the universe.\nElectrons have an electric charge of coulombs, which is used as a standard unit of charge for subatomic particles, and is also called the elementary charge. Within the limits of experimental accuracy, the electron charge is identical to the charge of a proton, but with the opposite sign. The electron is commonly symbolized by , and the positron is symbolized by .\nThe electron has an intrinsic angular momentum or spin of . This property is usually stated by referring to the electron as a spin- particle. For such particles the spin magnitude is , while the result of the measurement of a projection of the spin on any axis can only be \u00b1. In addition to spin, the electron has an intrinsic magnetic moment along its spin axis. It is approximately equal to one Bohr magneton,=\\frac{e\\hbar}{2m_{\\mathrm{e}}}.&lt;/math&gt;}} which is a physical constant equal to . The orientation of the spin with respect to the momentum of the electron defines the property of elementary particles known as helicity.\nThe electron has no known substructure. Nevertheless, in condensed matter physics, spin\u2013charge separation can occur in some materials. In such cases, electrons 'split' into three independent particles, the spinon, the orbiton and the holon (or chargon). The electron can always be theoretically considered as a bound state of the three, with the spinon carrying the spin of the electron, the orbiton carrying the orbital degree of freedom and the chargon carrying the charge, but in certain conditions they can behave as independent quasiparticles.\nThe issue of the radius of the electron is a challenging problem of modern theoretical physics. The admission of the hypothesis of a finite radius of the electron is incompatible to the premises of the theory of relativity. On the other hand, a point-like electron (zero radius) generates serious mathematical difficulties due to the self-energy of the electron tending to infinity. Observation of a single electron in a Penning trap suggests the upper limit of the particle's radius to be 10\u221222\u00a0meters.\nThe upper bound of the electron radius of 10\u221218\u00a0meters can be derived using the uncertainty relation in energy. There \"is\" also a physical constant called the \"classical electron radius\", with the much larger value of , greater than the radius of the proton. However, the terminology comes from a simplistic calculation that ignores the effects of quantum mechanics; in reality, the so-called classical electron radius has little to do with the true fundamental structure of the electron.\nThere are elementary particles that spontaneously decay into less massive particles. An example is the muon, with a mean lifetime of \u00a0seconds, which decays into an electron, a muon neutrino and an electron antineutrino. The electron, on the other hand, is thought to be stable on theoretical grounds: the electron is the least massive particle with non-zero electric charge, so its decay would violate charge conservation. The experimental lower bound for the electron's mean lifetime is years, at a 90% confidence level.\nQuantum properties.\nAs with all particles, electrons can act as waves. This is called the wave\u2013particle duality and can be demonstrated using the double-slit experiment.\nThe wave-like nature of the electron allows it to pass through two parallel slits simultaneously, rather than just one slit as would be the case for a classical particle. In quantum mechanics, the wave-like property of one particle can be described mathematically as a complex-valued function, the wave function, commonly denoted by the Greek letter psi (\"\u03c8\"). When the absolute value of this function is squared, it gives the probability that a particle will be observed near a location\u2014a probability density.\nElectrons are identical particles because they cannot be distinguished from each other by their intrinsic physical properties. In quantum mechanics, this means that a pair of interacting electrons must be able to swap positions without an observable change to the state of the system. The wave function of fermions, including electrons, is antisymmetric, meaning that it changes sign when two electrons are swapped; that is, \"\u03c8\"(\"r\"1, \"r\"2) \n \u2212\"\u03c8\"(\"r\"2, \"r\"1), where the variables \"r\"1 and \"r\"2 correspond to the first and second electrons, respectively. Since the absolute value is not changed by a sign swap, this corresponds to equal probabilities. Bosons, such as the photon, have symmetric wave functions instead.\nIn the case of antisymmetry, solutions of the wave equation for interacting electrons result in a zero probability that each pair will occupy the same location or state. This is responsible for the Pauli exclusion principle, which precludes any two electrons from occupying the same quantum state. This principle explains many of the properties of electrons. For example, it causes groups of bound electrons to occupy different orbitals in an atom, rather than all overlapping each other in the same orbit.\nVirtual particles.\nIn a simplified picture, which often tends to give the wrong idea but may serve to illustrate some aspects, every photon spends some time as a combination of a virtual electron plus its antiparticle, the virtual positron, which rapidly annihilate each other shortly thereafter. The combination of the energy variation needed to create these particles, and the time during which they exist, fall under the threshold of detectability expressed by the Heisenberg uncertainty relation, \u0394\"E\"\u00a0\u00b7\u00a0\u0394\"t\"\u00a0\u2265\u00a0\"\u0127\". In effect, the energy needed to create these virtual particles, \u0394\"E\", can be \"borrowed\" from the vacuum for a period of time, \u0394\"t\", so that their product is no more than the reduced Planck constant, \"\u0127\" \u2248. Thus, for a virtual electron, \u0394\"t\" is at most .\nWhile an electron\u2013positron virtual pair is in existence, the Coulomb force from the ambient electric field surrounding an electron causes a created positron to be attracted to the original electron, while a created electron experiences a repulsion. This causes what is called vacuum polarization. In effect, the vacuum behaves like a medium having a dielectric permittivity more than unity. Thus the effective charge of an electron is actually smaller than its true value, and the charge decreases with increasing distance from the electron. This polarization was confirmed experimentally in 1997 using the Japanese TRISTAN particle accelerator. Virtual particles cause a comparable shielding effect for the mass of the electron.\nThe interaction with virtual particles also explains the small (about 0.1%) deviation of the intrinsic magnetic moment of the electron from the Bohr magneton (the anomalous magnetic moment). The extraordinarily precise agreement of this predicted difference with the experimentally determined value is viewed as one of the great achievements of quantum electrodynamics.\nThe apparent paradox in classical physics of a point particle electron having intrinsic angular momentum and magnetic moment can be explained by the formation of virtual photons in the electric field generated by the electron. These photons can heuristically be thought of as causing the electron to shift about in a jittery fashion (known as zitterbewegung), which results in a net circular motion with precession. This motion produces both the spin and the magnetic moment of the electron. In atoms, this creation of virtual photons explains the Lamb shift observed in spectral lines. The Compton Wavelength shows that near elementary particles such as the electron, the uncertainty of the energy allows for the creation of virtual particles near the electron. This wavelength explains the \"static\" of virtual particles around elementary particles at a close distance.\nInteraction.\nAn electron generates an electric field that exerts an attractive force on a particle with a positive charge, such as the proton, and a repulsive force on a particle with a negative charge. The strength of this force in nonrelativistic approximation is determined by Coulomb's inverse square law. When an electron is in motion, it generates a magnetic field.140 The Amp\u00e8re\u2013Maxwell law relates the magnetic field to the mass motion of electrons (the current) with respect to an observer. This property of induction supplies the magnetic field that drives an electric motor. The electromagnetic field of an arbitrary moving charged particle is expressed by the Li\u00e9nard\u2013Wiechert potentials, which are valid even when the particle's speed is close to that of light (relativistic).\nWhen an electron is moving through a magnetic field, it is subject to the Lorentz force that acts perpendicularly to the plane defined by the magnetic field and the electron velocity. This centripetal force causes the electron to follow a helical trajectory through the field at a radius called the gyroradius. The acceleration from this curving motion induces the electron to radiate energy in the form of synchrotron radiation.160 The energy emission in turn causes a recoil of the electron, known as the Abraham\u2013Lorentz\u2013Dirac Force, which creates a friction that slows the electron. This force is caused by a back-reaction of the electron's own field upon itself.\nPhotons mediate electromagnetic interactions between particles in quantum electrodynamics. An isolated electron at a constant velocity cannot emit or absorb a real photon; doing so would violate conservation of energy and momentum. Instead, virtual photons can transfer momentum between two charged particles. This exchange of virtual photons, for example, generates the Coulomb force. Energy emission can occur when a moving electron is deflected by a charged particle, such as a proton. The deceleration of the electron results in the emission of Bremsstrahlung radiation.\nAn inelastic collision between a photon (light) and a solitary (free) electron is called Compton scattering. This collision results in a transfer of momentum and energy between the particles, which modifies the wavelength of the photon by an amount called the Compton shift.c} (1 - \\cos \\theta),&lt;/math&gt;\nwhere \"c\" is the speed of light in vacuum and \"m\"e is the electron mass. See Zombeck (2007).393, 396 }} The maximum magnitude of this wavelength shift is \"h\"/\"m\"e\"c\", which is known as the Compton wavelength. For an electron, it has a value of . When the wavelength of the light is long (for instance, the wavelength of the visible light is 0.4\u20130.7\u00a0\u03bcm) the wavelength shift becomes negligible. Such interaction between the light and free electrons is called Thomson scattering or linear Thomson scattering.\nThe relative strength of the electromagnetic interaction between two charged particles, such as an electron and a proton, is given by the fine-structure constant. This value is a dimensionless quantity formed by the ratio of two energies: the electrostatic energy of attraction (or repulsion) at a separation of one Compton wavelength, and the rest energy of the charge. It is given by \"\u03b1\"\u00a0\u2248\u00a0, which is approximately equal to .\nWhen electrons and positrons collide, they annihilate each other, giving rise to two or more gamma ray photons. If the electron and positron have negligible momentum, a positronium atom can form before annihilation results in two or three gamma ray photons totalling 1.022\u00a0MeV. On the other hand, a high-energy photon can transform into an electron and a positron by a process called pair production, but only in the presence of a nearby charged particle, such as a nucleus.\nIn the theory of electroweak interaction, the left-handed component of electron's wavefunction forms a weak isospin doublet with the electron neutrino. This means that during weak interactions, electron neutrinos behave like electrons. Either member of this doublet can undergo a charged current interaction by emitting or absorbing a and be converted into the other member. Charge is conserved during this reaction because the W\u00a0boson also carries a charge, canceling out any net change during the transmutation. Charged current interactions are responsible for the phenomenon of beta decay in a radioactive atom. Both the electron and electron neutrino can undergo a neutral current interaction via a exchange, and this is responsible for neutrino-electron elastic scattering.\nAtoms and molecules.\nAn electron can be \"bound\" to the nucleus of an atom by the attractive Coulomb force. A system of one or more electrons bound to a nucleus is called an atom. If the number of electrons is different from the nucleus's electrical charge, such an atom is called an ion. The wave-like behavior of a bound electron is described by a function called an atomic orbital. Each orbital has its own set of quantum numbers such as energy, angular momentum and projection of angular momentum, and only a discrete set of these orbitals exist around the nucleus. According to the Pauli exclusion principle each orbital can be occupied by up to two electrons, which must differ in their spin quantum number.\nElectrons can transfer between different orbitals by the emission or absorption of photons with an energy that matches the difference in potential. Other methods of orbital transfer include collisions with particles, such as electrons, and the Auger effect. To escape the atom, the energy of the electron must be increased above its binding energy to the atom. This occurs, for example, with the photoelectric effect, where an incident photon exceeding the atom's ionization energy is absorbed by the electron.\nThe orbital angular momentum of electrons is quantized. Because the electron is charged, it produces an orbital magnetic moment that is proportional to the angular momentum. The net magnetic moment of an atom is equal to the vector sum of orbital and spin magnetic moments of all electrons and the nucleus. The magnetic moment of the nucleus is negligible compared with that of the electrons. The magnetic moments of the electrons that occupy the same orbital (so called, paired electrons) cancel each other out.\nThe chemical bond between atoms occurs as a result of electromagnetic interactions, as described by the laws of quantum mechanics. The strongest bonds are formed by the sharing or transfer of electrons between atoms, allowing the formation of molecules. Within a molecule, electrons move under the influence of several nuclei, and occupy molecular orbitals; much as they can occupy atomic orbitals in isolated atoms. A fundamental factor in these molecular structures is the existence of electron pairs. These are electrons with opposed spins, allowing them to occupy the same molecular orbital without violating the Pauli exclusion principle (much like in atoms). Different molecular orbitals have different spatial distribution of the electron density. For instance, in bonded pairs (i.e. in the pairs that actually bind atoms together) electrons can be found with the maximal probability in a relatively small volume between the nuclei. By contrast, in non-bonded pairs electrons are distributed in a large volume around nuclei.\nConductivity.\nIf a body has more or fewer electrons than are required to balance the positive charge of the nuclei, then that object has a net electric charge. When there is an excess of electrons, the object is said to be negatively charged. When there are fewer electrons than the number of protons in nuclei, the object is said to be positively charged. When the number of electrons and the number of protons are equal, their charges cancel each other and the object is said to be electrically neutral. A macroscopic body can develop an electric charge through rubbing, by the triboelectric effect.\nIndependent electrons moving in vacuum are termed \"free\" electrons. Electrons in metals also behave as if they were free. In reality the particles that are commonly termed electrons in metals and other solids are quasi-electrons\u2014quasiparticles, which have the same electrical charge, spin, and magnetic moment as real electrons but might have a different mass. When free electrons\u2014both in vacuum and metals\u2014move, they produce a net flow of charge called an electric current, which generates a magnetic field. Likewise a current can be created by a changing magnetic field. These interactions are described mathematically by Maxwell's equations.\nAt a given temperature, each material has an electrical conductivity that determines the value of electric current when an electric potential is applied. Examples of good conductors include metals such as copper and gold, whereas glass and Teflon are poor conductors. In any dielectric material, the electrons remain bound to their respective atoms and the material behaves as an insulator. Most semiconductors have a variable level of conductivity that lies between the extremes of conduction and insulation. On the other hand, metals have an electronic band structure containing partially filled electronic bands. The presence of such bands allows electrons in metals to behave as if they were free or delocalized electrons. These electrons are not associated with specific atoms, so when an electric field is applied, they are free to move like a gas (called Fermi gas) through the material much like free electrons.\nBecause of collisions between electrons and atoms, the drift velocity of electrons in a conductor is on the order of millimeters per second. However, the speed at which a change of current at one point in the material causes changes in currents in other parts of the material, the velocity of propagation, is typically about 75% of light speed. This occurs because electrical signals propagate as a wave, with the velocity dependent on the dielectric constant of the material.\nMetals make relatively good conductors of heat, primarily because the delocalized electrons are free to transport thermal energy between atoms. However, unlike electrical conductivity, the thermal conductivity of a metal is nearly independent of temperature. This is expressed mathematically by the Wiedemann\u2013Franz law, which states that the ratio of thermal conductivity to the electrical conductivity is proportional to the temperature. The thermal disorder in the metallic lattice increases the electrical resistivity of the material, producing a temperature dependence for electric current.\nWhen cooled below a point called the critical temperature, materials can undergo a phase transition in which they lose all resistivity to electric current, in a process known as superconductivity. In BCS theory, pairs of electrons called Cooper pairs have their motion coupled to nearby matter via lattice vibrations called phonons, thereby avoiding the collisions with atoms that normally create electrical resistance. (Cooper pairs have a radius of roughly 100\u00a0nm, so they can overlap each other.) However, the mechanism by which higher temperature superconductors operate remains uncertain.\nElectrons inside conducting solids, which are quasi-particles themselves, when tightly confined at temperatures close to absolute zero, behave as though they had split into three other quasiparticles: spinons, orbitons and holons. The former carries spin and magnetic moment, the next carries its orbital location while the latter electrical charge.\nMotion and energy.\nAccording to Einstein's theory of special relativity, as an electron's speed approaches the speed of light, from an observer's point of view its relativistic mass increases, thereby making it more and more difficult to accelerate it from within the observer's frame of reference. The speed of an electron can approach, but never reach, the speed of light in vacuum, \"c\". However, when relativistic electrons\u2014that is, electrons moving at a speed close to \"c\"\u2014are injected into a dielectric medium such as water, where the local speed of light is significantly less than \"c\", the electrons temporarily travel faster than light in the medium. As they interact with the medium, they generate a faint light called Cherenkov radiation.\nThe effects of special relativity are based on a quantity known as the Lorentz factor, defined as formula_1 where \"v\" is the speed of the particle. The kinetic energy \"K\"e of an electron moving with velocity \"v\" is:\nformula_2\nwhere \"m\"e is the mass of electron. For example, the Stanford linear accelerator can accelerate an electron to roughly 51\u00a0GeV.\nSince an electron behaves as a wave, at a given velocity it has a characteristic de Broglie wavelength. This is given by \"\u03bb\"e\u00a0=\u00a0\"h\"/\"p\" where \"h\" is the Planck constant and \"p\" is the momentum. For the 51\u00a0GeV electron above, the wavelength is about , small enough to explore structures well below the size of an atomic nucleus.\nFormation.\nThe Big Bang theory is the most widely accepted scientific theory to explain the early stages in the evolution of the Universe. For the first millisecond of the Big Bang, the temperatures were over 10\u00a0billion\u00a0kelvins and photons had mean energies over a million electronvolts. These photons were sufficiently energetic that they could react with each other to form pairs of electrons and positrons. Likewise, positron-electron pairs annihilated each other and emitted energetic photons:\nAn equilibrium between electrons, positrons and photons was maintained during this phase of the evolution of the Universe. After 15 seconds had passed, however, the temperature of the universe dropped below the threshold where electron-positron formation could occur. Most of the surviving electrons and positrons annihilated each other, releasing gamma radiation that briefly reheated the universe.\nFor reasons that remain uncertain, during the annihilation process there was an excess in the number of particles over antiparticles. Hence, about one electron for every billion electron-positron pairs survived. This excess matched the excess of protons over antiprotons, in a condition known as baryon asymmetry, resulting in a net charge of zero for the universe. The surviving protons and neutrons began to participate in reactions with each other\u2014in the process known as nucleosynthesis, forming isotopes of hydrogen and helium, with trace amounts of lithium. This process peaked after about five minutes. Any leftover neutrons underwent negative beta decay with a half-life of about a thousand seconds, releasing a proton and electron in the process,\nFor about the next \u2013, the excess electrons remained too energetic to bind with atomic nuclei. What followed is a period known as recombination, when neutral atoms were formed and the expanding universe became transparent to radiation.\nRoughly one million years after the big bang, the first generation of stars began to form. Within a star, stellar nucleosynthesis results in the production of positrons from the fusion of atomic nuclei. These antimatter particles immediately annihilate with electrons, releasing gamma rays. The net result is a steady reduction in the number of electrons, and a matching increase in the number of neutrons. However, the process of stellar evolution can result in the synthesis of radioactive isotopes. Selected isotopes can subsequently undergo negative beta decay, emitting an electron and antineutrino from the nucleus. An example is the cobalt-60 (60Co) isotope, which decays to form nickel-60 (Ni).\nAt the end of its lifetime, a star with more than about 20 solar masses can undergo gravitational collapse to form a black hole. According to classical physics, these massive stellar objects exert a gravitational attraction that is strong enough to prevent anything, even electromagnetic radiation, from escaping past the Schwarzschild radius. However, quantum mechanical effects are believed to potentially allow the emission of Hawking radiation at this distance. Electrons (and positrons) are thought to be created at the event horizon of these stellar remnants.\nWhen a pair of virtual particles (such as an electron and positron) is created in the vicinity of the event horizon, random spatial positioning might result in one of them to appear on the exterior; this process is called quantum tunnelling. The gravitational potential of the black hole can then supply the energy that transforms this virtual particle into a real particle, allowing it to radiate away into space. In exchange, the other member of the pair is given negative energy, which results in a net loss of mass-energy by the black hole. The rate of Hawking radiation increases with decreasing mass, eventually causing the black hole to evaporate away until, finally, it explodes.\nCosmic rays are particles traveling through space with high energies. Energy events as high as have been recorded. When these particles collide with nucleons in the Earth's atmosphere, a shower of particles is generated, including pions. More than half of the cosmic radiation observed from the Earth's surface consists of muons. The particle called a muon is a lepton produced in the upper atmosphere by the decay of a pion.\nA muon, in turn, can decay to form an electron or positron.\nObservation.\nRemote observation of electrons requires detection of their radiated energy. For example, in high-energy environments such as the corona of a star, free electrons form a plasma that radiates energy due to Bremsstrahlung radiation. Electron gas can undergo plasma oscillation, which is waves caused by synchronized variations in electron density, and these produce energy emissions that can be detected by using radio telescopes.\nThe frequency of a photon is proportional to its energy. As a bound electron transitions between different energy levels of an atom, it absorbs or emits photons at characteristic frequencies. For instance, when atoms are irradiated by a source with a broad spectrum, distinct dark lines appear in the spectrum of transmitted radiation in places where the corresponding frequency is absorbed by the atom's electrons. Each element or molecule displays a characteristic set of spectral lines, such as the hydrogen spectral series. When detected, spectroscopic measurements of the strength and width of these lines allow the composition and physical properties of a substance to be determined.\nIn laboratory conditions, the interactions of individual electrons can be observed by means of particle detectors, which allow measurement of specific properties such as energy, spin and charge. The development of the Paul trap and Penning trap allows charged particles to be contained within a small region for long durations. This enables precise measurements of the particle properties. For example, in one instance a Penning trap was used to contain a single electron for a period of 10 months. The magnetic moment of the electron was measured to a precision of eleven digits, which, in 1980, was a greater accuracy than for any other physical constant.\nThe first video images of an electron's energy distribution were captured by a team at Lund University in Sweden, February 2008. The scientists used extremely short flashes of light, called attosecond pulses, which allowed an electron's motion to be observed for the first time.\nThe distribution of the electrons in solid materials can be visualized by angle-resolved photoemission spectroscopy (ARPES). This technique employs the photoelectric effect to measure the reciprocal space\u2014a mathematical representation of periodic structures that is used to infer the original structure. ARPES can be used to determine the direction, speed and scattering of electrons within the material.\nPlasma applications.\nParticle beams.\nElectron beams are used in welding. They allow energy densities up to across a narrow focus diameter of 0.1\u20131.3 mm and usually require no filler material. This welding technique must be performed in a vacuum to prevent the electrons from interacting with the gas before reaching their target, and it can be used to join conductive materials that would otherwise be considered unsuitable for welding.\nElectron-beam lithography (EBL) is a method of etching semiconductors at resolutions smaller than a micrometer. This technique is limited by high costs, slow performance, the need to operate the beam in the vacuum and the tendency of the electrons to scatter in solids. The last problem limits the resolution to about 10\u00a0nm. For this reason, EBL is primarily used for the production of small numbers of specialized integrated circuits.\nElectron beam processing is used to irradiate materials in order to change their physical properties or sterilize medical and food products. Electron beams fluidise or quasi-melt glasses without significant increase of temperature on intensive irradiation: e.g. intensive electron radiation causes a many orders of magnitude decrease of viscosity and stepwise decrease of its activation energy.\nLinear particle accelerators generate electron beams for treatment of superficial tumors in radiation therapy. Electron therapy can treat such skin lesions as basal-cell carcinomas because an electron beam only penetrates to a limited depth before being absorbed, typically up to 5\u00a0cm for electron energies in the range 5\u201320\u00a0MeV. An electron beam can be used to supplement the treatment of areas that have been irradiated by X-rays.\nParticle accelerators use electric fields to propel electrons and their antiparticles to high energies. These particles emit synchrotron radiation as they pass through magnetic fields. The dependency of the intensity of this radiation upon spin polarizes the electron beam\u2014a process known as the Sokolov\u2013Ternov effect. Polarized electron beams can be useful for various experiments. Synchrotron radiation can also cool the electron beams to reduce the momentum spread of the particles. Electron and positron beams are collided upon the particles' accelerating to the required energies; particle detectors observe the resulting energy emissions, which particle physics studies .\nImaging.\nLow-energy electron diffraction (LEED) is a method of bombarding a crystalline material with a collimated beam of electrons and then observing the resulting diffraction patterns to determine the structure of the material. The required energy of the electrons is typically in the range 20\u2013200\u00a0eV. The reflection high-energy electron diffraction (RHEED) technique uses the reflection of a beam of electrons fired at various low angles to characterize the surface of crystalline materials. The beam energy is typically in the range 8\u201320\u00a0keV and the angle of incidence is 1\u20134\u00b0.\nThe electron microscope directs a focused beam of electrons at a specimen. Some electrons change their properties, such as movement direction, angle, and relative phase and energy as the beam interacts with the material. Microscopists can record these changes in the electron beam to produce atomically resolved images of the material. In blue light, conventional optical microscopes have a diffraction-limited resolution of about 200\u00a0nm. By comparison, electron microscopes are limited by the de Broglie wavelength of the electron. This wavelength, for example, is equal to 0.0037\u00a0nm for electrons accelerated across a 100,000-volt potential. The Transmission Electron Aberration-Corrected Microscope is capable of sub-0.05\u00a0nm resolution, which is more than enough to resolve individual atoms. This capability makes the electron microscope a useful laboratory instrument for high resolution imaging. However, electron microscopes are expensive instruments that are costly to maintain.\nTwo main types of electron microscopes exist: transmission and scanning. Transmission electron microscopes function like overhead projectors, with a beam of electrons passing through a slice of material then being projected by lenses on a photographic slide or a charge-coupled device. Scanning electron microscopes rasteri a finely focused electron beam, as in a TV set, across the studied sample to produce the image. Magnifications range from 100\u00d7 to 1,000,000\u00d7 or higher for both microscope types. The scanning tunneling microscope uses quantum tunneling of electrons from a sharp metal tip into the studied material and can produce atomically resolved images of its surface.\nOther applications.\nIn the free-electron laser (FEL), a relativistic electron beam passes through a pair of undulators that contain arrays of dipole magnets whose fields point in alternating directions. The electrons emit synchrotron radiation that coherently interacts with the same electrons to strongly amplify the radiation field at the resonance frequency. FEL can emit a coherent high-brilliance electromagnetic radiation with a wide range of frequencies, from microwaves to soft X-rays. These devices are used in manufacturing, communication, and in medical applications, such as soft tissue surgery.\nElectrons are important in cathode-ray tubes, which have been extensively used as display devices in laboratory instruments, computer monitors and television sets. In a photomultiplier tube, every photon striking the photocathode initiates an avalanche of electrons that produces a detectable current pulse. Vacuum tubes use the flow of electrons to manipulate electrical signals, and they played a critical role in the development of electronics technology. However, they have been largely supplanted by solid-state devices such as the transistor.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9477", "revid": "24315734", "url": "https://en.wikipedia.org/wiki?curid=9477", "title": "Europium", "text": "Chemical element, symbol Eu and atomic number 63\nEuropium is a chemical element with the symbol Eu and atomic number 63. Europium is a silvery-white metal of the lanthanide series that reacts readily with air to form a dark oxide coating. It is the most chemically reactive, least dense, and softest of the lanthanide elements. It is soft enough to be cut with a knife. Europium was isolated in 1901 and named after the continent of Europe. Europium usually assumes the oxidation state +3, like other members of the lanthanide series, but compounds having oxidation state +2 are also common. All europium compounds with oxidation state +2 are slightly reducing. Europium has no significant biological role and is relatively non-toxic compared to other heavy metals. Most applications of europium exploit the phosphorescence of europium compounds. Europium is one of the rarest of the rare-earth elements on Earth.\nCharacteristics.\nPhysical properties.\nEuropium is a ductile metal with a hardness similar to that of lead. It crystallizes in a body-centered cubic lattice. Some properties of europium are strongly influenced by its half-filled electron shell. Europium has the second lowest melting point and the lowest density of all lanthanides.\nEuropium has been claimed to become a superconductor when it is cooled below 1.8 K and compressed to above 80 GPa. However the experimental evidence on which this claim is based has been challenged, and the paper reporting superconductivity has been subsequently retracted. If it becomes a superconductor this is believed to occur because europium is divalent in the metallic state, and is converted into the trivalent state by the applied pressure. In the divalent state, the strong local magnetic moment (arising from total electronic angular momentum \"J\" = 7/2) suppresses the superconductivity, which is induced by eliminating this local moment (\"J\" = 0 in Eu3+).\nChemical properties.\nEuropium is the most reactive rare-earth element. It rapidly oxidizes in air, so that bulk oxidation of a centimeter-sized sample occurs within several days. Its reactivity with water is comparable to that of calcium, and the reaction is\n2 Eu + 6 H2O \u2192 2 Eu(OH)3 + 3 H2\nBecause of the high reactivity, samples of solid europium rarely have the shiny appearance of the fresh metal, even when coated with a protective layer of mineral oil. Europium ignites in air at 150 to 180\u00a0\u00b0C to form europium(III) oxide:\n4 Eu + 3 O2 \u2192 2 Eu2O3\nEuropium dissolves readily in dilute sulfuric acid to form pale pink solutions of [Eu(H2O)9]3+:\n2 Eu + 3 H2SO4 + 18 H2O \u2192 2 [Eu(H2O)9]3+ + 3 SO42\u2212 + 3 H2\nEu(II) vs. Eu(III).\nAlthough usually trivalent, europium readily forms divalent compounds. This behavior is unusual for most lanthanides, which almost exclusively form compounds with an oxidation state of +3. The +2 state has an electron configuration 4\"f\"7 because the half-filled \"f\"-shell provides more stability. In terms of size and coordination number, europium(II) and barium(II) are similar. The sulfates of both barium and europium(II) are also highly insoluble in water. Divalent europium is a mild reducing agent, oxidizing in air to form Eu(III) compounds. In anaerobic, and particularly geothermal conditions, the divalent form is sufficiently stable that it tends to be incorporated into minerals of calcium and the other alkaline earths. This ion-exchange process is the basis of the \"negative europium anomaly\", the low europium content in many lanthanide minerals such as monazite, relative to the chondritic abundance. Bastn\u00e4site tends to show less of a negative europium anomaly than does monazite, and hence is the major source of europium today. The development of easy methods to separate divalent europium from the other (trivalent) lanthanides made europium accessible even when present in low concentration, as it usually is.\nIsotopes.\nNaturally occurring europium is composed of two isotopes, 151Eu and 153Eu, which occur in almost equal proportions; 153Eu is slightly more abundant (52.2% natural abundance). While 153Eu is stable, 151Eu was found to be unstable to alpha decay with a half-life of in 2007, giving about one alpha decay per two minutes in every kilogram of natural europium. This value is in reasonable agreement with theoretical predictions. Besides the natural radioisotope 151Eu, 35 artificial radioisotopes have been characterized, the most stable being 150Eu with a half-life of 36.9 years, 152Eu with a half-life of 13.516 years, and 154Eu with a half-life of 8.593 years. All the remaining radioactive isotopes have half-lives shorter than 4.7612 years, and the majority of these have half-lives shorter than 12.2 seconds; the known isotopes of europium range from 130Eu to 170Eu. This element also has 17 meta states, with the most stable being 150mEu (\"t\"1/2=12.8 hours), 152m1Eu (\"t\"1/2=9.3116 hours) and 152m2Eu (\"t\"1/2=96 minutes).\nThe primary decay mode for isotopes lighter than 153Eu is electron capture, and the primary mode for heavier isotopes is beta minus decay. The primary decay products before 153Eu are isotopes of samarium (Sm) and the primary products after are isotopes of gadolinium (Gd).\nEuropium as a nuclear fission product.\nEuropium is produced by nuclear fission, but the fission product yields of europium isotopes are low near the top of the mass range for fission products.\nAs with other lanthanides, many isotopes of europium, especially those that have odd mass numbers or are neutron-poor like 152Eu, have high cross sections for neutron capture, often high enough to be neutron poisons.\n151Eu is the beta decay product of samarium-151, but since this has a long decay half-life and short mean time to neutron absorption, most 151Sm instead ends up as 152Sm.\n152Eu (half-life 13.516 years) and 154Eu (half-life 8.593 years) cannot be beta decay products because 152Sm and 154Sm are non-radioactive, but 154Eu is the only long-lived \"shielded\" nuclide, other than 134Cs, to have a fission yield of more than 2.5 parts per million fissions. A larger amount of 154Eu is produced by neutron activation of a significant portion of the non-radioactive 153Eu; however, much of this is further converted to 155Eu.\n155Eu (half-life 4.7612 years) has a fission yield of 330 parts per million (ppm) for uranium-235 and thermal neutrons; most of it is transmuted to non-radioactive and nonabsorptive gadolinium-156 by the end of fuel burnup.\nOverall, europium is overshadowed by caesium-137 and strontium-90 as a radiation hazard, and by samarium and others as a neutron poison.\nOccurrence.\nEuropium is not found in nature as a free element. Many minerals contain europium, with the most important sources being bastn\u00e4site, monazite, xenotime and loparite-(Ce). No europium-dominant minerals are known yet, despite a single find of a tiny possible Eu\u2013O or Eu\u2013O\u2013C system phase in the Moon's regolith.\nDepletion or enrichment of europium in minerals relative to other rare-earth elements is known as the europium anomaly. Europium is commonly included in trace element studies in geochemistry and petrology to understand the processes that form igneous rocks (rocks that cooled from magma or lava). The nature of the europium anomaly found helps reconstruct the relationships within a suite of igneous rocks. The average crustal abundance of europium is 2\u20132.2 ppm.\nDivalent europium (Eu2+) in small amounts is the activator of the bright blue fluorescence of some samples of the mineral fluorite (CaF2). The reduction from Eu3+ to Eu2+ is induced by irradiation with energetic particles. The most outstanding examples of this originated around Weardale and adjacent parts of northern England; it was the fluorite found here that fluorescence was named after in 1852, although it was not until much later that europium was determined to be the cause.\nIn astrophysics, the signature of europium in stellar spectra can be used to classify stars and inform theories of how or where a particular star was born. For instance, astronomers in 2019 identified higher-than-expected levels of europium within the star J1124+4535, hypothesizing that this star originated in a dwarf galaxy that collided with the Milky Way billions of years ago.\nProduction.\nEuropium is associated with the other rare-earth elements and is, therefore, mined together with them. Separation of the rare-earth elements occurs during later processing. Rare-earth elements are found in the minerals bastn\u00e4site, loparite-(Ce), xenotime, and monazite in mineable quantities. Bastn\u00e4site is a group of related fluorocarbonates, Ln(CO3)(F,OH). Monazite is a group of related of orthophosphate minerals LnPO4 (Ln denotes a mixture of all the lanthanides except promethium), loparite-(Ce) is an oxide, and xenotime is an orthophosphate (Y,Yb,Er...)PO4. Monazite also contains thorium and yttrium, which complicates handling because thorium and its decay products are radioactive. For the extraction from the ore and the isolation of individual lanthanides, several methods have been developed. The choice of method is based on the concentration and composition of the ore and on the distribution of the individual lanthanides in the resulting concentrate. Roasting the ore, followed by acidic and basic leaching, is used mostly to produce a concentrate of lanthanides. If cerium is the dominant lanthanide, then it is converted from cerium(III) to cerium(IV) and then precipitated. Further separation by solvent extractions or ion exchange chromatography yields a fraction which is enriched in europium. This fraction is reduced with zinc, zinc/amalgam, electrolysis or other methods converting the europium(III) to europium(II). Europium(II) reacts in a way similar to that of alkaline earth metals and therefore it can be precipitated as a carbonate or co-precipitated with barium sulfate. Europium metal is available through the electrolysis of a mixture of molten EuCl3 and NaCl (or CaCl2) in a graphite cell, which serves as cathode, using graphite as anode. The other product is chlorine gas.\nA few large deposits produce or produced a significant amount of the world production. The Bayan Obo iron ore deposit in Inner Mongolia contains significant amounts of bastn\u00e4site and monazite and is, with an estimated 36 million tonnes of rare-earth element oxides, the largest known deposit. The mining operations at the Bayan Obo deposit made China the largest supplier of rare-earth elements in the 1990s. Only 0.2% of the rare-earth element content is europium. The second large source for rare-earth elements between 1965 and its closure in the late 1990s was the Mountain Pass rare earth mine in California. The bastn\u00e4site mined there is especially rich in the light rare-earth elements (La-Gd, Sc, and Y) and contains only 0.1% of europium. Another large source for rare-earth elements is the loparite found on the Kola peninsula. It contains besides niobium, tantalum and titanium up to 30% rare-earth elements and is the largest source for these elements in Russia.\nCompounds.\nEuropium compounds tend to exist in a trivalent oxidation state under most conditions. Commonly these compounds feature Eu(III) bound by 6\u20139 oxygenic ligands. The Eu(III) sulfates, nitrates and chlorides are soluble in water or polar organic solvents. Lipophilic europium complexes often feature acetylacetonate-like ligands, such as EuFOD.\nHalides.\nEuropium metal reacts with all the halogens:\n2 Eu + 3 X2 \u2192 2 EuX3 (X = F, Cl, Br, I)\nThis route gives white europium(III) fluoride (EuF3), yellow europium(III) chloride (EuCl3), gray europium(III) bromide (EuBr3), and colorless europium(III) iodide (EuI3). Europium also forms the corresponding dihalides: yellow-green europium(II) fluoride (EuF2), colorless europium(II) chloride (EuCl2) (although it has a bright blue fluorescence under UV light), colorless europium(II) bromide (EuBr2), and green europium(II) iodide (EuI2).\nChalcogenides and pnictides.\nEuropium forms stable compounds with all of the chalcogens, but the heavier chalcogens (S, Se, and Te) stabilize the lower oxidation state. Three oxides are known: europium(II) oxide (EuO), europium(III) oxide (Eu2O3), and the mixed-valence oxide Eu3O4, consisting of both Eu(II) and Eu(III). Otherwise, the main chalcogenides are europium(II) sulfide (EuS), europium(II) selenide (EuSe) and europium(II) telluride (EuTe): all three of these are black solids. Europium(II) sulfide is prepared by sulfiding the oxide at temperatures sufficiently high to decompose the Eu2O3:\nEu2O3 + 3 H2S \u2192 2 EuS + 3 H2O + S\nThe main nitride of europium is europium(III) nitride (EuN).\nHistory.\nAlthough europium is present in most of the minerals containing the other rare elements, due to the difficulties in separating the elements it was not until the late 1800s that the element was isolated. William Crookes observed the phosphorescent spectra of the rare elements including those eventually assigned to europium.\nEuropium was first found in 1892 by Paul \u00c9mile Lecoq de Boisbaudran, who obtained basic fractions from samarium-gadolinium concentrates which had spectral lines not accounted for by samarium or gadolinium. However, the discovery of europium is generally credited to French chemist Eug\u00e8ne-Anatole Demar\u00e7ay, who suspected samples of the recently discovered element samarium were contaminated with an unknown element in 1896 and who was able to isolate it in 1901; he then named it \"europium\".\nWhen the europium-doped yttrium orthovanadate red phosphor was discovered in the early 1960s, and understood to be about to cause a revolution in the color television industry, there was a scramble for the limited supply of europium on hand among the monazite processors, as the typical europium content in monazite is about 0.05%. However, the Molycorp bastn\u00e4site deposit at the Mountain Pass rare earth mine, California, whose lanthanides had an unusually high europium content of 0.1%, was about to come on-line and provide sufficient europium to sustain the industry. Prior to europium, the color-TV red phosphor was very weak, and the other phosphor colors had to be muted, to maintain color balance. With the brilliant red europium phosphor, it was no longer necessary to mute the other colors, and a much brighter color TV picture was the result. Europium has continued to be in use in the TV industry ever since as well as in computer monitors. Californian bastn\u00e4site now faces stiff competition from Bayan Obo, China, with an even \"richer\" europium content of 0.2%.\nFrank Spedding, celebrated for his development of the ion-exchange technology that revolutionized the rare-earth industry in the mid-1950s, once related the story of how he was lecturing on the rare earths in the 1930s, when an elderly gentleman approached him with an offer of a gift of several pounds of europium oxide. This was an unheard-of quantity at the time, and Spedding did not take the man seriously. However, a package duly arrived in the mail, containing several pounds of genuine europium oxide. The elderly gentleman had turned out to be Herbert Newby McCoy, who had developed a famous method of europium purification involving redox chemistry.\nApplications.\nRelative to most other elements, commercial applications for europium are few and rather specialized. Almost invariably, its phosphorescence is exploited, either in the +2 or +3 oxidation state.\nIt is a dopant in some types of glass in lasers and other optoelectronic devices. Europium oxide (Eu2O3) is widely used as a red phosphor in television sets and fluorescent lamps, and as an activator for yttrium-based phosphors. Color TV screens contain between 0.5 and 1\u00a0g of europium oxide. Whereas trivalent europium gives red phosphors, the luminescence of divalent europium depends strongly on the composition of the host structure. UV to deep red luminescence can be achieved. The two classes of europium-based phosphor (red and blue), combined with the yellow/green terbium phosphors give \"white\" light, the color temperature of which can be varied by altering the proportion or specific composition of the individual phosphors. This phosphor system is typically encountered in helical fluorescent light bulbs. Combining the same three classes is one way to make trichromatic systems in TV and computer screens, but as an additive, it can be particularly effective in improving the intensity of red phosphor. Europium is also used in the manufacture of fluorescent glass, increasing the general efficiency of fluorescent lamps. One of the more common persistent after-glow phosphors besides copper-doped zinc sulfide is europium-doped strontium aluminate. Europium fluorescence is used to interrogate biomolecular interactions in drug-discovery screens. It is also used in the anti-counterfeiting phosphors in euro banknotes.\nAn application that has almost fallen out of use with the introduction of affordable superconducting magnets is the use of europium complexes, such as Eu(fod)3, as shift reagents in NMR spectroscopy. Chiral shift reagents, such as Eu(hfc)3, are still used to determine enantiomeric purity.\nPrecautions.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nThere are no clear indications that europium is particularly toxic compared to other heavy metals. Europium chloride, nitrate and oxide have been tested for toxicity: europium chloride shows an acute intraperitoneal LD50 toxicity of 550\u00a0mg/kg and the acute oral LD50 toxicity is 5000\u00a0mg/kg. Europium nitrate shows a slightly higher intraperitoneal LD50 toxicity of 320\u00a0mg/kg, while the oral toxicity is above 5000\u00a0mg/kg. The metal dust presents a fire and explosion hazard.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9478", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=9478", "title": "Erbium", "text": "Chemical element, symbol Er and atomic number 68\nErbium is a chemical element with the symbol Er and atomic number 68. A silvery-white solid metal when artificially isolated, natural erbium is always found in chemical combination with other elements. It is a lanthanide, a rare-earth element, originally found in the gadolinite mine in Ytterby, Sweden, which is the source of the element's name.\nErbium's principal uses involve its pink-colored Er3+ ions, which have optical fluorescent properties particularly useful in certain laser applications. Erbium-doped glasses or crystals can be used as optical amplification media, where Er3+ ions are optically pumped at around 980 or and then radiate light at in stimulated emission. This process results in an unusually mechanically simple laser optical amplifier for signals transmitted by fiber optics. The wavelength is especially important for optical communications because standard single mode optical fibers have minimal loss at this particular wavelength.\nIn addition to optical fiber amplifier-lasers, a large variety of medical applications (i.e. dermatology, dentistry) rely on the erbium ion's emission (see ) when lit at another wavelength, which is highly absorbed in water in tissues, making its effect very superficial. Such shallow tissue deposition of laser energy is helpful in laser surgery, and for the efficient production of steam which produces enamel ablation by common types of dental laser.\nCharacteristics.\nPhysical properties.\nA trivalent element, pure erbium metal is malleable (or easily shaped), soft yet stable in air, and does not oxidize as quickly as some other rare-earth metals. Its salts are rose-colored, and the element has characteristic sharp absorption spectra bands in visible light, ultraviolet, and near infrared. Otherwise it looks much like the other rare earths. Its sesquioxide is called erbia. Erbium's properties are to a degree dictated by the kind and amount of impurities present. Erbium does not play any known biological role, but is thought to be able to stimulate metabolism.\nErbium is ferromagnetic below 19\u00a0K, antiferromagnetic between 19 and 80 K and paramagnetic above 80\u00a0K.\nErbium can form propeller-shaped atomic clusters Er3N, where the distance between the erbium atoms is 0.35\u00a0nm. Those clusters can be isolated by encapsulating them into fullerene molecules, as confirmed by transmission electron microscopy.\nLike most rare-earth elements, erbium is usually found in the +3 oxidation state. However, it is possible for erbium to also be found in the 0, +1 and +2 oxidation states.\nChemical properties.\nErbium metal retains its luster in dry air, however will tarnish slowly in moist air and burns readily to form erbium(III) oxide:\n4 Er + 3 O2 \u2192 2 Er2O3\nErbium is quite electropositive and reacts slowly with cold water and quite quickly with hot water to form erbium hydroxide:\n2 Er (s) + 6 H2O (l) \u2192 2 Er(OH)3 (aq) + 3 H2 (g)\nErbium metal reacts with all the halogens:\n2 Er (s) + 3 F2 (g) \u2192 2 ErF3 (s) [pink]\n2 Er (s) + 3 Cl2 (g) \u2192 2 ErCl3 (s) [violet]\n2 Er (s) + 3 Br2 (g) \u2192 2 ErBr3 (s) [violet]\n2 Er (s) + 3 I2 (g) \u2192 2 ErI3 (s) [violet]\nErbium dissolves readily in dilute sulfuric acid to form solutions containing hydrated Er(III) ions, which exist as rose red [Er(OH2)9]3+ hydration complexes:\n2 Er (s) + 3 H2SO4 (aq) \u2192 2 Er3+ (aq) + 3 SO42- (aq) + 3 H2 (g)\nIsotopes.\nNaturally occurring erbium is composed of 6 stable isotopes, Er, Er, Er, Er, Er, and Er, with Er being the most abundant (33.503% natural abundance). 29 radioisotopes have been characterized, with the most stable being Er with a half-life of , Er with a half-life of , Er with a half-life of , Er with a half-life of , and Er with a half-life of . All of the remaining radioactive isotopes have half-lives that are less than , and the majority of these have half-lives that are less than 4 minutes. This element also has 13 meta states, with the most stable being Er with a half-life of .\nThe isotopes of erbium range in atomic weight from (Er) to (Er). The primary decay mode before the most abundant stable isotope, Er, is electron capture, and the primary mode after is beta decay. The primary decay products before Er are element 67 (holmium) isotopes, and the primary products after are element 69 (thulium) isotopes.\nCompounds.\nOxides.\nErbium(III) oxide (also known as erbia) is the only known oxide of erbium, first isolated by Carl Gustaf Mosander in 1843, and first obtained in pure form in 1905 by Georges Urbain and Charles James. It has a cubic structure resembling the bixbyite motif. The Er3+ centers are octahedral. The formation of erbium oxide is accomplished by burning erbium metal. Erbium oxide is insoluble in water and soluble in mineral acids.\nHalides.\nErbium(III) fluoride is a pinkish powder that can be produced by reacting erbium(III) nitrate and ammonium fluoride. It can be used to make infrared light-transmitting materials and up-converting luminescent materials. Erbium(III) chloride is a violet compounds that can be formed by first heating erbium(III) oxide and ammonium chloride to prouce the ammonium salt of the pentachloride ([NH4]2ErCl5) then heating it in a vacuum at 350-400 \u00b0C. It forms crystals of the type, with monoclinic crystals and the point group \"C\"2/m. Erbium(III) chloride hexahydrate also forms monoclinic crystals with the point group of \"P\"2/\"n\" (\"P\"2/\"c\") - \"C\"42h. In this compound, erbium is octa-coordinated to form ions with the isolated completing the structure.\nErbium(III) bromide is a violet solid. It is used, like other metal bromide compounds, in water treatment, chemical analysis and for certain crystal growth applications. Erbium(III) iodide is a slightly pink compound that is insoluble in water. It can be prepared by directly reacting erbium with iodine.\nOrganoerbium compounds.\nOrganoerbium compounds are very similar to those of the other lanthanides, as they all share an inability to undergo \u03c0 backbonding. They are thus mostly restricted to the mostly ionic cyclopentadienides (isostructural with those of lanthanum) and the \u03c3-bonded simple alkyls and aryls, some of which may be polymeric.\nHistory.\nErbium (for Ytterby, a village in Sweden) was discovered by Carl Gustaf Mosander in 1843. Mosander was working with a sample of what was thought to be the single metal oxide yttria, derived from the mineral gadolinite. He discovered that the sample contained at least two metal oxides in addition to pure yttria, which he named \"erbia\" and \"terbia\" after the village of Ytterby where the gadolinite had been found. Mosander was not certain of the purity of the oxides and later tests confirmed his uncertainty. Not only did the \"yttria\" contain yttrium, erbium, and terbium; in the ensuing years, chemists, geologists and spectroscopists discovered five additional elements: ytterbium, scandium, thulium, holmium, and gadolinium.\nErbia and terbia, however, were confused at this time. A spectroscopist mistakenly switched the names of the two elements during spectroscopy. After 1860, terbia was renamed erbia and after 1877 what had been known as erbia was renamed terbia. Fairly pure Er2O3 was independently isolated in 1905 by Georges Urbain and Charles James. Reasonably pure erbium metal was not produced until 1934 when Wilhelm Klemm and Heinrich Bommer reduced the anhydrous chloride with potassium vapor. It was only in the 1990s that the price for Chinese-derived erbium oxide became low enough for erbium to be considered for use as a colorant in art glass.\nOccurrence.\nThe concentration of erbium in the Earth crust is about 2.8\u00a0mg/kg and in seawater 0.9\u00a0ng/L. Erbium is the 44th most abundant element in the Earth's crust at about 3.0\u20133.8 ppm.\nLike other rare earths, this element is never found as a free element in nature but is found bound in monazite sand ores. It has historically been very difficult and expensive to separate rare earths from each other in their ores but ion-exchange chromatography methods developed in the late 20th century have greatly brought down the cost of production of all rare-earth metals and their chemical compounds.\nThe principal commercial sources of erbium are from the minerals xenotime and euxenite, and most recently, the ion adsorption clays of southern China; in consequence, China has now become the principal global supplier of this element. In the high-yttrium versions of these ore concentrates, yttrium is about two-thirds of the total by weight, and erbia is about 4\u20135%. When the concentrate is dissolved in acid, the erbia liberates enough erbium ion to impart a distinct and characteristic pink color to the solution. This color behavior is similar to what Mosander and the other early workers in the lanthanides would have seen in their extracts from the gadolinite minerals of Ytterby.\nProduction.\nCrushed minerals are attacked by hydrochloric or sulfuric acid that transforms insoluble rare-earth oxides into soluble chlorides or sulfates. The acidic filtrates are partially neutralized with caustic soda (sodium hydroxide) to pH 3\u20134. Thorium precipitates out of solution as hydroxide and is removed. After that the solution is treated with ammonium oxalate to convert rare earths into their insoluble oxalates. The oxalates are converted to oxides by annealing. The oxides are dissolved in nitric acid that excludes one of the main components, cerium, whose oxide is insoluble in HNO3. The solution is treated with magnesium nitrate to produce a crystallized mixture of double salts of rare-earth metals. The salts are separated by ion exchange. In this process, rare-earth ions are sorbed onto suitable ion-exchange resin by exchange with hydrogen, ammonium or cupric ions present in the resin. The rare earth ions are then selectively washed out by suitable complexing agent. Erbium metal is obtained from its oxide or salts by heating with calcium at under argon atmosphere.\nApplications.\nErbium's everyday uses are varied. It is commonly used as a photographic filter, and because of its resilience it is useful as a metallurgical additive.\nLasers and optics.\nA large variety of medical applications (i.e. dermatology, dentistry) utilize erbium ion's emission (see ), which is highly absorbed in water (absorption coefficient about ). Such shallow tissue deposition of laser energy is necessary for laser surgery, and the efficient production of steam for laser enamel ablation in dentistry.\nErbium-doped optical silica-glass fibers are the active element in erbium-doped fiber amplifiers (EDFAs), which are widely used in optical communications. The same fibers can be used to create fiber lasers. In order to work efficiently, erbium-doped fiber is usually co-doped with glass modifiers/homogenizers, often aluminium or phosphorus. These dopants help prevent clustering of Er ions and transfer the energy more efficiently between excitation light (also known as optical pump) and the signal. Co-doping of optical fiber with Er and Yb is used in high-power Er/Yb fiber lasers. Erbium can also be used in erbium-doped waveguide amplifiers.\nOther applications.\nWhen added to vanadium as an alloy, erbium lowers hardness and improves workability. An erbium-nickel alloy Er3Ni has an unusually high specific heat capacity at liquid-helium temperatures and is used in cryocoolers; a mixture of 65% Er3Co and 35% Er0.9Yb0.1Ni by volume improves the specific heat capacity even more.\nErbium oxide has a pink color, and is sometimes used as a colorant for glass, cubic zirconia and porcelain. The glass is then often used in sunglasses and cheap jewelry.\nErbium is used in nuclear technology in neutron-absorbing control rods. or as a burnable poison in nuclear fuel design. Recently, erbium has been used in experiments related to lattice confinement fusion.\nBiological role and precautions.\nErbium does not have a biological role, but erbium salts can stimulate metabolism. Humans consume 1 milligram of erbium a year on average. The highest concentration of erbium in humans is in the bones, but there is also erbium in the human kidneys and liver. Erbium is slightly toxic if ingested, but erbium compounds are not toxic. Metallic erbium in dust form presents a fire and explosion hazard.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9479", "revid": "31831", "url": "https://en.wikipedia.org/wiki?curid=9479", "title": "Einsteinium", "text": "Chemical element, symbol Es and atomic number 99\nEinsteinium is a synthetic element with the symbol Es and atomic number 99. Einsteinium is a member of the actinide series and it is the seventh transuranium element. It was named in honor of Albert Einstein.\nEinsteinium was discovered as a component of the debris of the first hydrogen bomb explosion in 1952. Its most common isotope, einsteinium-253 (half-life 20.47 days), is produced artificially from decay of californium-253 in a few dedicated high-power nuclear reactors with a total yield on the order of one milligram per year. The reactor synthesis is followed by a complex process of separating einsteinium-253 from other actinides and products of their decay. Other isotopes are synthesized in various laboratories, but in much smaller amounts, by bombarding heavy actinide elements with light ions. Due to the small amounts of produced einsteinium and the short half-life of its most common isotope, there are no practical applications for it except basic scientific research. In particular, einsteinium was used to synthesize, for the first time, 17 atoms of the new element mendelevium in 1955.\nEinsteinium is a soft, silvery, paramagnetic metal. Its chemistry is typical of the late actinides, with a preponderance of the +3 oxidation state; the +2 oxidation state is also accessible, especially in solids. The high radioactivity of einsteinium-253 produces a visible glow and rapidly damages its crystalline metal lattice, with released heat of about 1000 watts per gram. Difficulty in studying its properties is due to einsteinium-253's decay to berkelium-249 and then californium-249 at a rate of about 3% per day. The isotope of einsteinium with the longest half-life, einsteinium-252 (half-life 471.7 days) would be more suitable for investigation of physical properties, but it has proven far more difficult to produce and is available only in minute quantities, and not in bulk. Einsteinium is the element with the highest atomic number which has been observed in macroscopic quantities in its pure form and this was the common short-lived isotope einsteinium-253.\nLike all synthetic transuranium elements, isotopes of einsteinium are very radioactive and are considered highly dangerous to health on ingestion.\nHistory.\nEinsteinium was first identified in December 1952 by Albert Ghiorso and co-workers at the University of California, Berkeley in collaboration with the Argonne and Los Alamos National Laboratories, in the fallout from the \"Ivy Mike\" nuclear test. The test was carried out on November 1, 1952, at Enewetak Atoll in the Pacific Ocean and was the first successful test of a thermonuclear weapon. Initial examination of the debris from the explosion had shown the production of a new isotope of plutonium, Pu, which could only have formed by the absorption of six neutrons by a uranium-238 nucleus followed by two beta decays.\n&lt;chem&gt;^{238}_{92}U -&gt;[\\ce{+ 6(n,\\gamma)}][-2\\ \\beta^-]{} ^{244}_{94}Pu&lt;/chem&gt;\nAt the time, the multiple neutron absorption was thought to be an extremely rare process, but the identification of Pu indicated that still more neutrons could have been captured by the uranium nuclei, thereby producing new elements heavier than californium.\nGhiorso and co-workers analyzed filter papers which had been flown through the explosion cloud on airplanes (the same sampling technique that had been used to discover Pu). Larger amounts of radioactive material were later isolated from coral debris of the atoll, which were delivered to the U.S. The separation of suspected new elements was carried out in the presence of a citric acid/ammonium buffer solution in a weakly acidic medium (pH \u2248 3.5), using ion exchange at elevated temperatures; fewer than 200 atoms of einsteinium were recovered in the end. Nevertheless, element 99 (einsteinium), namely its 253Es isotope, could be detected via its characteristic high-energy alpha decay at 6.6\u00a0MeV. It was produced by the capture of 15 neutrons by uranium-238 nuclei followed by seven beta-decays, and had a half-life of 20.5 days. Such multiple neutron absorption was made possible by the high neutron flux density during the detonation, so that newly generated heavy isotopes had plenty of available neutrons to absorb before they could disintegrate into lighter elements. Neutron capture initially raised the mass number without changing the atomic number of the nuclide, and the concomitant beta-decays resulted in a gradual increase in the atomic number:\n&lt;chem&gt;\n^{238}_{92}U -&gt;[\\ce{+15n}][6 \\beta^-] ^{253}_{98}Cf -&gt;[\\beta^-] ^{253}_{99}Es\n&lt;/chem&gt;\nSome 238U atoms, however, could absorb two additional neutrons (for a total of 17), resulting in 255Es, as well as in the 255Fm isotope of another new element, fermium. The discovery of the new elements and the associated new data on multiple neutron capture were initially kept secret on the orders of the U.S.\u00a0military until 1955 due to Cold War tensions and competition with Soviet Union in nuclear technologies. However, the rapid capture of so many neutrons would provide needed direct experimental confirmation of the so-called r-process multiple neutron absorption needed to explain the cosmic nucleosynthesis (production) of certain heavy chemical elements (heavier than nickel) in supernova explosions, before beta decay. Such a process is needed to explain the existence of many stable elements in the universe.\nMeanwhile, isotopes of element 99 (as well as of new element 100, fermium) were produced in the Berkeley and Argonne laboratories, in a nuclear reaction between nitrogen-14 and uranium-238, and later by intense neutron irradiation of plutonium or californium:\n&lt;chem&gt;^{252}_{98}Cf -&gt;[\\ce{(n,\\gamma)}] ^{253}_{98}Cf -&gt;[\\beta^-][17.81 \\ce{d}] ^{253}_{99}Es -&gt;[\\ce{(n,\\gamma)}] ^{254}_{99}Es -&gt;[\\beta^-] ^{254}_{100}Fm&lt;/chem&gt;\nThese results were published in several articles in 1954 with the disclaimer that these were not the first studies that had been carried out on the elements. The Berkeley team also reported some results on the chemical properties of einsteinium and fermium. The \"Ivy Mike\" results were declassified and published in 1955.\nIn their discovery of the elements 99 and 100, the American teams had competed with a group at the Nobel Institute for Physics, Stockholm, Sweden. In late 1953 \u2013 early 1954, the Swedish group succeeded in the synthesis of light isotopes of element 100, in particular 250Fm, by bombarding uranium with oxygen nuclei. These results were also published in 1954. Nevertheless, the priority of the Berkeley team was generally recognized, as its publications preceded the Swedish article, and they were based on the previously undisclosed results of the 1952 thermonuclear explosion; thus the Berkeley team was given the privilege to name the new elements. As the effort which had led to the design of \"Ivy Mike\" was codenamed Project PANDA, element 99 had been jokingly nicknamed \"Pandemonium\" but the official names suggested by the Berkeley group derived from two prominent scientists, Albert Einstein and Enrico Fermi: \"We suggest for the name for the element with the atomic number 99, einsteinium (symbol E) after Albert Einstein and for the name for the element with atomic number 100, fermium (symbol Fm), after Enrico Fermi.\" Both Einstein and Fermi died between the time the names were originally proposed and when they were announced. The discovery of these new elements was announced by Albert Ghiorso at the first Geneva Atomic Conference held on 8\u201320 August 1955. The symbol for einsteinium was first given as \"E\" and later changed to \"Es\" by IUPAC.\nCharacteristics.\nPhysical.\nEinsteinium is a synthetic, silver, radioactive metal. In the periodic table, it is located to the right of the actinide californium, to the left of the actinide fermium and below the lanthanide holmium with which it shares many similarities in physical and chemical properties. Its density of 8.84\u00a0g/cm3 is lower than that of californium (15.1\u00a0g/cm3) and is nearly the same as that of holmium (8.79\u00a0g/cm3), despite atomic einsteinium being much heavier than holmium. The melting point of einsteinium (860\u00a0\u00b0C) is also relatively low \u2013 below californium (900\u00a0\u00b0C), fermium (1527\u00a0\u00b0C) and holmium (1461\u00a0\u00b0C). Einsteinium is a soft metal, with the bulk modulus of only 15 GPa, which value is one of the lowest among non-alkali metals.\nContrary to the lighter actinides californium, berkelium, curium and americium, which crystallize in a double hexagonal structure at ambient conditions, einsteinium is believed to have a face-centered cubic (\"fcc\") symmetry with the space group \"Fm\"3\"m\" and the lattice constant \"a\" = 575 pm. However, there is a report of room-temperature hexagonal einsteinium metal with \"a\" = 398 pm and \"c\" = 650 pm, which converted to the \"fcc\" phase upon heating to 300\u00a0\u00b0C.\nThe self-damage induced by the radioactivity of einsteinium is so strong that it rapidly destroys the crystal lattice, and the energy release during this process, 1000 watts per gram of 253Es, induces a visible glow. These processes may contribute to the relatively low density and melting point of einsteinium. Further, owing to the small size of the available samples, the melting point of einsteinium was often deduced by observing the sample being heated inside an electron microscope. Thus, the surface effects in small samples could reduce the melting point value.\nThe metal is trivalent and has a noticeably high volatility. In order to reduce the self-radiation damage, most measurements of solid einsteinium and its compounds are performed right after thermal annealing. Also, some compounds are studied under the atmosphere of the reductant gas, for example H2O+HCl for EsOCl so that the sample is partly regrown during its decomposition.\nApart from the self-destruction of solid einsteinium and its compounds, other intrinsic difficulties in studying this element include scarcity \u2013 the most common 253Es isotope is available only once or twice a year in sub-milligram amounts \u2013 and self-contamination due to rapid conversion of einsteinium to berkelium and then to californium at a rate of about 3.3% per day:\n&lt;chem&gt;\n^{253}_{99}Es -&gt;[\\alpha][20 \\ce{d}] ^{249}_{97}Bk -&gt;[\\beta^-][314 \\ce{d}] ^{249}_{98}Cf\n&lt;/chem&gt;\nThus, most einsteinium samples are contaminated, and their intrinsic properties are often deduced by extrapolating back experimental data accumulated over time. Other experimental techniques to circumvent the contamination problem include selective optical excitation of einsteinium ions by a tunable laser, such as in studying its luminescence properties.\nMagnetic properties have been studied for einsteinium metal, its oxide and fluoride. All three materials showed Curie\u2013Weiss paramagnetic behavior from liquid helium to room temperature. The effective magnetic moments were deduced as for Es2O3 and for the EsF3, which are the highest values among actinides, and the corresponding Curie temperatures are 53 and 37 K.\nChemical.\nLike all actinides, einsteinium is rather reactive. Its trivalent oxidation state is most stable in solids and aqueous solution where it induces a pale pink color. The existence of divalent einsteinium is firmly established, especially in the solid phase; such +2 state is not observed in many other actinides, including protactinium, uranium, neptunium, plutonium, curium and berkelium. Einsteinium(II) compounds can be obtained, for example, by reducing einsteinium(III) with samarium(II) chloride. The oxidation state +4 was postulated from vapor studies and is as yet uncertain.\nIsotopes.\nNineteen isotopes and three nuclear isomers are known for einsteinium, with mass numbers ranging from 240 to 257. All are radioactive and the most stable nuclide, 252Es, has a half-life of 471.7 days. The next most stable isotopes are 254Es (half-life 275.7 days), 255Es (39.8 days), and 253Es (20.47 days). All of the remaining isotopes have half-lives shorter than 40 hours, most shorter than 30 minutes. Of the three nuclear isomers, the most stable is 254mEs with a half-life of 39.3 hours.\nNuclear fission.\nEinsteinium has a high rate of nuclear fission that results in a low critical mass for a sustained nuclear chain reaction. This mass is 9.89 kilograms for a bare sphere of 254Es isotope, and can be lowered to 2.9 kilograms by adding a 30-centimeter-thick steel neutron reflector, or even to 2.26 kilograms with a 20-cm-thick reflector made of water. However, even this small critical mass greatly exceeds the total amount of einsteinium isolated thus far, especially of the rare 254Es isotope.\nNatural occurrence.\nBecause of the short half-life of all isotopes of einsteinium, any primordial einsteinium\u2014that is, einsteinium that could have been present on the Earth at its formation\u2014has long since decayed. Synthesis of einsteinium from naturally-occurring actinides uranium and thorium in the Earth's crust requires multiple neutron capture, which is an extremely unlikely event. Therefore, all terrestrial einsteinium is produced in scientific laboratories, high-power nuclear reactors, or in nuclear weapons tests, and exists only within a few years from the time of the synthesis.\nThe transuranic elements from americium to fermium, including einsteinium, were once created in the natural nuclear fission reactor at Oklo, but no longer.\nEinsteinium was theoretically observed in the spectrum of Przybylski's Star. However, the lead author of the studies finding einsteinium and other short-lived actinides in Przybylski's Star, Vera F. Gopka, admitted that \"the position of lines of the radioactive elements under search were simply visualized in synthetic spectrum as vertical markers because there are not any atomic data for these lines except for their wavelengths (Sansonetti et al. 2004), enabling one to calculate their profiles with more or less real intensities.\" The signature spectra of einsteinium's isotopes have since been comprehensively analyzed experimentally (in 2021), though there is no published research confirming whether the theorized einsteinium signatures proposed to be found in the star's spectrum match the lab-determined results.\nSynthesis and extraction.\nEinsteinium is produced in minute quantities by bombarding lighter actinides with neutrons in dedicated high-flux nuclear reactors. The world's major irradiation sources are the 85-megawatt High Flux Isotope Reactor (HFIR) at the Oak Ridge National Laboratory in Tennessee, U.S., and the SM-2 loop reactor at the Research Institute of Atomic Reactors (NIIAR) in Dimitrovgrad, Russia, which are both dedicated to the production of transcurium (\"Z\"\u00a0&gt; 96) elements. These facilities have similar power and flux levels, and are expected to have comparable production capacities for transcurium elements, although the quantities produced at NIIAR are not widely reported. In a \"typical processing campaign\" at Oak Ridge, tens of grams of curium are irradiated to produce decigram quantities of californium, milligram quantities of berkelium (249Bk) and einsteinium and picogram quantities of fermium.\nThe first microscopic sample of 253Es sample weighing about 10 nanograms was prepared in 1961 at HFIR. A special magnetic balance was designed to estimate its weight. Larger batches were produced later starting from several kilograms of plutonium with the einsteinium yields (mostly 253Es) of 0.48 milligrams in 1967\u20131970, 3.2 milligrams in 1971\u20131973, followed by steady production of about 3 milligrams per year between 1974 and 1978. These quantities however refer to the integral amount in the target right after irradiation. Subsequent separation procedures reduced the amount of isotopically pure einsteinium roughly tenfold.\nLaboratory synthesis.\nHeavy neutron irradiation of plutonium results in four major isotopes of einsteinium: 253Es (\u03b1-emitter with half-life of 20.47 days and with a spontaneous fission half-life of 7\u00d7105 years); 254\"m\"Es (\u03b2-emitter with half-life of 39.3 hours), 254Es (\u03b1-emitter with half-life of about 276 days) and 255Es (\u03b2-emitter with half-life of 39.8 days). An alternative route involves bombardment of uranium-238 with high-intensity nitrogen or oxygen ion beams.\nEinsteinium-247 (half-life 4.55 minutes) was produced by irradiating americium-241 with carbon or uranium-238 with nitrogen ions. The latter reaction was first realized in 1967 in Dubna, Russia, and the involved scientists were awarded the Lenin Komsomol Prize.\nThe isotope 248Es was produced by irradiating 249Cf with deuterium ions. It mainly decays by emission of electrons to 248Cf with a half-life of minutes, but also releases \u03b1-particles of 6.87\u00a0MeV energy, with the ratio of electrons to \u03b1-particles of about 400.\nformula_1\nThe heavier isotopes 249Es, 250Es, 251Es and 252Es were obtained by bombarding 249Bk with \u03b1-particles. One to four neutrons are liberated in this process making possible the formation of four different isotopes in one reaction.\n&lt;chem&gt;^{249}_{97}Bk -&gt;[+\\alpha] ^{249,250,251,252}_{99}Es&lt;/chem&gt;\nEinsteinium-253 was produced by irradiating a 0.1\u20130.2 milligram 252Cf target with a thermal neutron flux of (2\u20135)\u00d71014 neutrons\u00b7cm\u22122\u00b7s\u22121 for 500\u2013900 hours:\n&lt;chem&gt;^{252}_{98}Cf -&gt;[\\ce{(n,\\gamma)}] ^{253}_{98}Cf -&gt;[\\beta^-][17.81 \\ce{d}] ^{253}_{99}Es&lt;/chem&gt;\nIn 2020, scientists at the Oak Ridge National Laboratory were able to create 233 nanograms of 254Es, a new world record. This allowed some chemical properties of the element to be studied for the first time.\nSynthesis in nuclear explosions.\nThe analysis of the debris at the 10-megaton \"Ivy Mike\" nuclear test was a part of long-term project. One of the goals of which was studying the efficiency of production of transuranium elements in high-power nuclear explosions. The motivation for these experiments was that synthesis of such elements from uranium requires multiple neutron capture. The probability of such events increases with the neutron flux, and nuclear explosions are the most powerful man-made neutron sources, providing densities of the order 1023 neutrons/cm2 within a microsecond, or about 1029 neutrons/(cm2\u00b7s). In comparison, the flux of the HFIR reactor is 5\u00d71015 neutrons/(cm2\u00b7s). A dedicated laboratory was set up right at Enewetak Atoll for preliminary analysis of debris, as some isotopes could have decayed by the time the debris samples reached the mainland U.S. The laboratory was receiving samples for analysis as soon as possible, from airplanes equipped with paper filters which flew over the atoll after the tests. Whereas it was hoped to discover new chemical elements heavier than fermium, none of these were found even after a series of megaton explosions conducted between 1954 and 1956 at the atoll.\nThe atmospheric results were supplemented by the underground test data accumulated in the 1960s at the Nevada Test Site, as it was hoped that powerful explosions conducted in confined space might result in improved yields and heavier isotopes. Apart from traditional uranium charges, combinations of uranium with americium and thorium have been tried, as well as a mixed plutonium-neptunium charge, but they were less successful in terms of yield and was attributed to stronger losses of heavy isotopes due to enhanced fission rates in heavy-element charges. Product isolation was problematic as the explosions were spreading debris through melting and vaporizing the surrounding rocks at depths of 300\u2013600 meters. Drilling to such depths to extract the products was both slow and inefficient in terms of collected volumes.\nAmong the nine underground tests that were carried between 1962 and 1969, the last one was the most powerful and had the highest yield of transuranium elements. Milligrams of einsteinium that would normally take a year of irradiation in a high-power reactor, were produced within a microsecond. However, the major practical problem of the entire proposal was collecting the radioactive debris dispersed by the powerful blast. Aircraft filters adsorbed only about 4\u00d710-14 of the total amount, and collection of tons of corals at Enewetak Atoll increased this fraction by only two orders of magnitude. Extraction of about 500 kilograms of underground rocks 60 days after the Hutch explosion recovered only about 1\u00d710-7 of the total charge. The amount of transuranium elements in this 500-kg batch was only 30 times higher than in a 0.4\u00a0kg rock picked up 7 days after the test which demonstrated the highly non-linear dependence of the transuranium elements yield on the amount of retrieved radioactive rock. Shafts were drilled at the site before the test in order to accelerate sample collection after explosion, so that explosion would expel radioactive material from the epicenter through the shafts and to collecting volumes near the surface. This method was tried in two tests and instantly provided hundreds kilograms of material, but with actinide concentration 3 times lower than in samples obtained after drilling. Whereas such method could have been efficient in scientific studies of short-lived isotopes, it could not improve the overall collection efficiency of the produced actinides.\nAlthough no new elements (apart from einsteinium and fermium) could be detected in the nuclear test debris, and the total yields of transuranium elements were disappointingly low, these tests did provide significantly higher amounts of rare heavy isotopes than previously available in laboratories.\nSeparation.\nSeparation procedure of einsteinium depends on the synthesis method. In the case of light-ion bombardment inside a cyclotron, the heavy ion target is attached to a thin foil, and the generated einsteinium is simply washed off the foil after the irradiation. However, the produced amounts in such experiments are relatively low. The yields are much higher for reactor irradiation, but there, the product is a mixture of various actinide isotopes, as well as lanthanides produced in the nuclear fission decays. In this case, isolation of einsteinium is a tedious procedure which involves several repeating steps of cation exchange, at elevated temperature and pressure, and chromatography. Separation from berkelium is important, because the most common einsteinium isotope produced in nuclear reactors, 253Es, decays with a half-life of only 20 days to 249Bk, which is fast on the timescale of most experiments. Such separation relies on the fact that berkelium easily oxidizes to the solid +4 state and precipitates, whereas other actinides, including einsteinium, remain in their +3 state in solutions.\nSeparation of trivalent actinides from lanthanide fission products can be done by a cation-exchange resin column using a 90% water/10% ethanol solution saturated with hydrochloric acid (HCl) as eluant. It is usually followed by anion-exchange chromatography using 6 molar HCl as eluant. A cation-exchange resin column (Dowex-50 exchange column) treated with ammonium salts is then used to separate fractions containing elements 99, 100 and 101. These elements can be then identified simply based on their elution position/time, using \u03b1-hydroxyisobutyrate solution (\u03b1-HIB), for example, as eluant.\nSeparation of the 3+ actinides can also be achieved by solvent extraction chromatography, using bis-(2-ethylhexyl) phosphoric acid (abbreviated as HDEHP) as the stationary organic phase, and nitric acid as the mobile aqueous phase. The actinide elution sequence is reversed from that of the cation-exchange resin column. The einsteinium separated by this method has the advantage to be free of organic complexing agent, as compared to the separation using a resin column.\nPreparation of the metal.\nEinsteinium is highly reactive and therefore strong reducing agents are required to obtain the pure metal from its compounds. This can be achieved by reduction of einsteinium(III) fluoride with metallic lithium:\nEsF3 + 3 Li \u2192 Es + 3 LiF\nHowever, owing to its low melting point and high rate of self-radiation damage, einsteinium has high vapor pressure, which is higher than that of lithium fluoride. This makes this reduction reaction rather inefficient. It was tried in the early preparation attempts and quickly abandoned in favor of reduction of einsteinium(III) oxide with lanthanum metal:\nEs2O3 + 2 La \u2192 2 Es + La2O3\nChemical compounds.\nOxides.\nEinsteinium(III) oxide (Es2O3) was obtained by burning einsteinium(III) nitrate. It forms colorless cubic crystals, which were first characterized from microgram samples sized about 30 nanometers. Two other phases, monoclinic and hexagonal, are known for this oxide. The formation of a certain Es2O3 phase depends on the preparation technique and sample history, and there is no clear phase diagram. Interconversions between the three phases can occur spontaneously, as a result of self-irradiation or self-heating. The hexagonal phase is isotypic with lanthanum oxide where the Es3+ ion is surrounded by a 6-coordinated group of O2\u2212 ions.\nHalides.\nEinsteinium halides are known for the oxidation states +2 and +3. The most stable state is +3 for all halides from fluoride to iodide.\nEinsteinium(III) fluoride (EsF3) can be precipitated from einsteinium(III) chloride solutions upon reaction with fluoride ions. An alternative preparation procedure is to exposure einsteinium(III) oxide to chlorine trifluoride (ClF3) or F2 gas at a pressure of 1\u20132 atmospheres and a temperature between 300 and 400\u00a0\u00b0C. The EsF3 crystal structure is hexagonal, as in californium(III) fluoride (CfF3) where the Es3+ ions are 8-fold coordinated by fluorine ions in a bicapped trigonal prism arrangement.\nEinsteinium(III) chloride (EsCl3) can be prepared by annealing einsteinium(III) oxide in the atmosphere of dry hydrogen chloride vapors at about 500\u00a0\u00b0C for some 20 minutes. It crystallizes upon cooling at about 425\u00a0\u00b0C into an orange solid with a hexagonal structure of UCl3 type, where einsteinium atoms are 9-fold coordinated by chlorine atoms in a tricapped trigonal prism geometry. Einsteinium(III) bromide (EsBr3) is a pale-yellow solid with a monoclinic structure of AlCl3 type, where the einsteinium atoms are octahedrally coordinated by bromine (coordination number 6).\nThe divalent compounds of einsteinium are obtained by reducing the trivalent halides with hydrogen:\n2 EsX3 + H2 \u2192 2 EsX2 + 2 HX, \u00a0\u00a0\u00a0X = F, Cl, Br, I\nEinsteinium(II) chloride (EsCl2), einsteinium(II) bromide (EsBr2), and einsteinium(II) iodide (EsI2) have been produced and characterized by optical absorption, with no structural information available yet.\nKnown oxyhalides of einsteinium include EsOCl, EsOBr and EsOI. These salts are synthesized by treating a trihalide with a vapor mixture of water and the corresponding hydrogen halide: for example, EsCl3 + H2O/HCl to obtain EsOCl.\nOrganoeinsteinium compounds.\nThe high radioactivity of einsteinium has a potential use in radiation therapy, and organometallic complexes have been synthesized in order to deliver einsteinium atoms to an appropriate organ in the body. Experiments have been performed on injecting einsteinium citrate (as well as fermium compounds) to dogs. Einsteinium(III) was also incorporated into beta-diketone chelate complexes, since analogous complexes with lanthanides previously showed strongest UV-excited luminescence among metallorganic compounds. When preparing einsteinium complexes, the Es3+ ions were 1000 times diluted with Gd3+ ions. This allowed reducing the radiation damage so that the compounds did not disintegrate during the period of 20 minutes required for the measurements. The resulting luminescence from Es3+ was much too weak to be detected. This was explained by the unfavorable relative energies of the individual constituents of the compound that hindered efficient energy transfer from the chelate matrix to Es3+ ions. Similar conclusion was drawn for other actinides americium, berkelium and fermium.\nLuminescence of Es3+ ions was however observed in inorganic hydrochloric acid solutions as well as in organic solution with di(2-ethylhexyl)orthophosphoric acid. It shows a broad peak at about 1064 nanometers (half-width about 100\u00a0nm) which can be resonantly excited by green light (ca. 495\u00a0nm wavelength). The luminescence has a lifetime of several microseconds and the quantum yield below 0.1%. The relatively high, compared to lanthanides, non-radiative decay rates in Es3+ were associated with the stronger interaction of f-electrons with the inner Es3+ electrons.\nApplications.\nThere is almost no use for any isotope of einsteinium outside basic scientific research aiming at production of higher transuranium elements and superheavy elements.\nIn 1955, mendelevium was synthesized by irradiating a target consisting of about 109 atoms of 253Es in the 60-inch cyclotron at Berkeley Laboratory. The resulting 253Es(\u03b1,n)256Md reaction yielded 17 atoms of the new element with the atomic number of 101.\nThe rare isotope 254Es is favored for production of superheavy elements because of its large mass, relatively long half-life of 270 days, and availability in significant amounts of several micrograms. Hence 254Es was used as a target in the attempted synthesis of ununennium (element 119) in 1985 by bombarding it with calcium-48 ions at the superHILAC linear particle accelerator at Berkeley, California. No atoms were identified, setting an upper limit for the cross section of this reaction at 300 nanobarns.\n&lt;chem&gt;{^{254}_{99}Es} + {^{48}_{20}Ca} -&gt; {^{302}_{119}Uue^\\ast} -&gt; no\\ atoms&lt;/chem&gt;\n254Es was used as the calibration marker in the chemical analysis spectrometer (\"alpha-scattering surface analyzer\") of the Surveyor 5 lunar probe. The large mass of this isotope reduced the spectral overlap between signals from the marker and the studied lighter elements of the lunar surface.\nSafety.\nMost of the available einsteinium toxicity data, is from research on animals. Upon ingestion by rats, only ~0.01% of it ends in the bloodstream. From there, about 65% goes to the bones, where it would remain for ~50 years if not for its radioactive decay, not to speak of the 3-year maximum lifespan of rats, 25% to the lungs (biological half-life ~20 years, though this is again rendered irrelevant by the short half-life of einsteinium), 0.035% to the testicles or 0.01% to the ovaries \u2013 where einsteinium stays indefinitely. About 10% of the ingested amount is excreted. The distribution of einsteinium over bone surfaces is uniform and is similar to that of plutonium.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9480", "revid": "1152511442", "url": "https://en.wikipedia.org/wiki?curid=9480", "title": "Edmund Stoiber", "text": "German politician\nEdmund R\u00fcdiger Stoiber (born 28 September 1941) is a German politician who served as the 16th Minister President of the state of Bavaria between 1993 and 2007 and chairman of the Christian Social Union (CSU) between 1999 and 2007. In 2002, he ran for the office of Chancellor of Germany in the federal election, but in one of the narrowest elections in German history lost against Gerhard Schr\u00f6der. On 18 January 2007, he announced his decision to step down from the posts of minister-president and party chairman by 30 September, after having been under fire in his own party for weeks.\nEarly life.\nStoiber was born in Oberaudorf in the district of Rosenheim in Bavaria. Prior to entering politics in 1974 and serving in the Bavarian Parliament, he was a lawyer and worked at the University of Regensburg.\nEducation and profession.\nStoiber attended the Ignaz-G\u00fcnther-Gymnasium in Rosenheim, where he received his \"Abitur\" (high school diploma) in 1961, although he had to repeat one year for failing Latin. His military service was with the 1st Gebirgsdivision (mountain infantry division) in Mittenwald and Bad Reichenhall and was cutshort due to a knee injury. Stoiber then studied political science and (from the fall of 1962) law at the Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen. In 1967, he passed the state law exam and then worked at the University of Regensburg in criminal law and Eastern European law. He received a doctorate in jurisprudence, and then in 1971 passed the second state examination with distinction.\nIn 1971, Stoiber joined the Bavarian State Ministry of Development and Environment.\nPolitical career.\nIn 1978, Stoiber was elected secretary general of the CSU, a post he held until 1982/83. In this capacity, he served as campaign manager of Franz-Josef Strauss, the first Bavarian leader to run for the chancellorship, in the 1980 national elections. From 1982 to 1986 he served as deputy to the Bavarian secretary of the state and then, in the position of State Minister, led the State Chancellery from 1982 to 1988. From 1988 to 1993 he served as State Minister of the Interior.\nMinister-President of Bavaria, 1993\u20132007.\nIn May 1993, the Landtag of Bavaria, the state's parliament, elected Stoiber as Minister-President succeeding Max Streibl. He came to power amid a political crisis involving a sex scandal, surrounding a contender for the state premiership. Upon taking office, he nominated Strauss' daughter Monika Hohlmeier as State Minister for Education and Cultural Affairs.\nIn his capacity as Minister-President, Stoiber served as President of the Bundesrat in 1995/96. In 1998, he also succeeded Theo Waigel as chairman of the CSU.\nDuring Stoiber's 14 years leading Bavaria, the state solidified its position as one of Germany's richest. Already by 1998, under his leadership, the state had privatized more than $3 billion worth of state-owned businesses and used that money to invest in new infrastructure and provide venture capital for new companies. He was widely regarded a central figure in building one of Europe's most powerful regional economies, attracting thousands of hi-tech, engineering and media companies and reducing unemployment to half the national average.\nCandidate for Chancellor, 2002.\nIn 2002, Stoiber politically outmaneuvered CDU chairwoman, Angela Merkel, and was declared the CDU/CSU's candidate for the office of chancellor by practically the entire leadership of the CSU's sister party CDU, challenging Gerhard Schr\u00f6der. At that time, Merkel had generally been seen as a transitional chair and was strongly opposed by the CDU's male leaders, often called the party's \"crown princes\".\nIn the run up to the 2002 national elections, the CSU/CDU held a huge lead in the opinion polls and Stoiber famously remarked that \"...this election is like a football match where it's the second half and my team is ahead by 2\u20130.\" However, on election day things had changed. The SPD had mounted a huge comeback, and the CDU/CSU was narrowly defeated (though both the SPD and CDU/CSU had 38.5% of the vote, the SPD was ahead by a small 6,000 vote margin, winning 251 seats to the CDU/CSU's 248). The election was one of modern Germany's closest votes.\nGerhard Schr\u00f6der was re-elected as chancellor by the parliament in a coalition with the Greens, who had increased their vote share marginally. Many commentators faulted Stoiber's reaction to the floods in eastern Germany, in the run-up to the election, as a contributory factor in his party's poor electoral result and defeat. In addition, Schr\u00f6der distinguished himself from his opponent by taking an active stance against the upcoming United States-led Iraq War. His extensive campaigning on this stance was widely seen as swinging the election to the SPD in the weeks running up to the election.\nLater political career.\nStoiber subsequently led the CSU to an absolute majority in the 2003 Bavarian state elections, for the third time in a row, winning this time 60.7% of the votes and a two-thirds majority in the Landtag. This was the widest margin ever achieved by a German party in any state.\nBetween 2003 and 2004, Stoiber served as co-chair (alongside Franz M\u00fcntefering) of the First Commission on the modernization of the federal state (\"F\u00f6deralismuskommission I\"), which had been established to reform the division of powers between federal and state authorities in Germany. In February 2004, he became a candidate of Jacques Chirac and Gerhard Schr\u00f6der for the presidency of the European Commission but he decided not to run for this office.\nStoiber had ambitions to run again for the chancellorship, but Merkel secured the nomination, and in November 2005 she won the general election. He was slated to join Merkel's first grand coalition cabinet as Economics minister. However, on 1 November 2005, he announced his decision to stay in Bavaria, due to personnel changes on the SPD side of the coalition (Franz M\u00fcntefering resigned as SPD chairman) and an unsatisfactory apportionment of competences between himself and designated Science minister Annette Schavan. Stoiber also resigned his seat in the 16th Bundestag, being a member from 18 October to 8 November.\nSubsequently, criticism grew in the CSU, where other politicians had to scale back their ambitions after Stoiber's decision to stay in Bavaria. On 18 January 2007, he announced his decision to stand down from the posts of minister-president and party chairman by 30 September. G\u00fcnther Beckstein, then Bavarian state minister of the interior, succeeded him as minister-president and Erwin Huber as party chairman, defeating Horst Seehofer at a convention at 18 September 2007 with 58,1% of the votes. Both Beckstein and Huber resigned after the 2008 state elections, in which the CSU vote dropped to 43,4% and the party had to form a coalition with another party for the first time since 1966.\nLife after politics.\nStoiber was first appointed in 2007 as a special adviser to European Commission President Jos\u00e9 Manuel Barroso to chair the \"High level group on administrative burdens\", made up of national experts, NGOs, business and industry organizations. Quickly nicknamed the \"Stoiber Group\", it produced a report in July 2014 with several proposals on streamlining the regulatory process. Stoiber was re-appointed in December 2014 by Jean-Claude Juncker to the same role, from which he resigned after one year in late 2015.\nSince his retirement from German politics in 2007, Stoiber has worked as a lawyer and held paid and unpaid positions, including:\nStoiber was a CSU delegate to the Federal Convention for the purpose of electing the President of Germany in 2017.\nPolitical positions.\nForeign policy.\nIn his capacity as Minister-President, Stoiber made 58 foreign trips, including to China (1995, 2003), Israel (2001), Egypt (2001), India (2004, 2007) and South Korea (2007).\nIn 2002, Stoiber publicly expressed support for the United States in their policy toward Iraq. During his election campaign, he made clear his opposition to war, and his support for the introduction of weapons inspectors to Iraq without preconditions as a way of avoiding war, and he criticized Schr\u00f6der for harming the German-American alliance by not calling President George W. Bush and discussing the issue privately. He also attacked German Foreign Minister Joschka Fischer for his criticism of the U.S. position.\nStoiber is known for backing Vladimir Putin and there have been comparisons to Gerhard Schr\u00f6der. One author called Stoiber a \"Moscow's Trojan Horse\". Putin is known to have given Stoiber \"extreme forms of flattery\" and privileges such as a private dinner at Putin's residence outside Moscow.\nEuropean integration.\nStoiber has been said to be skeptical of Germany's decision to adopt the euro. In 1997, he joined the ministers-president of two other German states, Kurt Biedenkopf and Gerhard Schr\u00f6der, in making the case for a five-year delay in Europe's currency union. When the European Commission recommended that Greece be allowed to join the eurozone in 1998, he demanded that the country be barred from adopting the common currency for several years instead. He is a staunch opponent of Turkey's integration into the European Union, claiming that its non-Christian culture would dilute the Union.\nAt the same time, Stoiber has repeatedly insisted he is a \"good European\" who is keen, for instance, on forging an EU-wide foreign policy, replete with a single European army. Earlier, in 1993, he had told German newspapers: \"I want a simple confederation. That means the nation-states maintain their dominant role, at least as far as internal matters are concerned.\"\nEconomic policy.\nWhile the conservative wing of the German political spectrum, primarily formed of the CDU and CSU, enjoys considerable support, this support tends to be less extended to Stoiber. He enjoys considerably more support in his home state of Bavaria than in the rest of Germany, where CDU chairwoman Angela Merkel is more popular. This has its reasons: Merkel supports a kind of fiscal conservatism, but a more liberal social policy. Stoiber, on the other hand, favors a more conservative approach to both fiscal and social matters, and while this ensures him the religious vote, strongest in Bavaria, it has weakened his support at the national level.\nIn 2005, Stoiber successfully lobbied Novartis, the Swiss pharmaceuticals group, to move the headquarters of its Sandoz subsidiary to Munich, making it one of Europe's highest-profile corporate relocations that year as well as a significant boost to Stoiber's attempts to build up Bavaria as a pharmaceuticals and biotechnology center.\nDuring his time as Minister-President of Bavaria, Stoiber pushed for the construction of a roughly 40-kilometer high-speed magnetic-levitation link from Munich's main station to its airport, to be built by Transrapid International, a consortium including ThyssenKrupp and Munich-based Siemens. After he left office, the German federal government abandoned the plans in 2008 because of spiraling costs of as much as \u20ac3.4 billion.\nDomestic policy.\nStoiber, as a minister in the state of Bavaria, was widely known for advocating a reduction in the number of asylum seekers Germany accepts, something that prompted critics to label him xenophobic, anti-Turkish and anti-Islam. In the late 1990s, he criticized the incoming Chancellor Gerhard Schr\u00f6der for saying that he would work hard in the interest of Germans \"and\" people living in Germany. Stoiber's remarks drew heavy criticism in the press.\nWhen Germany's Federal Constitutional Court decided in 1995 that a Bavarian law requiring a crucifix to be hung in each of the state's 40,000 classrooms was unconstitutional, Stoiber said he would not order the removal of crucifixes \"for the time being\", and asserted that he was under no obligation to remove them in schools where parents unanimously opposed such action.\nDuring his 2002 election campaign, Stoiber indicated he would not ban same-sex marriages\u2014sanctioned by the Schr\u00f6der government\u2014a policy he had vehemently objected to when it was introduced.\nMedia policy.\nStoiber has been a staunch advocate of changes in German law that would give more power to owners of private TV channels. In 1995, he publicly called for the abolition of Germany's public television service ARD and a streamlining of its regional services, adding that he and Minister-President Kurt Biedenkopf of Saxony would break the contract ARD has with regional governments if reforms were not undertaken. However, when European Commissioner for Competition Karel van Miert unveiled ideas for reforming the rules governing the financing of public service broadcasters in 1998, Stoiber led the way in rejecting moves to reform established practice.\nControversies.\nComments on East Germany.\nDuring the run-up to the German general election in 2005, which was held ahead of schedule, Stoiber created controversy through a campaign speech held in the beginning of August 2005 in the federal state of Baden-W\u00fcrttemberg. He said, \"I do not accept that the East [of Germany] will again decide who will be Germany's chancellor. It cannot be allowed that the frustrated determine Germany's fate.\" People in the new federal states of Germany (the former German Democratic Republic) were offended by Stoiber's remarks. While the CSU attempted to portray them as \"misinterpreted\", Stoiber created further controversy when he claimed that \"if it was like Bavaria everywhere, there wouldn't be any problems. Unfortunately, not everyone in Germany is as intelligent as in Bavaria.\" The tone of the comments was exacerbated by a perception by some within Germany of the state of Bavaria as \"arrogant\".\nMany, including members of the CDU, attribute Stoiber's comments and behavior as a contributing factor to the CDU's losses in the 2005 general election. He was accused by many in the CDU/CSU of offering \"half-hearted\" support to Angela Merkel, with some even accusing him of being reluctant to support a female candidate from the East. (This also contrasted unfavorably with Merkel's robust support for his candidacy in the 2002 election.) He has insinuated that votes were lost because of the choice of a female candidate. He came under heavy fire for these comments from press and politicians alike, especially since he himself lost almost 10% of the Bavarian vote\u2014a dubious feat in itself as Bavarians tend to consistently vote conservatively. Nonetheless, a poll has suggested over 9% may have voted differently if the conservative candidate was a man from the West, although this does not clearly show if such a candidate would have gained or lost votes for the conservatives.\nBayernLB activities.\nWhen the Croatian National Bank turned down BayernLB's original bid to take over the local arm of Hypo Alpe-Adria-Bank International, this drew strong criticism from Stoiber, who said the decision was \"unacceptable\" and a \"severe strain\" for Bavaria's relations with Croatia. Croatia was seeking to join the European Union at the time. The central bank's board later reviewed and accepted BayernLB's offer of 1.6 billion euros. The investment in Hypo Group Alpe Adria was part of a series of ill-fated investments, which later forced BayernLB to take a 10 billion-euro bailout in the financial crisis.\nEuropean Commission job.\nIn September 2015, Emily O'Reilly, the European Ombudsman, received a complaint from two NGOs, Corporate Europe Observatory and Friends of the Earth, according to which Stoiber's appointment as special adviser on the commission's better regulation agenda broke internal rules on appointments.\nPersonal life.\nStoiber is Roman Catholic. He is married to Karin Stoiber. They have three children: Constanze (born 1971, married \"Hausmann\"), Veronica (born 1977, married \"Sa\u00df\"), Dominic (born 1980) and five grandchildren: Johannes (1999), Benedikt (2001), Theresa Marie (2005), Ferdinand (2009) and another grandson (2011).\nStoiber is a keen football fan and operative. In his youth, he played for local football side BCF Wolfratshausen. Stoiber serves as Member of the Supervisory Board of FC Bayern M\u00fcnchen AG (the stock corporation that runs the professional football section) and Chairman of the Administrative Advisory Board of FC Bayern Munich e.V. (the club that owns the majority of the club corporation).\nBefore the 2002 election, FC Bayern general manager Uli Hoene\u00df expressed his support for Stoiber and the CSU. Football legend, former FC Bayern president and DFB vice president Franz Beckenbauer showed his support for Stoiber by letting him join the Germany national football team on their flight home from Japan after the 2002 FIFA World Cup.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9481", "revid": "8917946", "url": "https://en.wikipedia.org/wiki?curid=9481", "title": "Erfurt", "text": "Capital of Thuringia, Germany\n \nErfurt (] ()) is the capital and largest city of the Central German state of Thuringia. It is in the wide valley of the River Gera, in the southern part of the Thuringian Basin, north of the Thuringian Forest, and in the middle of a line of the six largest Thuringian cities (\"\"), stretching from Eisenach in the west, via Gotha, Erfurt, Weimar and Jena, to Gera in the east, close to the geographic centre of Germany. Erfurt is south-west of Leipzig, north-east of Frankfurt, south-west of Berlin and north of Munich.\nErfurt's old town is one of the best preserved medieval city centres in Germany. Tourist attractions include the Merchants' Bridge (\"Kr\u00e4merbr\u00fccke\"), the Old Synagogue (\"Alte Synagoge\"), the oldest in Europe, Cathedral Hill (\"Domberg\") with the ensemble of Erfurt Cathedral (\"Erfurter Dom\") and St Severus' Church (\"Severikirche\") and Petersberg Citadel (\"Zitadelle Petersberg\"), one of the largest and best preserved town fortresses in Central Europe. The city's economy is based on agriculture, horticulture and microelectronics. Its central location has made it a logistics hub for Germany and central Europe. Erfurt hosts the second-largest trade fair in eastern Germany (after Leipzig), as well as the public television children's channel KiKa.\nThe city is on the Via Regia, a medieval trade and pilgrims' road network. Modern Erfurt is also a hub for ICE high speed trains and other German and European transport networks. Erfurt was first mentioned in 742, as Saint Boniface founded the diocese. Although the town did not belong to any of the Thuringian states politically, it quickly became the economic centre of the region and was a member of the Hanseatic League. It was part of the Electorate of Mainz during the Holy Roman Empire, and became part of the Kingdom of Prussia in 1802. From 1949 until 1990 Erfurt was part of the German Democratic Republic (East Germany).\nThe University of Erfurt was founded in 1379, making it the first university to be established within the geographic area which constitutes modern Germany. It closed in 1816 and was re-established in 1994. Martin Luther (1483\u20131546) was its most famous student, studying there from 1501 before entering St Augustine's Monastery in 1505. Other noted Erfurters include the medieval philosopher and mystic Meister Eckhart (c. 1260\u20131328), the Baroque composer Johann Pachelbel (1653\u20131706) and the sociologist Max Weber (1864\u20131920).\nHistory.\nPrehistory and antiquity.\nErfurt is an old Germanic settlement. The earliest evidence of human settlement dates from the prehistoric era; archaeological finds from the north of Erfurt revealed human traces from the paleolithic period, ca. 10,000 BCE.\nTo the west of Erfurt in Frienstedt existed, in the AD era, a big Germanic village, which was found during the construction of a highway. Where they also discovered the oldest Germanic word ever discovered in Central Germany written in runic script was found on a comb from a sacrificial shaft the word: \"kaba\". From Roman Times, however, they found 200 coins dating back to the third century, plus 150 Roman ceramic fragments and more than 200 fibulae. Also 11 inhumation graves of the Ha\u00dfleben-Leuna group, which is an archeological cultural group.\nThe Melchendorf dig in the southern city part showed a settlement from the neolithic period. The Thuringii inhabited the Erfurt area in \"c.\"\u00a0480 and gave their name to Thuringia in \"c.\"\u00a0500.\nMiddle Ages.\nThe town is first mentioned in 742 under the name of \"Erphesfurt\": in that year, Saint Boniface wrote to Pope Zachary to inform him that he had established three dioceses in central Germany, one of them \"in a place called Erphesfurt, which for a long time has been inhabited by pagan natives.\" All three dioceses (the other two were W\u00fcrzburg and B\u00fcraburg) were confirmed by Zachary the next year, though in 755 Erfurt was brought into the diocese of Mainz. That the place was populous already is borne out by archeological evidence, which includes 23 graves and six horse burials from the sixth and seventh centuries.\nThroughout the Middle Ages, Erfurt was an important trading town because of its location, near a ford across the Gera river. Together with the other five Thuringian woad towns of Gotha, Tennstedt, Arnstadt and Langensalza it was the centre of the German woad trade, which made those cities very wealthy. Erfurt was the junction of important trade routes: the Via Regia was one of the most used east\u2013west roads between France and Russia (via Frankfurt, Erfurt, Leipzig and Wroc\u0142aw) and another route in the north\u2013south direction was the connection between the Baltic Sea ports (e. g. L\u00fcbeck) and the potent upper Italian city-states like Venice and Milan.\nDuring the tenth and eleventh centuries both the Emperor and the Electorate of Mainz held some privileges in Erfurt. The German kings had an important monastery on Petersberg hill and the Archbishops of Mainz collected taxes from the people. Around 1100, some people became free citizens by paying the annual \"\" (liberation tax), which marks a first step in becoming an independent city. During the 12th century, as a sign of more and more independence, the citizens built a city wall around Erfurt (in the area of today's ). After 1200, independence was fulfilled and a city council was founded in 1217; the town hall was built in 1275. In the following decades, the council bought a city-owned territory around Erfurt which consisted at its height of nearly 100 villages and castles and even another small town (S\u00f6mmerda). Erfurt became an important regional power between the Landgraviate of Thuringia around, the Electorate of Mainz to the west and the Electorate of Saxony to the east. Between 1306 and 1481, Erfurt was allied with the two other major Thuringian cities (M\u00fchlhausen and Nordhausen) in the Thuringian City Alliance and the three cities joined the Hanseatic League together in 1430. A peak in economic development was reached in the 15th century, when the city had a population of 20,000 making it one of the largest in Germany. Between 1432 and 1446, a second and higher city wall was established. In 1483, a first city fortress was built on Cyriaksburg hill in the southwestern part of the town.\nIn the year 1184, Erfurt was the location of a notable accident called the \"Erfurter Latrinensturz\" ('Erfurt latrine fall'). King Henry VI held council in a building of the Erfurt Cathedral to negotiate peace between two of his vassals, Archbishop Konrad I of Mainz and Landgrave Ludwig III of Thuringia. The amassed weight of all the gathered men proved too heavy for the floor to bear, which collapsed. According to contemporary accounts, dozens of people fell to their death into the latrine pit below. Ludwig III, Konrad I and Henry VI survived the affair.\nThe Jewish community of Erfurt was founded in the 11th century and became, together with Mainz, Worms and Speyer, one of the most influential in Germany. Their Old Synagogue is still extant and a museum today, as is the mikveh at Gera river near . In 1349, during the wave of Black Death Jewish persecutions across Europe, the Jews of Erfurt were rounded up, with more than 100 killed and the rest driven from the city. Before the persecution, a wealthy Jewish merchant buried his property in the basement of his house. In 1998, this treasure was found during construction works. The Erfurt Treasure with various gold and silver objects is shown in the exhibition in the synagogue today. Only a few years after 1349, the Jews moved back to Erfurt and founded a second community, which was disbanded by the city council in 1458.\nIn 1379, the University of Erfurt was founded. Together with the University of Cologne it was one of the first city-owned universities in Germany, while they were usually owned by the \"\". Some buildings of this old university are extant or restored in the \"Latin Quarter\" in the northern city centre (like , student dorms \"\" and others, the hospital and the church of the university). The university quickly became a hotspot of German cultural life in Renaissance humanism with scholars like Ulrich von Hutten, Helius Eobanus Hessus and Justus Jonas.\nEarly modern period.\nIn 1501 Martin Luther (1483\u20131546) moved to Erfurt and began his studies at the university. After 1505, he lived at St. Augustine's Monastery as a friar. In 1507 he was ordained as a priest in Erfurt Cathedral. He moved permanently to Wittenberg in 1511. Erfurt was an early adopter of the Protestant Reformation, in 1521.\nIn 1530, the city became one of the first in Europe to be officially bi-confessional with the Hammelburg Treaty. It kept that status through all the following centuries. The later 16th and the 17th century brought a slow economic decline of Erfurt. Trade shrank, the population was falling and the university lost its influence. The city's independence was endangered. In 1664, the city and surrounding area were brought under the dominion of the Electorate of Mainz and the city lost its independence. The Electorate built a huge fortress on Petersberg hill between 1665 and 1726 to control the city and instituted a governor to rule Erfurt.\nIn 1682 and 1683 Erfurt experienced the worst plague years in its history. In 1683 more than half of the population died because of the deadly disease.\nIn Erfurt witch-hunts are known from 1526 to 1705. Trial records are only incomplete. Twenty people were involved in witch trials and at least eight people died.\nDuring the late 18th century, Erfurt saw another cultural peak. Governor Karl Theodor Anton Maria von Dalberg had close relations with Johann Wolfgang von Goethe, Friedrich Schiller, Johann Gottfried Herder, Christoph Martin Wieland and Wilhelm von Humboldt, who often visited him at his court in Erfurt.\nErfurt during the Napoleonic Wars.\nErfurt became part of the Kingdom of Prussia in 1802, to compensate for territories Prussia lost to France on the Left Bank of the Rhine. In the Capitulation of Erfurt, the city, its 12,000 Prussian and Saxon defenders under William VI, Prince of Orange-Nassau, 65 artillery pieces, and the Petersberg Citadel and Cyriaksburg Citadel , were handed over to the French on 16 October 1806.&lt;ref name=\"Petre 1907/1993\"&gt;&lt;/ref&gt; At the time of the capitulation, Joachim Murat, Marshal of France, had about 16,000 troops near Erfurt. With the attachment of the Saxe-Weimar territory of Blankenhain, the city became part of the First French Empire in 1806 as the Principality of Erfurt, directly subordinate to Napoleon as an \"imperial state domain\" (), separate from the Confederation of the Rhine, which the surrounding Thuringian states had joined. Erfurt was administered by a civilian and military Senate (\"\") under a French governor, based in the , previously the seat of the city's governor under the Electorate. Napoleon first visited the principality on 23 July 1807, inspecting the citadels and fortifications. In 1808, the Congress of Erfurt was held with Napoleon and Alexander I of Russia visiting the city.\nDuring their administration, the French introduced street lighting and a tax on foreign horses to pay for maintaining the road surface. The suffered under the French occupation, with its inventory being auctioned off to other local churches \u2013 including the organ, bells and even the tower of the chapel (\"\") \u2013 and the former monastery's library being donated to the University of Erfurt (and then to the Boineburg Library when the university closed in 1816). Similarly the Cyriaksburg Citadel was damaged by the French, with the city-side walls being partially dismantled in the hunt for imagined treasures from the convent, workers being paid from the sale of the building materials.\nIn 1811, to commemorate the birth of the Prince Imperial, a ceremonial column (') of wood and plaster was erected on the common. Similarly, the ' \u2013 a Greek-style temple topped by a winged victory with shield, sword and lance and containing a bust of Napoleon sculpted by Friedrich D\u00f6ll \u2013 was erected in the ' woods, including a grotto with fountain and flower beds, using a large pond (') from the , inaugurated with ceremony on 14 August 1811 after extravagant celebrations for Napoleon's birthday, which were repeated in 1812 with a concert in the conducted by Louis Spohr.\nWith the Sixth Coalition forming after French defeat in Russia, on 24 February 1813 Napoleon ordered the Petersburg Citadel to prepare for siege, visiting the city on 25 April to inspect the fortifications, in particular both Citadels. On 10 July 1813, Napoleon put Alexandre d'Alton, baron of the Empire, in charge of the defences of Erfurt. However, when the French decreed that 1000 men would be conscripted into the , the recruits were joined by other citizens in rioting on 19 July that led to 20 arrests, of whom 2 were sentenced to death by French court-martial; as a result, the French ordered the closure of all inns and alehouses.\nWithin a week of the Sixth Coalition's decisive victory at Leipzig (16\u201319 October 1813), however, Erfurt was besieged by Prussian, Austrian and Russian troops under the command of Prussian Lt Gen von Kleist. After a first capitulation signed by d'Alton on 20 December 1813 the French troops withdrew to the two fortresses of Petersberg and Cyriaksburg, allowing for the Coalition forces to march into Erfurt on 6 January 1814 to jubilant greetings; the ' ceremonial column was burned and destroyed as a symbol of the citizens' oppression under the French; similarly the ' was burned on 1 November 1813 and completely destroyed by Erfurters and their besiegers in 1814. After a call for volunteers 3 days later, 300 Erfurters joined the Coalition armies in France. Finally, in May 1814, the French capitulated fully, with 1,700 French troops vacating the Petersberg and Cyriaksburg fortresses. During the two and a half months of siege, the mortality rate rose in the city greatly; 1,564 Erfurt citizens died in 1813, around a thousand more than the previous year.\nAfter the Congress of Vienna, Erfurt was restored to Prussia on 21 June 1815, becoming the capital of one of the three districts (\"\") of the new Province of Saxony, but some southern and eastern parts of Erfurter lands joined Blankenhain in being transferred to the Grand Duchy of Saxe-Weimar-Eisenach the following September. Although enclosed by Thuringian territory in the west, south and east, the city remained part of the Prussian Province of Saxony until 1944.\nSince 1815.\nAfter the 1848 Revolution, many Germans desired to have a united national state. An attempt in this direction was the failed Erfurt Union of German states in 1850.\nThe Industrial Revolution reached Erfurt in the 1840s, when the Thuringian Railway connecting Berlin and Frankfurt was built. During the following years, many factories in different sectors were founded. One of the biggest was the \"Royal Gun Factory of Prussia\" in 1862. After the Unification of Germany in 1871, Erfurt moved from the southern border of Prussia to the centre of Germany, so the fortifications of the city were no longer needed. The demolition of the city fortifications in 1873 led to a construction boom in Erfurt, because it was now possible to build in the area formerly occupied by the city walls and beyond. Many public and private buildings emerged and the infrastructure (such as a tramway, hospitals, and schools) improved rapidly. The number of inhabitants grew from 40,000 around 1870 to 130,000 in 1914 and the city expanded in all directions.\nThe \"Erfurt Program\" was adopted by the Social Democratic Party of Germany during its congress at Erfurt in 1891.\nBetween the wars, the city kept growing. Housing shortages were fought with building programmes and social infrastructure was broadened according to the welfare policy in the Weimar Republic. The Great Depression between 1929 and 1932 led to a disaster for Erfurt, nearly one out of three became unemployed. Conflicts between far-left and far-right-oriented milieus increased and many inhabitants supported the new Nazi government and Adolf Hitler. Others, especially some communist workers, put up resistance against the new administration. In 1938, the new synagogue was destroyed during the . Jews lost their property and emigrated or were deported to Nazi concentration camps (together with many communists). In 1914, the company \"Topf and Sons\" began the manufacture of crematoria later becoming the market leader in this industry. Under the Nazis, \"JA Topf &amp; Sons\" supplied specially developed crematoria, ovens and associated plants to the Auschwitz-Birkenau, Buchenwald and Mauthausen-Gusen concentration camps. On 27 January 2011 a memorial and museum dedicated to the Holocaust victims was opened at the former company premises in Erfurt.\nDuring World War II, Erfurt experienced more than 27 British and American air raids, about 1600 civilians died. Bombed as a target of the Oil Campaign of World War II, Erfurt suffered only limited damage and was captured on 12 April 1945, by the US 80th Infantry Division. On 3 July, American troops left the city, which then became part of the Soviet Zone of Occupation and eventually of the German Democratic Republic (East Germany). In 1948, Erfurt became the capital of Thuringia, replacing Weimar. In 1952, the in the GDR were dissolved in favour of centralization under the new socialist government. Erfurt then became the capital of a new \" (district). In 1953, the of education was founded, followed by the of medicine in 1954, the first academic institutions in Erfurt since the closing of the university in 1816.\nOn 19 March 1970, the East and West German heads of government Willi Stoph and Willy Brandt met in Erfurt, the first such meeting since the division of Germany. During the 1970s and 1980s, as the economic situation in GDR worsened, many old buildings in city centre decayed, while the government fought against the housing shortage by building large settlements in the periphery. The Peaceful Revolution of 1989/1990 led to German reunification.\nWith the re-formation of the state of Thuringia in 1990, the city became the state capital. After reunification, a deep economic crisis occurred in Eastern Germany. Many factories closed and many people lost their jobs and moved to the former West Germany. At the same time, many buildings were redeveloped and the infrastructure improved massively. In 1994, the new university was opened, as was the Fachhochschule in 1991. Between 2005 and 2008, the economic situation improved as the unemployment rate decreased and new enterprises developed. In addition, the population began to increase once again.\nA school shooting occurred on 26 April 2002 at the Gutenberg-Gymnasium.\nSince the 1990s, organized crime has gained a foothold in Erfurt, with several mafia groups, including the Armenian mafia present in the city. Among other events, there has been a robbery and an arson attack targeting the gastronomy sector and in 2014 there was a shoot-out in an open street.\nGeography.\nTopography.\nErfurt is situated in the south of the Thuringian basin, a fertile agricultural area between the Harz mountains to the north and the Thuringian forest to the southwest. Whereas the northern parts of the city area are flat, the southern ones consist of hilly landscape up to 430 m of elevation. In this part lies the municipal forest of \" with beeches and oaks as main tree species. To the east and to the west are some non-forested hills so that the Gera river valley within the town forms a basin. North of the city are some gravel pits in operation, while others are abandoned, flooded and used as leisure areas.\nClimate.\nErfurt has a humid continental climate (\"Dfb\") or an oceanic climate (\"Cfb\") according to the K\u00f6ppen climate classification system. Summers are warm and sometimes humid with average high temperatures of and lows of . Winters are relatively cold with average high temperatures of and lows of . The city's topography creates a microclimate caused by the location inside a basin with sometimes inversion in winter (quite cold nights under ) and inadequate air circulation in summer. Annual precipitation is only with moderate rainfall throughout the year. Light snowfall mainly occurs from December through February, but snow cover does not usually remain for long.\nAdministrative divisions.\nErfurt abuts the districts of S\u00f6mmerda (municipalities Witterda, Elxleben, Walschleben, Riethnordhausen, N\u00f6da, Alperstedt, Gro\u00dfrudestedt, Udestedt, Kleinm\u00f6lsen and Gro\u00dfm\u00f6lsen) in the north, Weimarer Land (municipalities Niederzimmern, Nohra, M\u00f6nchenholzhausen and Klettbach) in the east, Ilm-Kreis (municipalities Kirchheim, Rockhausen and Amt Wachsenburg) in the south and Gotha (municipalities Nesse-Apfelst\u00e4dt, Nottleben, Zimmernsupra and Bienst\u00e4dt) in the west.\nThe city itself is divided into 53 districts. The centre is formed by the district ' (old town) and the districts ' in the northwest, ' in the northeast, ' in the east, ' in the southeast, ' in the southwest and ' in the west. More former industrial districts are ' (incorporated in 1911), ' and ' in the north. Another group of districts is marked by Plattenbau settlements, constructed during the DDR period: ', ', ', ' and ' in the northern as well as ', ' and ' in the southern city parts.\nFinally, there are many villages with an average population of approximately 1,000 which were incorporated during the 20th century; however, they have mostly stayed rural to date:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nErfurt-Southeast.\nErfurt-Southeast (German: Erfurt-S\u00fcdost) is the collective name for a series of prefabricated housing areas that emerged in the south-east of Erfurt in the last ten years of the GDR .\nThe districts of Melchendorf , Herrenberg and Wiesen H\u00fcgel belong to Erfurt-S\u00fcdost , all of which were formed from the former local area of Melchendorf. The village of Melchendorf with around 1000 inhabitants lies between the prefabricated building areas. In addition to the old village, the district of Melchendorf also includes the prefab housing areas of Drosselberg and Buchenberg as well as several four-story apartment blocks from the 1950s and 1960s on Kranichfelder Strasse. Around 24,000 people still live in the large settlement, which was once designed for almost 40,000 inhabitants.\nIn addition to Erfurt-Nord, Erfurt-S\u00fcdost is the second large prefabricated building area in the state capital. The problems associated with large housing estates are not as pronounced in the Southeast as in the North, but they are still present. (German: \"Erfurt-S\u00fcdost\") is the collective name for a series of prefabricated housing areas that emerged in the south-east of Erfurt in the last ten years of the GDR .\nThe districts of Melchendorf , Herrenberg and Wiesen H\u00fcgel belong to Erfurt-S\u00fcdost , all of which were formed from the former local area of Melchendorf. The village of Melchendorf with around 1000 inhabitants lies between the prefabricated building areas. In addition to the old village, the district of Melchendorf also includes the prefab housing areas of Drosselberg and Buchenberg as well as several four-story apartment blocks from the 1950s and 1960s on Kranichfelder Strasse. Around 24,000 people still live in the large settlement, which was once designed for almost 40,000 inhabitants.\nIn addition to Erfurt-Nord, Erfurt-S\u00fcdost is the second large prefabricated building area in the state capital. The problems associated with large housing estates are not as pronounced in the Southeast as in the North, but they are still present.\nPopulation.\nAround the year 1500, the city had 18,000 inhabitants and was one of the largest cities in the Holy Roman Empire. The population then more or less stagnated until the 19th century. The population of Erfurt was 21,000 in 1820, and increased to 32,000 in 1847, the year of rail connection as industrialization began. In the following decades Erfurt grew up to 130,000 at the beginning of World War I and 190,000 inhabitants in 1950. A maximum was reached in 1988 with 220,000 persons. In 1991, after the German reunification and when Erfurt became the capital of Thuringia state, it had a population of about 205,000. The bad economic situation in eastern Germany after the reunification resulted in a decline in population, which fell to 200,000 in 2002 before rising again to 206,000 in 2011. The average growth of population between 2009 and 2012 was approximately 0.68% p. a, whereas the population in bordering rural regions is shrinking with accelerating tendency. Suburbanization played only a small role in Erfurt. It occurred after reunification for a short time in the 1990s, but most of the suburban areas were situated within the administrative city borders. Erfurt is also the 10th largest city in Germany by area with area of .\nThe birth deficit was 200 in 2012, this is \u22121.0 per 1,000 inhabitants (Thuringian average: -4.5; national average: -2.4). The net migration rate was +8.3 per 1,000 inhabitants in 2012 (Thuringian average: -0.8; national average: +4.6). The most important regions of origin of Erfurt migrants are rural areas of Thuringia, Saxony-Anhalt and Saxony as well as foreign countries like Poland, Russia, Syria, Afghanistan and Hungary. Erfurt is today one of the popular cities in former East Germany due to its universities and broadcasting companies.\nLike other eastern German cities, foreigners account only for a small share of Erfurt's population: circa 3.0% are non-Germans by citizenship and overall 5.9% are migrants (according to the 2011 EU census).\nDue to the official atheism of the former GDR, most of the population is non-religious. 14.8% are members of the Evangelical Church in Central Germany and 6.8% are Catholics (according to the 2011 EU census). The Jewish Community consists of 500 members. Most of them migrated to Erfurt from Russia and Ukraine in the 1990s.\nCulture, sights and cityscape.\nResidents notable in cultural history.\nThe theologian, philosopher and mystic Meister Eckhart (c. 1260\u20131328) entered the Dominican monastery () in Erfurt when he was aged about 18 (around 1275). Eckhart was the Dominican prior at Erfurt from 1294 until 1298, and Vicar of Thuringia from 1298 to 1302. After a year in Paris, he returned to Erfurt in 1303 and administered his duties as Provincial of Saxony from there until 1311.\nMartin Luther (1483\u20131546) studied law and philosophy at the University of Erfurt from 1501. He lived in St\u00a0Augustine's Monastery in Erfurt, as a friar from 1505 to 1511.\nJohann Pachelbel (1653\u20131706) served as organist at the (Preachers Church) in Erfurt from June 1678 until August 1690. Pachelbel composed approximately seventy pieces for organ while in Erfurt.\nThe city is the birthplace of one of Johann Sebastian Bach's cousins, Johann Bernhard Bach, as well as Johann Sebastian Bach's father Johann Ambrosius Bach. Bach's parents were married in 1668 in the (Merchant's Church) that still exists on the main square of .\nAlexander M\u00fcller (1808\u20131863), pianist, conductor and composer, was born in Erfurt. He later moved to Z\u00fcrich where he served as leader of the General Music Society's subscription concerts series.\nMax Weber (1864\u20131920) was born in Erfurt. He was a sociologist, philosopher, lawyer, and political economist whose ideas have profoundly influenced modern social theory and social research.\nAfter 1906 the composer Richard Wetz (1875\u20131935) lived in Erfurt and became the leading person in the city's musical life. His major works were written here, including three symphonies, a Requiem and a Christmas Oratorio.\nThe textile designer Margaretha Reichardt (1907\u20131984) was born and died in Erfurt. She studied at the Bauhaus from 1926 to 1930, and while there worked with Marcel Breuer on his innovative chair designs. Her former home and weaving workshop in Erfurt, the \"Margaretha Reichardt Haus\", is now a museum, managed by the Angermuseum Erfurt.\nFamous contemporary musicians from Erfurt are Clueso, the Boogie Pimps and Yvonne Catterfeld.\nMuseums.\nErfurt has a great variety of museums:\nTheatre.\nSince 2003, the modern opera house is home to Theater Erfurt and its Philharmonic Orchestra. The \"grand stage\" section has 800 seats and the \"studio stage\" can hold 200 spectators. In September 2005, the opera \"Waiting for the Barbarians\" by Philip Glass premiered in the opera house. The Erfurt Theatre has been a source of controversy. In 2005, a performance of Engelbert Humperdinck's opera \"\" stirred up the local press since the performance contained suggestions of pedophilia and incest. The opera was advertised in the programme with the addition \"for adults only\".\nOn 12 April 2008, a version of Verdi's opera \" directed by Johann Kresnik opened at the Erfurt Theatre. The production stirred deep controversy by featuring nude performers in Mickey Mouse masks dancing on the ruins of the World Trade Center and a female singer with a painted on Hitler toothbrush moustache performing a straight arm Nazi salute, along with sinister portrayals of American soldiers, Uncle Sam, and Elvis Presley impersonators. The director described the production as a populist critique of modern American society, aimed at showing up the disparities between rich and poor. The controversy prompted one local politician to call for locals to boycott the performances, but this was largely ignored and the premi\u00e8re was sold out.\nSport.\nThe Messe Erfurt serves as home court for the Oettinger Rockets, a professional basketball team in Germany's first division, the Basketball Bundesliga.\nNotable types of sport in Erfurt are athletics, ice skating, cycling (with the oldest velodrome in use in the world, opened in 1885), swimming, handball, volleyball, tennis and football. The city's football club is member of and based in with a capacity of 20,000. The \" was the second indoor speed skating arena in Germany.\nCityscape.\nErfurt's cityscape features a medieval core of narrow, curved alleys in the centre surrounded by a belt of \" architecture, created between 1873 and 1914. In 1873, the city's fortifications were demolished and it became possible to build houses in the area in front of the former city walls. In the following years, Erfurt saw a construction boom. In the northern area (districts Andreasvorstadt, Johannesvorstadt and Ilversgehofen) tenements for the factory workers were built whilst the eastern area (Kr\u00e4mpfervorstadt and Daberstedt) featured apartments for white-collar workers and clerks and the southwestern part (L\u00f6bervorstadt and Br\u00fchlervorstadt) with its beautiful valley landscape saw the construction of villas and mansions of rich factory owners and notables.\nDuring the interwar period, some settlements in Bauhaus style were realized, often as housing cooperatives.\nAfter World War II and over the whole GDR period, housing shortages remained a problem even though the government started a big apartment construction programme. Between 1970 and 1990 large settlements with high-rise blocks on the northern (for 50,000 inhabitants) and southeastern (for 40,000 inhabitants) periphery were constructed. After reunification the renovation of old houses in city centre and the \" areas was a big issue. The federal government granted substantial subsidies, so that many houses could be restored.\nCompared to many other German cities, little of Erfurt was destroyed in World War II. This is one reason why the centre today offers a mixture of medieval, Baroque and Neoclassical architecture as well as buildings from the last 150 years.\nPublic green spaces are located along Gera river and in several parks like the ', the ' and the \"\". The largest green area is the Egapark, a horticultural exhibition park and botanic garden established in 1961.\nSights and architectural heritage.\nChurches, monasteries and synagogues.\nThe city centre has about 25 churches and monasteries, most of them in Gothic style, some also in Romanesque style or a mixture of Romanesque and Gothic elements, and a few in later styles. The various steeples characterize the medieval centre and led to one of Erfurt's nicknames as the \"Thuringian Rome\".\nSynagogues.\nThe oldest parts of Erfurt's \"Alte Synagoge\" (Old Synagogue) date to the 11th century. It was used until 1349 when the Jewish community was destroyed in a pogrom known as the Erfurt Massacre. The building had many other uses since then. It was conserved in the 1990s and in 2009 it became a museum of Jewish history. A rare Mikveh, a ritual bath, dating from c.1250, was discovered by archeologists in 2007. It has been accessible to visitors on guided tours since September 2011. In 2015 the Old Synagogue and Mikveh were nominated as a World Heritage Site. It has been tentatively listed but a final decision has not yet been made.\nAs religious freedom was granted in the 19th century, some Jews returned to Erfurt. They built their synagogue on the banks of the Gera river and used it from 1840 until 1884. The neoclassical building is known as the \"Kleine Synagoge\" (Small Synagogue). Today it is used an events centre. It is also open to visitors.\nA larger synagogue, the \"Gro\u00dfe Synagoge\" (Great Synagogue), was opened in 1884 because the community had become larger and wealthier. This moorish style building was destroyed during nationwide Nazi riots, known as on 9\u201310 November 1938.\nIn 1947 the land which the Great Synagogue had occupied was returned to the Jewish community and they built their current place of worship, the \"Neue Synagoge\" (New Synagogue) which opened in 1952. It was the only synagogue building erected under communist rule in East Germany.\nSecular architecture.\nBesides the religious buildings there is a lot of historic secular architecture in Erfurt, mostly concentrated in the city centre, but some 19th- and 20th-century buildings are located on the outskirts. \nFortifications.\nFrom 1066 until 1873 the old town of Erfurt was encircled by a fortified wall. About 1168 this was extended to run around the western side of Petersberg hill, enclosing it within the city boundaries.\nAfter German Unification in 1871, Erfurt became part of the newly created German Empire. The threat to the city from its Saxon neighbours and from Bavaria was no longer present, so it was decided to dismantle the city walls. Only a few remnants remain today. A piece of inner wall can be found in a small park at the corner Juri-Gagarin-Ring and Johannesstra\u00dfe and another piece at the flood ditch (\"Flutgraben\") near Franckestra\u00dfe. There is also a small restored part of the wall in the Br\u00fchler Garten, behind the Catholic orphanage. Only one of the wall's fortified towers was left standing, on Boyneburgufer, but this was destroyed in an air raid in 1944.\nThe Petersberg Citadel is one of the largest and best preserved city fortresses in Europe, covering an area of 36 hectares in the north-west of the city centre. It was built from 1665 on Petersberg hill and was in military use until 1963. Since 1990, it has been significantly restored and is now open to the public as an historic site.\nThe Cyriaksburg Citadel is a smaller citadel south-west of the city centre, dating from 1480. Today, it houses the German horticulture museum.\n19th- and 20th-century architecture in the outskirts.\nBetween 1873 and 1914, a belt of ' architecture emerged around the city centre. The mansion district in the south-west around , and hosts some interesting ' and \"Art Nouveau\" buildings.\nThe \"M\u00fchlenviertel\" (\"mill quarter\"), is an area of beautiful Art Nouveau apartment buildings, cobblestone streets and street trees just to the north of the old city, in the vicinity of Nord Park, bordered by the Gera river on its east side. The Schmale Gera stream runs through the area. In the Middle Ages numerous small enterprises using the power of water mills occupied the area, hence the name \"M\u00fchlenviertel\", with street names such as Waidm\u00fchlenweg (woad, or indigo, mill way), Storchm\u00fchlenweg (stork mill way) and Papierm\u00fchlenweg (paper mill way).\nThe \"Bauhaus\" style is represented by some housing cooperative projects in the east around and and in the north around . Lutherkirke Church in (1927), is an Art Deco building.\nThe former malt factory \"Wolff\" at in the east of Erfurt is a large industrial complex built between 1880 and 1939, and in use until 2000. A new use has not been found yet, but the area is sometimes used as a location in movie productions because of its atmosphere.\nExamples of Nazi architecture include the buildings of the (Thuringian parliament) and (an event hall) in the south at . While the building (1930s) represents more the neo-Roman/fascist style, (1940s) is marked by some neo-Germanic \" style elements.\nThe Stalinist early-GDR style is manifested in the main building of the university at (1953) and the later more international modern GDR style is represented by the horticultural exhibition centre \" at , the housing complexes like Rieth or and the redevelopment of and area along in the city centre.\nThe current international glass and steel architecture is dominant among most larger new buildings like the Federal Labour Court of Germany (1999), the new opera house (2003), the new main station (2007), the university library, the Erfurt Messe (convention centre) and the ice rink.\nEconomy and infrastructure.\nDuring recent years, the economic situation of the city improved: the unemployment rate declined from 21% in 2005 to 9% in 2013. Nevertheless, some 14,000 households with 24,500 persons (12% of population) are dependent upon state social benefits (Hartz IV).\nAgriculture, industry and services.\nFarming has a great tradition in Erfurt: the cultivation of woad made the city rich during the Middle Ages. Today, horticulture and the production of flower seeds is still an important business in Erfurt. There is also growing of fruits (like apples, strawberries and sweet cherries), vegetables (e.g. cauliflowers, potatoes, cabbage and sugar beets) and grain on more than 60% of the municipal territory.\nIndustrialization in Erfurt started around 1850. Until World War I, many factories were founded in different sectors like engine building, shoes, guns, malt and later electro-technics, so that there was no industrial monoculture in the city. After 1945, the companies were nationalized by the GDR government, which led to the decline of some of them. After reunification, nearly all factories were closed, either because they failed to successfully adopt to a free market economy or because the German government sold them to west German businessmen who closed them to avoid competition to their own enterprises. However, in the early 1990s the federal government started to subsidize the foundation of new companies. It still took a long time before the economic situation stabilized around 2006. Since this time, unemployment has decreased and overall, new jobs were created. Today, there are many small and medium-sized companies in Erfurt with electro-technics, semiconductors and photovoltaics in focus. Engine production, food production, the Braugold brewery, and Born Feinkost, a producer of Thuringian mustard, remain important industries.\nErfurt is an \"\" (which means \"supra-centre\" according to Central place theory) in German regional planning. Such centres are always hubs of service businesses and public services like hospitals, universities, research, trade fairs, retail etc. Additionally, Erfurt is the capital of the federal state of Thuringia, so that there are many institutions of administration like all the Thuringian state ministries and some nationwide authorities. Typical for Erfurt are the logistic business with many distribution centres of big companies, the Erfurt Trade Fair and the media sector with KiKa and MDR as public broadcast stations. A growing industry is tourism, due to the various historical sights of Erfurt. There are 4,800 hotel beds and (in 2012) 450,000 overnight visitors spent a total of 700,000 nights in hotels. Nevertheless, most tourists are one-day visitors from Germany. The Christmas Market in December attracts some 2,000,000 visitors each year.\nTransport.\nBy rail.\nThe ICE railway network puts Erfurt 1&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 hours from Berlin, 2&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 hours from Frankfurt, 2 hours from Dresden, and 45 minutes from Leipzig. In 2017, the ICE line to Munich opened, making the trip to Erfurt main station only 2&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 hours.\nThere are regional trains from Erfurt to Weimar, Jena, Gotha, Eisenach, Bad Langensalza, Magdeburg, Nordhausen, G\u00f6ttingen, M\u00fchlhausen, W\u00fcrzburg, Meiningen, Ilmenau, Arnstadt, and Gera.\nIn freight transport there is an intermodal terminal in the district of Vieselbach \"()\" with connections to rail and the autobahn.\nBy road.\nThe two Autobahnen crossing each other nearby at \"Erfurter Kreuz\" are the Bundesautobahn 4 (Frankfurt\u2013Dresden) and the Bundesautobahn 71 (Schweinfurt\u2013Sangerhausen). Together with the east tangent both motorways form a circle road around the city and lead the interregional traffic around the centre. Whereas the A 4 was built in the 1930s, the A 71 came into being after the reunification in the 1990s and 2000s. In addition to both motorways there are two Bundesstra\u00dfen: the Bundesstra\u00dfe 7 connects Erfurt parallel to A 4 with Gotha in the west and Weimar in the east. The Bundesstra\u00dfe 4 is a connection between Erfurt and Nordhausen in the north. Its southern part to Coburg was annulled when A 71 was finished (in this section, the A 71 now effectively serves as B 4). Within the circle road, B 7 and B 4 are also annulled, so that the city government has to pay for maintenance instead of the German federal government. The access to the city is restricted as \" since 2012 for some vehicles. Large parts of the inner city are a pedestrian area which can not be reached by car (except for residents).\nBy light rail and bus.\nThe Erfurt public transport system is marked by the area-wide (light rail) network, established as a tram system in 1883, upgraded to a light rail (\") system in 1997, and continually expanded and upgraded through the 2000s. Today, there are six \"Stadtbahn\" lines running every ten minutes on every light rail route.\nAdditionally, Erfurt operates a bus system, which connects the sparsely populated outer districts of the region to the city center. Both systems are organized by \"SWE EVAG\", a transit company owned by the city administration. Trolleybuses were in service in Erfurt from 1948 until 1975, but are no longer in service.\nBy airplane.\nErfurt-Weimar Airport lies west of the city centre. It is linked to the central train station via Stadtbahn (tram). It was significantly extended in the 1990s, with flights mostly to Mediterranean holiday destinations and to London during the peak Christmas market tourist season. Connections to longer haul flights are easily accessible via Frankfurt Airport, which can be reached in 2 hours via a direct train from Frankfurt Airport to Erfurt, and from Leipzig/Halle Airport, which can be reached within half an hour.\nBy bike.\nBiking is becoming increasingly popular since construction of high quality cycle tracks began in the 1990s. There are cycle lanes for general commuting within Erfurt city.\nLong-distance trails, such as the \"Gera track\" and the \"\" (Thuringian cities trail), connect points of tourist interest. The former runs along the Gera river valley from the Thuringian forest to the river Unstrut; the latter follows the medieval Via Regia from Eisenach to Altenburg via Gotha, Erfurt, Weimar, and Jena.\nThe Rennsteig Cycle Way was opened in 2000. This designated high-grade hiking and bike trail runs along the ridge of the Thuringian Central Uplands. The bike trail, about long, occasionally departs from the course of the historic Rennsteig hiking trail, which dates back to the 1300s, to avoid steep inclines. It is therefore about longer than the hiking trail.\nThe Rennsteig is connected to the E3 European long distance path, which goes from the Atlantic coast of Spain to the Black Sea coast of Bulgaria, and the E6 European long distance path, running from Arctic Finland to Turkey.\nEducation.\nAfter reunification, the educational system was reorganized. The University of Erfurt, founded in 1379 and closed in 1816, was refounded in 1994 with a focus on social sciences, modern languages, humanities and teacher training. Today there are approximately 6,000 students working within four faculties, the Max Weber Center for Advanced Cultural and Social Studies, and three academic research institutes. The university has an international reputation and participates in international student exchange programmes.\nThe \"Fachhochschule Erfurt\", is a university of applied sciences, founded in 1991, which offers a combination of academic training and practical experience in subjects such as social work and social pedagogy, business studies, and engineering. There are nearly 5,000 students in six faculties, of which the faculty of landscaping and horticulture has a national reputation.\nThe International University of Applied Sciences Bad Honnef \u2013 Bonn (IUBH), is a privately run university with a focus on business and economics. It merged with the former Adam-Ries-Fachhochschule in 2013.\nThe world renowned Bauhaus design school was founded in 1919 in the city of Weimar, approximately from Erfurt, 12 minutes by train. The buildings are now part of a World Heritage Site and are today used by the Bauhaus-Universit\u00e4t Weimar, which teaches design, arts, media and technology related subjects.\nFurthermore, there are eight ', six state-owned, one Catholic and one Protestant (Evangelisches Ratsgymnasium Erfurt). One of the state-owned schools is a ', an elite boarding school for young talents in athletics, swimming, ice skating or football. Another state-owned school, \"\", offers a focus in sciences as an elite boarding school in addition to the common curriculum.\nMedia.\nThe German national public television children's channel \"KiKa\" is based in Erfurt.\nMDR, Mitteldeutscher Rundfunk, a radio and television company, has a broadcast centre and studios in Erfurt.\nThe Th\u00fcringer Allgemeine is a statewide newspaper that is headquartered in the city.\nPolitics.\nMayor and city council.\nThe first freely elected mayor after German reunification was Manfred Ruge of the Christian Democratic Union, who served from 1990 to 2006. Since 2006, Andreas Bausewein of the Social Democratic Party (SPD) has been mayor. The most recent mayoral election was held on 15 April 2018, with a runoff held on 29 April, and the results were as follows:\nThe most recent city council election was held on 26 May 2019, and the results were as follows:\nTwin towns \u2013 sister cities.\nErfurt is twinned with:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9482", "revid": "18872885", "url": "https://en.wikipedia.org/wiki?curid=9482", "title": "Enya", "text": "Irish singer (born 1961)\nEithne P\u00e1draig\u00edn N\u00ed Bhraon\u00e1in (anglicised as Enya Patricia Brennan; born 17 May 1961), known mononymously as Enya, is an Irish singer, songwriter, and musician. Noted for her modern Celtic music, she is a best-selling Irish solo artist and the second-best-selling Irish musical act overall after the rock band U2.\nBorn into a musical family and raised in the Irish-speaking area of Gaoth Dobhair, Enya began her career in 1980 when she joined her family's Celtic folk band Clannad. She left Clannad in 1982 to pursue a solo career with Clannad's manager and producer, Nicky and Roma Ryan as her lyricists. Over the following four years, she developed her sound by combining multitracked vocals and keyboards with elements of musical genres such as Celtic, classical, church, new age, world, pop, and Irish folk.\nEnya's first solo projects included soundtrack work for \"The Frog Prince\" (1985) and the BBC documentary series \"The Celts\" (1986), which was released as her debut album \"Enya\" (1987). She signed with Warner Music UK, which granted her considerable artistic freedom and minimal interference. The commercial and critical success of \"Watermark\" (1988) propelled her to worldwide fame, helped mostly by the international hit single \"Orinoco Flow (Sail Away)\". This was followed by the multi-million-selling albums \"Shepherd Moons\" (1991), \"The Memory of Trees\" (1995), and \"A Day Without Rain\" (2000). Sales of \"A Day Without Rain\" and its lead single, \"Only Time\", surged in the United States following its use in media coverage of the 9/11 attacks. After \"Amarantine\" (2005) and \"And Winter Came...\" (2008), Enya took a four-year break from music, returning in 2012 to begin work on her eighth studio album \"Dark Sky Island\" (2015).\nEarly life.\nEithne P\u00e1draig\u00edn N\u00ed Bhraon\u00e1in was born in the Dore area of Gweedore on 17 May 1961, the sixth of nine children born to Catholic parents who were part of the Brennan family of musicians. Her father, Leo Brennan, was the leader of an Irish showband called the Slieve Foy Band and ran Leo's Tavern in Meenaleck. Her mother, M\u00e1ire (n\u00e9e Duggan), had distant Spanish roots with ancestors who settled on Tory Island, and was an amateur musician who played in the Slieve Foy Band. She also taught music at Gweedore Community School. Enya grew up in Gweedore, a region where Irish is the primary language. Her name is anglicised as Enya Patricia Brennan, with \"Enya\" being the phonetic spelling of how \"Eithne\" is pronounced in her native Ulster dialect. \"N\u00ed Bhraon\u00e1in\" translates to \"daughter of Brennan\". \nEnya's maternal grandfather, Aodh, was the headmaster of the primary school in Dore where her grandmother was a teacher. Aodh was also the founder of the Gweedore Theatre company. Enya described her upbringing as \"very quiet and happy\". At age three, she took part in her first singing competition at the annual Feis Ceoil music festival. She took part in pantomimes at Gweedore Theatre and sang with her siblings in her mother's choir at St. Mary's church in Derrybeg. She learned English in primary school and began piano lessons at age four. She later said, \"I had to do school work and then travel to a neighboring town for piano lessons, and then more school work. I remember my brothers and sisters playing outside and I would be inside playing the piano, this one big book of scales, practising them over and over.\" From the age of 11, Enya attended a convent boarding school in Milford run by the Sisters of Loreto, and her education there was paid for by her grandfather. The boarding school was where Enya developed a taste for classical music, art, Latin, and watercolor painting. She said, \"It was devastating to be torn away from such a large family but it was good for my music.\" Enya left the school at age 17 and studied classical music in college for one year, intending to become a piano teacher because she \"never thought of [herself] composing or being on stage\".\nCareer.\n1980\u20131985: Clannad and early solo career.\nIn 1970, several members of Enya's family formed Clannad, a Celtic folk band. Clannad hired Nicky Ryan as their manager, sound engineer, and producer, and Ryan's future wife, Roma Ryan, as tour manager and administrator. In 1980, after her year at college, Enya decided not to pursue a music degree at university and instead accepted Ryan's invitation to join Clannad, having wanted to expand their sound with keyboards and an additional vocalist. Enya performed an uncredited role on their sixth studio album, \"Crann \u00dall\" (1980), with a line-up of siblings M\u00e1ire, P\u00f3l, and Ciar\u00e1n Brennan, and twin uncles Noel and P\u00e1draig Duggan. She features in their follow-up, \"Fuaim\" (1981), as a full-time member. Nicky said it was not his intention to make Enya a permanent member, as she was \"fiercely independent [...] intent on playing her own music. She was just not sure of how to go about it.\" This sparked discussions between the two on layering vocals to create a \"choir of one\", a concept inspired by Phil Spector's Wall of Sound technique that had interested them.\nDuring a Clannad tour in 1982, Nicky called for a band meeting to address internal issues that had arisen. He recalled: \"It was short and only required a vote, I was a minority of one and lost. Roma and I were out. This left the question of what happened with Enya. I decided to stand back and say nothing.\" Enya chose to leave with the Ryans and pursue a solo career, having felt confined in the group and disliked being \"somebody in the background\". The split caused some friction between the parties, but they settled their differences.\nNicky suggested to Enya that either she return to Gweedore \"with no particular definite future\", or live with him and Roma in Artane, Dublin, \"and see what happens, musically\", which Enya accepted. After their bank denied them a loan, Enya sold her saxophone and gave piano lessons for income. The Ryans used what they could afford to build a recording facility in their garden shed which they named Aigle Studio, after the French word for eagle. They also rented the studio out to other musicians to help recoup the costs. The trio formed a musical and business partnership, with Nicky as Enya's producer and arranger and Roma as her lyricist. They called their company Aigle Music. In the following two years, Enya developed her technique and composition by listening to recordings of her reciting pieces of classical music and repeated this process until she started to improvise sections and develop her own arrangements. Her first composition was \"An Aibhse Uaighneach\", Irish for \"The Lonely Ghost\". During this time Enya played the synthesiser on \"Ceol Aduaidh\" (1983) by Mair\u00e9ad N\u00ed Mhaonaigh and Frankie Kennedy, and declined an offer by Mike Oldfield to sing on his single \"Moonlight Shadow\".\nEnya's first solo endeavour arrived in 1983 when she recorded two piano instrumentals, \"An Ghaoth \u00d3n Ghrian\", Irish for \"The Solar Wind\", and \"Miss Clare Remembers\". Both were recorded at Windmill Lane Studios in Dublin and released on \"Touch Travel\" (1984), a limited-release cassette of music from various artists on the Touch label. She is credited as Eithne N\u00ed Bhraon\u00e1in in the liner notes. After several months of preparation, Enya's first live solo performance took place at the National Stadium in Dublin on 23 September 1983, which was televised for RT\u00c9's music show \"Festival Folk\". Niall Morris, a musician who worked with her during this time, recalled she \"was so nervous she could barely get on stage, and she cowered behind the piano until the gig was over\".\nMorris assisted Enya in the production of a demo tape, adding additional keyboards to her compositions. Roma thought the music would suit accompanying visuals and sent it to various film producers. Among them was David Puttnam, who liked the tape and offered Enya to compose the soundtrack to his upcoming romantic comedy film, \"The Frog Prince\" (1984). Enya scored nine pieces for the film; later, against her wishes, the pieces were rearranged and orchestrated by Richard Myhill, except for two pieces in which she sang, \"The Frog Prince\" and \"Dreams\". The words to \"Dreams\" were penned by Charlie McGettigan. The film editor Jim Clark said the rearrangements were necessary as Enya found it difficult to compose to the picture. Released in 1985, the album is the first commercial release that credits her as \"Enya\". Nicky Ryan suggested the phonetic spelling of her name, thinking that Eithne would be mispronounced by non-Irish speakers. Enya looked back at her composition work on the film as a good career move, but a disappointing one as \"we weren't part of it at the end\". Also in 1985, she sang on three tracks on \"Ordinary Man\" (1985) by Christy Moore.\n1985\u20131989: \"The Celts\" and \"Watermark\".\nIn 1985, producer Tony McAuley asked Enya to contribute a track for the six-part BBC television documentary series \"The Celts\". She had already written a Celtic-influenced song called \"The March of the Celts\", and submitted it to the project. Each episode was to feature a different composer at first, but director David Richardson liked her track so much that he had Enya score the entire series. Enya recorded 72 minutes of music at Aigle Studio and the BBC studios in Wood Lane, London, without recording to the picture. She was required to portray certain themes and ideas that the producers wanted; but unlike \"The Frog Prince\", she worked with little interference which granted her freedom to establish the sound that she would adopt throughout her future career, signified by layered vocals, keyboard-oriented music, and percussion with elements of Celtic, classical, church, and folk music.\nIn March 1987, two months before \"The Celts\" aired, a 40-minute selection of Enya's score was released as her debut solo album, \"Enya\", by BBC Records in the United Kingdom and by Atlantic Records in the United States. The latter promoted it with a new-age imprint on the packaging, which Nicky later thought was \"a cowardly thing for them to do\". The album gained enough public attention to reach number 8 on the Irish Albums Chart and number 69 on the UK Albums Chart. \"I Want Tomorrow\" was released as Enya's first single. \"Boadicea\" was sampled by The Fugees on their 1996 song \"Ready or Not\"; the group neither sought permission nor gave credit. Enya took legal action and the group subsequently gave her credit; they paid a fee of approximately $3 million. Later in 1987, Enya appeared on Sin\u00e9ad O'Connor's debut album \"The Lion and the Cobra\", reciting Psalm 91 in Irish on \"Never Get Old\".\nSeveral weeks after the release of \"Enya\", Enya secured a recording contract with Warner Music UK after Rob Dickins, the label's chairman and a fan of Clannad, took a liking to \"Enya\" and found himself playing it \"every night before I went to bed\". He later met Enya and the Ryans at a chance meeting at the Irish Recorded Music Association award ceremony in Dublin, where he learned that Enya had entered negotiations with a rival label. Dickins seized the opportunity and signed her, in doing so granting her wish to write and record with artistic freedom, minimal interference from the label, and without set deadlines to finish albums. Dickins said: \"Sometimes you sign an act to make money, and sometimes you sign an act to make music. This was the latter... I just wanted to be involved with this music.\" Enya left Atlantic and signed with the Warner-led Geffen Records to handle her American distribution.\nWith the green-light to produce a new album, Enya recorded \"Watermark\" from June 1987 to April 1988. It was initially recorded in analogue at Aigle before Dickins requested to have it re-recorded digitally at Orinoco Studios in Bermondsey, London. \"Watermark\" was released in September 1988 and became an unexpected hit, reaching number 5 in the United Kingdom and number 25 on the \"Billboard\" 200 in the United States following its release there in January 1989. Its lead single, \"Orinoco Flow\", was the last song written for the album. It was not intended to be a single at first, but Enya and the Ryans chose it after Dickins jokingly asked for a single; he knew that Enya's music was not made for the Top 40 chart. Dickins and engineer Ross Cullum are referenced in the song's lyrics. \"Orinoco Flow\" became an international top 10 hit and was number one in the United Kingdom for three weeks. The new-found success propelled Enya to international fame and she received endorsement deals and offers to use her music in television commercials. She spent one year traveling worldwide to promote the album which increased her exposure through interviews, appearances, and live performances.\n1989\u20131997: \"Shepherd Moons\" and \"The Memory of Trees\".\nAfter promoting \"Watermark\", Enya purchased new recording equipment and started work on her next album, \"Shepherd Moons\". She found that the success of \"Watermark\" caused a considerable amount of pressure when it came to writing new songs, stating, \"I kept thinking, 'Would this have gone on \"Watermark\"? Is it as good?' Eventually I had to forget about this and start on a blank canvas and just really go with what felt right\". \nEnya wrote songs based on several ideas, including entries from her diary, the Blitz in London, and her grandparents. \"Shepherd Moons\" was released in November 1991, her first album released under Warner-led Reprise Records in the United States. It became a greater commercial success than \"Watermark\", reaching number one in the UK for one week and number 17 in the United States. \"Caribbean Blue\", its lead single, charted at number 13 in the United Kingdom.\nIn 1991, Warner Music released a collection of five Enya music videos as \"Moonshadows\" for home video. In 1993 Enya won her first Grammy Award in the Best New Age Album category for \"Shepherd Moons\". Soon after, Enya and Nicky entered discussions with Industrial Light &amp; Magic, founded by George Lucas, regarding an elaborate stage lighting system for a proposed concert tour, but nothing resulted from those discussions. In November 1992, Warner obtained the rights to \"Enya\" and re-released the album as \"The Celts\" with new artwork. It surpassed its initial sale performance, reaching number 10 in the UK.\nAfter traveling worldwide to promote \"Shepherd Moons\", Enya started to write and record her fourth album, \"The Memory of Trees\". The album was released in November 1995. It peaked at number 5 in the UK and number 9 in the US, where it sold over 3 million copies. Its lead single, \"Anywhere Is\", reached number 7 in the UK. The second, \"On My Way Home\", reached number 26 in the UK. In late 1994, Enya put out an extended play of Christmas music titled \"The Christmas EP\". Enya was offered to compose the film score for \"Titanic\" but declined as it would be a collaboration, rather than solely her composition. A recording of her singing \"O\u00edche Chi\u00fain\", an Irish-language version of \"Silent Night\", appeared on the charity album \"A Very Special Christmas 3\", released in benefit of the Special Olympics in October 1997.\nIn early 1997, Enya began to select tracks for her first compilation album, \"trying to select the obvious ones, the hits, and others.\" She chose to work on the collection following the promotional tour for \"The Memory of Trees\" as she felt it was the right time in her career, and that her contract with WEA required her to release a \"best of\" album. The set, named \"Paint the Sky with Stars: The Best of Enya\", features two new tracks, \"Paint the Sky with Stars\" and \"Only If...\". Released in November 1997, the album was a worldwide commercial success, reaching number 4 in the UK and number 30 in the US, where it went on to sell over 4 million copies. \"Only If...\" was released as a single in 1997. Enya described the album as \"like a musical diary... each melody has a little story and I live through that whole story from the beginning... your mind goes back to that day and what you were thinking.\"\n1998\u20132007: \"A Day Without Rain\" and \"Amarantine\".\nEnya started work on her fifth studio album, titled \"A Day Without Rain\", in mid-1998. In a departure from her previous albums, she incorporated the use of a string section into her compositions, something that was not a conscious decision at first, but Enya and Nicky Ryan agreed that it complemented the songs that were being written. The album was released in November 2000 and reached number 6 in the UK and an initial peak of number 17 in the US.\nIn the aftermath of the 11 September attacks, sales of the album and its lead single, \"Only Time\", surged after the song was widely used during radio and television coverage of the events, leading to its description as \"a post-September 11 anthem\". The exposure caused \"A Day Without Rain\" to outperform its original chart performance to peak at number 2 on the \"Billboard\" 200, and the release of a maxi-single containing the original and a pop remix of \"Only Time\" in November 2001. Enya donated its proceeds in aid of the International Association of Firefighters. The song topped the \"Billboard\" Hot Adult Contemporary Tracks chart and went to number 10 on the Hot 100 singles, Enya's highest charting US single to date.\nIn 2001, Enya agreed to write and perform on two tracks for the of \"\" (2001) at the request of director Peter Jackson. Its composer Howard Shore \"imagined her voice\" as he wrote the film's score, making an uncommon exception to include another artist in one of his soundtracks. After flying to New Zealand to observe the filming and to watch a rough cut of the film, Enya returned to Ireland and composed \"An\u00edron\" (the theme for Aragorn and Arwen), with lyrics by Roma in J. R. R. Tolkien's fictional Elvish language Sindarin, and \"May It Be\", sung in English and another Tolkien language, Quenya. Shore then based his orchestrations around Enya's recorded vocals and themes to create \"a seamless sound\". In 2002, Enya released \"May It Be\" as a single which earned her an Academy Award nomination for Best Original Song. She performed the song live with an orchestra at the 74th Academy Awards ceremony in March 2002, and later cited the moment as a career highlight.\nEnya undertook additional studio projects in 2001 and 2002. The first was work on the soundtrack of the Japanese romantic film \"Calmi Cuori Appassionati\" (2001), which was subsequently released as \"Themes from Calmi Cuori Appassionati\" (2001). The album is formed of tracks spanning her career from \"Enya\" to \"A Day Without Rain\" with two B-sides. The album went to number 2 in Japan and became Enya's second album to sell one million copies in the country.\nIn September 2003, Enya returned to Aigle Studio to start work on her sixth studio album, \"Amarantine\". Roma said the title means \"everlasting\". The album marks the first instance of Enya singing in Loxian, a fictional language created by Roma that came about when Enya was working on \"Water Shows the Hidden Heart\". After numerous attempts to sing the song in English, Irish, and Latin, Roma suggested a new language based on some of the sounds Enya would sing along to when developing her songs. It was a success, and Enya sang \"Less Than a Pearl\" and \"The River Sings\" in the same way. Roma worked on the language further, creating a \"culture and history\" behind it surrounding the Loxian people who are on another planet, questioning the existence of life outside of Earth. \"Sumiregusa (Wild Violet)\" is sung in Japanese. \"Amarantine\" was a global success, reaching number 6 on the \"Billboard\" 200 and number 8 in the UK. It has sold over 1 million certified copies in the US, a considerable drop in sales in comparison to her previous albums. Enya dedicated the album to BBC producer Tony McAuley who had commissioned Enya to write the soundtrack to \"The Celts\", following his death in 2003. The lead single, \"Amarantine\", was released in December 2005.\nIn June 2007, Enya received an honorary doctorate from the National University of Ireland, Galway. A month later, she also received one from the University of Ulster.\n2008\u2013present: \"And Winter Came...\" and \"Dark Sky Island\".\nEnya wrote music with a winter and Christmas theme for her seventh studio album, \"And Winter Came...\" Initially, she intended to make an album of seasonal songs and hymns set for a release in late 2007 but decided to produce a winter-themed album instead. The track \"My! My! Time Flies!\", a tribute to the late Irish guitarist Jimmy Faulkner, incorporates a guitar solo performed by Pat Farrell, the first use of a guitar on an Enya album since \"I Want Tomorrow\" from \"Enya\". The lyrics also include atypical pop-culture references, such as The Beatles' famous photo shoot for the cover of \"Abbey Road\". Upon its release in November 2008, \"And Winter Came...\" reached number 6 in the UK and number 8 in the US and sold almost 3.5 million copies worldwide by 2011.\nAfter promoting \"And Winter Came...\", Enya took an extended break from writing and recording music. She spent her time resting, visiting family in Australia, and renovating her new home in the south of France. In March 2009, her first four studio albums were reissued in Japan in the Super High Material CD format with bonus tracks. Her second compilation album, \"The Very Best of Enya\", was released in November 2009 and featured songs from 1987 to 2008, including a previously unreleased version of \"An\u00edron\" and a DVD compiling most of her music videos to date. In 2013, \"Only Time\" was used in the \"Epic Split\" advertisement by Volvo Trucks starring Jean-Claude Van Damme who does the splits while suspended between two lorries.\nIn 2012, Enya returned to the studio to record her eighth album, \"Dark Sky Island\". Its name refers to the island of Sark, which became the first island to be designated a dark-sky preserve, and a series of poems on islands by Roma Ryan. Upon its release on 20 November 2015, \"Dark Sky Island\" went to number 4 in the UK, Enya's highest charting studio album there since \"Shepherd Moons\" went to number 1, and to number 8 in the US. A Deluxe Edition features three additional songs. Enya completed a promotional tour of the UK, Europe, the US, and Japan. During her visit to Japan, Enya performed \"Orinoco Flow\" and \"Echoes in Rain\" at the Universal Studios Japan Christmas show in Osaka. In December 2016, Enya appeared on the Irish television show \"Christmas Carols from Cork\", marking her first Irish television appearance in over seven years. She sang \"Adeste Fideles\", \"Oiche Chi\u00fain\", and \"The Spirit of Christmas Past\".\nIn November 2020, a \"watch party\" video was posted on Enya's official YouTube channel to commemorate the 20th anniversary of \"A Day Without Rain\", and included written introductory messages from Enya and the Ryans. The trio did the same thing for the 30th anniversary of \"Shepherd Moons\", on 4 November 2021. In his introductory message, Nicky Ryan said that they used the downtime from the COVID-19 pandemic to renovate Aigle Studio and install new recording equipment and instruments. He stated that when the work is finished, Enya will start working on new music.\nMusical style.\nEnya's vocal range has been described as mezzo-soprano. She has cited her musical foundations as \"the classics\", church music, and \"Irish reels and jigs\" with a particular interest in Sergei Rachmaninoff, a favourite composer of hers. She has an autographed picture of him in her home. Since 1982, she has recorded her music with Nicky Ryan as producer and arranger and his wife Roma Ryan as a lyricist. While in Clannad, Enya chose to work with Nicky as the two shared an interest in vocal harmonies, and Ryan, influenced by The Beach Boys and the \"Wall of Sound\" technique that Phil Spector pioneered, wanted to explore the idea of \"the multivocals\" for which her music became known. According to Enya, \"Angeles\" from \"Shepherd Moons\" has roughly 500 vocals recorded individually and layered. Enya performs all vocals and the majority of instruments in her songs, apart from guest musicians, playing percussion, guitar, violin, uilleann pipes, cornet, and double bass. Her early works, including \"Watermark,\" feature numerous keyboards, including the Yamaha KX88 Master, Yamaha DX7, Oberheim Matrix, Kurzweil K250, E-mu Emulator II, Akai S900, Roland D-50 (famously used with the Pizzagogo patch in \"Orinoco Flow\"), and the Roland Juno-60, the latter a particular favorite of hers.\nNumerous critics and reviewers classify Enya's albums as new-age music and she has won four Grammy Awards in the category. However, Enya does not classify her music as part of the genre. When asked what genre she would classify her music, she replied \"Enya\". Nicky Ryan commented on the new age designation: \"Initially it was fine, but it's really not new age. Enya plays a whole lot of instruments, not just keyboards. Her melodies are strong and she sings a lot. So I can't see a comparison.\" The music video for \"Caribbean Blue\" and the artwork for \"The Memory of Trees\" feature adapted works from artist Maxfield Parrish.\nIn addition to her native Irish, Enya has recorded songs in languages including English, French, Latin, Spanish, and Welsh. She has recorded music influenced by works from fantasy author J. R. R. Tolkien, including the instrumental \"Lothl\u00f3rien\" from \"Shepherd Moons\". For \"\", she sang \"May It Be\" in English and Tolkien's fictional language Quenya, and she sang \"An\u00edron\" in another of Tolkien's fictional languages, Sindarin. \"Amarantine\" and \"Dark Sky Island\" include songs sung in Loxian, a fictional language created by Roma Ryan, that has no official syntax. Its vocabulary was formed by Enya singing the song's notes to which Roma wrote their phonetic spelling.\nEnya adopted a composing and songwriting method that has deviated little throughout her career. At the start of the recording process for an album, she enters the studio, forgetting about her previous success, fame, and songs of hers that became hits. \"If I did that\", she said, \"I'd have to call it a day\". She then develops ideas on the piano, keeping note of any arrangement that can be worked on further. During her time writing, Enya works a five-day week, takes weekends off, and does not work on her music at home. With Irish as her first language, Enya initially records her songs in Irish as she can express \"feeling much more directly\" in Irish than in English. After some time, Enya presents her ideas to Nicky to discuss what pieces work best, while Roma works in parallel to devise lyrics for the songs. Enya considered \"Fallen Embers\" from \"A Day Without Rain\" a perfect time when the lyrics reflect how she felt while writing the song. In 2008, she newly discovered her tendency to write \"two or three songs\" during the winter months, work on the arrangements and lyrics the following spring and summer, and then work on the next couple of songs when autumn arrives.\nLive performances.\nEnya says that Warner Music and she \"did not see eye to eye\" initially as the label imagined her performing on stage \"with a piano... maybe two or three synthesizer players and that's it\". Enya also explained that the time put into her studio albums caused her to \"run overtime\", leaving little time to plan for other such projects. She also expressed the difficulty in recreating her studio-oriented sound for the stage. In 1996, Ryan said Enya had received an offer worth almost \u00a3500,000 to perform a concert in Japan. In 2016, Enya spoke about the prospect of a live concert when she revealed talks with the Ryans during her three-year break after \"And Winter Came...\" (2008) to perform a show at the Metropolitan Opera House in New York City that would be simulcast to cinemas worldwide. Before such an event could happen, Nicky suggested that she enter a studio and record \"all the hits\" live with an orchestra and choir to see how they would sound.\nEnya has sung with live and lip-syncing vocals on various talk and music shows, events, and ceremonies throughout her career, most often during her worldwide press tours for each album. In December 1995, she performed \"Anywhere Is\" at a Christmas concert at Vatican City with Pope John Paul II in attendance; he later met and thanked her for performing. In April 1996, Enya performed the same song during her surprise appearance at the fiftieth birthday celebration for Carl XVI Gustaf, the king of Sweden and a fan of Enya's. In 1997, Enya participated in a live Christmas Eve broadcast in London and flew to County Donegal afterward to join her family for their annual midnight Mass choral performance, in which she participates each year. In March 2002, she performed \"May It Be\" with an orchestra at the year's Academy Awards ceremony. Enya and her sisters performed as part of the local choir Cor Mhuire in July 2005 at St. Mary's church in Gweedore during the annual Earagail Arts Festival.\nLegacy.\nIn 1991, a minor planet first discovered in 1978, 6433 Enya, was named after her. In 2017, a newly discovered species of fish, \"Leporinus enyae\", found in the Orinoco River drainage area, was also named after her.\nPersonal life.\nKnown for her staunchly private lifestyle, Enya has said, \"The music is what sells. Not me, or what I stand for... that's the way I've always wanted it.\" She is unmarried and has no children, but has many nieces and nephews and is considered an aunt to the Ryans' two daughters, having shared their Artane home for some years. In 1991, she said, \"I'm afraid of marriage because I'm afraid someone might want me because of who I am instead of because they loved me... I wouldn't go rushing into anything unexpected, but I do think a great deal about this.\" A relationship she had with one man ended in 1997, around the time when she considered taking time out of music to have a family, but found she was putting pressure on herself over the matter and \"gone the route [she] wanted to go\". She has identified herself as \"more spiritual than religious\" and has said that she sometimes prays, but prefers \"going into churches when they're empty\".\nAt an auction in 1997, Enya spent an estimated \u20ac3.8 million on a 157-year-old Victorian Grade-A listed castellated mansion in Killiney. Formerly known as Victoria Castle and Ayesha Castle, she renamed it Manderley Castle after the house featured in Daphne du Maurier's novel \"Rebecca\" (1938). She spent seven years and approximately \u20ac300,000 renovating the property and installing considerable security measures because of threats from stalkers. The improvements covered gaps in the castle's outer wall, installed new solid timber entrance gates and iron railings, and brought the surrounding of stone wall up to a new height of . In late 2005, the property had two security breaches; during one incident, two people attacked and tied up one of her housekeepers before stealing several items. Enya alerted police by raising an alarm from her safe room.\nDiscography.\nThe discography of Enya includes 26.5 million certified album sales in the United States and an estimated 80 million record sales worldwide, making her one of the best-selling musicians of all time. \"A Day Without Rain\" is the best-selling new-age album, with an estimated 16 million copies sold worldwide. Enya's awards include seven World Music Awards, four Grammy Awards for Best New Age Album, and an Ivor Novello Award. She was nominated for an Academy Award and a Golden Globe Award for \"May It Be\", a song she wrote for the film \"\" (2001).\nStudio albums\nAwards and nominations.\nBillboard Music Awards\n&lt;templatestyles src=\"Template:Awards table/styles.css\" /&gt;\nGrammy Awards\n&lt;templatestyles src=\"Template:Awards table/styles.css\" /&gt;\nIFPI Hong Kong Top Sales Music Awards\n&lt;templatestyles src=\"Template:Awards table/styles.css\" /&gt;\nJapan Gold Disc Awards.\n&lt;templatestyles src=\"Template:Awards table/styles.css\" /&gt;\nWorld Music Awards\n&lt;templatestyles src=\"Template:Awards table/styles.css\" /&gt;\n\u017deb\u0159\u00edk Music Awards\n&lt;templatestyles src=\"Template:Awards table/styles.css\" /&gt;\nOther awards\n&lt;templatestyles src=\"Template:Awards table/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources"}
{"id": "9483", "revid": "36800263", "url": "https://en.wikipedia.org/wiki?curid=9483", "title": "East Berlin", "text": "Soviet sector of Berlin between 1949 and 1990\nEast Berlin (; ] ()) was the partially recognised capital city of East Germany (GDR) from 1949 to 1990, although it was recognised by the Three Powers (United States, United Kingdom, and France) as the Soviet occupation sector of Berlin, established in 1945. The American, British, and French sectors were known as West Berlin. From 13 August 1961 until 9 November 1989, East Berlin was separated from West Berlin by the Berlin Wall. The Western Allied powers did not recognize East Berlin as the GDR's capital, nor the GDR's authority to govern East Berlin. On 3 October 1990, the day Germany was officially reunified, East and West Berlin formally reunited as the city of Berlin.\nOverview.\nWith the London Protocol of 1944 signed on 12 September 1944, the United States, the United Kingdom, and the Soviet Union decided to divide Germany into three occupation zones and to establish a special area of Berlin, which was occupied by the three Allied Forces together. In May 1945, the Soviet Union installed a city government for the whole city that was called \"Magistrate of Greater Berlin\", which existed until 1947. After the war, the Allied Forces initially administered the city together within the Allied Kommandatura, which served as the governing body of the city. However, in 1948 the Soviet representative left the Kommandatura and the common administration broke apart during the following months. In the Soviet sector, a separate city government was established, which continued to call itself the \"Magistrate of Greater Berlin\".\nWhen the German Democratic Republic was established in 1949, it immediately claimed East Berlin as its capital\u2014a claim that was recognized by all communist countries. Nevertheless, its representatives to the were not directly elected and did not have full voting rights until 1981.\nIn June 1948, all railways and roads leading to West Berlin were blocked, and East Berliners were not allowed to emigrate. Nevertheless, more than 1,000 East Germans were escaping to West Berlin each day by 1960, caused by the strains on the East German economy from war reparations owed to the Soviet Union, massive destruction of industry, and lack of assistance from the Marshall Plan. In August 1961, the East German Government tried to stop the population exodus by enclosing West Berlin within the Berlin Wall. It was very dangerous for fleeing residents to cross because armed soldiers were trained to shoot illegal migrants.\nEast Germany was a socialist republic. Eventually, Christian churches were allowed to operate without restraint after years of harassment by authorities. In the 1970s, the wages of East Berliners rose and working hours fell.\nThe Soviet Union and the Communist Bloc recognized East Berlin as the GDR's capital. However, Western Allies (the United States, United Kingdom, and France) never formally acknowledged the authority of the East German government to govern East Berlin. Official Allied protocol recognized only the authority of the Soviet Union in East Berlin in accordance with the occupation status of Berlin as a whole. The United States Command Berlin, for example, published detailed instructions for U.S. military and civilian personnel wishing to visit East Berlin. In fact, the three Western commandants regularly protested against the presence of the East German National People's Army in East Berlin, particularly on the occasion of military parades. Nevertheless, the three Western Allies eventually established embassies in East Berlin in the 1970s, although they never recognized it as the capital of East Germany. Treaties instead used terms such as \"seat of government\".\nOn 3 October 1990, East and West Germany and East and West Berlin were reunited, thus formally ending the existence of East Berlin. Citywide elections in December 1990 resulted in the first \"all-Berlin\" mayor being elected to take office in January 1991, with the separate offices of mayors in East and West Berlin expiring at the time, and Eberhard Diepgen (a former mayor of West Berlin) became the first elected mayor of a reunited Berlin.\nEast Berlin today.\nSince reunification, the German government has spent vast amounts of money on reintegrating the two halves of the city and bringing services and infrastructure in the former East Berlin up to the standard established in West Berlin.\nAfter reunification, the East German economy suffered significantly. Under the adopted policy of privatization of state-owned firms under the auspices of the , many East German factories were shut down\u2014which also led to mass unemployment\u2014due to gaps in productivity with and investment compared to West German companies, as well as an inability to comply with West German pollution and safety standards in a way that was deemed cost-effective. Because of this, a massive amount of West German economic aid was poured into East Germany to revitalize it. This stimulus was part-funded through a 7.5% tax on income for individuals and companies (in addition to normal income tax or company tax) known as the \"\" (SolZG) or \"solidarity surcharge\", which though only in effect for 1991\u20131992 (later reintroduced in 1995 at 7.5 and then dropped down to 5.5% in 1998 and continues to be levied to this day) led to a great deal of resentment toward the East Germans.\nDespite the large sums of economic aid poured into East Berlin, there still remain obvious differences between the former East and West Berlins. East Berlin has a distinct visual style; this is partly due to the greater survival of prewar fa\u00e7ades and streetscapes, with some still showing signs of wartime damage. The unique look of Socialist Classicism that was used in East Berlin (along with the rest of the former GDR) also contrasts markedly with the urban development styles employed in the former West Berlin. Additionally, the former East Berlin (along with the rest of the former GDR) retains a small number of its GDR-era street and place names commemorating German socialist heroes, such as Karl-Marx-Allee, Rosa-Luxemburg-Platz, and Karl-Liebknecht-Stra\u00dfe. Many such names, however, were deemed inappropriate (for various reasons) and, through decommunization, changed after a long process of review (so, for instance, Leninallee reverted to Landsberger Allee in 1991, and Dimitroffstra\u00dfe reverted to Danziger Stra\u00dfe in 1995).\nAnother symbolic icon of the former East Berlin (and of East Germany as a whole) is the (tr. \"little traffic light men\"), a stylized version of a fedora-wearing man crossing the street, which is found on traffic lights at many pedestrian crosswalks throughout the former East. Following a civic debate about whether the should be abolished or disseminated more widely (due to concerns of consistency), several crosswalks in some parts of the former West Berlin also employ the .\nTwenty-five years after the two cities were reunified, the people of East and West Berlin still had noticeable differences between them, which became more apparent among the older generations. The two groups also had sometimes-derogatory slang terms to refer to each other. A former East Berliner (or East German) was known as an \"'\" (from the German word for east, '), and a former West Berliner (or West German) was known as a \"'\" (from the German word for west, '). Both sides also engaged in stereotyping the other. A stereotypical ' had little ambition or poor work ethic and was chronically bitter, while a stereotypical ' was arrogant, selfish, impatient and pushy.\nBoroughs.\nAt the time of German reunification, East Berlin comprised the boroughs of\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9485", "revid": "182", "url": "https://en.wikipedia.org/wiki?curid=9485", "title": "Electronic instruments", "text": ""}
{"id": "9486", "revid": "16490385", "url": "https://en.wikipedia.org/wiki?curid=9486", "title": "List of international environmental agreements", "text": "This is a list of international environmental agreements.\nMost of the following agreements are legally binding for countries that have formally ratified them. Some, such as the Kyoto Protocol, differentiate between types of countries and each nation's respective responsibilities under the agreement. Several hundred international environmental agreements exist but most link only a limited number of countries. These bilateral or sometimes trilateral agreements are only binding for the countries that have ratified them but are nevertheless essential in the international environmental regime. Including the major conventions listed below, more than 3,000 international environmental instruments have been identified by the IEA Database Project.\n&lt;templatestyles src=\"Template:TOC_left/styles.css\" /&gt;\nAlphabetical order.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9487", "revid": "44795365", "url": "https://en.wikipedia.org/wiki?curid=9487", "title": "Epsilon", "text": "Fifth letter of the Greek alphabet\nEpsilon (, ; uppercase ', lowercase ' or lunate ; ) is the fifth letter of the Greek alphabet, corresponding phonetically to a ] or ]. In the system of Greek numerals it also has the value five. It was derived from the Phoenician letter He . Letters that arose from epsilon include the Roman E, \u00cb and \u0190, and Cyrillic \u0415, \u00c8, \u0401, \u0404 and \u042d.\nThe name of the letter was originally (]), but it was later changed to ( 'simple e') in the Middle Ages to distinguish the letter from the digraph , a former diphthong that had come to be pronounced the same as epsilon.\nThe uppercase form of epsilon is identical to Latin E but has its own code point in Unicode: . The lowercase version has two typographical variants, both inherited from medieval Greek handwriting. One, the most common in modern typography and inherited from medieval minuscule, looks like a reversed number \"3\" and is encoded . The other, also known as lunate or uncial epsilon and inherited from earlier uncial writing, looks like a semicircle crossed by a horizontal bar: it is encoded . While in normal typography these are just alternative font variants, they may have different meanings as mathematical symbols: computer systems therefore offer distinct encodings for them. In TeX, codice_1 ( formula_1 ) denotes the lunate form, while codice_2 ( formula_2 ) denotes the reversed-3 form. In the Unicode version 1.0.0, the lunate form was used as the lowercase epsilon letter, while the version 2.0.0 and onwards use the reversed-3 form as the lowercase epsilon letter.\nThere is also a 'Latin epsilon', \u025b or \"open e\", which looks similar to the Greek lowercase epsilon. It is encoded in Unicode as and and is used as an IPA phonetic symbol. The lunate or uncial epsilon provided inspiration for the euro sign, \u20ac.\nThe lunate epsilon, \u03f5, is not to be confused with the set membership symbol \u2208; nor should the Latin uppercase epsilon, \u0190, be confused with the Greek uppercase \u03a3 (sigma). The symbol formula_3, first used in set theory and logic by Giuseppe Peano and now used in mathematics in general for set membership (\"belongs to\") evolved from the letter epsilon, since the symbol was originally used as an abbreviation for the Latin word . In addition, mathematicians often read the symbol \u2208 as \"element of\", as in \"1 is an element of the natural numbers\" for formula_4, for example. As late as 1960, \u03b5 itself was used for set membership, while its negation \"does not belong to\" (now \u2209) was denoted by \u03b5' (epsilon prime). Only gradually did a fully separate, stylized symbol take the place of epsilon in this role. In a related context, Peano also introduced the use of a backwards epsilon, \u03f6, for the phrase \"such that\", although the abbreviation \"s.t.\" is occasionally used in place of \u03f6 in informal cardinals.\nHistory.\nOrigin.\nThe letter \u0395 was adopted from the Phoenician letter He () when Greeks first adopted alphabetic writing. In archaic Greek writing, its shape is often still identical to that of the Phoenician letter. Like other Greek letters, it could face either leftward or rightward (), depending on the current writing direction, but, just as in Phoenician, the horizontal bars always faced in the direction of writing. Archaic writing often preserves the Phoenician form with a vertical stem extending slightly below the lowest horizontal bar. In the classical era, through the influence of more cursive writing styles, the shape was simplified to the current E glyph.\nSound value.\nWhile the original pronunciation of the Phoenician letter \"He\" was [h], the earliest Greek sound value of \u0395 was determined by the vowel occurring in the Phoenician letter name, which made it a natural choice for being reinterpreted from a consonant symbol to a vowel symbol denoting an [e] sound. Besides its classical Greek sound value, the short /e/ phoneme, it could initially also be used for other [e]-like sounds. For instance, in early Attic before c.\u2009500 BC, it was used also both for the long, open /\u025b\u02d0/, and for the long close /e\u02d0/. In the former role, it was later replaced in the classic Greek alphabet by Eta (\u0397), which was taken over from eastern Ionic alphabets, while in the latter role it was replaced by the digraph spelling \u0395\u0399.\nEpichoric alphabets.\nSome dialects used yet other ways of distinguishing between various e-like sounds.\nIn Corinth, the normal function of \u0395 to denote /e/ and /\u025b\u02d0/ was taken by a glyph resembling a pointed B (), while \u0395 was used only for long close /e\u02d0/. The letter Beta, in turn, took the deviant shape .\nIn Sicyon, a variant glyph resembling an X () was used in the same function as Corinthian .\nIn Thespiai (Boeotia), a special letter form consisting of a vertical stem with a single rightward-pointing horizontal bar () was used for what was probably a raised variant of /e/ in pre-vocalic environments. This tack glyph was used elsewhere also as a form of \"Heta\", i.e. for the sound /h/.\nGlyph variants.\nAfter the establishment of the canonical classical Ionian (Euclidean) Greek alphabet, new glyph variants for \u0395 were introduced through handwriting. In the uncial script (used for literary papyrus manuscripts in late antiquity and then in early medieval vellum codices), the \"lunate\" shape () became predominant. In cursive handwriting, a large number of shorthand glyphs came to be used, where the cross-bar and the curved stroke were linked in various ways. Some of them resembled a modern lowercase Latin \"e\", some a \"6\" with a connecting stroke to the next letter starting from the middle, and some a combination of two small \"c\"-like curves. Several of these shapes were later taken over into minuscule book hand. Of the various minuscule letter shapes, the inverted-3 form became the basis for lower-case Epsilon in Greek typography during the modern era.\nUses.\nInternational Phonetic Alphabet.\nDespite its pronunciation as , in the International Phonetic Alphabet, the Latin epsilon represents open-mid front unrounded vowel, as in the English word \"pet\" .\nSymbol.\nThe uppercase Epsilon is not commonly used outside of the Greek language because of its similarity to the Latin letter E. However, it is commonly used in structural mechanics with Young's Modulus equations for calculating tensile, compressive and areal strain.\nThe Greek lowercase epsilon , the lunate epsilon symbol , and the Latin lowercase epsilon (see above) are used in a variety of places:\nUnicode.\nThese characters are used only as mathematical symbols. Stylized Greek text should be encoded using the normal Greek letters, with markup and formatting to indicate text style.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9488", "revid": "4119380", "url": "https://en.wikipedia.org/wiki?curid=9488", "title": "Eta", "text": "Seventh letter in the Greek alphabet\nEta (uppercase \u0397, lowercase \u03b7; \"\u0113\u0302ta\" ] or \"ita\" ]) is the seventh letter of the Greek alphabet, representing the close front unrounded vowel ]. Originally denoting the voiceless glottal fricative ] in most dialects, its sound value in the classical Attic dialect of Ancient Greek was a long open-mid front unrounded vowel ], raised to ] in hellenistic Greek, a process known as iotacism or itacism.\nIn the ancient Attic number system (Herodianic or acrophonic numbers), the number 100 was represented by \"\u0397\", because it was the initial of , the ancient spelling of = \"one hundred\". In the later system of (Classical) Greek numerals eta represents 8. \nEta was derived from the Phoenician letter heth . Letters that arose from eta include the Latin H and the Cyrillic letter \u0418 and \u0419.\nHistory.\nConsonant h.\nThe letter shape 'H' was originally used in most Greek dialects to represent the voiceless glottal fricative ]. In this function, it was borrowed in the 8th century BC by the Etruscan and other Old Italic alphabets, which were based on the Euboean form of the Greek alphabet. This also gave rise to the Latin alphabet with its letter H.\nOther regional variants of the Greek alphabet (epichoric alphabets), in dialects that still preserved the sound ], employed various glyph shapes for consonantal \"heta\" side by side with the new vocalic \"eta\" for some time. \nIn the southern Italian colonies of Heracleia and Tarentum, the letter shape was reduced to a \"half-heta\" lacking the right vertical stem (\u0370). From this sign later developed the sign for rough breathing or \"spiritus asper\", which brought back the marking of the ] sound into the standardized post-classical (polytonic) orthography.\nDionysius Thrax in the second century BC records that the letter name was still pronounced \"heta\" (\u1f25\u03c4\u03b1), correctly explaining this irregularity by stating \"in the old days the letter \u0397 served to stand for the rough breathing, as it still does with the Romans.\"\nLong e.\nIn the East Ionic dialect, however, the sound ] disappeared by the sixth century BC, and the letter was re-used initially to represent a development of a long open front unrounded vowel ], which later merged in East Ionic with the long open-mid front unrounded vowel ] instead. In 403 BC, Athens took over the Ionian spelling system and with it the vocalic use of H (even though it still also had the ] sound itself at that time). This later became the standard orthography in all of Greece.\nItacism.\nDuring the time of post-classical Koin\u00e9 Greek, the ] sound represented by eta was raised and merged with several other formerly distinct vowels, a phenomenon called \"iotacism\" or \"itacism\", after the new pronunciation of the letter name as \"ita\" instead of \"eta\".\nItacism is continued into Modern Greek, where the letter name is pronounced [\u02c8ita] and represents the close front unrounded vowel ]. It shares this function with several other letters (\u03b9, \u03c5) and digraphs (\u03b5\u03b9, \u03bf\u03b9), which are all pronounced alike.\nCyrillic script.\nEta was also borrowed with the sound value of [i] into the Cyrillic script, where it gave rise to the Cyrillic letter \u0418.\nUses.\nLetter.\nIn Modern Greek, due to iotacism, the letter (pronounced ]) represents a close front unrounded vowel, ]. In Classical Greek, it represented the long open-mid front unrounded vowel ].\nSymbol.\nUpper case.\nThe uppercase letter \u0397 is used as a symbol in textual criticism for the Alexandrian text-type (from Hesychius, its once-supposed editor).\nIn chemistry, the letter H as symbol of enthalpy sometimes is said to be a Greek eta, but since enthalpy comes from \u1f10\u03bd\u03b8\u03ac\u03bb\u03c0\u03bf\u03c2, which begins in a smooth breathing and epsilon, it is more likely a Latin H for 'heat'.\nIn information theory the uppercase Greek letter \u0397 is used to represent the concept of entropy of a discrete random variable.\nLower case.\nThe lowercase letter \u03b7 is used as a symbol in:\nCharacter encodings.\nMathematical Eta.\nThese characters are used only as mathematical symbols. Stylized Greek text should be encoded using the normal Greek letters, with markup and formatting to indicate text style.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9489", "revid": "42408183", "url": "https://en.wikipedia.org/wiki?curid=9489", "title": "Eric Arthur Blair", "text": ""}
{"id": "9491", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=9491", "title": "Eskimo", "text": "Exonym used to describe Indigenous people from the circumpolar region\nEskimo () is an exonym used to refer to two closely related Indigenous peoples: the Inuit (including the Alaska Native I\u00f1upiat, the Canadian Inuit, and the Greenlandic Inuit) and the Yupik (or Yuit) of eastern Siberia and Alaska. A related third group, the Aleut, which inhabit the Aleutian Islands, are generally excluded from the definition of Eskimo. The three groups share a relatively recent common ancestor, and speak related languages belonging to the Eskaleut language family.\nThese circumpolar peoples have traditionally inhabited the Arctic and subarctic regions from eastern Siberia (Russia) to Alaska (United States), Northern Canada, Nunavik, Nunatsiavut, and Greenland.\nMany Inuit, Yupik, Aleut, and other individuals consider the term \"Eskimo\", which is of a disputed etymology, to be unacceptable and even pejorative. Eskimo continues to be used within a historical, linguistic, archaeological, and cultural context. The governments in Canada and the United States have made moves to cease using the term \"Eskimo\" in official documents, but it has not been eliminated, as the word is in some places written into tribal, and therefore national, legal terminology. Canada officially uses the term \"Inuit\" to describe the indigenous Canadian people who are living in the country's northern sectors and are not First Nations or M\u00e9tis. The United States government legally uses \"Alaska Native\" for Native Alaskans including the Yupik, Inuit, and Aleut, but also for non-Eskimo Native Alaskans including the Tlingit, the Haida, the Eyak, and the Tsimshian, in addition to at least nine separate northern Athabaskan/Dene peoples. The designation \"Alaska Native\" applies to enrolled tribal members only, in contrast to individual Eskimo/Aleut persons claiming descent from the world's \"most widespread aboriginal group\". \nThere are between 171,000 and 187,000 Inuit and Yupik, the majority of whom live in or near their traditional circumpolar homeland. Of these, 53,785 (2010) live in the United States, 65,025 (2016) in Canada, and 51,730 (2021) in Greenland. In addition, 16,730 people living in Denmark were born in Greenland, and an unknown number are Siberians. The non-governmental organization (NGO) known as the Inuit Circumpolar Council claims to represent 180,000 people.\nThe non-Inuit sub-branch of the Eskimo branch of the Eskaleut language family consists of four distinct Yupik languages, two of them are used in the Russian Far East as well as on St. Lawrence Island, and two of them are used in western Alaska, southwestern Alaska, and the western part of Southcentral Alaska. The extinct language of the Sirenik people is sometimes claimed to be related to these other languages.\nNomenclature.\nEtymology.\nA variety of theories have been postulated for the etymological origin of the word Eskimo. According to Smithsonian linguist Ives Goddard, etymologically the word derives from the Innu-aimun (Montagnais) word \"ayas\u0306kimew\", meaning \"a person who laces a snowshoe\", and is related to \"husky\" (a breed of dog). The word \"assime\u00b7w\" means \"she laces a snowshoe\" in Innu, and Innu language speakers refer to the neighbouring Mi'kmaq people using words that sound like \"eskimo\". This interpretation is generally confirmed by more recent academic sources.\nIn 1978, Jos\u00e9 Mailhot, a Quebec anthropologist who speaks Innu-aimun (Montagnais), published a paper suggesting that Eskimo meant \"people who speak a different language\". French traders who encountered the Innu (Montagnais) in the eastern areas adopted their word for the more western peoples and spelled it as \"Esquimau\" or \"Esquimaux\" in a transliteration.\nSome people consider \"Eskimo\" offensive, because it is popularly perceived to mean \"eaters of raw meat\" in Algonquian languages common to people along the Atlantic coast. An unnamed Cree speaker suggested the original word that became corrupted to Eskimo might have been \"askamiciw\" (meaning \"he eats it raw\"); the Inuit are referred to in some Cree texts as \"askipiw\" (meaning \"eats something raw\"). Regardless, the term still carries a derogatory connotation for many Inuit and Yupik.\nOne of the first printed uses of the French word \"Esquimaux\" comes from Samuel Hearne's \"A Journey from Prince of Wales's Fort in Hudson's Bay to the Northern Ocean in the Years 1769, 1770, 1771, 1772\" first published in 1795.\nUsage.\nThe term \"Eskimo\" is still used by people to encompass the Inuit and Yupik, as well as other Indigenous or Alaska Native and Siberian peoples. In the 21st century, usage in North America has declined. Linguistic, ethnic, and cultural differences exist between Yupik and Inuit.\nIn Canada and Greenland, and to a certain extent in Alaska, the term \"Eskimo\" is predominantly seen as offensive and has been widely replaced by the term \"Inuit\" or terms specific to a particular group or community. This has resulted in a trend whereby some Canadians and Americans believe that they should use \"Inuit\" even for Yupik who are non-Inuit.\nThe Inuit of Greenland generally refer to themselves as Greenlanders (\"Kalaallit\" or \"Gr\u00f8nl\u00e6ndere\") and speak the Greenlandic language and Danish. The Inuit of Greenland belong to three groups: the Kalaallit of west Greenland, who speak Kalaallisut; the Tunumiit of Tunu (east Greenland), who speak Tunumiit oraasiat (\"East Greenlandic\"); and the Inughuit of north Greenland, who speak Inuktun.\nThe word \"Eskimo\" is a racially charged term in Canada. In Canada's Central Arctic, \"Inuinnaq\" is the preferred term, and in the eastern Canadian Arctic \"Inuit\". The language is often called \"Inuktitut\", though other local designations are also used.\nSection 25 of the Canadian Charter of Rights and Freedoms and section 35 of the Canadian Constitution Act of 1982 recognized the Inuit as a distinctive group of Aboriginal peoples in Canada. Although \"Inuit\" can be applied to all of the Eskimo peoples in Canada and Greenland, that is not true in Alaska and Siberia. In Alaska, the term \"Eskimo\" is still used because it includes both I\u00f1upiat (singular: I\u00f1upiaq), who are Inuit, and Yupik, who are not.\nThe term \"Alaska Native\" is inclusive of (and under U.S. and Alaskan law, as well as the linguistic and cultural legacy of Alaska, refers to) all Indigenous peoples of Alaska, including not only the I\u00f1upiat (Alaskan Inuit) and the Yupik, but also groups such as the Aleut, who share a recent ancestor, as well as the largely unrelated indigenous peoples of the Pacific Northwest Coast and the Alaskan Athabaskans, such as the Eyak people. The term \"Alaska Native\" has important legal usage in Alaska and the rest of the United States as a result of the Alaska Native Claims Settlement Act of 1971. It does not apply to Inuit or Yupik originating outside the state. As a result, the term Eskimo is still in use in Alaska. Alternative terms, such as \"Inuit-Yupik\", have been proposed, but none has gained widespread acceptance. Early 21st century population estimates registered more than 135,000 individuals of Eskimo descent, with approximately 85,000 living in North America, 50,000 in Greenland, and the rest residing in Siberia.\nInuit Circumpolar Council.\nIn 1977, the Inuit Circumpolar Conference (ICC) meeting in Utqia\u0121vik, Alaska, officially adopted \"Inuit\" as a designation for all circumpolar Native peoples, regardless of their local view on an appropriate term. They voted to replace the word \"Eskimo\" with \"Inuit\". Even at that time, such a designation was not accepted by all. As a result, the Canadian government usage has replaced the term \"Eskimo\" with \"Inuit\" (\"Inuk\" in singular).\nThe ICC charter defines \"Inuit\" as including \"the Inupiat, Yupik (Alaska), Inuit, Inuvialuit (Canada), Kalaallit (Greenland) and Yupik (Russia)\". Despite the ICC's 1977 decision to adopt the term \"Inuit\", this has not been accepted by all or even most Yupik people.\nIn 2010, the ICC passed a resolution in which they implored scientists to use \"Inuit\" and \"Paleo-Inuit\" instead of \"Eskimo\" or \"Paleo-Eskimo\".\nAcademic response.\nIn a 2015 commentary in the journal \"Arctic\", Canadian archaeologist Max Friesen argued fellow Arctic archaeologists should follow the ICC and use \"Paleo-Inuit\" instead of \"Paleo-Eskimo\". In 2016, Lisa Hodgetts and \"Arctic\" editor Patricia Wells wrote: \"In the Canadian context, continued use of any term that incorporates \"Eskimo\" is potentially harmful to the relationships between archaeologists and the Inuit and Inuvialuit communities who are our hosts and increasingly our research partners.\"\nHodgetts and Wells suggested using more specific terms when possible (e.g., Dorset and Groswater) and agreed with Frieson in using the \"Inuit tradition\" to replace \"Neo-Eskimo\", although they noted replacement for \"Palaeoeskimo\" was still an open question and discussed \"Paleo-Inuit\", \"Arctic Small Tool Tradition\", and \"pre-Inuit\", as well as Inuktitut loanwords like \"Tuniit\" and \"Sivullirmiut\", as possibilities.\nIn 2020, Katelyn Braymer-Hayes and colleagues argued in the \"Journal of Anthropological Archaeology\" that there is a \"clear need\" to replace the terms \"Neo-Eskimo\" and \"Paleo-Eskimo\", citing the ICC resolution, but finding a consensus within the Alaskan context particularly is difficult, since Alaska Natives do not use the word \"Inuit\" to describe themselves nor is the term legally applicable only to I\u00f1upiat and Yupik in Alaska, and as such, terms used in Canada like \"Paleo Inuit\" and \"Ancestral Inuit\" would not be acceptable.\nAmerican linguist Lenore Grenoble has also explicitly deferred to the ICC resolution and used \"Inuit\u2013Yupik\" instead of \"Eskimo\" with regards to the language branch.\nHistory.\nGenetic evidence suggests that the Americas were populated from northeastern Asia in multiple waves. While the great majority of indigenous American peoples can be traced to a single early migration of Paleo-Indians, the Na-Den\u00e9, Inuit and Indigenous Alaskan populations exhibit admixture from distinct populations that migrated into America at a later date and are closely linked to the peoples of far northeastern Asia (e.g. Chukchi), and only more remotely to the majority indigenous American type. For modern Eskimo\u2013Aleut speakers, this later ancestral component makes up almost half of their genomes. The ancient Paleo-Eskimo population was genetically distinct from the modern circumpolar populations, but eventually derives from the same far northeastern Asian cluster. It is understood that some or all of these ancient people migrated across the Chukchi Sea to North America during the pre-neolithic era, somewhere around 5,000 to 10,000 years ago. It is believed that ancestors of the Aleut people inhabited the Aleutian Chain 10,000 years ago.\nThe earliest positively identified Paleo-Eskimo cultures (Early Paleo-Eskimo) date to 5,000 years ago. Several earlier indigenous peoples existed in the northern circumpolar regions of eastern Siberia, Alaska, and Canada (although probably not in Greenland). The Paleo-Eskimo peoples appear to have developed in Alaska from people related to the Arctic small tool tradition in eastern Asia, whose ancestors had probably migrated to Alaska at least 3,000 to 5,000 years earlier.\nThe Yupik languages and cultures in Alaska evolved in place, beginning with the original pre-Dorset Indigenous culture developed in Alaska. At least 4,000 years ago, the Unangan culture of the Aleut became distinct. It is not generally considered an Eskimo culture. However, there is some possibility of an Aleutian origin of the Dorset people, who in turn are a likely ancestor of today's Inuit and Yupik.\nApproximately 1,500 to 2,000 years ago, apparently in northwestern Alaska, two other distinct variations appeared. Inuit language became distinct and, over a period of several centuries, its speakers migrated across northern Alaska, through Canada, and into Greenland. The distinct culture of the Thule people (drawing strongly from the Birnirk culture) developed in northwestern Alaska. It very quickly spread over the entire area occupied by Eskimo peoples, though it was not necessarily adopted by all of them.\nLanguages.\nLanguage family.\nThe Eskimo\u2013Aleut family of languages includes two cognate branches: the Aleut (Unangan) branch and the Eskimo branch.\nThe number of cases varies, with Aleut languages having a greatly reduced case system compared to those of the Eskimo subfamily. Eskimo\u2013Aleut languages possess voiceless plosives at the bilabial, coronal, velar and uvular positions in all languages except Aleut, which has lost the bilabial stops but retained the nasal. In the Eskimo subfamily a voiceless alveolar lateral fricative is also present.\nThe Eskimo sub-family consists of the Inuit language and Yupik language sub-groups. The Sirenikski language, which is virtually extinct, is sometimes regarded as a third branch of the Eskimo language family. Other sources regard it as a group belonging to the Yupik branch.\nInuit languages comprise a dialect continuum, or dialect chain, that stretches from Unalakleet and Norton Sound in Alaska, across northern Alaska and Canada, and east to Greenland. Changes from western (I\u00f1upiaq) to eastern dialects are marked by the dropping of vestigial Yupik-related features, increasing consonant assimilation (e.g., \"kumlu\", meaning \"thumb\", changes to \"kuvlu\", changes to \"kublu\", changes to \"kulluk\", changes to \"kulluq\",) and increased consonant lengthening, and lexical change. Thus, speakers of two adjacent Inuit dialects would usually be able to understand one another, but speakers from dialects distant from each other on the dialect continuum would have difficulty understanding one another. Seward Peninsula dialects in western Alaska, where much of the I\u00f1upiat culture has been in place for perhaps less than 500 years, are greatly affected by phonological influence from the Yupik languages. Eastern Greenlandic, at the opposite end of the Inuit range, has had significant word replacement due to a unique form of ritual name avoidance.\nEthnographically, Inuit of Greenland belong to three groups: the Kalaallit of west Greenland, who speak Kalaallisut; the Tunumiit of Tunu (east Greenland), who speak Tunumiit oraasiat (\"East Greenlandic\"), and the Inughuit of north Greenland, who speak Inuktun.\nThe four Yupik languages, by contrast, including Alutiiq (Sugpiaq), Central Alaskan Yup'ik, Naukan (Naukanski), and Siberian Yupik, are distinct languages with phonological, morphological, and lexical differences. They demonstrate limited mutual intelligibility. Additionally, both Alutiiq and Central Yup'ik have considerable dialect diversity. The northernmost Yupik languages \u2013 Siberian Yupik and Naukan Yupik \u2013 are linguistically only slightly closer to Inuit than is Alutiiq, which is the southernmost of the Yupik languages. Although the grammatical structures of Yupik and Inuit languages are similar, they have pronounced differences phonologically. Differences of vocabulary between Inuit and any one of the Yupik languages are greater than between any two Yupik languages. Even the dialectal differences within Alutiiq and Central Alaskan Yup'ik sometimes are relatively great for locations that are relatively close geographically.\nDespite the relatively small population of Naukan speakers, documentation of the language dates back to 1732. While Naukan is only spoken in Siberia, the language acts as an intermediate between two Alaskan languages: Siberian Yupik Eskimo and Central Yup'ik Eskimo.\nThe Sirenikski language is sometimes regarded as a third branch of the Eskimo language family, but other sources regard it as a group belonging to the Yupik branch.\nAn overview of the Eskimo\u2013Aleut languages family is given below:\nAleut\nAleut language\nWestern-Central dialects: Atkan, Attuan, Unangan, Bering (60\u201380 speakers)\nEastern dialect: Unalaskan, Pribilof (400 speakers)\nEskimo (Yup'ik, Yuit, and Inuit)\nYupik\nCentral Alaskan Yup'ik (10,000 speakers)\nAlutiiq or Pacific Gulf Yup'ik (400 speakers)\nCentral Siberian Yupik or Yuit (Chaplinon and St Lawrence Island, 1,400 speakers)\nNaukan (700 speakers)\nInuit or Inupik (75,000 speakers)\nI\u00f1upiaq (northern Alaska, 3,500 speakers)\nInuvialuktun (western Canada; together with Siglitun, Natsilingmiutut, Inuinnaqtun and Uummarmiutun 765 speakers)\nInuktitut (eastern Canada; together with Inuktun and Inuinnaqtun, 30,000 speakers)\nKalaallisut (Greenlandic (Greenland, 47,000 speakers)\nInuktun (Avanersuarmiutut, Thule dialect or Polar Eskimo, approximately 1,000 speakers)\nTunumiit oraasiat (East Greenlandic known as Tunumiisut, 3,500 speakers)\nSirenik Eskimo language (Sirenikskiy) (extinct)\nAmerican linguist Lenore Grenoble has explicitly deferred to this resolution and used \"Inuit\u2013Yupik\" instead of \"Eskimo\" with regards to the language branch.\nWords for \"snow\".\nThere has been a long-running linguistic debate about whether or not the speakers of the Eskimo-Aleut language group have an unusually large number of words for snow. The general modern consensus is that, in multiple Eskimo languages, there are, or have been in simultaneous usage, indeed fifty plus words for snow.\nInuit.\nThe Inuit inhabit the Arctic and northern Bering Sea coasts of Alaska in the United States, and Arctic coasts of the Northwest Territories, Nunavut, Quebec, and Labrador in Canada, and Greenland (associated with Denmark). Until fairly recent times, there has been a remarkable homogeneity in the culture throughout this area, which traditionally relied on fish, marine mammals, and land animals for food, heat, light, clothing, and tools. Their food sources primarily relied on seals, whales, whale blubber, walrus, and fish, all of which they hunted using harpoons on the ice. Clothing consisted of robes made of wolfskin and reindeer skin to acclimate to the low temperatures. They maintain a unique Inuit culture.\nGreenland's Inuit.\nGreenlandic Inuit make up 90% of Greenland's population. They belong to three major groups:\nCanadian Inuit.\nCanadian Inuit live primarily in Inuit Nunangat (lit. \"lands, waters and ices of the [Inuit] people\"), their traditional homeland although some people live in southern parts of Canada. Inuit Nunangat ranges from the Yukon\u2013Alaska border in the west across the Arctic to northern Labrador.\nThe Inuvialuit live in the Inuvialuit Settlement Region, the northern part of Yukon and the Northwest Territories, which stretches to the Amundsen Gulf and the Nunavut border and includes the western Canadian Arctic Islands. The land was demarked in 1984 by the Inuvialuit Final Agreement.\nThe majority of Inuit live in Nunavut (a territory of Canada), Nunavik (the northern part of Quebec) and in Nunatsiavut (the Inuit settlement region in Labrador).\nAlaska's I\u00f1upiat.\nThe I\u00f1upiat are the Inuit of Alaska's Northwest Arctic and North Slope boroughs and the Bering Straits region, including the Seward Peninsula. Utqia\u0121vik, the northernmost city in the United States, is above the Arctic Circle and in the I\u00f1upiat region. Their language is known as I\u00f1upiaq. Their current communities include 34 villages across \"I\u00f1upiat Nuna\u014bat\" (I\u00f1upiaq lands) including seven Alaskan villages in the North Slope Borough, affiliated with the Arctic Slope Regional Corporation; eleven villages in Northwest Arctic Borough; and sixteen villages affiliated with the Bering Straits Regional Corporation.\nYupik.\nThe Yupik are indigenous or aboriginal peoples who live along the coast of western Alaska, especially on the Yukon-Kuskokwim delta and along the Kuskokwim River (Central Alaskan Yup'ik); in southern Alaska (the Alutiiq); and along the eastern coast of Chukotka in the Russian Far East and St. Lawrence Island in western Alaska (the Siberian Yupik). The Yupik economy has traditionally been strongly dominated by the harvest of marine mammals, especially seals, walrus, and whales.\nAlutiiq.\nThe Alutiiq language is relatively close to that spoken by the Yupik in the Bethel, Alaska area. But, it is considered a distinct language with two major dialects: the Koniag dialect, spoken on the Alaska Peninsula and on Kodiak Island, and the Chugach dialect, spoken on the southern Kenai Peninsula and in Prince William Sound. Residents of Nanwalek, located on southern part of the Kenai Peninsula near Seldovia, speak what they call Sugpiaq. They are able to understand those who speak Yupik in Bethel. With a population of approximately 3,000, and the number of speakers in the hundreds, Alutiiq communities are working to revitalize their language.\nCentral Alaskan Yup'ik.\n\"Yup'ik\", with an apostrophe, denotes the speakers of the Central Alaskan Yup'ik language, who live in western Alaska and southwestern Alaska from southern Norton Sound to the north side of Bristol Bay, on the Yukon\u2013Kuskokwim Delta, and on Nelson Island. The use of the apostrophe in the name \"Yup'ik\" is a written convention to denote the long pronunciation of the \"p\" sound; but it is spoken the same in other Yupik languages. Of all the Alaska Native languages, Central Alaskan Yup'ik has the most speakers, with about 10,000 of a total Yup'ik population of 21,000 still speaking the language. The five dialects of Central Alaskan Yup'ik include General Central Yup'ik, and the Egegik, Norton Sound, Hooper Bay-Chevak, and Nunivak dialects. In the latter two dialects, both the language and the people are called \"Cup'ik\".\nSiberian Yupik.\nSiberian Yupik reside along the Bering Sea coast of the Chukchi Peninsula in Siberia in the Russian Far East and in the villages of Gambell and Savoonga on St. Lawrence Island in Alaska. The Central Siberian Yupik spoken on the Chukchi Peninsula and on St. Lawrence Island is nearly identical. About 1,050 of a total Alaska population of 1,100 Siberian Yupik people in Alaska speak the language. It is the first language of the home for most St. Lawrence Island children. In Siberia, about 300 of a total of 900 Siberian Yupik people still learn and study the language, though it is no longer learned as a first language by children.\nNaukan.\nAbout 70 of 400 Naukan people still speak Naukanski. The Naukan originate on the Chukot Peninsula in Chukotka Autonomous Okrug in Siberia. Despite the relatively small population of Naukan speakers, documentation of the language dates back to 1732. While Naukan is only spoken in Siberia, the language acts as an intermediate between two Alaskan languages: Siberian Yupik Eskimo and Central Yup'ik Eskimo.\nSirenik Eskimos.\nSome speakers of Siberian Yupik languages used to speak an Eskimo variant in the past, before they underwent a language shift. These former speakers of Sirenik Eskimo language inhabited the settlements of Sireniki, Imtuk, and some small villages stretching to the west from Sireniki along south-eastern coasts of Chukchi Peninsula. They lived in neighborhoods with Siberian Yupik and Chukchi peoples.\nAs early as in 1895, Imtuk was a settlement with a mixed population of Sirenik Eskimos and Ungazigmit (the latter belonging to Siberian Yupik). Sirenik Eskimo culture has been influenced by that of Chukchi, and the language shows Chukchi language influences. Folktale motifs also show the influence of Chuckchi culture.\nThe above peculiarities of this (already extinct) Eskimo language amounted to mutual unintelligibility even with its nearest language relatives: in the past, Sirenik Eskimos had to use the unrelated Chukchi language as a lingua franca for communicating with Siberian Yupik.\nMany words are formed from entirely different roots from in Siberian Yupik, but even the grammar has several peculiarities distinct not only among Eskimo languages, but even compared to Aleut. For example, dual number is not known in Sirenik Eskimo, while most Eskimo\u2013Aleut languages have dual, including its neighboring Siberian Yupikax relatives.\nLittle is known about the origin of this diversity. The peculiarities of this language may be the result of a supposed long isolation from other Eskimo groups, and being in contact only with speakers of unrelated languages for many centuries. The influence of the Chukchi language is clear.\nBecause of all these factors, the classification of Sireniki Eskimo language is not settled yet: Sireniki language is sometimes regarded as a third branch of Eskimo (at least, its possibility is mentioned). Sometimes it is regarded rather as a group belonging to the Yupik branch.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9495", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=9495", "title": "EU", "text": ""}
{"id": "9496", "revid": "1914667", "url": "https://en.wikipedia.org/wiki?curid=9496", "title": "Epiphenomenalism", "text": "Position on the mind\u2013body problem\nEpiphenomenalism is a position on the mind\u2013body problem which holds that physical and biochemical events within the human body (sense organs, neural impulses, and muscle contractions, for example) are the sole cause of mental events (thought, consciousness, and cognition). According to this view, subjective mental events are completely dependent for their existence on corresponding physical and biochemical events within the human body, yet themselves have no influence over physical events. The appearance that subjective mental states (such as intentions) influence physical events is merely an illusion. For instance, fear seems to make the heart beat faster, but according to epiphenomenalism the biochemical secretions of the brain and nervous system (such as adrenaline)\u2014not the experience of fear\u2014is what raises the heartbeat. Because mental events are a kind of overflow that cannot cause anything physical, yet have non-physical properties, epiphenomenalism is viewed as a form of property dualism.\nDevelopment.\nDuring the seventeenth century, Ren\u00e9 Descartes argued that animals are subject to mechanical laws of nature. He defended the idea of automatic behavior, or the performance of actions without conscious thought. Descartes questioned how the immaterial mind and the material body can interact causally. His interactionist model (1649) held that the body relates to the mind through the pineal gland. La Mettrie, Leibniz, and Spinoza all in their own way began this way of thinking. The idea that even if the animal were conscious nothing would be added to the production of behavior, even in animals of the human type, was first voiced by La Mettrie (1745), and then by Cabanis (1802), and was further explicated by Hodgson (1870) and Huxley (1874).\nThomas Henry Huxley agreed with Descartes that behavior is determined solely by physical mechanisms, but he also believed that humans enjoy an intelligent life. In 1874, Huxley argued, in the Presidential Address to the British Association for the Advancement of Science, that animals are conscious automata. Huxley proposed that psychical changes are collateral products of physical changes. Like the bell of a clock that has no role in keeping the time, consciousness has no role in determining behavior.\nHuxley defended automatism by testing reflex actions, originally supported by Descartes. Huxley hypothesized that frogs that undergo lobotomy would swim when thrown into water, despite being unable to initiate actions. He argued that the ability to swim was solely dependent on the molecular change in the brain, concluding that consciousness is not necessary for reflex actions. According to epiphenomenalism, animals experience pain only as a result of neurophysiology.\nIn 1870, Huxley conducted a case study on a French soldier who had sustained a shot in the Franco-Prussian War that fractured his left parietal bone. Every few weeks the soldier would enter a trance-like state, smoking, dressing himself, and aiming his cane like a rifle all while being insensitive to pins, electric shocks, odorous substances, vinegar, noise, and certain light conditions. Huxley used this study to show that consciousness was not necessary to execute these purposeful actions, justifying the assumption that humans are insensible machines. Huxley's mechanistic attitude towards the body convinced him that the brain alone causes behavior.\nIn the early 1900s scientific behaviorists such as Ivan Pavlov, John B. Watson, and B. F. Skinner began the attempt to uncover laws describing the relationship between stimuli and responses, without reference to inner mental phenomena. Instead of adopting a form of eliminativism or mental fictionalism, positions that deny that inner mental phenomena exist, a behaviorist was able to adopt epiphenomenalism in order to allow for the existence of mind. George Santayana (1905) believed that all motion has merely physical causes. Because consciousness is accessory to life and not essential to it, natural selection is responsible for ingraining tendencies to avoid certain contingencies without any conscious achievement involved. By the 1960s, scientific behaviourism met substantial difficulties and eventually gave way to the cognitive revolution. Participants in that revolution, such as Jerry Fodor, reject epiphenomenalism and insist upon the efficacy of the mind. Fodor even speaks of \"epiphobia\"\u2014fear that one is becoming an epiphenomenalist.\nHowever, since the cognitive revolution, there have been several who have argued for a version of epiphenomenalism. In 1970, Keith Campbell proposed his \"new epiphenomenalism\", which states that the body produces a spiritual mind that does not act on the body. How the brain causes a spiritual mind, according to Campbell, is destined to remain beyond our understanding forever (see New Mysterianism). In 2001, David Chalmers and Frank Jackson argued that claims about conscious states should be deduced a priori from claims about physical states alone. They offered that epiphenomenalism bridges, but does not close, the explanatory gap between the physical and the phenomenal realms. These more recent versions maintain that only the subjective, qualitative aspects of mental states are epiphenomenal. Imagine both Pierre and a robot eating a cupcake. Unlike the robot, Pierre is conscious of eating the cupcake while the behavior is under way. This subjective experience is often called a \"quale\" (plural qualia), and it describes the private \"raw feel\" or the subjective \"what-it-is-like\" that is the inner accompaniment of many mental states. Thus, while Pierre and the robot are both doing the same thing, only Pierre has the inner conscious experience.\nFrank Jackson (1982), for example, once espoused the following view:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I am what is sometimes known as a \"qualia freak\". I think that there are certain features of bodily sensations especially, but also of certain perceptual experiences, which no amount of purely physical information includes. Tell me everything physical there is to tell about what is going on in a living brain... you won't have told me about the hurtfulness of pains, the itchiness of itches, pangs of jealousy...\nAccording to epiphenomenalism, mental states like Pierre's pleasurable experience\u2014or, at any rate, their distinctive qualia\u2014are epiphenomena; they are side-effects or by-products of physical processes in the body. If Pierre takes a second bite, it is not caused by his pleasure from the first; If Pierre says, \"That was good, so I will take another bite\", his speech act is not caused by the preceding pleasure. The conscious experiences that accompany brain processes are causally impotent. The mind might simply be a byproduct of other properties such as brain size or pathway activation synchronicity, which are adaptive.\nSome thinkers draw distinctions between different varieties of epiphenomenalism. In \"Consciousness Explained\", Daniel Dennett distinguishes between a purely metaphysical sense of epiphenomenalism, in which the epiphenomenon has no causal impact at all, and Huxley's \"steam whistle\" epiphenomenalism, in which effects exist but are not functionally relevant.\nArguments for.\nA large body of neurophysiological data seems to support epiphenomenalism . Some of the oldest such data is the Bereitschaftspotential or \"readiness potential\" in which electrical activity related to voluntary actions can be recorded up to two seconds before the subject is aware of making a decision to perform the action. More recently Benjamin Libet et al. (1979) have shown that it can take 0.5 seconds before a stimulus becomes part of conscious experience even though subjects can respond to the stimulus in reaction time tests within 200 milliseconds. The methods and conclusions of this experiment have received much criticism (e.g., see the many critical commentaries in Libet's (1985) target article), including fairly recently by neuroscientists such as Peter Tse, who claim to show that the readiness potential has nothing to do with consciousness at all. Recent research on the Event Related Potential also shows that conscious experience does not occur until the late phase of the potential (P3 or later) that occurs 300 milliseconds or more after the event. In Bregman's auditory continuity illusion, where a pure tone is followed by broadband noise and the noise is followed by the same pure tone it seems as if the tone occurs throughout the period of noise. This also suggests a delay for processing data before conscious experience occurs. Popular science author Tor N\u00f8rretranders has called the delay the \"user illusion\", implying that we only have the illusion of conscious control, most actions being controlled automatically by non-conscious parts of the brain with the conscious mind relegated to the role of spectator.\nThe scientific data seem to support the idea that conscious experience is created by non-conscious processes in the brain (i.e., there is subliminal processing that becomes conscious experience). These results have been interpreted to suggest that people are capable of action before conscious experience of the decision to act occurs. Some argue that this supports epiphenomenalism, since it shows that the feeling of making a decision to act is actually an epiphenomenon; the action happens before the decision, so the decision did not cause the action to occur.\nArguments against.\nThe most powerful argument against epiphenomenalism is that it is self-contradictory: if we have knowledge about epiphenomenalism, then our brains know about the existence of the mind, but if epiphenomenalism were correct, then our brains should not have any knowledge about the mind, because the mind does not affect anything physical.\nHowever, some philosophers do not accept this as a rigorous refutation. For example, Victor Argonov states that epiphenomenalism is a questionable, but experimentally falsifiable theory. He argues that the personal mind is not the only source of knowledge about the existence of mind in the world. A creature (even a philosophical zombie) could have knowledge about mind and the mind-body problem by virtue of some innate knowledge. The information about mind (and its problematic properties such as qualia and the hard problem of consciousness) could have been, in principle, implicitly \"written\" in the material world since its creation. Epiphenomenalists can say that God created an immaterial mind and a detailed \"program\" of material human behavior that makes it possible to speak about the mind\u2013body problem. That version of epiphenomenalism seems highly exotic, but it cannot be excluded from consideration by pure theory. However, Argonov suggests that experiments could refute epiphenomenalism. In particular, epiphenomenalism could be refuted if neural correlates of consciousness can be found in the human brain, and it is proven that human speech about consciousness is caused by them.\nSome philosophers, such as Dennett, reject both epiphenomenalism and the existence of qualia with the same charge that Gilbert Ryle leveled against a Cartesian \"ghost in the machine\", that they too are category mistakes. A quale or conscious experience would not belong to the category of objects of reference on this account, but rather to the category of ways of doing things.\nFunctionalists assert that mental states are well described by their overall role, their activity in relation to the organism as a whole. \"This doctrine is rooted in Aristotle's conception of the soul, and has antecedents in Hobbes's conception of the mind as a 'calculating machine', but it has become fully articulated (and popularly endorsed) only in the last third of the 20th century.\" In so far as it mediates stimulus and response, a mental function is analogous to a program that processes input/output in automata theory. In principle, multiple realisability would guarantee platform dependencies can be avoided, whether in terms of hardware and operating system or, \"ex hypothesi\", biology and philosophy. Because a high-level language is a practical requirement for developing the most complex programs, functionalism implies that a non-reductive physicalism would offer a similar advantage over a strictly eliminative materialism.\nEliminative materialists believe \"folk psychology\" is so unscientific that, ultimately, it will be better to eliminate primitive concepts such as \"mind,\" \"desire\" and \"belief,\" in favor of a future neuro-scientific account. A more moderate position such as J. L. Mackie's \"error theory\" suggests that false beliefs should be stripped away from a mental concept without eliminating the concept itself, the legitimate core meaning being left intact.\nBenjamin Libet's results are quoted in favor of epiphenomenalism, but he believes subjects still have a \"conscious veto\", since the readiness potential does not invariably lead to an action. In \"Freedom Evolves\", Daniel Dennett argues that a no-free-will conclusion is based on dubious assumptions about the location of consciousness, as well as questioning the accuracy and interpretation of Libet's results. Similar criticism of Libet-style research has been made by neuroscientist Adina Roskies and cognitive theorists Tim Bayne and Alfred Mele.\nOthers have argued that data such as the Bereitschaftspotential undermine epiphenomenalism for the same reason, that such experiments rely on a subject reporting the point in time at which a conscious experience and a conscious decision occurs, thus relying on the subject to be able to consciously perform an action. That ability would seem to be at odds with early epiphenomenalism, which according to Huxley is the broad claim that consciousness is \"completely without any power\u2026 as the steam-whistle which accompanies the work of a locomotive engine is without influence upon its machinery\". Mind\u2013body dualists reject epiphenomenalism on the same grounds.\nAdrian G. Guggisberg and Anna\u00efs Mottaz have also challenged those findings.\nA study by Aaron Schurger and colleagues published in PNAS challenged assumptions about the causal nature of the readiness potential itself (and the \"pre-movement buildup\" of neural activity in general), thus denying the conclusions drawn from studies such as Libet's and Fried's.\nIn favor of interactionism, Celia Green (2003) argues that epiphenomenalism does not even provide a satisfactory solution to the problem of interaction posed by substance dualism. Although it does not entail substance dualism, according to Green, epiphenomenalism implies a one-way form of interactionism that is just as hard to conceive of as the two-way form embodied in substance dualism. Green suggests the assumption that it is less of a problem may arise from the unexamined belief that physical events have some sort of primacy over mental ones.\nA number of scientists and philosophers, including William James, Karl Popper, John C. Eccles and Donald Symons, dismiss epiphenomenalism from an evolutionary perspective. They point out that the view that mind is an epiphenomenon of brain activity is not consistent with evolutionary theory, because if mind were functionless, it would have disappeared long ago, as it would not have been favoured by evolution.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9497", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=9497", "title": "Esperantio", "text": ""}
{"id": "9498", "revid": "39281725", "url": "https://en.wikipedia.org/wiki?curid=9498", "title": "Esperantujo", "text": "Esperantujo (]) or Esperantio (]) is the Esperanto community; the community of speakers of the Esperanto language and their culture, as well as the places and institutions where the language is used. The term is used \"as if it were a country.\"\nAlthough it does not occupy its own area of Earth's surface, it can be said to constitute the 120 countries which have their own national Esperanto association.\nEtymology and terminology.\nThe word is formed analogously to country names. In Esperanto, the names of countries were traditionally formed from the ethnic name of their inhabitants plus the suffix \"-ujo\". For example, \"France\" was , from (a Frenchman).\nThe term analogous to \"Francujo\" would be \"Esperantistujo\" (Esperantist-nation). However, that would convey the idea of the physical body of people, whereas using the name of the language as the basis of the word gives it the more abstract connotation of a cultural sphere.\nCurrently, names of nation states are often formed with the suffix \"-io\" (traditionally reserved for deriving country names from geographic features\u200a\u2014\u200ae.g. instead of ), and recently the form \"Esperantio\" has been used, among others, in the Pasporta Servo and the Esperanto Citizens' Community.\nHistory.\nIn 1908, Dr. Wilhelm Molly attempted to create an Esperanto state in the Prussian-Belgian condominium of Neutral Moresnet, known as \"Amikejo\" (place of friendship). What became of it is unclear, and Neutral Moresnet was annexed to Belgium in the Treaty of Versailles, 1919.\nDuring the 1960s came a new effort of creating an Esperanto state, which this time was called Republic of Rose Island. The state island stood in the Adriatic Sea near Italy.\nIn Europe on 2 June 2001 a number of organizations (they prefer to call themselves establishments) founded the \"Esperanta Civito\", which \"aims to be a subject of international law\" and \"aims to consolidate the relations between the Esperantists who feel themselves belonging to the diaspora language group which does not belong to any country\". \"Esperanto Civito\" always uses the name Esperantujo (introduced by Hector Hodler in 1908), which itself is defined according to their interpretation of \"raumism\", and the meaning, therefore, may differ from the traditional Esperanto understanding of the word \"Esperantujo\".\nA language learning partner application called Amikumu has been launched in 2017, allowing Esperanto speakers to find each other.\nGeography.\nEsperantujo includes any physical place where Esperanto speakers meet, such as Esperanto gatherings or virtual networks. Sometimes it is said that it is everywhere where Esperanto speakers are connected.\nAlthough Esperantujo does not have its own official territory, a number of places around the world are owned by Esperanto organizations or are otherwise permanently connected to the Esperanto language and its community:\nJudging by the members of the World Esperanto Association, the countries with the most Esperanto speakers are (in descending order): Brazil, Germany, Japan, France, the United States, China, Italy.\nPolitics.\nAssociations.\nThere is no governmental system in Esperantujo because it is not a true state. However, there is a social hierarchy of associations:\nAlso there are thematic associations worldwide, which are concerned with spirituality, hobbies, science or that brings together Esperantists which share common interests.\nThere is also a number of global organizations, such as Sennacieca Asocio Tutmonda (SAT), or the World Esperanto Youth Organization (TEJO), which has 46 national sections.\nForeign relations.\nUniversal Esperanto Association is not a governmental system; however, the association represents Esperanto worldwide. In addition to the United Nations and UNESCO, the UEA has consultative relationships with UNICEF and the Council of Europe and general cooperative relations with the Organization of American States. UEA officially collaborates with the International Organization for Standardization (ISO) by means of an active connection to the ISO Committee on terminology (ISO/TC 37). The association is active for information on the European Union and other interstate and international organizations and conferences. UEA is a member of European Language Council, a joint forum of universities and linguistic associations to promote the knowledge of languages and cultures within and outside the European Union. Moreover, on 10 May 2011, the UEA and the International Information Center for Terminology (Infoterm) signed an Agreement on Cooperation, its objectives are inter exchange information, support each other and help out for projects, meetings, publications in the field of terminology and by which the UEA become Associate Member of Infoterm.\nPolitical movement.\nIn 2003 there was a European political movement called Europe\u2013Democracy\u2013Esperanto created. Within it is found a European federation that brings together local associations whose statutes depends on the countries. The working language of the movement is Esperanto. The goal is \"to provide the European Union with the necessary tools to set up member rights democracy\". The international language is a tool to enable cross-border political and social dialogue and actively contribute to peace and understanding between peoples. The original idea in the first ballot was mainly to spread the existence and the use of Esperanto to the general public. However, in France voices have grown steadily: 25067 (2004) 28944 (2009) and 33115 (2014). In this country there are a number of movements which support the issue: France \u00c9quit\u00e9, Europe-Libert\u00e9, and Politicat.\nSymbols.\nThe flag of Esperanto is called \"Verda Flago\" (Green Flag). It consists of:\nThe anthem is called \"La Espero\" since 1891: it is a poem written by L. L. Zamenhof. The song is usually sung at the triumphal march composed by F\u00e9licien Menu de M\u00e9nil in 1909.\nThe Jubilee symbol represents the language internally, while the flag represents the Esperanto movement. It contains the Latin letter E (Esperanto) and the Cyrillic letter \u042d (\u042d\u0441\u043f\u0435\u0440\u0430\u043d\u0442\u043e) symbolizing the unification of West and East. The Jubilee symbol has been controversial, with some Esperantists derisively calling it \"the melon.\"\nIn addition, Ludwik Lejzer Zamenhof, the initiator of the language, is often used as a symbol. Sometimes he is even called \"Uncle Zam\", referring to the cartoon incarnation of American Uncle Sam.\nPopulation.\nEducation.\nIn addition to textbooks, including the \"Fundamento de Esperanto\" by Zamenhof, the Assimil-methods and the video-methods such as Muzzy in Gondoland of the BBC and \"Pasporto al la tuta mondo\", there are many courses for learning online. Moreover, some universities teach Esperanto, and the Higher Foreign Language training (University E\u00f6tv\u00f6s Lor\u00e1nd) delivers certificates in accordance with the Common European Framework of Reference for Languages (CEFR). More than 1600 people have such a certificate around the world: in 2014 around 470 at the level of B1, 510 at the level of B2 and 700 for C1. The International League of Esperanto Teachers (ILEI) is also working to publish learning materials for teachers.\nThe University of Esperanto offers video lectures in Esperanto, for specialties like Confronting War, Informational Technologies and Astronomy. Courses are also held during the World Esperanto Congress in the framework of the Internacia Kongresa Universitato (IKU). After that, UEA uploads the related documents on its website.\nScience is an appropriate department for works in Esperanto. For example, the Conference on the Application of Esperanto in Science and Technology (KAEST) occurs in November every year since 1998 in the Czech Republic and Slovakia. Personal initiatives are also common: Doctor of mathematics Ulrich Matthias created a document about the foundations of Linear Algebra and the American group of Maine (USA) wrote a guidebook to learn the programming language Python.\nIn general, Esperanto is used as a lingua franca in some websites aiming teaching of other languages, such as German, Slovak, Swahili, Wolof or Toki Pona.\nMedia.\nSince 1889 when \"La Esperantisto\" appeared, and soon other magazines in Esperanto throughout many countries in the world. Some of them are information media of Esperanto associations (\"Esperanto\", \"Sennaciulo\" and \"Kontakto\"). Online Esperanto magazines like \"Libera Folio\", launched in 2003, offer independent view of the Esperanto movement, aiming to soberly and critically shed light on current development. Most of the magazines deal with current events; one of such magazines is \"Monato\", which is read in more than 60 countries. Its articles are written by correspondents from 40 countries, which know the local situation very well. Other most popular Esperanto newspapers are \"La Ondo de Esperanto\", \"Beletra Almanako\", \"Literatura Foiro\", and \"Heroldo de Esperanto\". Often national associations magazines are also published in order to inform about the movement in the country, such as \"Le Monde de l'esp\u00e9ranto\" of Esp\u00e9ranto-France. There are also scientific journals, such as \"Scienca Revuo\" of Internacia Scienca Asocio Esperantista (ISAE).\n\"Muzaiko\" is a radio that has broadcast an all-day international program of songs, interviews and current events in Esperanto since 2011. The latest two can be downloaded as podcasts. Besides Muzaiko, these other stations offer an hour of Esperanto-language broadcasting of various topics: \"Radio Libertaire\", \"Polskie Radio\", \"Vatican Radio\", \"Varsovia Vento, \"Radio Verda and \"Kern.punkto\".\nInternet.\nSpread of the Internet has enabled more efficient communication among Esperanto speakers and slightly replaced slower media such as mail. Many massively used websites such as Facebook or Google offer Esperanto interface. On 15 December 2009, on the occasion of the jubilee of 150th birthday of L. L. Zamenhof, Google additionally made visible the Esperanto flag as a part of their Google Doodles. Media as Twitter, Telegram, Reddit or Ipernity also contain a significant number of people in this community. In addition, content-providers such as WordPress and YouTube also enable bloggers write in Esperanto. Esperanto versions of programs such as the office suite LibreOffice and Mozilla Firefox browser, or the educational program about programming Scratch are also available. Additionally, online games like Minecraft offer complete Esperanto interface.\nMonero, an anonymous cryptocurrency, was named after the Esperanto word for \"coin\" and its official wallet is available in Esperanto. The same applies to Monerujo (\"Monero container\"), the only open-source wallet for Android.\nSport.\nAlthough Esperantujo is not a country, there is an Esperanto football team , which has existed since 2014 and participates in matches during World Esperanto Congresses. The team is part of the N.F.-Board and not of FIFA, and have played against the teams of Armenian-originating Argentine Community in 2014 and the team from Western Sahara in 2015.\nEsperanto speakers and Esperantists.\nInitially, Esperanto speakers learned the language as it was described by L. L. Zamenhof. In 1905, the \"Fundamento de Esperanto\" put together the first Esperanto textbook, an exercise book and a universal dictionary.\nThe \"Declaration about the essence of Esperantism\" (1905) defines an \"Esperantist\" to be anyone who speaks and uses Esperanto. \"Esperantism\" was defined to be a movement to promote the widespread use of Esperanto as a supplement to mother tongues in international and inter-ethnic contexts. As the word \"esperantist\" is linked with this \"esperantism\" (the Esperanto movement) and as -ists and -isms are linked with ideologies, today many people who speak Esperanto prefer to be called \"Esperanto speaker\".\nThe monthly magazine \"La Ondo de Esperanto\" every year since 1998 proclaims an 'Esperantist of the year', who remarkably contributed to the spreading of the language during the year.\nEconomy.\nBusinesses.\nPublishing and selling books, the so-called book services, is the main market and is often the first expenditure of many Esperanto associations. Some companies are already well known: for example Vinilkosmo, which publishes and makes popular Esperanto music since 1990. Then there are initiatives such as the job-seeking website \"Eklaboru\", created by Chuck Smith, for job offers and candidates within Esperanto associations or Esperanto meetings.\nCurrency.\nIn 1907, Ren\u00e9 de Saussure proposed the spesmilo \u27e8\u20b7\u27e9 as an international currency. It had some use before the First World War.\nIn 1942 a currency called the \"stelo\" (\"star\"; plural, \"steloj\") was created. It was used at meetings of the \"Universala Ligo\" and in Esperanto environments such as the annual Universal Congress. Over the years it slowly became unusable and at the official closing of the Universala Ligo in the 1990s, the remaining \"steloj\" coins were handed over to the UEA. You can buy them at the UEA's book service as souvenirs.\nThe current \"steloj\" are made of plastic, they are used in a number of meetings, especially among young people. The currency is maintained by Stelaro, which calculates the rates, keeps the stock, and opened branches in various e-meetings. Currently, there are \"stelo\"-coins of 1 \u2605, 3 \u2605 and 10 \u2605. Quotes of Stars at 31 December 2014 were [25] 1 EUR = 4.189 \u2605.\nCulture.\nArchitectural heritage.\nThere exist Zamenhof-Esperanto objects (ZEOs), scattered in numerous countries around the world, which are the things named in honor of L. L. Zamenhof or Esperanto: monuments, street names, places and so on. There also exists a UEA-committee for ZEOs.\nIn addition, in several countries there are also sites dedicated to Esperanto: meetup places, workshops, seminars, festivals, Esperanto houses. These places provide attractions for Esperantists. Here are two: the Castle of Gr\u00e9silion in France and the Department of Planned Languages and Esperanto Museum in Vienna (Austria).\nCultural heritage.\nEsperanto literary heritage is the richest and the most diverse of any constructed language. There are over 25,000 Esperanto books (originals and translations) as well as over a hundred regularly distributed Esperanto magazines.\nThere are also a number of movies which have been published in Esperanto. Moreover, Esperanto itself was used in numerous movies.\nCelebrations.\nMany public holidays recognized by Esperanto speakers are celebrated internationally, having gained full acceptance by organizations such as UN and UNESCO, and are also publicly observed in select countries that are UN members. This is largely a byproduct of the influence the Esperanto community once had on organizations that worked in the field of international relations (including the United Nations) in the mid-20th century. Here are the celebrations proposed as international holidays by the UEA since 2010:\nCultural events.\nEvery year numerous meetings of Esperanto speakers in different topics around the world take place. They mobilize Esperanto-speakers which share the same will about a specific topic. The main example is the Universal Congress of Esperanto (UK), which annually organizes the UEA every summer for a week. Other events:\nNext to these globally comprising meetings there are also local events such as New Year's Gathering (NR) or Esperanto Youth Week (JES), which occur during the last days of December and first days of January. These meetings seem to have been successful during the last 20 years.\nDue to the fact that there are a lot of Esperanto meetings around the globe, there are two websites which aim to list and share them. Eventoj.hu describes them with a list and dates, and contains an archive until 1996, while Esperant.io offers world map with the locations of future meetings.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9499", "revid": "734812", "url": "https://en.wikipedia.org/wiki?curid=9499", "title": "Ethernet", "text": "Computer networking technology\nEthernet () is a family of wired computer networking technologies commonly used in local area networks (LAN), metropolitan area networks (MAN) and wide area networks (WAN). It was commercially introduced in 1980 and first standardized in 1983 as IEEE 802.3. Ethernet has since been refined to support higher bit rates, a greater number of nodes, and longer link distances, but retains much backward compatibility. Over time, Ethernet has largely replaced competing wired LAN technologies such as Token Ring, FDDI and ARCNET.\nThe original 10BASE5 Ethernet uses a thick coaxial cable as a shared medium. This was largely superseded by 10BASE2, which used a thinner and more flexible cable that was both cheaper and easier to use. More modern Ethernet variants use twisted pair and fiber optic links in conjunction with switches. Over the course of its history, Ethernet data transfer rates have been increased from the original to the latest , with rates up to under development. The include several wiring and signaling variants of the OSI physical layer.\nSystems communicating over Ethernet divide a stream of data into shorter pieces called frames. Each frame contains source and destination addresses, and error-checking data so that damaged frames can be detected and discarded; most often, higher-layer protocols trigger retransmission of lost frames. Per the OSI model, Ethernet provides services up to and including the data link layer. The 48-bit MAC address was adopted by other IEEE 802 networking standards, including IEEE 802.11 (Wi-Fi), as well as by FDDI. EtherType values are also used in Subnetwork Access Protocol (SNAP) headers.\nEthernet is widely used in homes and industry, and interworks well with wireless Wi-Fi technologies. The Internet Protocol is commonly carried over Ethernet and so it is considered one of the key technologies that make up the Internet.\nHistory.\nEthernet was developed at Xerox PARC between 1973 and 1974. It was inspired by ALOHAnet, which Robert Metcalfe had studied as part of his PhD dissertation. The idea was first documented in a memo that Metcalfe wrote on May 22, 1973, where he named it after the luminiferous aether once postulated to exist as an \"omnipresent, completely-passive medium for the propagation of electromagnetic waves.\" In 1975, Xerox filed a patent application listing Metcalfe, David Boggs, Chuck Thacker, and Butler Lampson as inventors. In 1976, after the system was deployed at PARC, Metcalfe and Boggs published a seminal paper. Yogen Dalal, Ron Crane, Bob Garner, and Roy Ogus facilitated the upgrade from the original 2.94\u00a0Mbit/s protocol to the 10\u00a0Mbit/s protocol, which was released to the market in 1980.\nMetcalfe left Xerox in June 1979 to form 3Com. He convinced Digital Equipment Corporation (DEC), Intel, and Xerox to work together to promote Ethernet as a standard. As part of that process Xerox agreed to relinquish their 'Ethernet' trademark. The first standard was published on September 30, 1980, as \"The Ethernet, A Local Area Network. Data Link Layer and Physical Layer Specifications\". This so-called DIX standard (Digital Intel Xerox) specified 10\u00a0Mbit/s Ethernet, with 48-bit destination and source addresses and a global 16-bit Ethertype-type field. Version 2 was published in November 1982 and defines what has become known as Ethernet II. Formal standardization efforts proceeded at the same time and resulted in the publication of IEEE 802.3 on June 23, 1983.\nEthernet initially competed with Token Ring and other proprietary protocols. Ethernet was able to adapt to market needs and with 10BASE2, shift to inexpensive thin coaxial cable and from 1990, to the now-ubiquitous twisted pair with 10BASE-T. By the end of the 1980s, Ethernet was clearly the dominant network technology. In the process, 3Com became a major company. 3Com shipped its first 10\u00a0Mbit/s Ethernet 3C100 NIC in March 1981, and that year started selling adapters for PDP-11s and VAXes, as well as Multibus-based Intel and Sun Microsystems computers. This was followed quickly by DEC's Unibus to Ethernet adapter, which DEC sold and used internally to build its own corporate network, which reached over 10,000 nodes by 1986, making it one of the largest computer networks in the world at that time. An Ethernet adapter card for the IBM PC was released in 1982, and, by 1985, 3Com had sold 100,000. In the 1980s, IBM's own PC Network product competed with Ethernet for the PC, and through the 1980s, LAN hardware, in general, was not common on PCs. However, in the mid to late 1980s, PC networking did become popular in offices and schools for printer and fileserver sharing, and among the many diverse competing LAN technologies of that decade, Ethernet was one of the most popular. Parallel port based Ethernet adapters were produced for a time, with drivers for DOS and Windows. By the early 1990s, Ethernet became so prevalent that Ethernet ports began to appear on some PCs and most workstations. This process was greatly sped up with the introduction of 10BASE-T and its relatively small modular connector, at which point Ethernet ports appeared even on low-end motherboards.\nSince then, Ethernet technology has evolved to meet new bandwidth and market requirements. In addition to computers, Ethernet is now used to interconnect appliances and other personal devices. As Industrial Ethernet it is used in industrial applications and is quickly replacing legacy data transmission systems in the world's telecommunications networks. By 2010, the market for Ethernet equipment amounted to over $16\u00a0billion per year.\nStandardization.\nIn February 1980, the Institute of Electrical and Electronics Engineers (IEEE) started project 802 to standardize local area networks (LAN). The \"DIX-group\" with Gary Robinson (DEC), Phil Arst (Intel), and Bob Printis (Xerox) submitted the so-called \"Blue Book\" CSMA/CD specification as a candidate for the LAN specification. In addition to CSMA/CD, Token Ring (supported by IBM) and Token Bus (selected and henceforward supported by General Motors) were also considered as candidates for a LAN standard. Competing proposals and broad interest in the initiative led to strong disagreement over which technology to standardize. In December 1980, the group was split into three subgroups, and standardization proceeded separately for each proposal.\nDelays in the standards process put at risk the market introduction of the Xerox Star workstation and 3Com's Ethernet LAN products. With such business implications in mind, David Liddle (General Manager, Xerox Office Systems) and Metcalfe (3Com) strongly supported a proposal of Fritz R\u00f6scheisen (Siemens Private Networks) for an alliance in the emerging office communication market, including Siemens' support for the international standardization of Ethernet (April 10, 1981). Ingrid Fromm, Siemens' representative to IEEE 802, quickly achieved broader support for Ethernet beyond IEEE by the establishment of a competing Task Group \"Local Networks\" within the European standards body ECMA TC24. In March 1982, ECMA TC24 with its corporate members reached an agreement on a standard for CSMA/CD based on the IEEE 802 draft. Because the DIX proposal was most technically complete and because of the speedy action taken by ECMA which decisively contributed to the conciliation of opinions within IEEE, the IEEE 802.3 CSMA/CD standard was approved in December 1982. IEEE published the 802.3 standard as a draft in 1983 and as a standard in 1985.\nApproval of Ethernet on the international level was achieved by a similar, cross-partisan action with Fromm as the liaison officer working to integrate with International Electrotechnical Commission (IEC) Technical Committee 83 and International Organization for Standardization (ISO) Technical Committee 97 Sub Committee 6. The ISO 8802-3 standard was published in 1989.\nEvolution.\nEthernet has evolved to include higher bandwidth, improved medium access control methods, and different physical media. The multidrop coaxial cable was replaced with physical point-to-point links connected by Ethernet repeaters or switches.\nEthernet stations communicate by sending each other data packets: blocks of data individually sent and delivered. As with other IEEE 802 LANs, adapters come programmed with globally unique 48-bit MAC address so that each Ethernet station has a unique address. The MAC addresses are used to specify both the destination and the source of each data packet. Ethernet establishes link-level connections, which can be defined using both the destination and source addresses. On reception of a transmission, the receiver uses the destination address to determine whether the transmission is relevant to the station or should be ignored. A network interface normally does not accept packets addressed to other Ethernet stations.\nAn EtherType field in each frame is used by the operating system on the receiving station to select the appropriate protocol module (e.g., an Internet Protocol version such as IPv4). Ethernet frames are said to be \"self-identifying\", because of the EtherType field. Self-identifying frames make it possible to intermix multiple protocols on the same physical network and allow a single computer to use multiple protocols together. Despite the evolution of Ethernet technology, all generations of Ethernet (excluding early experimental versions) use the same frame formats. Mixed-speed networks can be built using Ethernet switches and repeaters supporting the desired Ethernet variants.\nDue to the ubiquity of Ethernet, and the ever-decreasing cost of the hardware needed to support it, by 2004 most manufacturers built Ethernet interfaces directly into PC motherboards, eliminating the need for a separate network card.\nShared medium.\nEthernet was originally based on the idea of computers communicating over a shared coaxial cable acting as a broadcast transmission medium. The method used was similar to those used in radio systems, with the common cable providing the communication channel likened to the \"Luminiferous aether\" in 19th-century physics, and it was from this reference that the name \"Ethernet\" was derived.\nOriginal Ethernet's shared coaxial cable (the shared medium) traversed a building or campus to every attached machine. A scheme known as carrier-sense multiple access with collision detection (CSMA/CD) governed the way the computers shared the channel. This scheme was simpler than competing Token Ring or Token Bus technologies. Computers are connected to an Attachment Unit Interface (AUI) transceiver, which is in turn connected to the cable (with thin Ethernet the transceiver is usually integrated into the network adapter). While a simple passive wire is highly reliable for small networks, it is not reliable for large extended networks, where damage to the wire in a single place, or a single bad connector, can make the whole Ethernet segment unusable.\nThrough the first half of the 1980s, Ethernet's 10BASE5 implementation used a coaxial cable in diameter, later called \"thick Ethernet\" or \"thicknet\". Its successor, 10BASE2, called \"thin Ethernet\" or \"thinnet\", used the RG-58 coaxial cable. The emphasis was on making installation of the cable easier and less costly.\nSince all communication happens on the same wire, any information sent by one computer is received by all, even if that information is intended for just one destination. The network interface card interrupts the CPU only when applicable packets are received: the card ignores information not addressed to it. Use of a single cable also means that the data bandwidth is shared, such that, for example, available data bandwidth to each device is halved when two stations are simultaneously active.\nA collision happens when two stations attempt to transmit at the same time. They corrupt transmitted data and require stations to re-transmit. The lost data and re-transmission reduces throughput. In the worst case, where multiple active hosts connected with maximum allowed cable length attempt to transmit many short frames, excessive collisions can reduce throughput dramatically. However, a Xerox report in 1980 studied performance of an existing Ethernet installation under both normal and artificially generated heavy load. The report claimed that 98% throughput on the LAN was observed. This is in contrast with token passing LANs (Token Ring, Token Bus), all of which suffer throughput degradation as each new node comes into the LAN, due to token waits. This report was controversial, as modeling showed that collision-based networks theoretically became unstable under loads as low as 37% of nominal capacity. Many early researchers failed to understand these results. Performance on real networks is significantly better.\nIn a modern Ethernet, the stations do not all share one channel through a shared cable or a simple repeater hub; instead, each station communicates with a switch, which in turn forwards that traffic to the destination station. In this topology, collisions are only possible if station and switch attempt to communicate with each other at the same time, and collisions are limited to this link. Furthermore, the 10BASE-T standard introduced a full duplex mode of operation which became common with Fast Ethernet and the de facto standard with Gigabit Ethernet. In full duplex, switch and station can send and receive simultaneously, and therefore modern Ethernets are completely collision-free.\nRepeaters and hubs.\nFor signal degradation and timing reasons, coaxial Ethernet segments have a restricted size. Somewhat larger networks can be built by using an Ethernet repeater. Early repeaters had only two ports, allowing, at most, a doubling of network size. Once repeaters with more than two ports became available, it was possible to wire the network in a star topology. Early experiments with star topologies (called \"Fibernet\") using optical fiber were published by 1978.\nShared cable Ethernet is always hard to install in offices because its bus topology is in conflict with the star topology cable plans designed into buildings for telephony. Modifying Ethernet to conform to twisted pair telephone wiring already installed in commercial buildings provided another opportunity to lower costs, expand the installed base, and leverage building design, and, thus, twisted-pair Ethernet was the next logical development in the mid-1980s.\nEthernet on unshielded twisted-pair cables (UTP) began with StarLAN at 1\u00a0Mbit/s in the mid-1980s. In 1987 SynOptics introduced the first twisted-pair Ethernet at 10\u00a0Mbit/s in a star-wired cabling topology with a central hub, later called LattisNet. These evolved into 10BASE-T, which was designed for point-to-point links only, and all termination was built into the device. This changed repeaters from a specialist device used at the center of large networks to a device that every twisted pair-based network with more than two machines had to use. The tree structure that resulted from this made Ethernet networks easier to maintain by preventing most faults with one peer or its associated cable from affecting other devices on the network.\nDespite the physical star topology and the presence of separate transmit and receive channels in the twisted pair and fiber media, repeater-based Ethernet networks still use half-duplex and CSMA/CD, with only minimal activity by the repeater, primarily generation of the jam signal in dealing with packet collisions. Every packet is sent to every other port on the repeater, so bandwidth and security problems are not addressed. The total throughput of the repeater is limited to that of a single link, and all links must operate at the same speed.\nBridging and switching.\nWhile repeaters can isolate some aspects of Ethernet segments, such as cable breakages, they still forward all traffic to all Ethernet devices. The entire network is one collision domain, and all hosts have to be able to detect collisions anywhere on the network. This limits the number of repeaters between the farthest nodes and creates practical limits on how many machines can communicate on an Ethernet network. Segments joined by repeaters have to all operate at the same speed, making phased-in upgrades impossible.\nTo alleviate these problems, bridging was created to communicate at the data link layer while isolating the physical layer. With bridging, only well-formed Ethernet packets are forwarded from one Ethernet segment to another; collisions and packet errors are isolated. At initial startup, Ethernet bridges work somewhat like Ethernet repeaters, passing all traffic between segments. By observing the source addresses of incoming frames, the bridge then builds an address table associating addresses to segments. Once an address is learned, the bridge forwards network traffic destined for that address only to the associated segment, improving overall performance. Broadcast traffic is still forwarded to all network segments. Bridges also overcome the limits on total segments between two hosts and allow the mixing of speeds, both of which are critical to the incremental deployment of faster Ethernet variants.\nIn 1989, Motorola Codex introduced their 6310 EtherSpan, and Kalpana introduced their EtherSwitch; these were examples of the first commercial Ethernet switches. Early switches such as this used cut-through switching where only the header of the incoming packet is examined before it is either dropped or forwarded to another segment. This reduces the forwarding latency. One drawback of this method is that it does not readily allow a mixture of different link speeds. Another is that packets that have been corrupted are still propagated through the network. The eventual remedy for this was a return to the original store and forward approach of bridging, where the packet is read into a buffer on the switch in its entirety, its frame check sequence verified and only then the packet is forwarded. In modern network equipment, this process is typically done using application-specific integrated circuits allowing packets to be forwarded at wire speed.\nWhen a twisted pair or fiber link segment is used and neither end is connected to a repeater, full-duplex Ethernet becomes possible over that segment. In full-duplex mode, both devices can transmit and receive to and from each other at the same time, and there is no collision domain. This doubles the aggregate bandwidth of the link and is sometimes advertised as double the link speed (for example, 200\u00a0Mbit/s for Fast Ethernet). The elimination of the collision domain for these connections also means that all the link's bandwidth can be used by the two devices on that segment and that segment length is not limited by the constraints of collision detection.\nSince packets are typically delivered only to the port they are intended for, traffic on a switched Ethernet is less public than on shared-medium Ethernet. Despite this, switched Ethernet should still be regarded as an insecure network technology, because it is easy to subvert switched Ethernet systems by means such as ARP spoofing and MAC flooding.\nThe bandwidth advantages, the improved isolation of devices from each other, the ability to easily mix different speeds of devices and the elimination of the chaining limits inherent in non-switched Ethernet have made switched Ethernet the dominant network technology.\nAdvanced networking.\nSimple switched Ethernet networks, while a great improvement over repeater-based Ethernet, suffer from single points of failure, attacks that trick switches or hosts into sending data to a machine even if it is not intended for it, scalability and security issues with regard to switching loops, broadcast radiation, and multicast traffic.\nAdvanced networking features in switches use Shortest Path Bridging (SPB) or the Spanning Tree Protocol (STP) to maintain a loop-free, meshed network, allowing physical loops for redundancy (STP) or load-balancing (SPB). Shortest Path Bridging includes the use of the link-state routing protocol IS-IS to allow larger networks with shortest path routes between devices.\nAdvanced networking features also ensure port security, provide protection features such as MAC lockdown and broadcast radiation filtering, use VLANs to keep different classes of users separate while using the same physical infrastructure, employ multilayer switching to route between different classes, and use link aggregation to add bandwidth to overloaded links and to provide some redundancy.\nIn 2016, Ethernet replaced InfiniBand as the most popular system interconnect of TOP500 supercomputers.\nVarieties.\nThe Ethernet physical layer evolved over a considerable time span and encompasses coaxial, twisted pair and fiber-optic physical media interfaces, with speeds from 1 Mbit/s to 400 Gbit/s. The first introduction of twisted-pair CSMA/CD was StarLAN, standardized as 802.3 1BASE5. While 1BASE5 had little market penetration, it defined the physical apparatus (wire, plug/jack, pin-out, and wiring plan) that would be carried over to 10BASE-T through 10GBASE-T.\nThe most common forms used are 10BASE-T, 100BASE-TX, and 1000BASE-T. All three use twisted-pair cables and 8P8C modular connectors. They run at 10 Mbit/s, 100 Mbit/s, and 1 Gbit/s, respectively.\nFiber optic variants of Ethernet (that commonly use SFP modules) are also very popular in larger networks, offering high performance, better electrical isolation and longer distance (tens of kilometers with some versions). In general, network protocol stack software will work similarly on all varieties.\nFrame structure.\nIn IEEE 802.3, a datagram is called a \"packet\" or \"frame\". \"Packet\" is used to describe the overall transmission unit and includes the preamble, start frame delimiter (SFD) and carrier extension (if present). The \"frame\" begins after the start frame delimiter with a frame header featuring source and destination MAC addresses and the EtherType field giving either the protocol type for the payload protocol or the length of the payload. The middle section of the frame consists of payload data including any headers for other protocols (for example, Internet Protocol) carried in the frame. The frame ends with a 32-bit cyclic redundancy check, which is used to detect corruption of data in transit. Notably, Ethernet packets have no time-to-live field, leading to possible problems in the presence of a switching loop.\nAutonegotiation.\nAutonegotiation is the procedure by which two connected devices choose common transmission parameters, e.g. speed and duplex mode. Autonegotiation was initially an optional feature, first introduced with 100BASE-TX, while it is also backward compatible with 10BASE-T. Autonegotiation is mandatory for 1000BASE-T and faster.\nError conditions.\nSwitching loop.\nA switching loop or bridge loop occurs in computer networks when there is more than one Layer 2 (OSI model) path between two endpoints (e.g. multiple connections between two network switches or two ports on the same switch connected to each other). The loop creates broadcast storms as broadcasts and multicasts are forwarded by switches out every port, the switch or switches will repeatedly rebroadcast the broadcast messages flooding the network. Since the Layer 2 header does not support a \"time to live\" (TTL) value, if a frame is sent into a looped topology, it can loop forever.\nA physical topology that contains switching or bridge loops is attractive for redundancy reasons, yet a switched network must not have loops. The solution is to allow physical loops, but create a loop-free logical topology using the SPB protocol or the older STP on the network switches.\nJabber.\nA node that is sending longer than the maximum transmission window for an Ethernet packet is considered to be \"jabbering\". Depending on the physical topology, jabber detection and remedy differ somewhat.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9500", "revid": "66", "url": "https://en.wikipedia.org/wiki?curid=9500", "title": "E.P.Thompson on Luddites", "text": ""}
{"id": "9501", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9501", "title": "E. P. Thompson on Luddites", "text": ""}
{"id": "9502", "revid": "42522270", "url": "https://en.wikipedia.org/wiki?curid=9502", "title": "List of explorations", "text": "Some of the most important explorations of State Societies, in chronological order:"}
{"id": "9505", "revid": "2308770", "url": "https://en.wikipedia.org/wiki?curid=9505", "title": "Elias Canetti", "text": "German-language author (1905 \u2013 1994)\nElias Canetti (; 25 July 1905 \u2013 14 August 1994; ; ]) was a German-language writer, born in Ruse, Bulgaria to a Sephardic family. They moved to Manchester, England, but his father died in 1912, and his mother took her three sons back to continental Europe. They settled in Vienna.\nCanetti moved to England in 1938 after the Anschluss to escape Nazi persecution. He became a British citizen in 1952. He is known as a modernist novelist, playwright, memoirist, and nonfiction writer. He won the Nobel Prize in Literature in 1981, \"for writings marked by a broad outlook, a wealth of ideas and artistic power\". He is noted for his nonfiction book \"Crowds and Power\", among other works.\nLife and work.\nEarly life.\nBorn in 1905 to businessman Jacques Canetti and Mathilde \"n\u00e9e\" Arditti in Ruse, a city on the Danube in Bulgaria, Canetti was the eldest of three sons. His ancestors were Sephardic Jews. His paternal ancestors settled in Ruse from Ottoman Adrianople. The original family name was \"Ca\u00f1ete\", named after Ca\u00f1ete, Cuenca, a village in Spain.\nIn Ruse, Canetti's father and grandfather were successful merchants who operated out of a commercial building, which they had built in 1898. Canetti's mother descended from the Arditti family, one of the oldest Sephardic families in Bulgaria, who were among the founders of the Ruse Jewish colony in the late 18th century. The Ardittis can be traced to the 14th century, when they were court physicians and astronomers to the Aragonese royal court of Alfonso IV and Pedro IV. Before settling in Ruse, they had migrated into Italy and lived in Livorno in the 17th century.\nCanetti spent his childhood years, from 1905 to 1911, in Ruse until the family moved to Manchester, England, where Canetti's father joined a business established by his wife's brothers. In 1912, his father died suddenly, and his mother moved with their children first to Lausanne, then Vienna in the same year. They lived in Vienna from the time Canetti was aged seven onwards. His mother insisted that he speak German and taught it to him. By this time, Canetti already spoke Ladino (his native language), Bulgarian, English, and some French; the last two he studied in the one year that they were in Britain. Subsequently, the family moved first (from 1916 to 1921) to Z\u00fcrich and then (until 1924) to Frankfurt, where Canetti graduated from high school.\nCanetti went back to Vienna in 1924 in order to study chemistry. However, his primary interests during his years in Vienna became philosophy and literature. Introduced into the literary circles of First Republic Vienna, he started writing. Politically leaning towards the left, he was present at the July Revolt of 1927, came near to the action accidentally, was most impressed by the burning of books (recalled frequently in his writings) and left the place quickly with his bicycle. He received a doctorate in chemistry from the University of Vienna in 1929, but never worked as a chemist.\nHe published two works in Vienna, \"Kom\u00f6die der Eitelkeit\" 1934 (The Comedy of Vanity) and \n\"Die Blendung\" 1935 (\"Auto-da-F\u00e9\", 1935), before escaping to Great Britain. He reflected the experiences of Nazi Germany and political chaos in his works, especially exploring mob action and group thinking in the novel \"Die Blendung\" and in the non-fiction \"Crowds and Power\" (1960). He wrote several volumes of memoirs, contemplating the influence of his multi-lingual background and childhood.\nPersonal life.\nIn 1934 in Vienna he married Veza (Venetiana) Taubner-Calderon (1897\u20131963), who acted as his muse and devoted literary assistant. Canetti remained open to relationships with other women. He had a short affair with Anna Mahler. In 1938, after the \"Anschluss\" with Germany, the Canettis moved to London. He became closely involved with the painter Marie-Louise von Motesiczky, who was to remain a close companion for many years. His name has also been linked with the author Iris Murdoch (see John Bayley's \"Iris, A Memoir of Iris Murdoch\", which has several references to an author, referred to as \"the Dichter\", who was a Nobel Laureate and whose works included \"Die Blendung\" [English title \"Auto-da-F\u00e9\"]).\nAfter Veza died in 1963, Canetti married Hera Buschor (1933\u20131988), with whom he had a daughter, Johanna, in 1972. Canetti's brother Jacques Canetti settled in Paris, where he championed a revival of French chanson. Despite being a German-language writer, Canetti settled in Britain until the 1970s, receiving British citizenship in 1952. For his last 20 years, Canetti lived mostly in Z\u00fcrich.\nCareer.\nA writer in German, Canetti won the Nobel Prize in Literature in 1981, \"for writings marked by a broad outlook, a wealth of ideas and artistic power\". He is known chiefly for his celebrated trilogy of autobiographical memoirs of his childhood and of pre-Anschluss Vienna: \"Die Gerettete Zunge\" (The Tongue Set Free); \"Die Fackel im Ohr\" (The Torch in My Ear), and \"Das Augenspiel\" (The Play of the Eyes); for his modernist novel \"Auto-da-F\u00e9\" (\"Die Blendung\"); and for \"Crowds and Power\", a psychological study of crowd behaviour as it manifests itself in human activities ranging from mob violence to religious congregations.\nIn the 1970s, Canetti began to travel more frequently to Zurich, where he settled and lived for his last 20 years. He died in Z\u00fcrich in 1994.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9506", "revid": "31226230", "url": "https://en.wikipedia.org/wiki?curid=9506", "title": "Edward Jenner", "text": "English physician and pioneer of vaccines (1749\u20131823)\nEdward Jenner, (17 May 1749 \u2013 26 January 1823) was an English physician and scientist who pioneered the concept of vaccines and created the smallpox vaccine, the world's first vaccine. The terms \"vaccine\" and \"vaccination\" are derived from \"Variolae vaccinae\" ('pustules of the cow'), the term devised by Jenner to denote cowpox. He used it in 1798 in the title of his \"Inquiry into the Variolae vaccinae known as the Cow Pox\", in which he described the protective effect of cowpox against smallpox.\nIn the West, Jenner is often called \"the father of immunology\", and his work is said to have saved \"more lives than any other man\".100 In Jenner's time, smallpox killed around 10% of global population, with the number as high as 20% in towns and cities where infection spread more easily. In 1821, he was appointed physician to King George IV, and was also made mayor of Berkeley and justice of the peace. He was a member of the Royal Society. In the field of zoology, he was among the first modern scholars to describe the brood parasitism of the cuckoo (Aristotle also noted this behaviour in his \"History of Animals\"). In 2002, Jenner was named in the BBC's list of the 100 Greatest Britons.\nEarly life.\nEdward Jenner was born on 17 May 1749 in Berkeley, Gloucestershire, England as the eighth of nine children. His father, the Reverend Stephen Jenner, was the vicar of Berkeley, so Jenner received a strong basic education.\nEducation and training.\nWhen he was young, he went to school in Wotton-under-Edge at Katherine Lady Berkeley's School and in Cirencester. During this time, he was inoculated (by variolation) for smallpox, which had a lifelong effect upon his general health. At the age of 14, he was apprenticed for seven years to Daniel Ludlow, a surgeon of Chipping Sodbury, South Gloucestershire, where he gained most of the experience needed to become a surgeon himself.\nIn 1770, aged 21, Jenner became apprenticed in surgery and anatomy under surgeon John Hunter and others at St George's Hospital, London. William Osler records that Hunter gave Jenner William Harvey's advice, well known in medical circles (and characteristic of the Age of Enlightenment), \"Don't think; try.\" Hunter remained in correspondence with Jenner over natural history and proposed him for the Royal Society. Returning to his native countryside by 1773, Jenner became a successful family doctor and surgeon, practising on dedicated premises at Berkeley. In 1792, \"with twenty years' experience of general practice and surgery, Jenner obtained the degree of MD from the University of St Andrews\".\nLater life.\nJenner and others formed the Fleece Medical Society or Gloucestershire Medical Society, so called because it met in the parlour of the Fleece Inn, Rodborough, Gloucestershire. Members dined together and read papers on medical subjects. Jenner contributed papers on angina pectoris, ophthalmia, and cardiac valvular disease and commented on cowpox. He also belonged to a similar society which met in Alveston, near Bristol.\nHe became a master mason on 30 December 1802, in Lodge of Faith and Friendship #449. From 1812 to 1813, he served as worshipful master of Royal Berkeley Lodge of Faith and Friendship.\nZoology.\nEdward Jenner was elected fellow of the Royal Society in 1788, following his publication of a careful study of the previously misunderstood life of the nested cuckoo, a study that combined observation, experiment, and dissection.\nJenner described how the newly hatched cuckoo pushed its host's eggs and fledgling chicks out of the nest (contrary to existing belief that the adult cuckoo did it). Having observed this behaviour, Jenner demonstrated an anatomical adaptation for it\u00a0\u2013 the baby cuckoo has a depression in its back, not present after 12 days of life, that enables it to cup eggs and other chicks. The adult does not remain long enough in the area to perform this task. Jenner's findings were published in \"Philosophical Transactions of the Royal Society\" in 1788.\n\"The singularity of its shape is well adapted to these purposes; for, different from other newly hatched birds, its back from the scapula downwards is very broad, with a considerable depression in the middle. This depression seems formed by nature for the design of giving a more secure lodgement to the egg of the Hedge-sparrow, or its young one, when the young Cuckoo is employed in removing either of them from the nest. When it is about twelve days old, this cavity is quite filled up, and then the back assumes the shape of nestling birds in general.\" Jenner's nephew assisted in the study. He was born on 30 June 1737.\nJenner's understanding of the cuckoo's behaviour was not entirely believed until the artist Jemima Blackburn, a keen observer of birdlife, saw a blind nestling pushing out a host's egg. Blackburn's description and illustration were enough to convince Charles Darwin to revise a later edition of \"On the Origin of Species\".\nJenner's interest in zoology played a large role in his first experiment with inoculation. Not only did he have a profound understanding of human anatomy due to his medical training, but he also understood animal biology and its role in human-animal trans-species boundaries in disease transmission. At the time, there was no way of knowing how important this connection would be to the history and discovery of vaccinations. We see this connection now; many present-day vaccinations include animal parts from cows, rabbits, and chicken eggs, which can be attributed to the work of Jenner and his cowpox/smallpox vaccination.\nMarriage and human medicine.\nJenner married Catherine Kingscote (who died in 1815 from tuberculosis) in March 1788. He might have met her while he and other fellows were experimenting with balloons. Jenner's trial balloon descended into Kingscote Park, Gloucestershire, owned by Catherine's father Anthony Kingscote. They had three children: Edward Robert (1789\u20131810), Robert Fitzharding (1792\u20131854) and Catherine (1794\u20131833).\nHe earned his MD from the University of St Andrews in 1792. He is credited with advancing the understanding of angina pectoris. In his correspondence with Heberden, he wrote: \"How much the heart must suffer from the coronary arteries not being able to perform their functions\".\nInvention of the vaccine.\nInoculation was already a standard practice in Asian and African medicine but involved serious risks, including the possibility that those inoculated would become contagious and spread the disease to others. In 1721, Lady Mary Wortley Montagu had imported variolation to Britain after having observed it in Istanbul. While Johnnie Notions had great success with his self-devised inoculation (and was reputed not to have lost a single patient), his method's practice was limited to the Shetland Isles. Voltaire wrote that at this time 60% of the population caught smallpox and 20% of the population died from it. Voltaire also states that the Circassians used the inoculation from times immemorial, and the custom may have been borrowed by the Turks from the Circassians. In 1766, Daniel Bernoulli analysed smallpox morbidity and mortality data to demonstrate the efficacy of inoculation.\nBy 1768, English physician John Fewster had realised that prior infection with cowpox rendered a person immune to smallpox. In the years following 1770, at least five investigators in England and Germany (Sevel, Jensen, Jesty 1774, Rendell, Plett 1791) successfully tested in humans a cowpox vaccine against smallpox. For example, Dorset farmer Benjamin Jesty successfully vaccinated and presumably induced immunity with cowpox in his wife and two children during a smallpox epidemic in 1774, but it was not until Jenner's work that the procedure became widely understood. Jenner may have been aware of Jesty's procedures and success. A similar observation was later made in France by Jacques Antoine Rabaut-Pommier in 1780.\nJenner postulated that the pus in the blisters that affected individuals affected by cowpox (a disease similar to smallpox, but much less virulent) protected them from smallpox. On 14 May 1796, Jenner tested his hypothesis by inoculating James Phipps, an eight-year-old boy who was the son of Jenner's gardener. He scraped pus from cowpox blisters on the hands of Sarah Nelmes, a milkmaid who had caught cowpox from a cow called Blossom, whose hide now hangs on the wall of the St. George's Medical School library (now in Tooting). Phipps was the 17th case described in Jenner's first paper on vaccination.\nJenner inoculated Phipps in both arms that day, subsequently producing in Phipps a fever and some uneasiness, but no full-blown infection. Later, he injected Phipps with variolous material, the routine method of immunization at that time. No disease followed. The boy was later challenged with variolous material and again showed no sign of infection. No unexpected side effects occurred, and neither Phipps nor any other recipients underwent any future 'breakthrough' cases.\nJenner's biographer John Baron would later speculate that Jenner understood one could be inoculated against smallpox by being exposed to cowpox by observing the unblemished complexion of milkmaids, rather than building on the work of his predecessors. The milkmaids story is still widely repeated even though it appears to be a myth.\nDonald Hopkins has written, \"Jenner's unique contribution was not that he inoculated a few persons with cowpox, but that he then proved [by subsequent challenges] that they were immune to smallpox. Moreover, he demonstrated that the protective cowpox pus could be effectively inoculated from person to person, not just directly from cattle.\" Jenner successfully tested his hypothesis on 23 additional subjects.\nJenner continued his research and reported it to the Royal Society, which did not publish the initial paper. After revisions and further investigations, he published his findings on the 23 cases, including his 11-month-old son Robert. Some of his conclusions were correct, some erroneous; modern microbiological and microscopic methods would make his studies easier to reproduce. The medical establishment deliberated at length over his findings before accepting them. Eventually, vaccination was accepted, and in 1840, the British government banned variolation\u00a0\u2013 the use of smallpox to induce immunity\u00a0\u2013 and provided vaccination using cowpox free of charge (\"see\" Vaccination Act).\nThe success of his discovery soon spread around Europe and was used \"en masse\" in the Spanish Balmis Expedition (1803\u20131806), a three-year-long mission to the Americas, the Philippines, Macao, China, led by Francisco Javier de Balmis with the aim of giving thousands the smallpox vaccine. The expedition was successful, and Jenner wrote: \"I don't imagine the annals of history furnish an example of philanthropy so noble, so extensive as this\". Napoleon, who at the time was at war with Britain, had all his French troops vaccinated, awarded Jenner a medal, and at the request of Jenner, he released two English prisoners of war and permitted their return home. Napoleon remarked he could not \"refuse anything to one of the greatest benefactors of mankind\".\nJenner's continuing work on vaccination prevented him from continuing his ordinary medical practice. He was supported by his colleagues and the King in petitioning Parliament, and was granted \u00a310,000 in 1802 for his work on vaccination. In 1807, he was granted another \u00a320,000 after the Royal College of Physicians confirmed the widespread efficacy of vaccination.\nLater life.\nJenner was later elected a foreign honorary member of the American Academy of Arts and Sciences in 1802, a member of the American Philosophical Society in 1804, and a foreign member of the Royal Swedish Academy of Sciences in 1806. In 1803 in London, he became president of the Jennerian Society, concerned with promoting vaccination to eradicate smallpox. The Jennerian ceased operations in 1809. Jenner became a member of the Medical and Chirurgical Society on its founding in 1805 (now the Royal Society of Medicine) and presented several papers there. In 1808, with government aid, the National Vaccine Establishment was founded, but Jenner felt dishonoured by the men selected to run it and resigned his directorship.\nReturning to London in 1811, Jenner observed a significant number of cases of smallpox after vaccination. He found that in these cases the severity of the illness was notably diminished by previous vaccination. In 1821, he was appointed physician extraordinary to King George IV, and was also made mayor of Berkeley and magistrate303 (justice of the peace). He continued to investigate natural history, and in 1823, the last year of his life, he presented his \"Observations on the Migration of Birds\" to the Royal Society.\nJenner was a Freemason.\nDeath.\nJenner was found in a state of apoplexy on 25 January 1823, with his right side paralysed.314 He did not recover and died the next day of an apparent stroke, his second, on 26 January 1823, aged 73. He was buried in the family vault at the Church of St Mary, Berkeley.\nReligious views.\nNeither fanatic nor lax, Jenner was a Christian who in his personal correspondence showed himself quite spiritual.141 Some days before his death, he stated to a friend: \"I am not surprised that men are not grateful to me; but I wonder that they are not grateful to God for the good which He has made me the instrument of conveying to my fellow creatures\".295\nLegacy.\nIn 1980, the World Health Organization declared smallpox an eradicated disease. This was the result of coordinated public health efforts, but vaccination was an essential component. Although the disease was declared eradicated, some pus samples still remain in laboratories in Centers for Disease Control and Prevention in Atlanta in the US, and in State Research Center of Virology and Biotechnology VECTOR in Koltsovo, Novosibirsk Oblast, Russia.\nJenner's vaccine laid the foundation for contemporary discoveries in immunology. In 2002, Jenner was named in the BBC's list of the 100 Greatest Britons following a UK-wide vote. Commemorated on postage stamps issued by the Royal Mail, in 1999 he featured in their World Changers issue along with Charles Darwin, Michael Faraday and Alan Turing. The lunar crater Jenner is named in his honour. Jenner was recognized in the TV show 'The Walking Dead'. In \"TS-19\", a CDC scientist is named Edwin Jenner.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9507", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=9507", "title": "Encyclopedia Britannica", "text": ""}
{"id": "9508", "revid": "45242303", "url": "https://en.wikipedia.org/wiki?curid=9508", "title": "Encyclop\u00e6dia Britannica", "text": "General knowledge encyclopaedia\nThe (Latin for \"British Encyclop\u00e6dia\") is a general knowledge English-language encyclop\u00e6dia. It is published by Encyclop\u00e6dia Britannica, Inc.; the company has existed since the 18th century, although it has changed ownership various times throughout the centuries. The encyclop\u00e6dia is maintained by about 100\u00a0full-time editors and more than 4,000\u00a0contributors. The 2010 version of the 15th edition, which spans 32\u00a0volumes and 32,640\u00a0pages, was the last printed edition. Since 2016, it has been published exclusively as an online encyclopaedia.\nPrinted for 244\u00a0years, the \"Britannica\" was the longest-running in-print encyclopaedia in the English language. It was first published between 1768 and 1771 in the Scottish capital of Edinburgh, as three volumes. The encyclopaedia grew in size: the second edition was 10 volumes, and by its fourth edition (1801\u20131810) it had expanded to 20 volumes. Its rising stature as a scholarly work helped recruit eminent contributors, and the 9th (1875\u20131889) and 11th editions (1911) are landmark encyclopaedias for scholarship and literary style. Starting with the 11th edition and following its acquisition by an American firm, the \"Britannica\" shortened and simplified articles to broaden its appeal to the North American market. In 1933, the \"Britannica\" became the first encyclopaedia to adopt \"continuous revision\", in which the encyclopaedia is continually reprinted, with every article updated on a schedule. In the 21st century, Encyclop\u00e6dia Britannica has suffered due to competition with the online crowdsourced encyclopedia Wikipedia. In March 2012, it announced it would no longer publish printed editions and would focus instead on the online version.\nThe 15th edition has a three-part structure: a 12-volume of short articles (generally fewer than 750\u00a0words), a 17-volume of long articles (two to 310\u00a0pages), and a single volume to give a hierarchical outline of knowledge. The was meant for quick fact-checking and as a guide to the ; readers are advised to study the outline to understand a subject's context and to find more detailed articles. Over 70 years, the size of the \"Britannica\" has remained steady, with about 40\u00a0million words on half a million topics. Though published in the United States since 1901, the \"Britannica\" has for the most part maintained British English spelling.\nPresent status.\nPrint version.\nSince 1985, the \"Britannica\" had four parts: the , the , the , and a two-volume index. The \"Britannica\"'s articles are found in the and , which encompass 12 and 17 volumes, respectively, each volume having roughly one thousand pages. The 2007 has 699 in-depth articles, ranging in length from 2 to 310 pages and having references and named contributors. In contrast, the 2007 has roughly 65,000 articles, the vast majority (about 97%) of which contain fewer than 750 words, no references, and no named contributors. The articles are intended for quick fact-checking and to help in finding more thorough information in the . The articles are meant both as authoritative, well-written articles on their subjects and as storehouses of information not covered elsewhere. The longest article (310 pages) is on the United States, and resulted from the merger of the articles on the individual states. A 2013 \"Global Edition\" of \"Britannica\" contained approximately forty thousand articles.\nInformation can be found in the \"Britannica\" by following the cross-references in the and ; however, these are sparse, averaging one cross-reference per page. Hence, readers are instead recommended to consult the alphabetical index or the , which organizes the \"Britannica\"'s contents by topic.\nThe core of the is its \"Outline of Knowledge\", which aims to provide a logical framework for all human knowledge. Accordingly, the Outline is consulted by the \"Britannica\"'s editors to decide which articles should be included in the and . The Outline is also intended to be a study guide, to put subjects in their proper perspective, and to suggest a series of \"Britannica\" articles for the student wishing to learn a topic in depth. However, libraries have found that it is scarcely used, and reviewers have recommended that it be dropped from the encyclopaedia. The also has color transparencies of human anatomy and several appendices listing the staff members, advisors, and contributors to all three parts of the \"Britannica\".\nTaken together, the and comprise roughly 40 million words and 24,000 images. The two-volume index has 2,350 pages, listing the 228,274 topics covered in the \"Britannica\", together with 474,675 subentries under those topics. The \"Britannica\" generally prefers British spelling over American; for example, it uses \"colour\" (not \"color\"), \"centre\" (not \"center\"), and \"encyclopaedia\" (not \"encyclopedia\"). However, there are exceptions to this rule, such as \"defense\" rather than \"defence\". Common alternative spellings are provided with cross-references such as \"Color: \"see\" Colour.\"\nSince 1936, the articles of the \"Britannica\" have been revised on a regular schedule, with at least 10% of them considered for revision each year. According to one Britannica website, 46% of its articles were revised over the past three years; however, according to another Britannica website, only 35% of the articles were revised.\nThe alphabetization of articles in the and follows strict rules. Diacritical marks and non-English letters are ignored, while numerical entries such as \"1812, War of\" are alphabetized as if the number had been written out (\"Eighteen-twelve, War of\"). Articles with identical names are ordered first by persons, then by places, then by things. Rulers with identical names are organized first alphabetically by country and then by chronology; thus, Charles III of France precedes Charles I of England, listed in \"Britannica\" as the ruler of Great Britain and Ireland. (That is, they are alphabetized as if their titles were \"Charles, France, 3\" and \"Charles, Great Britain and Ireland, 1\".) Similarly, places that share names are organized alphabetically by country, then by ever-smaller political divisions.\nIn March 2012, the company announced that the 2010 edition would be the last printed version. This was announced as a move by the company to adapt to the times and focus on its future using digital distribution. The peak year for the printed encyclopaedia was 1990 when 120,000 sets were sold, but it dropped to 40,000 in 1996. 12,000 sets of the 2010 edition were printed, of which 8,000 had been sold as of 2012[ [update]]. By late April 2012, the remaining copies of the 2010 edition had sold out at Britannica's online store. As of 2016[ [update]], a replica of Britannica's 1768 first edition is sold on the online store.\nRelated printed material.\n\"Britannica Junior\" was first published in 1934 as 12 volumes. It was expanded to 15 volumes in 1947, and renamed \"Britannica Junior Encyclop\u00e6dia\" in 1963. It was taken off the market after the 1984 printing.\nA British \"Children's Britannica\" edited by John Armitage was issued in London in 1960. Its contents were determined largely by the eleven-plus standardized tests given in Britain. Britannica introduced the \"Children's Britannica\" to the US market in 1988, aimed at ages seven to 14.\nIn 1961, a 16-volume \"Young Children's Encyclopaedia\" was issued for children just learning to read.\n\"My First Britannica\" is aimed at children ages six to 12, and the \"Britannica Discovery Library\" is for children aged three to six (issued 1974 to 1991).\nThere have been, and are, several abridged \"Britannica\" encyclopaedias. The single-volume \"Britannica Concise Encyclop\u00e6dia\" has 28,000 short articles condensing the larger 32-volume \"Britannica\"; there are authorized translations in languages such as Chinese created by Encyclopedia of China Publishing House and Vietnamese. \"Compton's by Britannica\", first published in 2007, incorporating the former \"Compton's Encyclopedia\", is aimed at 10- to 17-year-olds and consists of 26 volumes and 11,000 pages.\nSince 1938, Encyclop\u00e6dia Britannica, Inc. has published annually a \"Book of the Year\" covering the past year's events. A given edition of the \"Book of the Year\" is named in terms of the year of its publication, though the edition actually covers the events of the previous year. The company also publishes several specialized reference works, such as \"Shakespeare: The Essential Guide to the Life and Works of the Bard\" (Wiley, 2006).\nOptical disc, online, and mobile versions.\nThe \"Britannica Ultimate Reference Suite 2012 DVD\" contains over 100,000 articles. This includes regular \"Britannica\" articles, as well as others drawn from the \"Britannica Student Encyclop\u00e6dia\", and the \"Britannica Elementary Encyclop\u00e6dia.\" The package includes a range of supplementary content including maps, videos, sound clips, animations and web links. It also offers study tools and dictionary and thesaurus entries from Merriam-Webster.\n\"Britannica\" Online is a website with more than 120,000 articles and is updated regularly. It has daily features, updates and links to news reports from \"The New York Times\" and the BBC. As of 2009[ [update]], roughly 60% of Encyclop\u00e6dia Britannica's revenue came from online operations, of which around 15% came from subscriptions to the consumer version of the websites. As of 2006[ [update]], subscriptions were available on a yearly, monthly or weekly basis. Special subscription plans are offered to schools, colleges and libraries; such institutional subscribers constitute an important part of Britannica's business. Beginning in early 2007, the \"Britannica\" made articles freely available if they are hyperlinked from an external site. Non-subscribers are served pop-ups and advertising.\nOn 20 February 2007, Encyclop\u00e6dia Britannica, Inc. announced that it was working with mobile phone search company AskMeNow to launch a mobile encyclopaedia. Users will be able to send a question via text message, and AskMeNow will search \"Britannica\"'s 28,000-article concise encyclopaedia to return an answer to the query. Daily topical features sent directly to users' mobile phones are also planned.\nOn 3 June 2008, an initiative to facilitate collaboration between online expert and amateur scholarly contributors for Britannica's online content (in the spirit of a wiki), with editorial oversight from Britannica staff, was announced. Approved contributions would be credited, though contributing automatically grants Encyclop\u00e6dia Britannica, Inc. perpetual, irrevocable license to those contributions.\nOn 22 January 2009, Britannica's president, Jorge Cauz, announced that the company would be accepting edits and additions to the online \"Britannica\" website from the public. The published edition of the encyclopaedia will not be affected by the changes. Individuals wishing to edit the \"Britannica\" website will have to register under their real name and address prior to editing or submitting their content. All edits submitted will be reviewed and checked and will have to be approved by the encyclopaedia's professional staff. Contributions from non-academic users will sit in a separate section from the expert-generated \"Britannica\" content, as will content submitted by non-\"Britannica\" scholars. Articles written by users, if vetted and approved, will also only be available in a special section of the website, separate from the professional articles. Official \"Britannica\" material would carry a \"Britannica Checked\" stamp, to distinguish it from the user-generated content.\nOn 14 September 2010, Encyclop\u00e6dia Britannica, Inc. announced a partnership with mobile phone development company Concentric Sky to launch a series of iPhone products aimed at the K\u201312 market. On 20 July 2011, Encyclop\u00e6dia Britannica, Inc. announced that Concentric Sky had ported the Britannica Kids product line to Intel's Intel Atom-based Netbooks and on 26 October 2011 that it had launched its encyclopedia as an iPad app. In 2010, Britannica released Britannica ImageQuest, a database of images.\nIn March 2012, it was announced that the company would cease printing the encyclopaedia set, and that it would focus more on its online version.\nOn 7 June 2018, Britannica released a Google Chrome extension, \"Britannica Insights\", which shows snippets of information from Britannica Online whenever the user performs a Google Search, in a box to the right of Google's results. Britannica Insights was also available as a Firefox extension but this was taken down due to a code review issue.\nPersonnel and management.\nContributors.\nThe print version of the \"Britannica\" has 4,411 contributors, many eminent in their fields, such as Nobel laureate economist Milton Friedman, astronomer Carl Sagan, and surgeon Michael DeBakey. Roughly a quarter of the contributors are deceased, some as long ago as 1947 (Alfred North Whitehead), while another quarter are retired or emeritus. Most (approximately 98%) contribute to only a single article; however, 64 contributed to three articles, 23 contributed to four articles, 10 contributed to five articles, and 8 contributed to more than five articles. An exceptionally prolific contributor is Christine Sutton of the University of Oxford, who contributed 24 articles on particle physics.\nWhile \"Britannica\"'s authors have included writers such as Albert Einstein, Marie Curie, and Leon Trotsky, as well as notable independent encyclopaedists such as Isaac Asimov, some have been criticized for lack of expertise. In 1911 the historian George L. Burr wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;With a temerity almost appalling, [the \"Britannica\" contributor, Mr. Philips] ranges over nearly the whole field of European history, political, social, ecclesiastical... The grievance is that [this work] lacks authority. This, too\u2014this reliance on editorial energy instead of on ripe special learning\u2014may, alas, be also counted an \"Americanizing\": for certainly nothing has so cheapened the scholarship of our American encyclopaedias.\nStaff.\nAs of 2007[ [update]] in the fifteenth edition of \"Britannica\", Dale Hoiberg, a sinologist, was listed as \"Britannica\"'s Senior Vice President and editor-in-chief. Among his predecessors as editors-in-chief were Hugh Chisholm (1902\u20131924), James Louis Garvin (1926\u20131932), Franklin Henry Hooper (1932\u20131938), Walter Yust (1938\u20131960), Harry Ashmore (1960\u20131963), Warren E. Preece (1964\u20131968, 1969\u20131975), Sir William Haley (1968\u20131969), Philip W. Goetz (1979\u20131991), and Robert McHenry (1992\u20131997). As of 2007[ [update]] Anita Wolff was listed as the Deputy Editor and Theodore Pappas as Executive Editor. Prior Executive Editors include John V. Dodge (1950\u20131964) and Philip W. Goetz.\nPaul T. Armstrong remains the longest working employee of Encyclop\u00e6dia Britannica. He began his career there in 1934, eventually earning the positions of treasurer, vice president, and chief financial officer in his 58 years with the company, before retiring in 1992.\nThe 2007 editorial staff of the \"Britannica\" included five Senior Editors and nine Associate Editors, supervised by Dale Hoiberg and four others. The editorial staff helped to write the articles of the and some sections of the .\nEditorial advisors.\nThe \"Britannica\" has an editorial board of advisors, which includes 12 distinguished scholars: non-fiction author Nicholas Carr, religion scholar Wendy Doniger, political economist Benjamin M. Friedman, Council on Foreign Relations President Emeritus Leslie H. Gelb, computer scientist David Gelernter, Physics Nobel laureate Murray Gell-Mann, Carnegie Corporation of New York President Vartan Gregorian, philosopher Thomas Nagel, cognitive scientist Donald Norman, musicologist Don Michael Randel, Stewart Sutherland, Baron Sutherland of Houndwood, President of the Royal Society of Edinburgh, and cultural anthropologist Michael Wesch.\nThe \"Prop\u00e6dia\" and its \"Outline of Knowledge\" were produced by dozens of editorial advisors under the direction of Mortimer J. Adler. Roughly half of these advisors have since died, including some of the Outline's chief architects \u2013 Rene Dubos (d. 1982), Loren Eiseley (d. 1977), Harold D. Lasswell (d. 1978), Mark Van Doren (d. 1972), Peter Ritchie Calder (d. 1982) and Mortimer J. Adler (d. 2001). The also lists just under 4,000 advisors who were consulted for the unsigned articles.\nCorporate structure.\nIn January 1996, the \"Britannica\" was purchased from the Benton Foundation by billionaire Swiss financier Jacqui Safra, who serves as its current chair of the board. In 1997, Don Yannias, a long-time associate and investment advisor of Safra, became CEO of Encyclop\u00e6dia Britannica, Inc. In 1999, a new company, Britannica.com Inc., was created to develop digital versions of the \"Britannica\"; Yannias assumed the role of CEO in the new company, while his former position at the parent company remained vacant for two years. Yannias' tenure at Britannica.com Inc. was marked by missteps, considerable lay-offs, and financial losses. In 2001, Yannias was replaced by Ilan Yeshua, who reunited the leadership of the two companies. Yannias later returned to investment management, but remains on the \"Britannica\"'s Board of Directors.\nIn 2003, former management consultant Jorge Aguilar-Cauz was appointed President of Encyclop\u00e6dia Britannica, Inc. Cauz is the senior executive and reports directly to the \"Britannica\"'s Board of Directors. Cauz has been pursuing alliances with other companies and extending the \"Britannica\" brand to new educational and reference products, continuing the strategy pioneered by former CEO Elkan Harrison Powell in the mid-1930s.\nIn the fall of 2017, Karthik Krishnan was appointed global chief executive officer of the Encyclop\u00e6dia Britannica Group. Krishnan brought a varied perspective to the role based on several high-level positions in digital media, including RELX (formerly known as Reed Elsevier, and one of the constituents of the FTSE 100 Index) and Rodale, in which he was responsible for \"driving business and cultural transformation and accelerating growth\".\nTaking the reins of the company as it was preparing to mark its 250th anniversary and define the next phase of its digital strategy for consumers and K-12 schools, Krishnan launched a series of new initiatives in his first year.\nFirst was Britannica Insights, a free, downloadable software extension to the Google Chrome browser that served up edited, fact-checked Britannica information with queries on search engines such as Google, Yahoo, and Bing. Its purpose, the company said, was to \"provide trusted, verified information\" in conjunction with search results that were thought to be increasingly unreliable in the era of misinformation and \"fake news.\"\nThe product was quickly followed by Britannica School Insights, which provided similar content for subscribers to Britannica's online classroom solutions, and a partnership with YouTube in which verified Britannica content appeared on the site as an antidote to user-generated video content that could be false or misleading. \u00a0\nKrishnan, himself an educator at New York University's Stern School of Business, believes in the \"transformative power of education\" and set steering the company toward solidifying its place among leaders in educational technology and supplemental curriculum. Krishnan aimed at providing more useful and relevant solutions to customer needs, extending and renewing Britannica's historical emphasis on \"Utility\", which had been the watchword of its first edition in 1768.\nKrishnan also is active in civic affairs, with organizations such as the Urban Enterprise Initiative and Urban Upbound, whose board he serves on.\nCompetition.\nAs the \"Britannica\" is a general encyclopaedia, it does not seek to compete with specialized encyclopaedias such as the \"Encyclopaedia of Mathematics\" or the \"Dictionary of the Middle Ages\", which can devote much more space to their chosen topics. In its first years, the \"Britannica\"'s main competitor was the general encyclopaedia of Ephraim Chambers and, soon thereafter, \"Rees's Cyclop\u00e6dia\" and Coleridge's \"Encyclop\u00e6dia Metropolitana\". In the 20th century, successful competitors included \"Collier's Encyclopedia\", the \"Encyclopedia Americana\", and the \"World Book Encyclopedia\". Nevertheless, from the 9th edition onwards, the \"Britannica\" was widely considered to have the greatest authority of any general English-language encyclopaedia, especially because of its broad coverage and eminent authors. The print version of the \"Britannica\" was significantly more expensive than its competitors.\nSince the early 1990s, the \"Britannica\" has faced new challenges from digital information sources. The Internet, facilitated by the development of Web search engines, has grown into a common source of information for many people, and provides easy access to reliable original sources and expert opinions, thanks in part to initiatives such as Google Books, MIT's release of its educational materials and the open PubMed Central library of the National Library of Medicine. In general, the Internet tends to provide more current coverage than print media, due to the ease with which material on the Internet can be updated. In rapidly changing fields such as science, technology, politics, culture and modern history, the \"Britannica\" has struggled to stay up to date, a problem first analysed systematically by its former editor Walter Yust. Eventually, the \"Britannica\" turned to focus more on its online edition.\nPrint encyclopaedias.\nThe has been compared with other print encyclopaedias, both qualitatively and quantitatively. A well-known comparison is that of Kenneth Kister, who gave a qualitative and quantitative comparison of the 1993 \"Britannica\" with two comparable encyclopaedias, \"Collier's Encyclopedia\" and the \"Encyclopedia Americana\". For the quantitative analysis, ten articles were selected at random\u2014circumcision, Charles Drew, Galileo, Philip Glass, heart disease, IQ, panda bear, sexual harassment, Shroud of Turin and Uzbekistan\u2014and letter grades of A\u2013D or F were awarded in four categories: coverage, accuracy, clarity, and recency. In all four categories and for all three encyclopaedias, the four average grades fell between B\u2212 and B+, chiefly because none of the encyclopaedias had an article on sexual harassment in 1994. In the accuracy category, the \"Britannica\" received one \"D\" and seven \"A\"s, \"Encyclopedia Americana\" received eight \"A\"s, and \"Collier's\" received one \"D\" and seven \"A\"s; thus, \"Britannica\" received an average score of 92% for accuracy to \"Americana\"'s 95% and \"Collier's\" 92%. In the timeliness category, \"Britannica\" averaged an 86% to \"Americana\"'s 90% and \"Collier's\" 85%.\nIn 2013, the President of Encyclop\u00e6dia Britannica announced that after 244 years, the encyclopedia would cease print production and all future editions would be entirely digital.\nDigital encyclopaedias on optical media.\nThe most notable competitor of the \"Britannica\" among CD/DVD-ROM digital encyclopaedias was \"Encarta\", now discontinued, a modern multimedia encyclopaedia that incorporated three print encyclopaedias: \"Funk &amp; Wagnalls\", \"Collier's\" and the \"New Merit Scholar's Encyclopedia\". \"Encarta\" was the top-selling multimedia encyclopaedia, based on total US retail sales from January 2000 to February 2006. Both occupied the same price range, with the \"2007 Encyclop\u00e6dia Britannica Ultimate\" CD or DVD costing US$40\u201350 and the Microsoft Encarta Premium 2007 DVD costing US$45. The \"Britannica\" disc contains 100,000 articles and \"Merriam-Webster's Dictionary and Thesaurus\" (US only), and offers Primary and Secondary School editions. \"Encarta\" contained 66,000 articles, a user-friendly Visual Browser, interactive maps, math, language and homework tools, a US and UK dictionary, and a youth edition. Like \"Encarta\", the digital \"Britannica\" has been criticized for being biased towards United States audiences; the United Kingdom-related articles are updated less often, maps of the United States are more detailed than those of other countries, and it lacks a UK dictionary. Like the \"Britannica\", \"Encarta\" was available online by subscription, although some content could be accessed free.\nWikipedia.\nThe main online alternative to \"Britannica\" is Wikipedia. The key differences between the two lie in accessibility; the model of participation they bring to an encyclopedic project; their respective style sheets and editorial policies; relative ages; the number of subjects treated; the number of languages in which articles are written and made available; and their underlying economic models: unlike \"Britannica\", Wikipedia is a not-for-profit and is not connected with traditional profit- and contract-based publishing distribution networks.\nThe 699 printed articles are generally written by identified contributors, and the roughly 65,000 printed articles are the work of the editorial staff and identified outside consultants. Thus, a \"Britannica\" article either has known authorship or a set of possible authors (the editorial staff). With the exception of the editorial staff, most of the \"Britannica\"'s contributors are experts in their field\u2014some are Nobel laureates. By contrast, the articles of Wikipedia are written by people of unknown degrees of expertise: most do not claim any particular expertise, and of those who do, many are anonymous and have no verifiable credentials. It is for this lack of institutional vetting, or certification, that former \"Britannica\" editor-in-chief Robert McHenry notes his belief that Wikipedia cannot hope to rival the \"Britannica\" in accuracy.\nIn 2005, the journal \"Nature\" chose articles from both websites in a wide range of science topics and sent them to what it called \"relevant\" field experts for peer review. The experts then compared the competing articles\u2014one from each site on a given topic\u2014side by side but were not told which article came from which site. \"Nature\" got back 42 usable reviews.\nIn the end, the journal found just eight serious errors, such as general misunderstandings of vital concepts: four from each site. It also discovered many factual errors, omissions or misleading statements: 162 in Wikipedia and 123 in \"Britannica\", an average of 3.86 mistakes per article for Wikipedia and 2.92 for \"Britannica\". \nAlthough \"Britannica \"was revealed as the more accurate encyclopedia, with fewer errors, Encyclop\u00e6dia Britannica, Inc. in its rebuttal called \"Nature\"'s study flawed and misleading and called for a \"prompt\" retraction. It noted that two of the articles in the study were taken from a \"Britannica\" yearbook and not the encyclopaedia, and another two were from \"Compton's Encyclopedia\" (called the \"Britannica Student Encyclopedia\" on the company's website). \n\"Nature\" defended its story and declined to retract, stating that, as it was comparing Wikipedia with the web version of \"Britannica\", it used whatever relevant material was available on \"Britannica\"'s website. Interviewed in February 2009, the managing director of \"Britannica UK\" said: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Wikipedia is a fun site to use and has a lot of interesting entries on there, but their approach wouldn't work for . My job is to create more awareness of our very different approaches to publishing in the public mind. They're a chisel, we're a drill, and you need to have the correct tool for the job.In a January 2016 press release, \"Britannica\" called Wikipedia \"an impressive achievement.\"\nCritical and popular assessments.\nReputation.\nSince the 3rd edition, the \"Britannica\" has enjoyed a popular and critical reputation for general excellence. The 3rd and the 9th editions were pirated for sale in the United States, beginning with \"Dobson's Encyclopaedia\". On the release of the 14th edition, \"Time\" magazine dubbed the \"Britannica\" the \"Patriarch of the Library\". In a related advertisement, naturalist William Beebe was quoted as saying that the \"Britannica\" was \"beyond comparison because there is no competitor.\" References to the \"Britannica\" can be found throughout English literature, most notably in one of Sir Arthur Conan Doyle's favourite Sherlock Holmes stories, \"The Red-Headed League\". The tale was highlighted by the Lord Mayor of London, Gilbert Inglefield, at the bicentennial of the \"Britannica\".\nThe \"Britannica\" has a reputation for summarising knowledge. To further their education, some people have devoted themselves to reading the entire \"Britannica\", taking anywhere from three to 22 years to do so. When Fat'h Ali became the Shah of Persia in 1797, he was given a set of the \"Britannica\"'s 3rd edition, which he read completely; after this feat, he extended his royal title to include \"Most Formidable Lord and Master of the \". Writer George Bernard Shaw claimed to have read the complete 9th edition\u2014except for the science articles\u2014and Richard Evelyn Byrd took the \"Britannica\" as reading material for his five-month stay at the South Pole in 1934, while Philip Beaver read it during a sailing expedition. More recently, A.J. Jacobs, an editor at \"Esquire\" magazine, read the entire 2002 version of the 15th edition, describing his experiences in the well-received 2004 book, \"\". Only two people are known to have read two independent editions: the author C. S. Forester and Amos Urban Shirk, an American businessman who read the 11th and 14th editions, devoting roughly three hours per night for four and a half years to read the 11th.\nAwards.\nThe CD/DVD-ROM version of the \"Britannica\", \"Encyclop\u00e6dia Britannica Ultimate Reference Suite\", received the 2004 Distinguished Achievement Award from the Association of Educational Publishers. On 15 July 2009, was awarded a spot as one of \"Top Ten Superbrands in the UK\" by a panel of more than 2,000 independent reviewers, as reported by the BBC.\nCoverage of topics.\nTopics are chosen in part by reference to the \"Outline of Knowledge\". The bulk of the \"Britannica\" is devoted to geography (26% of the ), biography (14%), biology and medicine (11%), literature (7%), physics and astronomy (6%), religion (5%), art (4%), Western philosophy (4%), and law (3%). A complementary study of the found that geography accounted for 25% of articles, science 18%, social sciences 17%, biography 17%, and all other humanities 25%. Writing in 1992, one reviewer judged that the \"range, depth, and catholicity of coverage [of the \"Britannica\"] are unsurpassed by any other general Encyclopaedia.\"\nThe \"Britannica\" does not cover topics in equivalent detail; for example, the whole of Buddhism and most other religions is covered in a single article, whereas 14 articles are devoted to Christianity, comprising nearly half of all religion articles. However, the \"Britannica\" has been lauded as the \"least\" biased of general Encyclopaedias marketed to Western readers and praised for its biographies of important women of all eras.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It can be stated without fear of contradiction that the 15th edition of the \"Britannica\" accords non-Western cultural, social, and scientific developments more notice than any general English-language encyclopedia currently on the market.\nCriticism of editorial decisions.\nOn rare occasions, the \"Britannica\" has been criticized for its editorial choices. Given its roughly constant size, the encyclopaedia has needed to reduce or eliminate some topics to accommodate others, resulting in controversial decisions. The initial 15th edition (1974\u20131985) was faulted for having reduced or eliminated coverage of children's literature, military decorations, and the French poet Joachim du Bellay; editorial mistakes were also alleged, such as inconsistent sorting of Japanese biographies. Its elimination of the index was condemned, as was the apparently arbitrary division of articles into the and . Summing up, one critic called the initial 15th edition a \"qualified failure...[that] cares more for juggling its format than for preserving.\" More recently, reviewers from the American Library Association were surprised to find that most educational articles had been eliminated from the 1992 , along with the article on psychology.\nSome very few \"Britannica\"-appointed contributors are mistaken. A notorious instance from the \"Britannica\"'s early years is the rejection of Newtonian gravity by George Gleig, the chief editor of the 3rd edition (1788\u20131797), who wrote that gravity was caused by the classical element of fire. The \"Britannica\" has also staunchly defended a scientific approach to cultural topics, as it did with William Robertson Smith's articles on religion in the 9th edition, particularly his article stating that the Bible was not historically accurate (1875).\nOther criticisms.\nThe \"Britannica\" has received criticism, especially as editions become outdated. It is expensive to produce a completely new edition of the \"Britannica\", and its editors delay for as long as fiscally sensible (usually about 25 years). For example, despite continuous revision, the 14th edition became outdated after 35 years (1929\u20131964). When American physicist Harvey Einbinder detailed its failings in his 1964 book, \"The Myth of the Britannica\", the encyclopaedia was provoked to produce the 15th edition, which required 10 years of work. It is still difficult to keep the \"Britannica\" current; one 1994 critic writes, \"it is not difficult to find articles that are out-of-date or in need of revision\", noting that the longer articles are more likely to be outdated than the shorter articles. Information in the is sometimes inconsistent with the corresponding article(s), mainly because of the failure to update one or the other. The bibliographies of the articles have been criticized for being more out-of-date than the articles themselves.\nIn 2005, 12-year-old schoolboy Lucian George found several inaccuracies in the \"Britannica\"'s entries on Poland and wildlife in Eastern Europe.\nIn 2010, an inaccurate entry about the Irish Civil War was discussed in the Irish press following a decision of the Department of Education and Science to pay for online access.\nWriting about the 3rd edition (1788\u20131797), \"Britannica\"'s chief editor George Gleig observed that \"perfection seems to be incompatible with the nature of works constructed on such a plan, and embracing such a variety of subjects.\" In March 2006, the \"Britannica\" wrote, \"we in no way mean to imply that \"Britannica\" is error-free; we have never made such a claim\" (although in 1962 Britannica's sales department famously said of the 14th edition \"It is truth. It is unquestionable fact.\") The sentiment is expressed by its original editor, William Smellie:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nHowever, Jorge Cauz (president of Encyclop\u00e6dia Britannica Inc.) asserted in 2012 that \"\"Britannica\" [...] will always be factually correct.\"\nHistory.\nPast owners have included, in chronological order, the Edinburgh, Scotland printers Colin Macfarquhar and Andrew Bell, Scottish bookseller Archibald Constable, Scottish publisher A &amp; C Black, Horace Everett Hooper, Sears Roebuck and William Benton.\nThe present owner of Encyclop\u00e6dia Britannica Inc. is Jacqui Safra, a Brazilian billionaire and actor. Recent advances in information technology and the rise of electronic encyclopaedias such as Encyclop\u00e6dia Britannica Ultimate Reference Suite, \"Encarta\" and Wikipedia have reduced the demand for print encyclopaedias. To remain competitive, Encyclop\u00e6dia Britannica, Inc. has stressed the reputation of the \"Britannica\", reduced its price and production costs, and developed electronic versions on CD-ROM, DVD, and the World Wide Web. Since the early 1930s, the company has promoted spin-off reference works.\nEditions.\nThe \"Britannica\" has been issued in 15 editions, with multi-volume supplements to the 3rd and 4th editions (see the Table below). The 5th and 6th editions were reprints of the 4th, and the 10th edition was only a supplement to the 9th, just as the 12th and 13th editions were supplements to the 11th. The 15th underwent massive reorganization in 1985, but the updated, current version is still known as the 15th. The 14th and 15th editions were edited every year throughout their runs, so that later printings of each were entirely different from early ones.\nThroughout history, the \"Britannica\" has had two aims: to be an excellent reference book, and to provide educational material. In 1974, the 15th edition adopted a third goal: to systematize all human knowledge. The history of the \"Britannica\" can be divided into five eras, punctuated by changes in management, or reorganization of the dictionary.\n1768\u20131826.\nIn the first era (1st\u20136th editions, 1768\u20131826), the \"Britannica\" was managed and published by its founders, Colin Macfarquhar and Andrew Bell, by Archibald Constable, and by others. The \"Britannica\" was first published between December 1768 and 1771 in Edinburgh as the \"Encyclop\u00e6dia Britannica, or, A Dictionary of Arts and Sciences, compiled upon a New Plan\". In part, it was conceived in reaction to the French \"Encyclop\u00e9die\" of Denis Diderot and Jean le Rond d'Alembert (published 1751\u201372), which had been inspired by Chambers's \"Cyclopaedia\" (first edition 1728). It went on sale 10 December.\nThe \"Britannica\" of this period was primarily a Scottish enterprise, and it is one of the most enduring legacies of the Scottish Enlightenment. In this era, the \"Britannica\" moved from being a three-volume set (1st edition) compiled by one young editor\u2014William Smellie\u2014to a 20-volume set written by numerous authorities. Several other encyclopaedias competed throughout this period, among them editions of Abraham Rees's \"Cyclop\u00e6dia\" and Coleridge's \"Encyclop\u00e6dia Metropolitana\" and David Brewster's \"Edinburgh Encyclop\u00e6dia\".\n1827\u20131901.\nDuring the second era (7th\u20139th editions, 1827\u20131901), the \"Britannica\" was managed by the Edinburgh publishing firm A &amp; C Black. Although some contributors were again recruited through friendships of the chief editors, notably Macvey Napier, others were attracted by the \"Britannica\"'s reputation. The contributors often came from other countries and included the world's most respected authorities in their fields. A general index of all articles was included for the first time in the 7th edition, a practice maintained until 1974.\nProduction of the 9th edition was overseen by Thomas Spencer Baynes, the first English-born editor-in-chief. Dubbed the \"Scholar's Edition\", the 9th edition is the most scholarly of all \"Britannicas\". After 1880, Baynes was assisted by William Robertson Smith. No biographies of living persons were included. James Clerk Maxwell and Thomas Huxley were special advisors on science. However, by the close of the 19th century, the 9th edition was outdated, and the \"Britannica\" faced financial difficulties.\n1901\u20131973.\nIn the third era (10th\u201314th editions, 1901\u20131973), the \"Britannica\" was managed by American businessmen who introduced direct marketing and door-to-door sales. The American owners gradually simplified articles, making them less scholarly for a mass market. The 10th edition was an eleven-volume supplement (including one each of maps and an index) to the 9th, numbered as volumes 25\u201335, but the 11th edition was a completely new work, and is still praised for excellence; its owner, Horace Hooper, lavished enormous effort on its perfection.\nWhen Hooper fell into financial difficulties, the \"Britannica\" was managed by Sears Roebuck for 18 years (1920\u20131923, 1928\u20131943). In 1932, the vice-president of Sears, Elkan Harrison Powell, assumed presidency of the \"Britannica\"; in 1936, he began the policy of continuous revision. This was a departure from earlier practice, in which the articles were not changed until a new edition was produced, at roughly 25-year intervals, some articles unchanged from earlier editions. Powell developed new educational products that built upon the \"Britannica\"'s reputation.\nIn 1943, Sears donated the to the University of Chicago. William Benton, then a vice president of the university, provided the working capital for its operation. The stock was divided between Benton and the university, with the university holding an option on the stock. Benton became chairman of the board and managed the \"Britannica\" until his death in 1973. Benton set up the Benton Foundation, which managed the \"Britannica\" until 1996, and whose sole beneficiary was the University of Chicago. In 1968, near the end of this era, the \"Britannica\" celebrated its bicentennial.\n1974\u20131994.\nIn the fourth era (1974\u201394), the \"Britannica\" introduced its 15th edition, which was reorganized into three parts: the , the , and the . Under Mortimer J. Adler (member of the Board of Editors of Encyclop\u00e6dia Britannica since its inception in 1949, and its chair from 1974; director of editorial planning for the 15th edition of \"Britannica\" from 1965), the \"Britannica\" sought not only to be a good reference work and educational tool, but to systematize all human knowledge. The absence of a separate index and the grouping of articles into parallel encyclopaedias (the and ) provoked a \"firestorm of criticism\" of the initial 15th edition. In response, the 15th edition was completely reorganized and indexed for a re-release in 1985. This second version of the 15th edition continued to be published and revised until the 2010 print version. The official title of the 15th edition is the \"New Encyclop\u00e6dia Britannica\", although it has also been promoted as \"Britannica 3\".\nOn 9 March 1976 the US Federal Trade Commission entered an opinion and order enjoining Encyclop\u00e6dia Britannica, Inc. from using: a) deceptive advertising practices in recruiting sales agents and obtaining sales leads, and b) deceptive sales practices in the door-to-door presentations of its sales agents.\n1994\u2013present.\nIn the fifth era (1994\u2013present), digital versions have been developed and released on optical media and online. In 1996, the \"Britannica\" was bought by Jacqui Safra at well below its estimated value, owing to the company's financial difficulties. Encyclop\u00e6dia Britannica, Inc. split in 1999. One part retained the company name and developed the print version, and the other, Britannica.com Inc., developed digital versions. Since 2001, the two companies have shared a CEO, Ilan Yeshua, who has continued Powell's strategy of introducing new products with the \"Britannica\" name. In March 2012, Britannica's president, Jorge Cauz, announced that it would not produce any new print editions of the encyclopaedia, with the 2010 15th edition being the last. The company will focus only on the online edition and other educational tools.\n\"Britannica\"'s final print edition was in 2010, a 32-volume set. \"Britannica Global Edition\" was also printed in 2010, containing 30 volumes and 18,251 pages, with 8,500 photographs, maps, flags, and illustrations in smaller \"compact\" volumes, as well as over 40,000 articles written by scholars from across the world, including Nobel Prize winners. Unlike the 15th edition, it did not contain and sections, but ran A through Z as all editions up through the 14th had. The following is \"Britannica\"'s description of the work:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The editors of , the world standard in reference since 1768, present the \"Britannica Global Edition\". Developed specifically to provide comprehensive and global coverage of the world around us, this unique product contains thousands of timely, relevant, and essential articles drawn from the itself, as well as from the \"Britannica Concise Encyclopedia\", the \"Britannica Encyclopedia of World Religions\", and Compton's by Britannica. Written by international experts and scholars, the articles in this collection reflect the standards that have been the hallmark of the leading English-language encyclopedia for over 240 years.\nIn 2020, Encyclop\u00e6dia Britannica, Inc. released the \"Britannica All New Children's Encyclopedia: What We Know and What We Don't\", an encyclopedia aimed primarily at younger readers, covering major topics. The encyclopedia was widely praised for bringing back the print format. It was \"Britannica\"'s first encyclopedia for children since 1984.\nDedications.\nThe \"Britannica\" was dedicated to the reigning British monarch from 1788 to 1901 and then, upon its sale to an American partnership, to the British monarch and the President of the United States. Thus, the 11th edition is \"dedicated by Permission to His Majesty George the Fifth, King of Great Britain and Ireland and of the British Dominions beyond the Seas, Emperor of India, and to William Howard Taft, President of the United States of America.\" The order of the dedications has changed with the relative power of the United States and Britain, and with relative sales; the 1954 version of the 14th edition is \"Dedicated by Permission to the Heads of the Two English-Speaking Peoples, Dwight David Eisenhower, President of the United States of America, and Her Majesty, Queen Elizabeth the Second.\" Consistent with this tradition, the 2007 version of the current 15th edition was \"dedicated by permission to the current President of the United States of America, George W. Bush, and Her Majesty, Queen Elizabeth II\", while the 2010 version of the current 15th edition is \"dedicated by permission to Barack Obama, President of the United States of America, and Her Majesty Queen Elizabeth II.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9509", "revid": "1159465028", "url": "https://en.wikipedia.org/wiki?curid=9509", "title": "Endometrium", "text": "Inner mucous membrane of the mammalian uterus\nThe endometrium is the inner epithelial layer, along with its mucous membrane, of the mammalian uterus. It has a basal layer and a functional layer: the basal layer contains stem cells which regenerate the functional layer. The functional layer thickens and then is shed during menstruation in humans and some other mammals, including apes, Old World monkeys, some species of bat, the elephant shrew and the Cairo spiny mouse. In most other mammals, the endometrium is reabsorbed in the estrous cycle. During pregnancy, the glands and blood vessels in the endometrium further increase in size and number. Vascular spaces fuse and become interconnected, forming the placenta, which supplies oxygen and nutrition to the embryo and fetus. The speculated presence of an endometrial microbiota\nhas been argued against.\nStructure.\nThe endometrium consists of a single layer of columnar epithelium plus the stroma on which it rests. The stroma is a layer of connective tissue that varies in thickness according to hormonal influences. In the uterus, simple tubular glands reach from the endometrial surface through to the base of the stroma, which also carries a rich blood supply provided by the spiral arteries. In women of reproductive age, two layers of endometrium can be distinguished. These two layers occur only in the endometrium lining the cavity of the uterus, and not in the lining of the fallopian tubes.\nIn the absence of progesterone, the arteries supplying blood to the functional layer constrict, so that cells in that layer become ischaemic and die, leading to menstruation.\nIt is possible to identify the phase of the menstrual cycle by reference to either the ovarian cycle or the uterine cycle by observing microscopic differences at each phase\u2014for example in the ovarian cycle:\nGene and protein expression.\nAbout 20,000 protein coding genes are expressed in human cells and some 70% of these genes are expressed in the normal endometrium. Just over 100 of these genes are more specifically expressed in the endometrium with only a handful genes being highly endometrium specific. The corresponding specific proteins are expressed in the glandular and stromal cells of the endometrial mucosa. The expression of many of these proteins vary depending on the menstrual cycle, for example the progesterone receptor and thyrotropin-releasing hormone both expressed in the proliferative phase, and PAEP expressed in the secretory phase. Other proteins such as the HOX11 protein that is required for female fertility, is expressed in endometrial stroma cells throughout the menstrual cycle. Certain specific proteins such as the estrogen receptor are also expressed in other types of female tissue types, such as the cervix, fallopian tubes, ovaries and breast.\nMicrobiome speculation.\nThe uterus and endometrium was for a long time thought to be sterile. The cervical plug of mucosa was seen to prevent the entry of any microorganisms ascending from the vagina. In the 1980s this view was challenged when it was shown that uterine infections could arise from weaknesses in the barrier of the cervical plug. Organisms from the vaginal microbiota could enter the uterus during uterine contractions in the menstrual cycle. Further studies sought to identify microbiota specific to the uterus which would be of help in identifying cases of unsuccessful IVF and miscarriages. Their findings were seen to be unreliable due to the possibility of cross-contamination in the sampling procedures used. The well-documented presence of \"Lactobacillus\" species, for example, was easily explained by an increase in the vaginal population being able to seep into the cervical mucous. Another study highlighted the flaws of the earlier studies including cross-contamination. It was also argued that the evidence from studies using germ-free offspring of axenic animals (germ-free) clearly showed the sterility of the uterus. The authors concluded that in light of these findings there was no existence of a microbiome.\nThe normal dominance of Lactobacilli in the vagina is seen as a marker for vaginal health. However, in the uterus this much lower population is seen as invasive in a closed environment that is highly regulated by female sex hormones, and that could have unwanted consequences. In studies of endometriosis \"Lactobacillus\" is not the dominant type and there are higher levels of \"Streptococcus\" and \"Staphylococcus\" species. Half of the cases of bacterial vaginitis showed a polymicrobial biofilm attached to the endometrium.\nFunction.\nThe endometrium is the innermost lining layer of the uterus, and functions to prevent adhesions between the opposed walls of the myometrium, thereby maintaining the patency of the uterine cavity. During the menstrual cycle or estrous cycle, the endometrium grows to a thick, blood vessel-rich, glandular tissue layer. This represents an optimal environment for the implantation of a blastocyst upon its arrival in the uterus. The endometrium is central, echogenic (detectable using ultrasound scanners), and has an average thickness of 6.7\u00a0mm.\nDuring pregnancy, the glands and blood vessels in the endometrium further increase in size and number. Vascular spaces fuse and become interconnected, forming the placenta, which supplies oxygen and nutrition to the embryo and fetus.\nCycle.\nThe functional layer of the endometrial lining undergoes cyclic regeneration from stem cells in the basal layer. Humans, apes, and some other species display the menstrual cycle, whereas most other mammals are subject to an estrous cycle. In both cases, the endometrium initially proliferates under the influence of estrogen. However, once ovulation occurs, the ovary (specifically the corpus luteum) will produce much larger amounts of progesterone. This changes the proliferative pattern of the endometrium to a secretory lining. Eventually, the secretory lining provides a hospitable environment for one or more blastocysts.\nUpon fertilization, the egg may implant into the uterine wall and provide feedback to the body with human chorionic gonadotropin (hCG). hCG provides continued feedback throughout pregnancy by maintaining the corpus luteum, which will continue its role of releasing progesterone and estrogen. In case of implantation, the endometrial lining remains as \"decidua\". The decidua becomes part of the placenta; it provides support and protection for the gestation.\nWithout implantation of a fertilized egg, the endometrial lining is either reabsorbed (estrous cycle) or shed (menstrual cycle). In the latter case, the process of shedding involves the breaking down of the lining, the tearing of small connective blood vessels, and the loss of the tissue and blood that had constituted it through the vagina. The entire process occurs over a period of several days. Menstruation may be accompanied by a series of uterine contractions; these help expel the menstrual endometrium.\nIf there is inadequate stimulation of the lining, due to lack of hormones, the endometrium remains thin and inactive. In humans, this will result in amenorrhea, or the absence of a menstrual period. After menopause, the lining is often described as being atrophic. In contrast, endometrium that is chronically exposed to estrogens, but not to progesterone, may become hyperplastic. Long-term use of oral contraceptives with highly potent progestins can also induce endometrial atrophy.\nIn humans, the cycle of building and shedding the endometrial lining lasts an average of 28 days. The endometrium develops at different rates in different mammals. Various factors including the seasons, climate, and stress can affect its development. The endometrium itself produces certain hormones at different stages of the cycle and this affects other parts of the reproductive system.\nDiseases related with endometrium.\nChorionic tissue can result in marked endometrial changes, known as an Arias-Stella reaction, that have an appearance similar to cancer. Historically, this change was diagnosed as endometrial cancer and it is important only in so far as it should not be misdiagnosed as cancer.\nThin endometrium may be defined as an endometrial thickness of less than 8\u00a0mm. It usually occurs after menopause. Treatments that can improve endometrial thickness include Vitamin E, L-arginine and sildenafil citrate.\nGene expression profiling using cDNA microarray can be used for the diagnosis of endometrial disorders.\nThe European Menopause and Andropause Society (EMAS) released Guidelines with detailed information to assess the endometrium.\nEmbryo transfer.\nAn endometrial thickness (EMT) of less than 7\u00a0mm decreases the pregnancy rate in in vitro fertilization by an odds ratio of approximately 0.4 compared to an EMT of over 7\u00a0mm. However, such low thickness rarely occurs, and any routine use of this parameter is regarded as not justified. The optimal endometrial thickness is 10mm.\nObservation of the endometrium by transvaginal ultrasonography is used when administering fertility medication, such as in in vitro fertilization. At the time of embryo transfer, it is favorable to have an endometrium of a thickness of between 7 and 14 mm with a \"triple-line\" configuration, which means that the endometrium contains a hyperechoic (usually displayed as light) line in the middle surrounded by two more hypoechoic (darker) lines. A \"triple-line\" endometrium reflects the separation of the basal layer and the functional layer, and is also observed in the periovulatory period secondary to rising estradiol levels, and disappears after ovulation.\nEndometrial thickness is also associated with live births in IVF. The live birth rate in a normal endometrium is halved when the thickness is &lt;5mm.\nEndometrial protection.\nEstrogens stimulate endometrial proliferation and carcinogenesis. Conversely, progestogens inhibit endometrial proliferation and carcinogenesis caused by estrogens and stimulate differentiation of the endometrium into decidua, which is termed endometrial transformation or decidualization. This is mediated by the progestogenic and functional antiestrogenic effects of progestogens in this tissue. These effects of progestogens and their protection against endometrial hyperplasia and endometrial cancer caused by estrogens is referred to as \"endometrial protection\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9510", "revid": "1160092827", "url": "https://en.wikipedia.org/wiki?curid=9510", "title": "Electronic music", "text": "Music genre that uses electronic instruments\nElectronic music is a genre of music that employs electronic musical instruments, digital instruments, or circuitry-based music technology in its creation. It includes both music made using electronic and electromechanical means (electroacoustic music). Pure electronic instruments depended entirely on circuitry-based sound generation, for instance using devices such as an electronic oscillator, theremin, or synthesizer. Electromechanical instruments can have mechanical parts such as strings, hammers, and electric elements including magnetic pickups, power amplifiers and loudspeakers. Such electromechanical devices include the telharmonium, Hammond organ, electric piano and the electric guitar.\nThe first electronic musical devices were developed at the end of the 19th century. During the 1920s and 1930s, some electronic instruments were introduced and the first compositions featuring them were written. By the 1940s, magnetic audio tape allowed musicians to tape sounds and then modify them by changing the tape speed or direction, leading to the development of electroacoustic tape music in the 1940s, in Egypt and France. Musique concr\u00e8te, created in Paris in 1948, was based on editing together recorded fragments of natural and industrial sounds. Music produced solely from electronic generators was first produced in Germany in 1953 by Karlheinz Stockhausen. Electronic music was also created in Japan and the United States beginning in the 1950s and Algorithmic composition with computers was first demonstrated in the same decade.\nDuring the 1960s, digital computer music was pioneered, innovation in live electronics took place, and Japanese electronic musical instruments began to influence the music industry. In the early 1970s, Moog synthesizers and drum machines helped popularize synthesized electronic music. The 1970s also saw electronic music begin to have a significant influence on popular music, with the adoption of polyphonic synthesizers, electronic drums, drum machines, and turntables, through the emergence of genres such as disco, krautrock, new wave, synth-pop, hip hop, and EDM. In the early 1980s mass-produced digital synthesizers, such as the Yamaha DX7, became popular, and MIDI (Musical Instrument Digital Interface) was developed. In the same decade, with a greater reliance on synthesizers and the adoption of programmable drum machines, electronic popular music came to the fore. During the 1990s, with the proliferation of increasingly affordable music technology, electronic music production became an established part of popular culture. In Berlin starting in 1989, the Love Parade became the largest street party with over 1\u00a0million visitors, inspiring other such popular celebrations of electronic music. \nContemporary electronic music includes many varieties and ranges from experimental art music to popular forms such as electronic dance music. Pop electronic music is most recognizable in its 4/4 form and more connected with the mainstream than preceding forms which were popular in niche markets.\nOrigins: late 19th century to early 20th century.\nAt the turn of the 20th century, experimentation with emerging electronics led to the first electronic musical instruments. These initial inventions were not sold, but were instead used in demonstrations and public performances. The audiences were presented with reproductions of existing music instead of new compositions for the instruments. While some were considered novelties and produced simple tones, the Telharmonium synthesized the sound of several orchestral instruments with reasonable precision. It achieved viable public interest and made commercial progress into streaming music through telephone networks.\nCritics of musical conventions at the time saw promise in these developments. Ferruccio Busoni encouraged the composition of microtonal music allowed for by electronic instruments. He predicted the use of machines in future music, writing the influential \"Sketch of a New Esthetic of Music\" (1907). Futurists such as Francesco Balilla Pratella and Luigi Russolo began composing music with acoustic noise to evoke the sound of machinery. They predicted expansions in timbre allowed for by electronics in the influential manifesto \"The Art of Noises\" (1913).\nEarly compositions.\nDevelopments of the vacuum tube led to electronic instruments that were smaller, amplified, and more practical for performance. In particular, the theremin, ondes Martenot and trautonium were commercially produced by the early 1930s.\nFrom the late 1920s, the increased practicality of electronic instruments influenced composers such as Joseph Schillinger to adopt them. They were typically used within orchestras, and most composers wrote parts for the theremin that could otherwise be performed with string instruments.\nAvant-garde composers criticized the predominant use of electronic instruments for conventional purposes. The instruments offered expansions in pitch resources that were exploited by advocates of microtonal music such as Charles Ives, Dimitrios Levidis, Olivier Messiaen and Edgard Var\u00e8se. Further, Percy Grainger used the theremin to abandon fixed tonation entirely, while Russian composers such as Gavriil Popov treated it as a source of noise in otherwise-acoustic noise music.\nRecording experiments.\nDevelopments in early recording technology paralleled that of electronic instruments. The first means of recording and reproducing audio was invented in the late 19th century with the mechanical phonograph. Record players became a common household item, and by the 1920s composers were using them to play short recordings in performances.\nThe introduction of electrical recording in 1925 was followed by increased experimentation with record players. Paul Hindemith and Ernst Toch composed several pieces in 1930 by layering recordings of instruments and vocals at adjusted speeds. Influenced by these techniques, John Cage composed \"Imaginary Landscape No. 1\" in 1939 by adjusting the speeds of recorded tones.\nComposers began to experiment with newly developed sound-on-film technology. Recordings could be spliced together to create sound collages, such as those by Tristan Tzara, Kurt Schwitters, Filippo Tommaso Marinetti, Walter Ruttmann and Dziga Vertov. Further, the technology allowed sound to be graphically created and modified. These techniques were used to compose soundtracks for several films in Germany and Russia, in addition to the popular \"Dr. Jekyll and Mr. Hyde\" in the United States. Experiments with graphical sound were continued by Norman McLaren from the late 1930s.\nDevelopment: 1940s to 1950s.\nElectroacoustic tape music.\nThe first practical audio tape recorder was unveiled in 1935. Improvements to the technology were made using the AC biasing technique, which significantly improved recording fidelity. As early as 1942, test recordings were being made in stereo. Although these developments were initially confined to Germany, recorders and tapes were brought to the United States following the end of World War II. These were the basis for the first commercially produced tape recorder in 1948.\nIn 1944, before the use of magnetic tape for compositional purposes, Egyptian composer Halim El-Dabh, while still a student in Cairo, used a cumbersome wire recorder to record sounds of an ancient \"zaar\" ceremony. Using facilities at the Middle East Radio studios El-Dabh processed the recorded material using reverberation, echo, voltage controls and re-recording. What resulted is believed to be the earliest tape music composition. The resulting work was entitled \"The Expression of Zaar\" and it was presented in 1944 at an art gallery event in Cairo. While his initial experiments in tape-based composition were not widely known outside of Egypt at the time, El-Dabh is also known for his later work in electronic music at the Columbia-Princeton Electronic Music Center in the late 1950s.\nMusique concr\u00e8te.\nFollowing his work with Studio d'Essai at Radiodiffusion Fran\u00e7aise (RDF), during the early 1940s, Pierre Schaeffer is credited with originating the theory and practice of musique concr\u00e8te. In the late 1940s, experiments in sound-based composition using shellac record players were first conducted by Schaeffer. In 1950, the techniques of musique concrete were expanded when magnetic tape machines were used to explore sound manipulation practices such as speed variation (pitch shift) and tape splicing.\nOn 5 October 1948, RDF broadcast Schaeffer's \"Etude aux chemins de fer\". This was the first \"movement\" of \"Cinq \u00e9tudes de bruits\", and marked the beginning of studio realizations and musique concr\u00e8te (or acousmatic art). Schaeffer employed a disc cutting lathe, four turntables, a four-channel mixer, filters, an echo chamber, and a mobile recording unit. Not long after this, Pierre Henry began collaborating with Schaeffer, a partnership that would have profound and lasting effects on the direction of electronic music. Another associate of Schaeffer, Edgard Var\u00e8se, began work on \"D\u00e9serts\", a work for chamber orchestra and tape. The tape parts were created at Pierre Schaeffer's studio and were later revised at Columbia University.\nIn 1950, Schaeffer gave the first public (non-broadcast) concert of musique concr\u00e8te at the \u00c9cole Normale de Musique de Paris. \"Schaeffer used a PA system, several turntables, and mixers. The performance did not go well, as creating live montages with turntables had never been done before.\" Later that same year, Pierre Henry collaborated with Schaeffer on \"Symphonie pour un homme seul\" (1950) the first major work of musique concrete. In Paris in 1951, in what was to become an important worldwide trend, RTF established the first studio for the production of electronic music. Also in 1951, Schaeffer and Henry produced an opera, \"Orpheus\", for concrete sounds and voices.\nBy 1951 the work of Schaeffer, composer-percussionist Pierre Henry, and sound engineer Jacques Poullin had received official recognition and The Groupe de Recherches de Musique Concr\u00e8te, Club d 'Essai de la Radiodiffusion-T\u00e9l\u00e9vision Fran\u00e7aise was established at RTF in Paris, the ancestor of the ORTF.\nElektronische Musik.\nKarlheinz Stockhausen worked briefly in Schaeffer's studio in 1952, and afterward for many years at the WDR Cologne's Studio for Electronic Music.\n1954 saw the advent of what would now be considered authentic electric plus acoustic compositions\u2014acoustic instrumentation augmented/accompanied by recordings of manipulated or electronically generated sound. Three major works were premiered that year: Var\u00e8se's \"D\u00e9serts\", for chamber ensemble and tape sounds, and two works by Otto Luening and Vladimir Ussachevsky: \"Rhapsodic Variations for the Louisville Symphony\" and \"A Poem in Cycles and Bells\", both for orchestra and tape. Because he had been working at Schaeffer's studio, the tape part for Var\u00e8se's work contains much more concrete sounds than electronic. \"A group made up of wind instruments, percussion and piano alternate with the mutated sounds of factory noises and ship sirens and motors, coming from two loudspeakers.\"\nAt the German premiere of \"D\u00e9serts\" in Hamburg, which was conducted by Bruno Maderna, the tape controls were operated by Karlheinz Stockhausen. The title \"D\u00e9serts\" suggested to Var\u00e8se not only \"all physical deserts (of sand, sea, snow, of outer space, of empty streets), but also the deserts in the mind of man; not only those stripped aspects of nature that suggest bareness, aloofness, timelessness, but also that remote inner space no telescope can reach, where man is alone, a world of mystery and essential loneliness.\"\nIn Cologne, what would become the most famous electronic music studio in the world, was officially opened at the radio studios of the NWDR in 1953, though it had been in the planning stages as early as 1950 and early compositions were made and broadcast in 1951. The brainchild of Werner Meyer-Eppler, Robert Beyer, and Herbert Eimert (who became its first director), the studio was soon joined by Karlheinz Stockhausen and Gottfried Michael Koenig. In his 1949 thesis \"Elektronische Klangerzeugung: Elektronische Musik und Synthetische Sprache\", Meyer-Eppler conceived the idea to synthesize music entirely from electronically produced signals; in this way, \"elektronische Musik\" was sharply differentiated from French \"musique concr\u00e8te\", which used sounds recorded from acoustical sources.\nIn 1953, Stockhausen composed his \"Studie I\", followed in 1954 by \"Elektronische Studie II\"\u2014the first electronic piece to be published as a score. In 1955, more experimental and electronic studios began to appear. Notable were the creation of the Studio di fonologia musicale di Radio Milano, a studio at the NHK in Tokyo founded by Toshiro Mayuzumi, and the Philips studio at Eindhoven, the Netherlands, which moved to the University of Utrecht as the Institute of Sonology in 1960.\n\"With Stockhausen and Mauricio Kagel in residence, [Cologne] became a year-round hive of charismatic avante-gardism.\" on two occasions combining electronically generated sounds with relatively conventional orchestras\u2014in \"Mixtur\" (1964) and \"Hymnen, dritte Region mit Orchester\" (1967). Stockhausen stated that his listeners had told him his electronic music gave them an experience of \"outer space\", sensations of flying, or being in a \"fantastic dream world\".\nUnited States.\nIn the United States, electronic music was being created as early as 1939, when John Cage published \"Imaginary Landscape, No. 1\", using two variable-speed turntables, frequency recordings, muted piano, and cymbal, but no electronic means of production. Cage composed five more \"Imaginary Landscapes\" between 1942 and 1952 (one withdrawn), mostly for percussion ensemble, though No. 4 is for twelve radios and No. 5, written in 1952, uses 42 recordings and is to be realized as a magnetic tape. According to Otto Luening, Cage also performed \"Williams Mix\" at Donaueschingen in 1954, using eight loudspeakers, three years after his alleged collaboration. \"Williams Mix\" was a success at the Donaueschingen Festival, where it made a \"strong impression\".\nThe Music for Magnetic Tape Project was formed by members of the New York School (John Cage, Earle Brown, Christian Wolff, David Tudor, and Morton Feldman), and lasted three years until 1954. Cage wrote of this collaboration: \"In this social darkness, therefore, the work of Earle Brown, Morton Feldman, and Christian Wolff continues to present a brilliant light, for the reason that at the several points of notation, performance, and audition, action is provocative.\"\nCage completed \"Williams Mix\" in 1953 while working with the Music for Magnetic Tape Project. The group had no permanent facility, and had to rely on borrowed time in commercial sound studios, including the studio of Bebe and Louis Barron.\nColumbia-Princeton Center.\nIn the same year Columbia University purchased its first tape recorder\u2014a professional Ampex machine\u2014to record concerts. Vladimir Ussachevsky, who was on the music faculty of Columbia University, was placed in charge of the device, and almost immediately began experimenting with it.\nHerbert Russcol writes: \"Soon he was intrigued with the new sonorities he could achieve by recording musical instruments and then superimposing them on one another.\" Ussachevsky said later: \"I suddenly realized that the tape recorder could be treated as an instrument of sound transformation.\" On Thursday, 8 May 1952, Ussachevsky presented several demonstrations of tape music/effects that he created at his Composers Forum, in the McMillin Theatre at Columbia University. These included \"Transposition, Reverberation, Experiment, Composition\", and \"Underwater Valse\". In an interview, he stated: \"I presented a few examples of my discovery in a public concert in New York together with other compositions I had written for conventional instruments.\"\nOtto Luening, who had attended this concert, remarked: \"The equipment at his disposal consisted of an Ampex tape recorder . . . and a simple box-like device designed by the brilliant young engineer, Peter Mauzey, to create feedback, a form of mechanical reverberation. Other equipment was borrowed or purchased with personal funds.\"\nJust three months later, in August 1952, Ussachevsky traveled to Bennington, Vermont, at Luening's invitation to present his experiments. There, the two collaborated on various pieces. Luening described the event: \"Equipped with earphones and a flute, I began developing my first tape-recorder composition. Both of us were fluent improvisors and the medium fired our imaginations.\" They played some early pieces informally at a party, where \"a number of composers almost solemnly congratulated us saying, 'This is it' ('it' meaning the music of the future).\"\nWord quickly reached New York City. Oliver Daniel telephoned and invited the pair to \"produce a group of short compositions for the October concert sponsored by the American Composers Alliance and Broadcast Music, Inc., under the direction of Leopold Stokowski at the Museum of Modern Art in New York. After some hesitation, we agreed. . . . Henry Cowell placed his home and studio in Woodstock, New York, at our disposal. With the borrowed equipment in the back of Ussachevsky's car, we left Bennington for Woodstock and stayed two weeks. . . . In late September 1952, the travelling laboratory reached Ussachevsky's living room in New York, where we eventually completed the compositions.\"\nTwo months later, on 28 October, Vladimir Ussachevsky and Otto Luening presented the first Tape Music concert in the United States. The concert included Luening's \"Fantasy in Space\" (1952)\u2014\"an impressionistic virtuoso piece\" using manipulated recordings of flute\u2014and \"Low Speed\" (1952), an \"exotic composition that took the flute far below its natural range.\" Both pieces were created at the home of Henry Cowell in Woodstock, New York. After several concerts caused a sensation in New York City, Ussachevsky and Luening were invited onto a live broadcast of NBC's Today Show to do an interview demonstration\u2014the first televised electroacoustic performance. Luening described the event: \"I improvised some [flute] sequences for the tape recorder. Ussachevsky then and there put them through electronic transformations.\"\nThe score for \"Forbidden Planet\", by Louis and Bebe Barron, was entirely composed using custom-built electronic circuits and tape recorders in 1956 (but no synthesizers in the modern sense of the word).\nUSSR.\nIn 1929, Nikolai Obukhov invented the \"sounding cross\" (la croix sonore), comparable to the principle of the theremin. In the 1930s, Nikolai Ananyev invented \"sonar\", and engineer Alexander Gurov \u2014 neoviolena, I. Ilsarov \u2014 ilston., A. Rimsky-Korsakov and A. Ivanov \u2014 emiriton. Composer and inventor Arseny Avraamov was engaged in scientific work on sound synthesis and conducted a number of experiments that would later form the basis of Soviet electro-musical instruments.\nIn 1956 Vyacheslav Mescherin created the Ensemble of electro-musical instruments, which used theremins, electric harps, electric organs, the first synthesizer in the USSR \"Ekvodin\", and also created the first Soviet reverb machine. The style in which Meshcherin's ensemble played is known as \"Space age pop\". In 1957, engineer Igor Simonov assembled a working model of a noise recorder (electroeoliphone), with the help of which it was possible to extract various timbres and consonances of a noise nature. In 1958, Evgeny Murzin designed ANS synthesizer, one of the world's first polyphonic musical synthesizers.\nFounded by Murzin in 1966, the Moscow Experimental Electronic Music Studio became the base for a new generation of experimenters - Eduard Artemyev, Alexander Nemtin, S\u00e1ndor Kall\u00f3s, Sofia Gubaidulina, Alfred Schnittke, and Vladimir Martynov. By the end of the 1960s, musical groups playing light electronic music appeared in the USSR. At the state level, this music began to be used to attract foreign tourists to the country and for broadcasting to foreign countries. In the mid-1970s, composer Alexander Zatsepin designed an \"orchestrolla\" - a modification of the mellotron.\nThe Baltic Soviet Rebublics also had their own pioneers: in Estonian SSR \u2014 Sven Grunberg, in Lithuanian SSR \u2014 Gedrus Kupriavicius, in Latvian SSR \u2014 Opus and Zodiac.\nAustralia.\nThe world's first computer to play music was CSIRAC, which was designed and built by Trevor Pearcey and Maston Beard. Mathematician Geoff Hill programmed the CSIRAC to play popular musical melodies from the very early 1950s. In 1951 it publicly played the Colonel Bogey March, of which no known recordings exist, only the accurate reconstruction. However, CSIRAC played standard repertoire and was not used to extend musical thinking or composition practice. CSIRAC was never recorded, but the music played was accurately reconstructed. The oldest known recordings of computer-generated music were played by the Ferranti Mark 1 computer, a commercial version of the Baby Machine from the University of Manchester in the autumn of 1951. The music program was written by Christopher Strachey.\nJapan.\nThe earliest group of electronic musical instruments in Japan, Yamaha Magna Organ was built in 1935. however, after World War II, Japanese composers such as Minao Shibata knew of the development of electronic musical instruments. By the late 1940s, Japanese composers began experimenting with electronic music and institutional sponsorship enabled them to experiment with advanced equipment. Their infusion of Asian music into the emerging genre would eventually support Japan's popularity in the development of music technology several decades later.\nFollowing the foundation of electronics company Sony in 1946, composers Toru Takemitsu and Minao Shibata independently explored possible uses for electronic technology to produce music. Takemitsu had ideas similar to musique concr\u00e8te, which he was unaware of, while Shibata foresaw the development of synthesizers and predicted a drastic change in music. Sony began producing popular magnetic tape recorders for government and public use.\nThe avant-garde collective Jikken K\u014db\u014d (Experimental Workshop), founded in 1950, was offered access to emerging audio technology by Sony. The company hired Toru Takemitsu to demonstrate their tape recorders with compositions and performances of electronic tape music. The first electronic tape pieces by the group were \"Toraware no Onna\" (\"Imprisoned Woman\") and \"Piece B\", composed in 1951 by Kuniharu Akiyama. Many of the electroacoustic tape pieces they produced were used as incidental music for radio, film, and theatre. They also held concerts employing a slide show synchronized with a recorded soundtrack. Composers outside of the Jikken K\u014db\u014d, such as Yasushi Akutagawa, Saburo Tominaga, and Shir\u014d Fukai, were also experimenting with radiophonic tape music between 1952 and 1953.\nMusique concr\u00e8te was introduced to Japan by Toshiro Mayuzumi, who was influenced by a Pierre Schaeffer concert. From 1952, he composed tape music pieces for a comedy film, a radio broadcast, and a radio drama. However, Schaeffer's concept of \"sound object\" was not influential among Japanese composers, who were mainly interested in overcoming the restrictions of human performance. This led to several Japanese electroacoustic musicians making use of serialism and twelve-tone techniques, evident in Yoshir\u014d Irino's 1951 dodecaphonic piece \"Concerto da\nCamera\", in the organization of electronic sounds in Mayuzumi's \"X, Y, Z for Musique Concr\u00e8te\", and later in Shibata's electronic music by 1956.\nModelling the NWDR studio in Cologne, established an NHK electronic music studio in Tokyo in 1954, which became one of the world's leading electronic music facilities.The NHK electronic music studio was equipped with technologies such as tone-generating and audio processing equipment, recording and radiophonic equipment, ondes Martenot, Monochord and Melochord, sine-wave oscillators, tape recorders, ring modulators, band-pass filters, and four- and eight-channel mixers. Musicians associated with the studio included Toshiro Mayuzumi, Minao Shibata, Joji Yuasa, Toshi Ichiyanagi, and Toru Takemitsu. The studio's first electronic compositions were completed in 1955, including Mayuzumi's five-minute pieces \"Studie I: Music for Sine Wave by Proportion of Prime Number\", \"Music for Modulated Wave by Proportion of Prime Number\" and \"Invention for Square Wave and Sawtooth Wave\" produced using the studio's various tone-generating capabilities, and Shibata's 20-minute stereo piece \"Musique Concr\u00e8te for Stereophonic Broadcast\".\nMid-to-late 1950s.\nThe impact of computers continued in 1956. Lejaren Hiller and Leonard Isaacson composed \"Illiac Suite\" for string quartet, the first complete work of computer-assisted composition using algorithmic composition. \"... Hiller postulated that a computer could be taught the rules of a particular style and then called on to compose accordingly.\" Later developments included the work of Max Mathews at Bell Laboratories, who developed the influential MUSIC I program in 1957, one of the first computer programs to play electronic music. Vocoder technology was also a major development in this early era. In 1956, Stockhausen composed \"Gesang der J\u00fcnglinge\", the first major work of the Cologne studio, based on a text from the \"Book of Daniel\". An important technological development of that year was the invention of the Clavivox synthesizer by Raymond Scott with subassembly by Robert Moog.\nIn 1957, Kid Baltan (Dick Raaymakers) and Tom Dissevelt released their debut album, \"Song Of The Second Moon\", recorded at the Philips studio in the Netherlands. The public remained interested in the new sounds being created around the world, as can be deduced by the inclusion of Var\u00e8se's \"Po\u00e8me \u00e9lectronique\", which was played over four hundred loudspeakers at the Philips Pavilion of the 1958 Brussels World Fair. That same year, Mauricio Kagel, an Argentine composer, composed \"Transici\u00f3n II\". The work was realized at the WDR studio in Cologne. Two musicians performed on the piano, one in the traditional manner, the other playing on the strings, frame, and case. Two other performers used tape to unite the presentation of live sounds with the future of prerecorded materials from later on and its past of recordings made earlier in the performance.\nIn 1958, Columbia-Princeton developed the RCA Mark II Sound Synthesizer, the first programmable synthesizer. Prominent composers such as Vladimir Ussachevsky, Otto Luening, Milton Babbitt, Charles Wuorinen, Halim El-Dabh, B\u00fclent Arel and Mario Davidovsky used the RCA Synthesizer extensively in various compositions. One of the most influential composers associated with the early years of the studio was Egypt's Halim El-Dabh who, after having developed the earliest known electronic tape music in 1944, became more famous for \"Leiyla and the Poet\", a 1959 series of electronic compositions that stood out for its immersion and seamless fusion of electronic and folk music, in contrast to the more mathematical approach used by serial composers of the time such as Babbitt. El-Dabh's \"Leiyla and the Poet\", released as part of the album \"Columbia-Princeton Electronic Music Center\" in 1961, would be cited as a strong influence by a number of musicians, ranging from Neil Rolnick, Charles Amirkhanian and Alice Shields to rock musicians Frank Zappa and The West Coast Pop Art Experimental Band.\nFollowing the emergence of differences within the GRMC (Groupe de Recherche de Musique Concr\u00e8te) Pierre Henry, Philippe Arthuys, and several of their colleagues, resigned in April 1958. Schaeffer created a new collective, called Groupe de Recherches Musicales (GRM) and set about recruiting new members including Luc Ferrari, Beatriz Ferreyra, Fran\u00e7ois-Bernard M\u00e2che, Iannis Xenakis, Bernard Parmegiani, and Mireille Chamass-Kyrou. Later arrivals included Ivo Malec, Philippe Carson, Romuald Vandelle, Edgardo Canton and Fran\u00e7ois Bayle.\nExpansion: 1960s.\nThese were fertile years for electronic music\u2014not just for academia, but for independent artists as synthesizer technology became more accessible. By this time, a strong community of composers and musicians working with new sounds and instruments was established and growing. 1960 witnessed the composition of Luening's \"Gargoyles\" for violin and tape as well as the premiere of Stockhausen's \"Kontakte\" for electronic sounds, piano, and percussion. This piece existed in two versions\u2014one for 4-channel tape, and the other for tape with human performers. \"In \"Kontakte\", Stockhausen abandoned traditional musical form based on linear development and dramatic climax. This new approach, which he termed 'moment form', resembles the 'cinematic splice' techniques in early twentieth-century film.\"\nThe theremin had been in use since the 1920s but it attained a degree of popular recognition through its use in science-fiction film soundtrack music in the 1950s (e.g., Bernard Herrmann's classic score for \"The Day the Earth Stood Still\").\nIn the UK in this period, the BBC Radiophonic Workshop (established in 1958) came to prominence, thanks in large measure to their work on the BBC science-fiction series \"Doctor Who\". One of the most influential British electronic artists in this period was Workshop staffer Delia Derbyshire, who is now famous for her 1963 electronic realisation of the iconic \"Doctor Who\" theme, composed by Ron Grainer.\nDuring the time of the UNESCO fellowship for studies in electronic music (1958) Josef Tal went on a study tour in the US and Canada. He summarized his conclusions in two articles that he submitted to UNESCO. In 1961, he established the \"Centre for Electronic Music in Israel\" at The Hebrew University of Jerusalem. In 1962, Hugh Le Caine arrived in Jerusalem to install his \"Creative Tape Recorder\" in the centre. In the 1990s Tal conducted, together with Dr. Shlomo Markel, in cooperation with the Technion \u2013 Israel Institute of Technology, and the Volkswagen Foundation a research project ('Talmark') aimed at the development of a novel musical notation system for electronic music.\nMilton Babbitt composed his first electronic work using the synthesizer\u2014his \"Composition for Synthesizer\" (1961)\u2014which he created using the RCA synthesizer at the Columbia-Princeton Electronic Music Center.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For Babbitt, the RCA synthesizer was a dream come true for three reasons. First, the ability to pinpoint and control every musical element precisely. Second, the time needed to realize his elaborate serial structures were brought within practical reach. Third, the question was no longer \"What are the limits of the human performer?\" but rather \"What are the limits of human hearing?\"\nThe collaborations also occurred across oceans and continents. In 1961, Ussachevsky invited Var\u00e8se to the Columbia-Princeton Studio (CPEMC). Upon arrival, Varese embarked upon a revision of \"D\u00e9serts\". He was assisted by Mario Davidovsky and B\u00fclent Arel.\nThe intense activity occurring at CPEMC and elsewhere inspired the establishment of the San Francisco Tape Music Center in 1963 by Morton Subotnick, with additional members Pauline Oliveros, Ramon Sender, Anthony Martin, and Terry Riley.\nLater, the Center moved to Mills College, directed by Pauline Oliveros, where it is today known as the Center for Contemporary Music. Pietro Grossi was an Italian pioneer of computer composition and tape music, who first experimented with electronic techniques in the early sixties. Grossi was a cellist and composer, born in Venice in 1917. He founded the S 2F M (Studio de Fonologia Musicale di Firenze) in 1963 to experiment with electronic sound and composition.\nSimultaneously in San Francisco, composer Stan Shaff and equipment designer Doug McEachern, presented the first \"Audium\" concert at San Francisco State College (1962), followed by work at the San Francisco Museum of Modern Art (1963), conceived of as in time, controlled movement of sound in space. Twelve speakers surrounded the audience, four speakers were mounted on a rotating, mobile-like construction above. In an SFMOMA performance the following year (1964), \"San Francisco Chronicle\" music critic Alfred Frankenstein commented, \"the possibilities of the space-sound continuum have seldom been so extensively explored\". In 1967, the first Audium, a \"sound-space continuum\" opened, holding weekly performances through 1970. In 1975, enabled by seed money from the National Endowment for the Arts, a new Audium opened, designed floor to ceiling for spatial sound composition and performance. \"In contrast, there are composers who manipulated sound space by locating multiple speakers at various locations in a performance space and then switching or panning the sound between the sources. In this approach, the composition of spatial manipulation is dependent on the location of the speakers and usually exploits the acoustical properties of the enclosure. Examples include Varese's \"Poeme Electronique\" (tape music performed in the Philips Pavilion of the 1958 World Fair, Brussels) and Stan Schaff's \"Audium\" installation, currently active in San Francisco.\" Through weekly programs (over 4,500 in 40 years), Shaff \"sculpts\" sound, performing now-digitized spatial works live through 176 speakers.\nJean-Jacques Perrey experimented with Schaeffer's techniques on tape loops and was among the first to use the recently released Moog synthesizer developed by Robert Moog. With this instrument he composed some works with Gershon Kingsley and solo. A well-known example of the use of Moog's full-sized Moog modular synthesizer is the 1968 \"Switched-On Bach\" album by Wendy Carlos, which triggered a craze for synthesizer music. In 1969 David Tudor brought a Moog modular synthesizer and Ampex tape machines to the National Institute of Design in Ahmedabad with the support of the Sarabhai family, forming the foundation of India's first electronic music studio. Here a group of composers Jinraj Joshipura, Gita Sarabhai, SC Sharma, IS Mathur and Atul Desai developed experimental sound compositions between 1969 and 1973.\nComputer music.\nMusical melodies were first generated by the computer CSIRAC in Australia in 1950. There were newspaper reports from America and England (early and recently) that computers may have played music earlier, but thorough research has debunked these stories as there is no evidence to support the newspaper reports (some of which were obviously speculative). Research has shown that people \"speculated\" about computers playing music, possibly because computers would make noises, but there is no evidence that they actually did it.\nThe world's first computer to play music was CSIRAC, which was designed and built by Trevor Pearcey and Maston Beard in the 1950s. Mathematician Geoff Hill programmed the CSIRAC to play popular musical melodies from the very early 1950s. In 1951 it publicly played the \"Colonel Bogey March\" of which no known recordings exist.\nHowever, CSIRAC played standard repertoire and was not used to extend musical thinking or composition practice which is current computer-music practice.\nThe first music to be performed in England was a performance of the British National Anthem that was programmed by Christopher Strachey on the Ferranti Mark I, late in 1951. Later that year, short extracts of three pieces were recorded there by a BBC outside broadcasting unit: the National Anthem, \"Ba, Ba Black Sheep\", and \"In the Mood\" and this is recognised as the earliest recording of a computer to play music. This recording can be heard at this Manchester University site. Researchers at the University of Canterbury, Christchurch declicked and restored this recording in 2016 and the results may be heard on SoundCloud.\nThe late 1950s, 1960s, and 1970s also saw the development of large mainframe computer synthesis. Starting in 1957, Max Mathews of Bell Labs developed the MUSIC programs, culminating in MUSIC V, a direct digital synthesis language. Laurie Spiegel developed the algorithmic musical composition software \"Music Mouse\" (1986) for Macintosh, Amiga, and Atari computers.\nStochastic music.\nAn important new development was the advent of computers to compose music, as opposed to manipulating or creating sounds. Iannis Xenakis began what is called \"musique stochastique\", or \"stochastic music\", which is a composing method that uses mathematical probability systems. Different probability algorithms were used to create a piece under a set of parameters. Xenakis used computers to compose pieces like \"ST/4\" for string quartet and \"ST/48\" for orchestra (both 1962), \"Morsima-Amorsima\", \"ST/10\", and \"Atr\u00e9es\". He developed the computer system UPIC for translating graphical images into musical results and composed \"Myc\u00e8nes Alpha\" (1978) with it.\nLive electronics.\nIn Europe in 1964, Karlheinz Stockhausen composed \"Mikrophonie I\" for tam-tam, hand-held microphones, filters, and potentiometers, and \"Mixtur\" for orchestra, four sine-wave generators, and four ring modulators. In 1965 he composed \"Mikrophonie II\" for choir, Hammond organ, and ring modulators.\nIn 1966\u20131967, Reed Ghazala discovered and began to teach \"circuit bending\"\u2014the application of the creative short circuit, a process of chance short-circuiting, creating experimental electronic instruments, exploring sonic elements mainly of timbre and with less regard to pitch or rhythm, and influenced by John Cage's aleatoric music [\"sic\"] concept.\nCosey Fanni Tutti's performance art and musical career explored the concept of 'acceptable' music and she went on to explore the use of sound as a means of desire or discomfort.\nWendy Carlos performed selections from her album \"Switched-On Bach\" on stage with a synthesizer with the St. Louis Symphony Orchestra; another live performance was with Kurzweil Baroque Ensemble for \"Bach at the Beacon\" in 1997. In June 2018, Suzanne Ciani released \"LIVE Quadraphonic\", a live album documenting her first solo performance on a Buchla synthesizer in 40 years. It was one of the first quadraphonic vinyl releases in over 30 years.\nJapanese instruments.\nIn the 1950s, Japanese electronic musical instruments began influencing the international music industry. Ikutaro Kakehashi, who founded Ace Tone in 1960, developed his own version of electronic percussion that had been already popular on the overseas electronic organ. At NAMM 1964, he revealed it as the R-1 Rhythm Ace, a hand-operated percussion device that played electronic drum sounds manually as the user pushed buttons, in a similar fashion to modern electronic drum pads.\nIn 1963, Korg released the Donca-Matic DA-20, an electro-mechanical drum machine. In 1965, Nippon Columbia patented a fully electronic drum machine. Korg released the Donca-Matic DC-11 electronic drum machine in 1966, which they followed with the Korg Mini Pops, which was developed as an option for the Yamaha Electone electric organ. Korg's Stageman and Mini Pops series were notable for \"natural metallic percussion\" sounds and incorporating controls for drum \"breaks and fill-ins.\"\nIn 1967, Ace Tone founder Ikutaro Kakehashi patented a preset rhythm-pattern generator using diode matrix circuit similar to the Seeburg's prior U.S. Patent 3358068 filed in 1964 (See Drum machine#History), which he released as the FR-1 Rhythm Ace drum machine the same year. It offered 16 preset patterns, and four buttons to manually play each instrument sound (cymbal, claves, cowbell and bass drum). The rhythm patterns could also be cascaded together by pushing multiple rhythm buttons simultaneously, and the possible combination of rhythm patterns were more than a hundred. Ace Tone's Rhythm Ace drum machines found their way into popular music from the late 1960s, followed by Korg drum machines in the 1970s. Kakehashi later left Ace Tone and founded Roland Corporation in 1972, with and becoming highly influential for the next several decades. The company would go on to have a big impact on popular music, and do more to shape popular electronic music than any other company.\nTurntablism has origins in the invention of direct-drive turntables. Early belt-drive turntables were unsuitable for turntablism, since they had a slow start-up time, and they were prone to wear-and-tear and breakage, as the belt would break from backspin or scratching. The first direct-drive turntable was invented by Shuichi Obata, an engineer at Matsushita (now Panasonic), based in Osaka, Japan. It eliminated belts, and instead employed a motor to directly drive a platter on which a vinyl record rests. In 1969, Matsushita released it as the SP-10, the first direct-drive turntable on the market, and the first in their influential Technics series of turntables. It was succeeded by the Technics SL-1100 and SL-1200 in the early 1970s, and they were widely adopted by hip hop musicians, with the SL-1200 remaining the most widely used turntable in DJ culture for several decades.\nJamaican dub music.\nIn Jamaica, a form of popular electronic music emerged in the 1960s, dub music, rooted in sound system culture. Dub music was pioneered by studio engineers, such as Sylvan Morris, King Tubby, Errol Thompson, Lee \"Scratch\" Perry, and Scientist, producing reggae-influenced experimental music with electronic sound technology, in recording studios and at sound system parties. Their experiments included forms of tape-based composition comparable to aspects of \"musique concr\u00e8te\", an emphasis on repetitive rhythmic structures (often stripped of their harmonic elements) comparable to minimalism, the electronic manipulation of spatiality, the sonic electronic manipulation of pre-recorded musical materials from mass media, deejays toasting over pre-recorded music comparable to live electronic music, remixing music, turntablism, and the mixing and scratching of vinyl.\nDespite the limited electronic equipment available to dub pioneers such as King Tubby and Lee \"Scratch\" Perry, their experiments in remix culture were musically cutting-edge. King Tubby, for example, was a sound system proprietor and electronics technician, whose small front-room studio in the Waterhouse ghetto of western Kingston was a key site of dub music creation.\nLate 1960s to early 1980s.\nRise of popular electronic music.\nIn the late 1960s, pop and rock musicians, including the Beach Boys and the Beatles, began to use electronic instruments, like the theremin and Mellotron, to supplement and define their sound. In his book \"Electronic and Experimental Music\", Thom Holmes recognises the Beatles' 1966 recording \"Tomorrow Never Knows\" as the song that \"ushered in a new era in the use of electronic music in rock and pop music\" due to the band's incorporation of tape loops and reversed and speed-manipulated tape sounds.\nAlso in the late 1960s, the music duos Silver Apples, Beaver and Krause, and experimental rock bands like White Noise, the United States of America, Fifty Foot Hose, and Gong are regarded as pioneers in the electronic rock and electronica genres for their work in melding psychedelic rock with oscillators and synthesizers. The 1969 instrumental \"Popcorn\" written by Gershon Kingsley for \"Music To Moog By\" became a worldwide success due to the 1972 version made by Hot Butter.\nThe Moog synthesizer was brought to the mainstream in 1968 by \"Switched-On Bach\", a bestselling album of Bach compositions arranged for Moog synthesizer by American composer Wendy Carlos. The album achieved critical and commercial success, winning the 1970 Grammy Awards for Best Classical Album, Best Classical Performance \u2013 Instrumental Soloist or Soloists (With or Without Orchestra), and Best Engineered Classical Recording.\nIn 1969, David Borden formed the world's first synthesizer ensemble called the Mother Mallard's Portable Masterpiece Company in Ithaca, New York.\nBy the end of the 1960s, the Moog synthesizer took a leading place in the sound of emerging progressive rock with bands including Pink Floyd, Yes, Emerson, Lake &amp; Palmer, and Genesis making them part of their sound. Instrumental prog rock was particularly significant in continental Europe, allowing bands like Kraftwerk, Tangerine Dream, Cluster, Can, Neu!, and Faust to circumvent the language barrier. Their synthesiser-heavy \"krautrock\", along with the work of Brian Eno (for a time the keyboard player with Roxy Music), would be a major influence on subsequent electronic rock.\nAmbient dub was pioneered by King Tubby and other Jamaican sound artists, using DJ-inspired ambient electronics, complete with drop-outs, echo, equalization and psychedelic electronic effects. It featured layering techniques and incorporated elements of world music, deep basslines and harmonic sounds. Techniques such as a long echo delay were also used. Other notable artists within the genre include Dreadzone, Higher Intelligence Agency, The Orb, Ott, Loop Guru, Woob and Transglobal Underground.\nDub music influenced electronic musical techniques later adopted by hip hop music when Jamaican immigrant DJ Kool Herc in the early 1970s introduced Jamaica's sound system culture and dub music techniques to America. One such technique that became popular in hip hop culture was playing two copies of the same record on two turntables in alternation, extending the b-dancers' favorite section. The turntable eventually went on to become the most visible electronic musical instrument, and occasionally the most virtuosic, in the 1980s and 1990s.\nElectronic rock was also produced by several Japanese musicians, including Isao Tomita's \"Electric Samurai: Switched on Rock\" (1972), which featured Moog synthesizer renditions of contemporary pop and rock songs, and Osamu Kitajima's progressive rock album \"Benzaiten\" (1974). The mid-1970s saw the rise of electronic art music musicians such as Jean Michel Jarre, Vangelis, Tomita and Klaus Schulze who were significant influences on the development of new-age music. The \"hi-tech\" appeal of these works created for some years the trend of listing the electronic musical equipment employed in the album sleeves, as a distinctive feature. Electronic music began to enter regularly in radio programming and top-sellers charts, as the French band Space with their debut studio album \"Magic Fly\" or Jarre with \"Oxyg\u00e8ne\". Between 1977 and 1981, Kraftwerk released albums such as \"Trans-Europe Express\", \"The Man-Machine\" or \"Computer World\", which influenced subgenres of electronic music.\nIn this era, the sound of rock musicians like Mike Oldfield and The Alan Parsons Project (who is credited the first rock song to feature a digital vocoder in 1975, \"The Raven\") used to be arranged and blended with electronic effects and/or music as well, which became much more prominent in the mid-1980s. Jeff Wayne achieved a long-lasting success with his 1978 electronic rock musical version of \"The War of the Worlds\".\nFilm scores also benefit from the electronic sound. During the 1970s and 1980s, Wendy Carlos composed the score for \"A Clockwork Orange\", \"The Shining\" and \"Tron\". In 1977, Gene Page recorded a disco version of the hit theme by John Williams from Steven Spielberg film \"Close Encounters of the Third Kind\". Page's version peaked on the R&amp;B chart at #30. The score of 1978 film \"Midnight Express\" composed by Italian synth-pioneer Giorgio Moroder won the Academy Award for Best Original Score in 1979, as did it again in 1981 the score by Vangelis for \"Chariots of Fire\". After the arrival of punk rock, a form of basic electronic rock emerged, increasingly using new digital technology to replace other instruments. The American duo Suicide, who arose from the punk scene in New York, utilized drum machines and synthesizers in a hybrid between electronics and punk on their eponymous 1977 album.\nSynth-pop pioneering bands which enjoyed success for years included Ultravox with their 1977 track \"Hiroshima Mon Amour\" on \"Ha!-Ha!-Ha!\", Yellow Magic Orchestra with their self-titled album (1978), The Buggles with their prominent 1979 debut single \"Video Killed the Radio Star\", Gary Numan with his solo debut album \"The Pleasure Principle\" and single \"Cars\" in 1979, Orchestral Manoeuvres in the Dark with their 1979 single \"Electricity\" featured on their eponymous debut album, Depeche Mode with their first single \"Dreaming of Me\" recorded in 1980 and released in 1981 album \"Speak &amp; Spell\", A Flock of Seagulls with their 1981 single \"Talking\", New Order with \"Ceremony\" in 1981, and The Human League with their 1981 hit \"Don't You Want Me\" from their third album \"Dare\".\nThe definition of MIDI and the development of digital audio made the development of purely electronic sounds much easier, with audio engineers, producers and composers exploring frequently the possibilities of virtually every new model of electronic sound equipment launched by manufacturers. Synth-pop sometimes used synthesizers to replace all other instruments, but it was more common that bands had one or more keyboardists in their line-ups along with guitarists, bassists, and/or drummers. These developments led to the growth of synth-pop, which after it was adopted by the New Romantic movement, allowed synthesizers to dominate the pop and rock music of the early 1980s until the style began to fall from popularity in the mid-to-end of the decade. Along with the aforementioned successful pioneers, key acts included Yazoo, Duran Duran, Spandau Ballet, Culture Club, Talk Talk, Japan, and Eurythmics.\nSynth-pop was taken up across the world, with international hits for acts including Men Without Hats, Trans-X and Lime from Canada, Telex from Belgium, Peter Schilling, Sandra, Modern Talking, Propaganda and Alphaville from Germany, Yello from Switzerland and Azul y Negro from Spain. Also, the synth sound is a key feature of Italo-disco.\nSome synth-pop bands created futuristic visual styles of themselves to reinforce the idea of electronic sounds were linked primarily with technology, as Americans Devo and Spaniards Aviador Dro.\nKeyboard synthesizers became so common that even heavy metal rock bands, a genre often regarded as the \"opposite\" in aesthetics, sound and lifestyle from that of electronic pop artists by fans of both sides, achieved worldwide success with themes as 1983 \"Jump\" by Van Halen and 1986 \"The Final Countdown\" by Europe, which feature synths prominently.\nProliferation of electronic music research institutions.\nElektronmusikstudion (EMS), formerly known as Electroacoustic Music in Sweden, is the Swedish national centre for electronic music and sound art. The research organisation started in 1964 and is based in Stockholm.\nSTEIM is a center for research and development of new musical instruments in the electronic performing arts, located in Amsterdam, Netherlands. STEIM has existed since 1969. It was founded by Misha Mengelberg, Louis Andriessen, Peter Schat, Dick Raaymakers, Jan van Vlijmen, Reinbert de Leeuw, and Konrad Boehmer. This group of Dutch composers had fought for the reformation of Amsterdam's feudal music structures; they insisted on Bruno Maderna's appointment as musical director of the Concertgebouw Orchestra and enforced the first public fundings for experimental and improvised electronic music in the Netherlands.\nIRCAM in Paris became a major center for computer music research and realization and development of the Sogitec 4X computer system, featuring then revolutionary real-time digital signal processing. Pierre Boulez's \"R\u00e9pons\" (1981) for 24 musicians and 6 soloists used the 4X to transform and route soloists to a loudspeaker system.\nBarry Vercoe describes one of his experiences with early computer sounds:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;At IRCAM in Paris in 1982, flutist Larry Beauregard had connected his flute to DiGiugno's 4X audio processor, enabling real-time pitch-following. On a Guggenheim at the time, I extended this concept to real-time score-following with automatic synchronized accompaniment, and over the next two years Larry and I gave numerous demonstrations of the computer as a chamber musician, playing Handel flute sonatas, Boulez's \"Sonatine\" for flute and piano and by 1984 my own \"Synapse II\" for flute and computer\u2014the first piece ever composed expressly for such a setup. A major challenge was finding the right software constructs to support highly sensitive and responsive accompaniment. All of this was pre-MIDI, but the results were impressive even though heavy doses of tempo rubato would continually surprise my Synthetic Performer. In 1985 we solved the tempo rubato problem by incorporating \"learning from rehearsals\" (each time you played this way the machine would get better). We were also now tracking violin, since our brilliant, young flautist had contracted a fatal cancer. Moreover, this version used a new standard called MIDI, and here I was ably assisted by former student Miller Puckette, whose initial concepts for this task he later expanded into a program called MAX.\nKeyboard synthesizers.\nReleased in 1970 by Moog Music, the Mini-Moog was among the first widely available, portable, and relatively affordable synthesizers. It became once the most widely used synthesizer at that time in both popular and electronic art music.\nPatrick Gleeson, playing live with Herbie Hancock at the beginning of the 1970s, pioneered the use of synthesizers in a touring context, where they were subject to stresses the early machines were not designed for.\nIn 1974, the WDR studio in Cologne acquired an EMS Synthi 100 synthesizer, which many composers used to produce notable electronic works\u2014including Rolf Gehlhaar's \"F\u00fcnf deutsche T\u00e4nze\" (1975), Karlheinz Stockhausen's \"Sirius\" (1975\u20131976), and John McGuire's \"Pulse Music III\" (1978).\nThanks to miniaturization of electronics in the 1970s, by the start of the 1980s keyboard synthesizers, became lighter and affordable, integrating into a single slim unit all the necessary audio synthesis electronics and the piano-style keyboard itself, in sharp contrast with the bulky machinery and \"cable spaguetty\" employed along with the 1960s and 1970s. First, with analog synthesizers, the trend followed with digital synthesizers and samplers as well (see below).\nDigital synthesizers.\nIn 1975, the Japanese company Yamaha licensed the algorithms for frequency modulation synthesis (FM synthesis) from John Chowning, who had experimented with it at Stanford University since 1971. Yamaha's engineers began adapting Chowning's algorithm for use in a digital synthesizer, adding improvements such as the \"key scaling\" method to avoid the introduction of distortion that normally occurred in analog systems during frequency modulation.\nIn 1980, Yamaha eventually released the first FM digital synthesizer, the Yamaha GS-1, but at an expensive price. In 1983, Yamaha introduced the first stand-alone digital synthesizer, the DX7, which also used FM synthesis and would become one of the best-selling synthesizers of all time. The DX7 was known for its recognizable bright tonalities that was partly due to an overachieving sampling rate of 57\u00a0kHz.\nThe Korg Poly-800 is a synthesizer released by Korg in 1983. Its initial list price of $795 made it the first fully programmable synthesizer that sold for less than $1000. It had 8-voice polyphony with one Digitally controlled oscillator (DCO) per voice.\nThe Casio CZ-101 was the first and best-selling phase distortion synthesizer in the Casio CZ line. Released in November 1984, it was one of the first (if not the first) fully programmable polyphonic synthesizers that was available for under $500.\nThe Roland D-50 is a digital synthesizer produced by Roland and released in April 1987. Its features include subtractive synthesis, on-board effects, a joystick for data manipulation, and an analogue synthesis-styled layout design. The external Roland PG-1000 (1987\u20131990) programmer could also be attached to the D-50 for more complex manipulation of its sounds.\nSamplers.\nA sampler is an electronic or digital musical instrument which uses sound recordings (or \"samples\") of real instrument sounds (e.g., a piano, violin or trumpet), excerpts from recorded songs (e.g., a five-second bass guitar riff from a funk song) or found sounds (e.g., sirens and ocean waves). The samples are loaded or recorded by the user or by a manufacturer. These sounds are then played back using the sampler program itself, a MIDI keyboard, sequencer or another triggering device (e.g., electronic drums) to perform or compose music. Because these samples are usually stored in digital memory, the information can be quickly accessed. A single sample may often be pitch-shifted to different pitches to produce musical scales and chords.\nBefore computer memory-based samplers, musicians used tape replay keyboards, which store recordings on analog tape. When a key is pressed the tape head contacts the moving tape and plays a sound. The Mellotron was the most notable model, used by many groups in the late 1960s and the 1970s, but such systems were expensive and heavy due to the multiple tape mechanisms involved, and the range of the instrument was limited to three octaves at the most. To change sounds a new set of tapes had to be installed in the instrument. The emergence of the digital sampler made sampling far more practical.\nThe earliest digital sampling was done on the EMS Musys system, developed by Peter Grogono (software), David Cockerell (hardware and interfacing), and Peter Zinovieff (system design and operation) at their London (Putney) Studio c. 1969.\nThe first commercially available sampling synthesizer was the Computer Music Melodian by Harry Mendell (1976).\nFirst released in 1977\u20131978, the Synclavier I using FM synthesis, re-licensed from Yamaha, and sold mostly to universities, proved to be highly influential among both electronic music composers and music producers, including Mike Thorne, an early adopter from the commercial world, due to its versatility, its cutting-edge technology, and distinctive sounds.\nThe first polyphonic digital sampling synthesizer was the Australian-produced Fairlight CMI, first available in 1979. These early sampling synthesizers used wavetable sample-based synthesis.\nBirth of MIDI.\nIn 1980, a group of musicians and music merchants met to standardize an interface that new instruments could use to communicate control instructions with other instruments and computers. This standard was dubbed Musical Instrument Digital Interface (MIDI) and resulted from a collaboration between leading manufacturers, initially Sequential Circuits, Oberheim, Roland\u2014and later, other participants that included Yamaha, Korg, and Kawai. A paper was authored by Dave Smith of Sequential Circuits and proposed to the Audio Engineering Society in 1981. Then, in August 1983, the MIDI Specification 1.0 was finalized.\nMIDI technology allows a single keystroke, control wheel motion, pedal movement, or command from a microcomputer to activate every device in the studio remotely and synchrony, with each device responding according to conditions predetermined by the composer.\nMIDI instruments and software made powerful control of sophisticated instruments easily affordable by many studios and individuals. Acoustic sounds became reintegrated into studios via sampling and sampled-ROM-based instruments.\nMiller Puckette developed graphic signal-processing software for 4X called Max (after Max Mathews) and later ported it to Macintosh (with Dave Zicarelli extending it for Opcode) for real-time MIDI control, bringing algorithmic composition availability to most composers with modest computer programming background.\nSequencers and drum machines.\nThe early 1980s saw the rise of bass synthesizers, the most influential being the Roland TB-303, a bass synthesizer and sequencer released in late 1981 that later became a fixture in electronic dance music, particularly acid house. One of the first to use it was Charanjit Singh in 1982, though it would not be popularized until Phuture's \"Acid Tracks\" in 1987. Music sequencers began being used around the mid 20th century, and Tomita's albums in mid-1970s being later examples. In 1978, Yellow Magic Orchestra were using computer-based technology in conjunction with a synthesiser to produce popular music, making their early use of the microprocessor-based Roland MC-8 Microcomposer sequencer.\nDrum machines, also known as rhythm machines, also began being used around the late-1950s, with a later example being Osamu Kitajima's progressive rock album \"Benzaiten\" (1974), which used a rhythm machine along with electronic drums and a synthesizer. In 1977, Ultravox's \"Hiroshima Mon Amour\" was one of the first singles to use the metronome-like percussion of a Roland TR-77 drum machine. In 1980, Roland Corporation released the TR-808, one of the first and most popular programmable drum machines. The first band to use it was Yellow Magic Orchestra in 1980, and it would later gain widespread popularity with the release of Marvin Gaye's \"Sexual Healing\" and Afrika Bambaataa's \"Planet Rock\" in 1982. The TR-808 was a fundamental tool in the later Detroit techno scene of the late 1980s, and was the drum machine of choice for Derrick May and Juan Atkins.\nChiptunes.\nThe characteristic lo-fi sound of chip music was initially the result of early computer's sound chips and sound cards' technical limitations; however, the sound has since become sought after in its own right.\nCommon cheap popular sound chips of the first home computers of the 1980s include the SID of the Commodore 64 and General Instrument AY series and clones (like the Yamaha YM2149) used in the ZX Spectrum, Amstrad CPC, MSX compatibles and Atari ST models, among others.\nLate 1980s to 1990s.\nRise of dance music.\nSynth-pop continued into the late 1980s, with a format that moved closer to dance music, including the work of acts such as British duos Pet Shop Boys, Erasure and The Communards, achieving success along much of the 1990s.\nThe trend has continued to the present day with modern nightclubs worldwide regularly playing electronic dance music (EDM). Today, electronic dance music has radio stations, websites, and publications like \"Mixmag\" dedicated solely to the genre. Despite the industry's attempt to create a specific EDM brand, the initialism remains in use as an umbrella term for multiple genres, including dance-pop, house, techno, electro, and trance, as well as their respective subgenres. Moreover, the genre has found commercial and cultural significance in the United States and North America, thanks to the wildly popular big room house/EDM sound that has been incorporated into the U.S. pop music and the rise of large-scale commercial raves such as Electric Daisy Carnival, Tomorrowland and Ultra Music Festival.\nElectronica.\nOn the other hand, a broad group of electronic-based music styles intended for listening rather than strictly for dancing became known under the \"electronica\" umbrella which was also a music scene in the early 1990s in the United Kingdom. According to a 1997 \"Billboard\" article, \"the union of the club community and independent labels\" provided the experimental and trend-setting environment in which electronica acts developed and eventually reached the mainstream, citing American labels such as Astralwerks (The Chemical Brothers, Fatboy Slim, The Future Sound of London, Fluke), Moonshine (DJ Keoki), Sims, and City of Angels (The Crystal Method) for popularizing the latest version of electronic music.\n2000s and 2010s.\nAs computer technology has become more accessible and music software has advanced, interacting with music production technology is now possible using means that bear no relationship to traditional musical performance practices: for instance, laptop performance (\"laptronica\"), live coding and Algorave. In general, the term Live PA refers to any live performance of electronic music, whether with laptops, synthesizers, or other devices.\nBeginning around the year 2000, some software-based virtual studio environments emerged, with products such as Propellerhead's Reason and Ableton Live finding popular appeal. Such tools provide viable and cost-effective alternatives to typical hardware-based production studios, and thanks to advances in microprocessor technology, it is now possible to create high-quality music using little more than a single laptop computer. Such advances have democratized music creation, leading to a massive increase in the amount of home-produced electronic music available to the general public via the internet. Software-based instruments and effect units (so-called \"plugins\") can be incorporated in a computer-based studio using the VST platform. Some of these instruments are more or less exact replicas of existing hardware (such as the Roland D-50, ARP Odyssey, Yamaha DX7, or Korg M1). In many cases, these software-based instruments are sonically indistinguishable from their physical counterpart.\nCircuit bending.\nCircuit bending is the modification of battery-powered toys and synthesizers to create new unintended sound effects. It was pioneered by Reed Ghazala in the 1960s and Reed coined the name \"circuit bending\" in 1992.\nModular synth revival.\nFollowing the circuit bending culture, musicians also began to build their own modular synthesizers, causing a renewed interest in the early 1960s designs. Eurorack became a popular system.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "9513", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9513", "title": "Electronic art music", "text": ""}
