{"id": "9603", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=9603", "title": "Ernest Rutherford", "text": "New Zealand physicist (1871\u20131937)\nErnest Rutherford, 1st Baron Rutherford of Nelson, (30 August 1871\u00a0\u2013 19 October 1937) was a Nobel Prize winning New Zealand physicist who was a pioneering researcher in both atomic and nuclear physics. Decsribed as \"the father of nuclear physics\", and \"one of the greatest scientists of all time\", he spent a substantial amount of his career abroad, in both Canada and the United Kingdom.\nIn 1898, Rutherford moved to Canada and joined McGill University, in Montreal, where he discovered the concept of radioactive half-life, the radioactive element radon, and differentiated and named alpha and beta radiation. For this work he was awarded the Nobel Prize in Chemistry in 1908 \"for his investigations into the disintegration of the elements, and the chemistry of radioactive substances\". He was the first Oceanian Nobel laureate, and the first to perform the awarded work in Canada.\nRutherford moved in 1907 to the Victoria University of Manchester (today University of Manchester) in the UK, where he and Thomas Royds proved that alpha radiation is helium nuclei. In 1911, although he could not prove that it was positive or negative, he theorized that atoms have their charge concentrated in a very small nucleus, and thereby pioneered the Rutherford model of the atom, through his discovery and interpretation of Rutherford scattering by the gold foil experiment of Hans Geiger and Ernest Marsden.\nHe performed the first artificially induced nuclear reaction in 1917 in experiments where nitrogen nuclei were bombarded with alpha particles. As a result, he discovered the emission of a subatomic particle which, in 1919, he called the \"hydrogen atom\" but, in 1920, he more accurately named the proton.\nRutherford became Director of the Cavendish Laboratory at the University of Cambridge in 1919. Under his leadership the neutron was discovered by James Chadwick in 1932 and in the same year the first experiment to split the nucleus in a fully controlled manner was performed by students working under his direction, John Cockcroft and Ernest Walton.\nAfter his death in 1937, he was buried in Westminster Abbey near Charles Darwin and Isaac Newton. \"Encyclop\u00e6dia Britannica\" considers him to be the greatest experimentalist since Michael Faraday (1791\u20131867). The chemical element rutherfordium (element 104) was named after him in 1997.\nEarly life and education.\nErnest Rutherford was the son of James Rutherford, a farmer, and his wife Martha Thompson, originally from Hornchurch, Essex, England. James had emigrated to New Zealand from Perth, Scotland, \"to raise a little flax and a lot of children\". Ernest was born at Brightwater, near Nelson, New Zealand. His first name was mistakenly spelled 'Earnest' when his birth was registered. Rutherford's mother Martha Thompson was a schoolteacher.\nHe studied at Havelock School and then Nelson College and won a scholarship to study at Canterbury College, University of New Zealand, where he participated in the debating society and played rugby. He was awarded an MA in Mathematics and Physical Science from the Canterbury College in 1893 and received a BSc from the same institution in 1894.\nThereafter, he invented a new form of radio receiver, and in 1895 Rutherford was awarded an 1851 Research Fellowship from the Royal Commission for the Exhibition of 1851, to travel to England for postgraduate study at the Cavendish Laboratory, University of Cambridge. In 1897, he was awarded a BA Research Degree and the Coutts-Trotter Studentship from Trinity College, Cambridge.\nScientific career.\nAt Cambridge, he was among the first of the 'aliens' (those without a Cambridge degree) allowed to do research at the university, under the leadership of J. J. Thomson, which aroused jealousies from the more conservative members of the Cavendish fraternity.\nWith Thomson's encouragement, he detected radio waves at , and briefly held the world record for the distance over which electromagnetic waves could be detected, though when he presented his results at the British Association meeting in 1896, he discovered he had been outdone by Guglielmo Marconi, whose radio waves had sent a message across nearly .\nMcGill years.\nIn 1898, Thomson recommended Rutherford for a position at McGill University in Montreal, Canada, to replace Hugh Longbourne Callendar who held the chair of Macdonald Professor of physics, and was coming to Cambridge. Rutherford was accepted, which meant that in 1900 he could marry his fianc\u00e9 of two years, Mary Georgina Newton (1876\u20131954) In 1901, Rutherford gained a DSc from the University of New Zealand. \nAt Cambridge, Rutherford had worked with J. J. Thomson on the conductive effects of X-rays on gases, work which led to the discovery of the electron which Thomson presented to the world in 1897. Hearing of Becquerel's experience with uranium, Rutherford started to explore its radioactivity, discovering two types that differed from X-rays in their penetrating power. Continuing his research in Canada, he coined the terms alpha ray and beta ray in 1899 to describe the two distinct types of radiation.\nIn conjunction with R.B. Owens, Rutherford discovered thoron (220Rn), a noble gas emitted by the radioactive element thorium which was itself radioactive and would coat other substances. He found that a sample of this radioactive material of any size invariably took the same amount of time for half the sample to decay, for which he coined the term \"half-life\", (11&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 minutes in this case).\nFrom 1900 to 1903, he was joined at McGill by the young chemist Frederick Soddy (Nobel Prize in Chemistry, 1921) for whom he set the problem of identifying the thorium emanations. Once he had eliminated all the normal chemical reactions, Soddy suggested that it must be one of the inert gases, which they named thoron (later found to be an isotope of radon). They also found another type of thorium they called Thorium X, and kept on finding traces of helium. They also worked with samples of \"Uranium X\" from William Crookes and radium from Marie Curie.\nIn 1903, they published their \"Law of Radioactive Change\", to account for all their experiments. Until then, atoms were assumed to be the indestructible basis of all matter and although Curie had suggested that radioactivity was an atomic phenomenon, the idea of the atoms of radioactive substances breaking up was a radically new idea. Rutherford and Soddy demonstrated that radioactivity involved the spontaneous disintegration of atoms into other, as yet, unidentified matter. The Nobel Prize in Chemistry 1908 was awarded to Ernest Rutherford \"for his investigations into the disintegration of the elements, and the chemistry of radioactive substances\".\nIn 1903, Rutherford considered a type of radiation discovered (but not named) by French chemist Paul Villard in 1900, as an emission from radium, and realised that this observation must represent something different from his own alpha and beta rays, due to its very much greater penetrating power. Rutherford therefore gave this third type of radiation the name of gamma ray. All three of Rutherford's terms are in standard use today \u2013 other types of radioactive decay have since been discovered, but Rutherford's three types are among the most common.\nIn 1904, Rutherford suggested that radioactivity provides a source of energy sufficient to explain the existence of the Sun for the many millions of years required for the slow biological evolution on Earth proposed by biologists such as Charles Darwin. The physicist Lord Kelvin had argued earlier for a much younger Earth (see also ) based on the insufficiency of known energy sources, but Rutherford pointed out at a lecture attended by Kelvin that radioactivity could solve this problem.\nIn 1904, he was elected as a member to the American Philosophical Society, and in 1907, he returned to Britain to take the chair of physics at the Victoria University of Manchester.\nManchester years.\nIn Manchester, he continued to work with alpha radiation. In conjunction with Hans Geiger, he developed zinc sulfide scintillation screens and ionisation chambers to count alphas. By dividing the total charge they produced by the number counted, Rutherford decided that the charge on the alpha was two. In late 1907, Ernest Rutherford and Thomas Royds allowed alphas to penetrate a very thin window into an evacuated tube. As they sparked the tube into discharge, the spectrum obtained from it changed, as the alphas accumulated in the tube. Eventually, the clear spectrum of helium gas appeared, proving that alphas were at least ionised helium atoms, and probably helium nuclei.\nModel of the atom.\nRutherford continued to make ground breaking discoveries long after receiving the Nobel prize in 1908. Along with Hans Geiger and Ernest Marsden in 1909, he carried out the Geiger\u2013Marsden experiment, which demonstrated the nuclear nature of atoms by deflecting alpha particles passing through a thin gold foil. Rutherford was inspired to ask Geiger and Marsden in this experiment to look for alpha particles with very high deflection angles, of a type not expected from any theory of matter at that time. Such deflections, though rare, were found, and proved to be a smooth but high-order function of the deflection angle. It was Rutherford's interpretation of this data that led him to formulate the Rutherford model of the atom in 1911\u00a0\u2013 that a very small charged nucleus, containing much of the atom's mass, was orbited by low-mass electrons.\nIn 1912, Rutherford was joined by Niels Bohr (who postulated that electrons moved in specific orbits). Bohr adapted Rutherford's nuclear structure to be consistent with Max Planck's quantum theory, and the resulting Rutherford\u2013Bohr model is considered valid to this day.\nDiscovery of the proton.\nTogether with H.G. Moseley, Rutherford developed the atomic numbering system in 1913. Rutherford and Moseley's experiments used cathode rays to bombard various elements with a stream of electrons and observed that each element responded in a consistent and distinct manner. Their research was the first to assert that each element could be defined by the properties of its inner structures \u2013 an observation which later led to the discovery of the atomic nucleus. This research led Rutherford to theorize that the hydrogen atom (at the time the least massive entity known to bear a positive charge) was a sort of \"positive electron\" \u2013 a component of every atomic element.\nRutherford was knighted in 1914. During World War I, he worked on a top secret project to solve the practical problems of submarine detection by sonar. In 1916, he was awarded the Hector Memorial Medal.\nShortly before the end of his time at Manchester, Rutherford expanded upon his research of the \"positive electron\" with a series of experiments beginning in 1919. He found that nitrogen and other light elements ejected a proton, which he called a \"hydrogen atom\", when hit with \u03b1 (alpha) particles. In particular, he showed that particles ejected by alpha particles colliding with hydrogen have unit charge and 1/4 the momentum of alpha particles.\nBack to Cambridge.\nIn 1919, he returned to the Cavendish succeeding J. J. Thomson as the Cavendish professor and Director. Under him, Nobel Prizes were awarded to James Chadwick for discovering the neutron (in 1932), John Cockcroft and Ernest Walton for an experiment which was to be known as \"splitting the atom\" using a particle accelerator, and Edward Appleton for demonstrating the existence of the ionosphere.\nDevelopment of proton and neutron theory.\nIn 1919\u20131920, Rutherford continued his research on the \"hydrogen atom\" to confirm that alpha particles breakdown nitrogen nuclei and affirm the nature of the products. This result showed Rutherford that hydrogen nuclei were a part of nitrogen nuclei (and by inference, probably other nuclei as well). Such a construction had been suspected for many years on the basis of atomic weights which were whole numbers of that of hydrogen; see Prout's hypothesis. Hydrogen was known to be the lightest element, and its nuclei presumably the lightest nuclei. Now, because of all these considerations, Rutherford decided that a hydrogen nucleus was possibly a fundamental building block of all nuclei, and also possibly a new fundamental particle as well, since nothing was known from the nucleus that was lighter. Thus, confirming and extending the work of Wilhelm Wien who in 1898 discovered the proton in streams of ionized gas, Rutherford postulated the hydrogen nucleus to be a new particle in 1920, which he dubbed the \"proton\".\nIn 1921, while working with Niels Bohr, Rutherford theorized about the existence of neutrons, (which he had christened in his 1920 Bakerian Lecture), which could somehow compensate for the repelling effect of the positive charges of protons by causing an attractive nuclear force and thus keep the nuclei from flying apart from the repulsion between protons. The only alternative to neutrons was the existence of \"nuclear electrons\" which would counteract some of the proton charges in the nucleus, since by then it was known that nuclei had about twice the mass that could be accounted for if they were simply assembled from hydrogen nuclei (protons). But how these nuclear electrons could be trapped in the nucleus, was a mystery. Rutherford is widely quoted as saying, regarding the results of these experiments: \"It was quite the most incredible event that has ever happened to me in my life. It was almost as incredible as if you fired a 15-inch shell at a piece of tissue paper and it came back and hit you.\"\nRutherford's theory of neutrons was proved in 1932 by his associate James Chadwick, who recognized neutrons immediately when they were produced by other scientists and later himself, in bombarding beryllium with alpha particles. In 1935, Chadwick was awarded the Nobel Prize in Physics for this discovery.\nRe-evaluation of nuclear transmutation credit.\nA long-standing myth existed, at least as early as 1948, running at least to 2017, that Rutherford was the first scientist to observe and report an artificial transmutation of a stable element into another element: nitrogen into oxygen. It was thought by many people to be one of Rutherford's greatest accomplishments. The New Zealand government even issued a commemorative stamp in the belief that the nitrogen-to-oxygen discovery belonged to Rutherford. Beginning in 2017, many scientific institutions corrected their versions of this history to indicate that the discovery credit for the reaction belongs to Patrick Blackett. Rutherford did detect the ejected proton in 1919 and interpreted it as evidence for disintegration of the nitrogen nucleus (to lighter nuclei). In 1925, Blackett showed that the actual product is oxygen and identified the true reaction as 14N + \u03b1 \u2192 17O + p. Rutherford therefore recognized \"that the nucleus may increase rather than diminish in mass as the result of collisions in which the proton is expelled\".\nLater years and honours.\nIn 1925, Rutherford pushed calls to the New Zealand Government to support education and research, which led to the formation of the Department of Scientific and Industrial Research (DSIR) in the following year. Between 1925 and 1930, he served as President of the Royal Society, and later as president of the Academic Assistance Council which helped almost 1,000 university refugees from Germany. He was appointed to the Order of Merit in the 1925 New Year Honours and raised to the peerage as Baron Rutherford of Nelson, New Zealand and of Cambridge in the County of Cambridge in 1931, a title that became extinct upon his unexpected death in 1937. In 1933, Rutherford was one of the two inaugural recipients of the T. K. Sidey Medal, set up by the Royal Society of New Zealand as an award for outstanding scientific research.\nPersonal life and death.\nIn 1900, Rutherford married Mary Georgina Newton (1876\u20131954), to whom he had become engaged before leaving New Zealand, at St Paul's Anglican Church, Papanui in Christchurch. \nThey had one daughter, Eileen Mary (1901\u20131930), who married the physicist Ralph Fowler.\nBeyond science, Rutherford's hobbies included golf and motoring.\nFor some time before his death, Rutherford had a small hernia, which he had neglected to have fixed, and it became strangulated, rendering him violently ill. Despite an emergency operation in London, he died four days afterwards at age 66 of what physicians termed \"intestinal paralysis\", at Cambridge on 19 October 1937. After cremation at Golders Green Crematorium, he was given the high honour of burial in Westminster Abbey, near Isaac Newton and other illustrious British scientists such as Charles Darwin.\nLegacy.\nRutherford is considered to have been among the greatest scientists in history. At the opening session of the 1938 Indian Science Congress, which Rutherford had been expected to preside over before his death, astrophysicist James Jeans spoke in his place and deemed him \"one of the greatest scientists of all time\", saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In his flair for the right line of approach to a problem, as well as in the simple directness of his methods of attack, [Rutherford] often reminds us of Faraday, but he had two great advantages which Faraday did not possess, first, exuberant bodily health and energy, and second, the opportunity and capacity to direct a band of enthusiastic co-workers. Great though Faraday's output of work was, it seems to me that to match Rutherford's work in quantity as well as in quality, we must go back to Newton. In some respects he was more fortunate than Newton. Rutherford was ever the happy warrior \u2013 happy in his work, happy in its outcome, and happy in its human contacts.\nNuclear physics.\nRutherford is known as \"the father of nuclear physics\", because his research, and work done under him as laboratory director, established the nuclear structure of the atom and the essential nature of radioactive decay as a nuclear process. Patrick Blackett, a research fellow working under Rutherford, using natural alpha particles, demonstrated \"induced\" nuclear transmutation. Rutherford's team later, using protons from an accelerator, demonstrated \"artificially-induced\" nuclear reactions and transmutation.\nRutherford died too early to see Le\u00f3 Szil\u00e1rd's idea of controlled nuclear chain reactions come into being. However, a speech of Rutherford's about his artificially-induced transmutation in lithium, printed on 12 September 1933 London paper \"The Times\", was reported by Szil\u00e1rd to have been his inspiration for thinking of the possibility of a controlled energy-producing nuclear chain reaction. Szilard had this idea while walking in London, on the same day.\nRutherford's speech touched on the 1932 work of his students John Cockcroft and Ernest Walton in \"splitting\" lithium into alpha particles by bombardment with protons from a particle accelerator they had constructed. Rutherford realized that the energy released from the split lithium atoms was enormous, but he also realized that the energy needed for the accelerator, and its essential inefficiency in splitting atoms in this fashion, made the project an impossibility as a practical source of energy (accelerator-induced fission of light elements remains too inefficient to be used in this way, even today). Rutherford's speech in part, read:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We might in these processes obtain very much more energy than the proton supplied, but on the average we could not expect to obtain energy in this way. It was a very poor and inefficient way of producing energy, and anyone who looked for a source of power in the transformation of the atoms was talking moonshine. But the subject was scientifically interesting because it gave insight into the atoms.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9604", "revid": "1301909", "url": "https://en.wikipedia.org/wiki?curid=9604", "title": "Many-worlds interpretation", "text": "Interpretation of quantum mechanics that denies the collapse of the wavefunction\nThe many-worlds interpretation (MWI) is an interpretation of quantum mechanics that asserts that the universal wavefunction is objectively real, and that there is no wave function collapse. This implies that all possible outcomes of quantum measurements are physically realized in some \"world\" or universe. In contrast to some other interpretations, such as the Copenhagen interpretation, the evolution of reality as a whole in MWI is rigidly deterministic and local. Many-worlds is also called the relative state formulation or the Everett interpretation, after physicist Hugh Everett, who first proposed it in 1957. Bryce DeWitt popularized the formulation and named it \"many-worlds\" in the 1970s.\nIn many-worlds, the subjective appearance of wavefunction collapse is explained by the mechanism of quantum decoherence. Decoherence approaches to interpreting quantum theory have been widely explored and developed since the 1970s, and have become quite popular. MWI is now considered a mainstream interpretation along with the other decoherence interpretations, collapse theories (including the Copenhagen interpretation), and hidden variable theories such as Bohmian mechanics.\nThe many-worlds interpretation implies that there are most likely an infinite number of universes. It is one of a number of multiverse hypotheses in physics and philosophy. MWI views time as a many-branched tree, wherein every possible quantum outcome is realized. This is intended to resolve the measurement problem and thus some paradoxes of quantum theory, such as the EPR paradox and Schr\u00f6dinger's cat, since every possible outcome of a quantum event exists in its own universe.\nOverview of the interpretation.\nThe key idea of the many-worlds interpretation is that the linear and unitary dynamics of quantum mechanics applies everywhere and at all times and so describes the whole universe. In particular, it models a measurement as a unitary transformation, a correlation-inducing interaction, between observer and object, without using a collapse postulate, and models observers as ordinary quantum-mechanical systems. This stands in sharp contrast to the Copenhagen interpretation, in which a measurement is a \"primitive\" concept, not describable by unitary quantum mechanics; in Copenhagen the universe is divided into a quantum and a classical domain, and the collapse postulate is central. MWI's main conclusion is that the universe (or multiverse in this context) is composed of a quantum superposition of an infinite or undefinable amount or number of increasingly divergent, non-communicating parallel universes or quantum worlds. Sometimes dubbed Everett worlds, each is an internally consistent and actualized alternative history or timeline.\nThe many-worlds interpretation makes use of decoherence to explain the measurement process and the emergence of a quasi-classical world. Wojciech H. Zurek, one of decoherence theory's pioneers, stated: \"Under scrutiny of the environment, only pointer states remain unchanged. Other states decohere into mixtures of stable pointer states that can persist, and, in this sense, exist: They are einselected.\" Zurek emphasizes that his work does not depend on a particular interpretation.\nThe many-worlds interpretation shares many similarities with the decoherent histories interpretation, which also uses decoherence to explain the process of measurement or wavefunction collapse. MWI treats the other histories or worlds as real, since it regards the universal wavefunction as the \"basic physical entity\" or \"the fundamental entity, obeying at all times a deterministic wave equation\". Decoherent histories, on the other hand, needs only one of the histories (or worlds) to be real.\nSeveral authors, including Wheeler, Everett and Deutsch, call many-worlds a theory or metatheory, rather than just an interpretation. Everett argued that it was the \"only completely coherent approach to explaining both the contents of quantum mechanics and the appearance of the world.\" Deutsch dismissed the idea that many-worlds is an \"interpretation\", saying that to call it an interpretation \"is like talking about dinosaurs as an 'interpretation' of fossil records.\"\nFormulation.\nIn his 1957 doctoral dissertation, Everett proposed that, rather than relying on external observation for analysis of isolated quantum systems, one could mathematically model an object, as well as its observers, as purely physical systems within the mathematical framework developed by Paul Dirac, John von Neumann and others, discarding altogether the \"ad hoc\" mechanism of wave function collapse.\nRelative state.\nEverett's original work introduced the concept of a \"relative state\". Two (or more) subsystems, after a general interaction, become entangled. Everett noted that such entangled systems can be expressed as the sum of products of states, where the two or more subsystems are each in a state relative to each other. After a measurement or observation one of the pair (or triple...) is the measured, object or observed system, and one other member is the measuring apparatus (which may include an observer) having recorded the state of the measured system.\nIn the example of Schr\u00f6dinger's cat, after the box is opened, the entangled system is the cat, the poison vial and the observer. \"One\" relative triple of states would be the alive cat, the unbroken vial and the observer seeing an alive cat. \"Another\" relative triple of states would be the dead cat, the broken vial and the observer seeing a dead cat.\nThe process of measurement or observation, or any correlation-inducing interaction, splits the system up into sets of relative states, where each set of relative states, forming a branch of the universal wavefunction, is consistent within itself, and all future measurements (including by multiple observers) will confirm this consistency.\nThe many-worlds interpretation is DeWitt's popularisation of Everett, who had referred to the combined observer\u2013object system as split by an observation, each split corresponding to the different or multiple possible outcomes of an observation. These splits generate a branching tree, where each branch is a set of all the states relative to each other. DeWitt introduced the term \"world\" to describe a single branch of that tree, which is a consistent history. All observations or measurements in any branch are consistent with each other.\nUnder the many-worlds interpretation, the Schr\u00f6dinger equation, or its quantum field theory, relativistic analog, holds all the time, everywhere. An observation or measurement is modelled by applying the wave equation to the entire system, comprising the observer \"and\" the object being observed. One consequence is that every observation can be thought of as causing the combined observer\u2013object's wavefunction to change into a quantum superposition of two or more non-interacting branches, or split into many \"worlds\". Since many observation-like events have happened and are constantly happening, there are an enormous and growing number of simultaneously existing states.\nIf a system is composed of two or more subsystems, the system's state will be a superposition of products of the subsystems' states. Each product of subsystem states in the overall superposition evolves over time independently of other products. Once the subsystems interact, their states have become correlated or entangled and can no longer be considered independent. In Everett's terminology, each subsystem state was now \"correlated\" with its \"relative state\", since each subsystem must now be considered relative to the other subsystems with which it has interacted.\nProperties.\nMWI removes the observer-dependent role in the quantum measurement process by replacing wavefunction collapse with quantum decoherence. Since the observer's role lies at the heart of most if not all \"quantum paradoxes\", this automatically resolves a number of problems, such as Schr\u00f6dinger's cat thought experiment, the EPR paradox, von Neumann's \"boundary problem\", and others.\nSince the Copenhagen interpretation requires the existence of a classical domain beyond the one described by quantum mechanics, it has been criticized as inadequate for the study of cosmology. MWI was developed with the explicit goal of allowing quantum mechanics to be applied to the universe as a whole, making quantum cosmology possible.\nMWI is a realist, deterministic and local theory. It achieves this by removing wave function collapse, which is indeterministic and nonlocal, from the deterministic and local equations of quantum theory.\nMWI (like other, broader multiverse theories) provides a context for the anthropic principle, which may provide an explanation for the fine-tuned universe.\nMWI depends crucially on the linearity of quantum mechanics, which underpins the superposition principle. If the final theory of everything is non-linear with respect to wavefunctions, then many-worlds is invalid. All quantum field theories are linear and compatible with the MWI, a point emphasised by Everett as a motivation for the MWI. While quantum gravity or string theory may be non-linear in this respect, there is as yet no evidence of this.\nInterpreting wavefunction collapse.\nAs with the other interpretations of quantum mechanics, the many-worlds interpretation is motivated by behavior that can be illustrated by the double-slit experiment. When particles of light (or anything else) pass through the double slit, a calculation assuming wavelike behavior of light can be used to identify where the particles are likely to be observed. Yet when the particles are observed in this experiment, they appear as particles (i.e., at definite places) and not as non-localized waves.\nSome versions of the Copenhagen interpretation of quantum mechanics proposed a process of \"collapse\" in which an indeterminate quantum system would probabilistically collapse down onto, or select, just one determinate outcome to \"explain\" this phenomenon of observation. Wavefunction collapse was widely regarded as artificial and \"ad hoc\", so an alternative interpretation in which the behavior of measurement could be understood from more fundamental physical principles was considered desirable.\nEverett's PhD work provided such an interpretation. He argued that for a composite system\u2014such as a subject (the \"observer\" or measuring apparatus) observing an object (the \"observed\" system, such as a particle)\u2014the claim that either the observer or the observed has a well-defined state is meaningless; in modern parlance, the observer and the observed have become entangled: we can only specify the state of one \"relative\" to the other, i.e., the state of the observer and the observed are correlated \"after\" the observation is made. This led Everett to derive from the unitary, deterministic dynamics alone (i.e., without assuming wavefunction collapse) the notion of a \"relativity of states\".\nEverett noticed that the unitary, deterministic dynamics alone entailed that after an observation is made each element of the quantum superposition of the combined subject\u2013object wavefunction contains two \"relative states\": a \"collapsed\" object state and an associated observer who has observed the same collapsed outcome; what the observer sees and the state of the object have become correlated by the act of measurement or observation. The subsequent evolution of each pair of relative subject\u2013object states proceeds with complete indifference as to the presence or absence of the other elements, \"as if\" wavefunction collapse has occurred, which has the consequence that later observations are always consistent with the earlier observations. Thus the \"appearance\" of the object's wavefunction's collapse has emerged from the unitary, deterministic theory itself. (This answered Einstein's early criticism of quantum theory, that the theory should define what is observed, not for the observables to define the theory.) Since the wavefunction merely appears to have collapsed then, Everett reasoned, there was no need to actually assume that it had collapsed. And so, invoking Occam's razor, he removed the postulate of wavefunction collapse from the theory.\nTestability.\nIn 1985, David Deutsch proposed a variant of the Wigner's friend thought experiment as a test of many-worlds versus the Copenhagen interpretation. It consists of an experimenter (Wigner's friend) making a measurement on a quantum system in an isolated laboratory, and another experimenter (Wigner) who would make a measurement on the first one. According to the many-worlds theory, the first experimenter would end up in a macroscopic superposition of seeing one result of the measurement in one branch, and another result in another branch. The second experimenter could then interfere these two branches in order to test whether it is in fact in a macroscopic superposition or has collapsed into a single branch, as predicted by the Copenhagen interpretation. Since then Lockwood (1989), Vaidman and others have made similar proposals. These proposals require placing macroscopic objects in a coherent superposition and interfering them, a task currently beyond experimental capability.\nProbability and the Born rule.\nSince the many-worlds interpretation's inception, physicists have been puzzled about the role of probability in it. As put by Wallace, there are two facets to the question: the \"incoherence problem\", which asks why we should assign probabilities at all to outcomes that are certain to occur in some worlds, and the \"quantitative problem\", which asks why the probabilities should be given by the Born rule.\nEverett tried to answer these questions in the paper that introduced many-worlds. To address the incoherence problem, he argued that an observer who makes a sequence of measurements on a quantum system will in general have an apparently random sequence of results in their memory, which justifies the use of probabilities to describe the measurement process. To address the quantitative problem, Everett proposed a derivation of the Born rule based on the properties that a measure on the branches of the wavefunction should have. His derivation has been criticized as relying on unmotivated assumptions. Since then several other derivations of the Born rule in the many-worlds framework have been proposed. There is no consensus on whether this has been successful.\nFrequentism.\nDeWitt and Graham and Farhi et al., among others, have proposed derivations of the Born rule based on a frequentist interpretation of probability. They try to show that in the limit of infinitely many measurements no worlds would have relative frequencies that didn't match the probabilities given by the Born rule, but these derivations have been shown to be mathematically incorrect.\nDecision theory.\nA decision-theoretic derivation of the Born rule was produced by David Deutsch (1999) and refined by Wallace (2002\u20132009) and Saunders (2004). They consider an agent who takes part in a quantum gamble: the agent makes a measurement on a quantum system, branches as a consequence, and each of the agent's future selves receives a reward that depends on the measurement result. The agent uses decision theory to evaluate the price they would pay to take part in such a gamble, and concludes that the price is given by the utility of the rewards weighted according to the Born rule. Some reviews have been positive, although these arguments remain highly controversial; some theoretical physicists have taken them as supporting the case for parallel universes. For example, a \"New Scientist\" story on a 2007 conference about Everettian interpretations quoted physicist Andy Albrecht as saying, \"This work will go down as one of the most important developments in the history of science.\" In contrast, the philosopher Huw Price, also attending the conference, found the Deutsch\u2013Wallace\u2013Saunders approach fundamentally flawed.\nSymmetries and invariance.\nZurek (2005) has produced a derivation of the Born rule based on the symmetries of entangled states; Schlosshauer and Fine argue that Zurek's derivation is not rigorous, as it does not define what probability is and has several unstated assumptions about how it should behave.\nCharles Sebens and Sean M. Carroll, building on work by Lev Vaidman, proposed a similar approach based on self-locating uncertainty. In this approach, decoherence creates multiple identical copies of observers, who can assign credences to being on different branches using the Born rule. The Sebens\u2013Carroll approach has been criticized by Adrian Kent, and Vaidman himself does not find it satisfactory.\nThe preferred basis problem.\nAs originally formulated by Everett and DeWitt, the many-worlds interpretation had a privileged role for measurements: they determined which basis of a quantum system would give rise to the eponymous worlds. Without this the theory was ambiguous, as a quantum state can equally well be described (e.g.) as having a well-defined position or as being a superposition of two delocalised states. The assumption is that the preferred basis to use is the one which assigns a unique measurement outcome to each world. This special role for measurements is problematic for the theory, as it contradicts Everett and DeWitt's goal of having a reductionist theory and undermines their criticism of the ill-defined measurement postulate of the Copenhagen interpretation. This is known today as the \"preferred basis problem\".\nThe preferred basis problem has been solved, according to Saunders and Wallace, among others, by incorporating decoherence into the many-worlds theory. In this approach, the preferred basis does not have to be postulated, but rather is identified as the basis stable under environmental decoherence. In this way measurements no longer play a special role; rather, any interaction that causes decoherence causes the world to split. Since decoherence is never complete, there will always remain some infinitesimal overlap between two worlds, making it arbitrary whether a pair of worlds has split or not. Wallace argues that this is not problematic: it only shows that worlds are not a part of the fundamental ontology, but rather of the \"emergent\" ontology, where these approximate, effective descriptions are routine in the physical sciences. Since in this approach the worlds are derived, it follows that they must be present in any other interpretation of quantum mechanics that does not have a collapse mechanism, such as Bohmian mechanics.\nThis approach to deriving the preferred basis has been criticized as creating a circularity with derivations of probability in the many-worlds interpretation, as decoherence theory depends on probability, and probability depends on the ontology derived from decoherence. Wallace contends that decoherence theory depends not on probability but only on the notion that one is allowed to do approximations in physics.\nHistory.\nMWI originated in Everett's Princeton PhD thesis \"The Theory of the Universal Wavefunction\", developed under his thesis advisor John Archibald Wheeler, a shorter summary of which was published in 1957 under the title \"Relative State Formulation of Quantum Mechanics\" (Wheeler contributed the title \"relative state\"; Everett originally called his approach the \"Correlation Interpretation\", where \"correlation\" refers to quantum entanglement). The phrase \"many-worlds\" is due to Bryce DeWitt, who was responsible for the wider popularisation of Everett's theory, which had been largely ignored for a decade after publication in 1957.\nEverett's proposal was not without precedent. In 1952, Erwin Schr\u00f6dinger gave a lecture in Dublin in which at one point he jocularly warned his audience that what he was about to say might \"seem lunatic\". He went on to assert that while the Schr\u00f6dinger equation seemed to be describing several different histories, they were \"not alternatives but all really happen simultaneously\". According to David Deutsch, this is the earliest known reference to many-worlds; Jeffrey A. Barrett describes it as indicating the similarity of \"general views\" between Everett and Schr\u00f6dinger. Schr\u00f6dinger's writings from the period also contain elements resembling the modal interpretation originated by Bas van Fraassen. Because Schr\u00f6dinger subscribed to a kind of post-Machian neutral monism, in which \"matter\" and \"mind\" are only different aspects or arrangements of the same common elements, treating the wavefunction as physical and treating it as information became interchangeable.\nReception.\nMWI's initial reception was overwhelmingly negative, in the sense that it was ignored, with the notable exception of DeWitt. Wheeler made considerable efforts to formulate the theory in a way that would be palatable to Bohr, visited Copenhagen in 1956 to discuss it with him, and convinced Everett to visit as well, which happened in 1959. Nevertheless, Bohr and his collaborators completely rejected the theory. Everett had already left academia in 1956, never to return, and after his death, Wheeler disavowed the theory.\nSupport.\nOne of MWI's strongest longtime advocates is David Deutsch. According to Deutsch, the single photon interference pattern observed in the double slit experiment can be explained by interference of photons in multiple universes. Viewed this way, the single photon interference experiment is indistinguishable from the multiple photon interference experiment. In a more practical vein, in one of the earliest papers on quantum computing, he suggested that parallelism that results from MWI could lead to \"a method by which certain probabilistic tasks can be performed faster by a universal quantum computer than by any classical restriction of it\". Deutsch has also proposed that MWI will be testable (at least against \"naive\" Copenhagenism) when reversible computers become conscious via the reversible observation of spin.\nEquivocal.\nPhilosophers of science James Ladyman and Don Ross say that the MWI could be true, but that they do not embrace it. They note that no quantum theory is yet empirically adequate for describing all of reality, given its lack of unification with general relativity, and so they do not see a reason to regard any interpretation of quantum mechanics as the final word in metaphysics. They also suggest that the multiple branches may be an artifact of incomplete descriptions and of using quantum mechanics to represent the states of macroscopic objects. They argue that macroscopic objects are significantly different from microscopic objects in not being isolated from the environment, and that using quantum formalism to describe them lacks explanatory and descriptive power and accuracy.\nVictor J. Stenger remarked that Murray Gell-Mann's published work explicitly rejects the existence of simultaneous parallel universes. Collaborating with James Hartle, Gell-Mann worked toward the development a more \"palatable\" \"post-Everett quantum mechanics\". Stenger thought it fair to say that most physicists find the MWI too extreme, while noting it \"has merit in finding a place for the observer inside the system being analyzed and doing away with the troublesome notion of wave function collapse\".\nRichard Feynman, described as an Everettian in some sources, said of the MWI in 1982, \"It's possible, but I'm not very happy with it.\"\nRejection.\nSome scientists consider MWI unfalsifiable and hence unscientific because the multiple parallel universes are non-communicating, in the sense that no information can be passed between them. Others claim MWI is directly testable.\nRoger Penrose argues that the idea is flawed because it is based on an oversimplified version of quantum mechanics that does not account for gravity. In his view, applying conventional quantum mechanics to the universe implies the MWI, but the lack of a successful theory of quantum gravity negates the claimed universality of conventional quantum mechanics. According to Penrose, \"the rules must change when gravity is involved\". He further asserts that gravity helps anchor reality and \"blurry\" events have only one allowable outcome: \"electrons, atoms, molecules, etc., are so minute that they require almost no amount of energy to maintain their gravity, and therefore their overlapping states. They can stay in that state forever, as described in standard quantum theory\". On the other hand, \"in the case of large objects, the duplicate states disappear in an instant due to the fact that these objects create a large gravitational field\".\nPhilosopher of science Robert P. Crease says that the MWI is \"one of the most implausible and unrealistic ideas in the history of science\" because it means that everything conceivable happens. Science writer Philip Ball describes the MWI's implications as fantasies, since \"beneath their apparel of scientific equations or symbolic logic, they are acts of imagination, of 'just supposing'\".\nTheoretical physicist Gerard 't Hooft also dismisses the idea: \"I do not believe that we have to live with the many-worlds interpretation. Indeed, it would be a stupendous number of parallel worlds, which are only there because physicists couldn't decide which of them is real.\"\nAsher Peres was an outspoken critic of MWI. A section of his 1993 textbook had the title \"Everett's interpretation and other bizarre theories\". Peres argued that the various many-worlds interpretations merely shift the arbitrariness or vagueness of the collapse postulate to the question of when \"worlds\" can be regarded as separate, and that no objective criterion for that separation can actually be formulated.\nPolls.\nA poll of 72 \"leading quantum cosmologists and other quantum field theorists\" conducted before 1991 by L. David Raub showed 58% agreement with \"Yes, I think MWI is true\".\nMax Tegmark reports the result of a \"highly unscientific\" poll taken at a 1997 quantum mechanics workshop. According to Tegmark, \"The many worlds interpretation (MWI) scored second, comfortably ahead of the consistent histories and Bohm interpretations.\"\nIn response to Sean M. Carroll's statement \"As crazy as it sounds, most working physicists buy into the many-worlds theory\", Michael Nielsen counters: \"at a quantum computing conference at Cambridge in 1998, a many-worlder surveyed the audience of approximately 200 people... Many-worlds did just fine, garnering support on a level comparable to, but somewhat below, Copenhagen and decoherence.\" But Nielsen notes that it seemed most attendees found it to be a waste of time: Peres \"got a huge and sustained round of applause\u2026when he got up at the end of the polling and asked 'And who here believes the laws of physics are decided by a democratic vote?'\"\nA 2005 poll of fewer than 40 students and researchers taken after a course on the Interpretation of Quantum Mechanics at the Institute for Quantum Computing University of Waterloo found \"Many Worlds (and decoherence)\" to be the least favored.\nA 2011 poll of 33 participants at an Austrian conference found 6 endorsed MWI, 8 \"Information-based/information-theoretical\", and 14 Copenhagen; the authors remark that MWI received a similar percentage of votes as in Tegmark's 1997 poll.\nDebate whether the other worlds are real.\nEverett believed in the literal reality of the other quantum worlds. His son reported that he \"never wavered in his belief over his many-worlds theory\".\nAccording to Martin Gardner, the \"other\" worlds of MWI have two different interpretations: real or unreal; he claimed that Stephen Hawking and Steven Weinberg both favour the unreal interpretation. Gardner also claimed that most physicists favour the unreal interpretation, whereas the \"realist\" view is supported only by MWI experts such as Deutsch and DeWitt. Gardner reports Hawking saying that MWI is \"trivially true\". In a 1983 interview, Hawking also said he regarded MWI as \"self-evidently correct\" but was dismissive of questions about the interpretation of quantum mechanics, saying, \"When I hear of Schr\u00f6dinger's cat, I reach for my gun.\" In the same interview, he also said, \"But, look: All that one does, really, is to calculate conditional probabilities\u2014in other words, the probability of A happening, given B. I think that that's all the many-worlds interpretation is. Some people overlay it with a lot of mysticism about the wave function splitting into different parts. But all that you're calculating is conditional probabilities.\" Elsewhere Hawking contrasted his attitude towards the \"reality\" of physical theories with that of his colleague Roger Penrose, saying, \"He's a Platonist and I'm a positivist. He's worried that Schr\u00f6dinger's cat is in a quantum state, where it is half alive and half dead. He feels that can't correspond to reality. But that doesn't bother me. I don't demand that a theory correspond to reality because I don't know what it is. Reality is not a quality you can test with litmus paper. All I'm concerned with is that the theory should predict the results of measurements. Quantum theory does this very successfully.\"\nGell-Mann described himself as a \"post-Everett investigator\" and wrote, \"it is not necessary to become queasy trying to conceive of many 'parallel universes,' all equally real\". Instead, he advocated the language of \"many histories, all treated alike by the theory except for their different probabilities.\"\nSpeculative implications.\nQuantum suicide thought experiment.\n\"Quantum suicide\" is a thought experiment in quantum mechanics and the philosophy of physics. Purportedly, it can distinguish between the Copenhagen interpretation of quantum mechanics and the many-worlds interpretation by means of a variation of the Schr\u00f6dinger's cat thought experiment, from the cat's point of view. \"Quantum immortality\" refers to the subjective experience of surviving quantum suicide.\nMost experts believe that the experiment would not work in the real world, because the world with the surviving experimenter has a lower \"measure\" than the world before the experiment, making it less likely that the experimenter will experience their survival.\nAbsurdly improbable timelines.\nDeWitt has stated that \"[Everett, Wheeler and Graham] do not in the end exclude any element of the superposition. All the worlds are there, even those in which everything goes wrong and all the statistical laws break down.\"\nMax Tegmark has affirmed that absurd or highly unlikely events are inevitable but rare under MWI. To quote Tegmark, \"Things inconsistent with the laws of physics will never happen\u2014everything else will... it's important to keep track of the statistics, since even if everything conceivable happens somewhere, really freak events happen only exponentially rarely.\"\nLadyman and Ross state that, in general, many of the unrealized possibilities that are discussed in other scientific fields will not have counterparts in other branches, because they are in fact incompatible with the universal wavefunction.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9606", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9606", "title": "Ergonomics", "text": ""}
{"id": "9607", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=9607", "title": "Electromagnectic radiation", "text": ""}
{"id": "9611", "revid": "45585618", "url": "https://en.wikipedia.org/wiki?curid=9611", "title": "E-commerce", "text": "Type of business industry usually conducted over the internet\nE-commerce (electronic commerce) is the activity of electronically buying or selling of products on online services or over the Internet. E-commerce draws on technologies such as mobile commerce, electronic funds transfer, supply chain management, Internet marketing, online transaction processing, electronic data interchange (EDI), inventory management systems, and automated data collection systems. E-commerce is in turn driven by the technological advances of the semiconductor industry, and is the largest sector of the electronics industry.\nDefining e-commerce.\nThe term was coined and first employed by Dr. Robert Jacobson, Principal Consultant to the California State Assembly's Utilities &amp; Commerce Committee, in the title and text of California's Electronic Commerce Act, carried by the late Committee Chairwoman Gwen Moore (D-L.A.) and enacted in 1984.\nE-commerce typically uses the web for at least a part of a transaction's life cycle although it may also use other technologies such as e-mail. Typical e-commerce transactions include the purchase of products (such as books from Amazon) or services (such as music downloads in the form of digital distribution such as iTunes Store). There are three areas of e-commerce: online retailing, electronic markets, and online auctions. E-commerce is supported by electronic business. The existence value of e-commerce is to allow consumers to shop online and pay online through the Internet, saving the time and space of customers and enterprises, greatly improving transaction efficiency, especially for busy office workers, but also saving a lot of valuable time.\nE-commerce businesses may also employ some or all of the following:\nThere are five essential categories of E-commerce:\nForms.\nContemporary electronic commerce can be classified into two categories. The first category is business based on types of goods sold (involves everything from ordering \"digital\" content for immediate online consumption, to ordering conventional goods and services, to \"meta\" services to facilitate other types of electronic commerce). The second category is based on the nature of the participant (B2B, B2C, C2B and C2C).\nOn the institutional level, big corporations and financial institutions use the internet to exchange financial data to facilitate domestic and international business. Data integrity and security are pressing issues for electronic commerce.\nAside from traditional e-commerce, the terms m-Commerce (mobile commerce) as well (around 2013) t-Commerce have also been used.\nGovernmental regulation.\nIn the United States, California's Electronic Commerce Act (1984), enacted by the Legislature, the more recent California Privacy Rights Act (2020), enacted through a popular election proposition and to control specifically how electronic commerce may be conducted in California. In the US in its entirety, electronic commerce activities are regulated more broadly by the Federal Trade Commission (FTC). These activities include the use of commercial e-mails, online advertising and consumer privacy. The CAN-SPAM Act of 2003 establishes national standards for direct marketing over e-mail. The Federal Trade Commission Act regulates all forms of advertising, including online advertising, and states that advertising must be truthful and non-deceptive. Using its authority under Section 5 of the FTC Act, which prohibits unfair or deceptive practices, the FTC has brought a number of cases to enforce the promises in corporate privacy statements, including promises about the security of consumers' personal information. As a result, any corporate privacy policy related to e-commerce activity may be subject to enforcement by the FTC.\nThe Ryan Haight Online Pharmacy Consumer Protection Act of 2008, which came into law in 2008, amends the Controlled Substances Act to address online pharmacies.\nConflict of laws in cyberspace is a major hurdle for harmonization of legal framework for e-commerce around the world. In order to give a uniformity to e-commerce law around the world, many countries adopted the UNCITRAL Model Law on Electronic Commerce (1996).&lt;ref name=\"http://www.uncitral.org/uncitral/en/uncitral_texts/electronic_commerce/1996Model.html\"&gt;&lt;/ref&gt;\nInternationally there is the International Consumer Protection and Enforcement Network (ICPEN), which was formed in 1991 from an informal network of government customer fair trade organisations. The purpose was stated as being to find ways of co-operating on tackling consumer problems connected with cross-border transactions in both goods and services, and to help ensure exchanges of information among the participants for mutual benefit and understanding. From this came Econsumer.gov, an ICPEN initiative since April 2001. It is a portal to report complaints about online and related transactions with foreign companies.\nThere is also Asia Pacific Economic Cooperation. APEC was established in 1989 with the vision of achieving stability, security and prosperity for the region through free and open trade and investment. APEC has an Electronic Commerce Steering Group as well as working on common privacy regulations throughout the APEC region.\nIn Australia, trade is covered under Australian Treasury Guidelines for electronic commerce and the Australian Competition &amp; Consumer Commission regulates and offers advice on how to deal with businesses online, and offers specific advice on what happens if things go wrong.\nThe European Union undertook an extensive enquiry into e-commerce in 2015-16 which observed significant growth in the development of e-commerce, along with some developments which raised concerns, such as increased use of selective distribution systems, which allow manufacturers to control routes to market, and \"increased use of contractual restrictions to better control product distribution\". The European Commission felt that some emerging practices might be justified if they could improve the quality of product distribution, but \"others may unduly prevent consumers from benefiting from greater product choice and lower prices in e-commerce and therefore warrant Commission action\" in order to promote compliance with EU competition rules.\nIn the United Kingdom, the Financial Services Authority (FSA) was formerly the regulating authority for most aspects of the EU's Payment Services Directive (PSD), until its replacement in 2013 by the Prudential Regulation Authority and the Financial Conduct Authority. The UK implemented the PSD through the Payment Services Regulations 2009 (PSRs), which came into effect on 1 November 2009. The PSR affects firms providing payment services and their customers. These firms include banks, non-bank credit card issuers and non-bank merchant acquirers, e-money issuers, etc. The PSRs created a new class of regulated firms known as payment institutions (PIs), who are subject to prudential requirements. Article 87 of the PSD requires the European Commission to report on the implementation and impact of the PSD by 1 November 2012.\nIn India, the Information Technology Act 2000 governs the basic applicability of e-commerce.\nIn China, the Telecommunications Regulations of the People's Republic of China (promulgated on 25 September 2000), stipulated the Ministry of Industry and Information Technology (MIIT) as the government department regulating all telecommunications related activities, including electronic commerce. On the same day, the Administrative Measures on Internet Information Services were released, the first administrative regulations to address profit-generating activities conducted through the Internet, and lay the foundation for future regulations governing e-commerce in China. On 28 August 2004, the eleventh session of the tenth NPC Standing Committee adopted an Electronic Signature Law, which regulates data message, electronic signature authentication and legal liability issues. It is considered the first law in China's e-commerce legislation. It was a milestone in the course of improving China's electronic commerce legislation, and also marks the entering of China's rapid development stage for electronic commerce legislation.\nGlobal trends.\nIn 2010, the United Kingdom had the highest per capita e-commerce spending in the world. As of 2013, the Czech Republic was the European country where e-commerce delivers the biggest contribution to the enterprises' total revenue. Almost a quarter (24%) of the country's total turnover is generated via the online channel.\nAmong emerging economies, China's e-commerce presence continues to expand every year. With 668 million Internet users, China's online shopping sales reached $253 billion in the first half of 2015, accounting for 10% of total Chinese consumer retail sales in that period. The Chinese retailers have been able to help consumers feel more comfortable shopping online. e-commerce transactions between China and other countries increased 32% to 2.3 trillion yuan ($375.8 billion) in 2012 and accounted for 9.6% of China's total international trade. In 2013, Alibaba had an e-commerce market share of 80% in China. In 2014, Alibaba still dominated the B2B marketplace in China with a market share of 44.82%, followed by several other companies including Made-in-China.com at 3.21%, and GlobalSources.com at 2.98%, with the total transaction value of China's B2B market exceeding 4.5 billion yuan.In 2014, there were 600 million Internet users in China (twice as many as in the US), making it the world's biggest online market. China is also the largest e-commerce market in the world by value of sales, with an estimated US$ in 2016. Research shows that Chinese consumer motivations are different enough from Western audiences to require unique e-commerce app designs instead of simply porting Western apps into the Chinese market.\nRecent research indicates that electronic commerce, commonly referred to as e-commerce, presently shapes the manner in which people shop for products. The GCC countries have a rapidly growing market and are characterized by a population that becomes wealthier (Yuldashev). As such, retailers have launched Arabic-language websites as a means to target this population. Secondly, there are predictions of increased mobile purchases and an expanding internet audience (Yuldashev). The growth and development of the two aspects make the GCC countries become larger players in the electronic commerce market with time progress. Specifically, research shows that the e-commerce market is expected to grow to over $20 billion by 2020 among these GCC countries (Yuldashev). The e-commerce market has also gained much popularity among western countries, and in particular Europe and the U.S. These countries have been highly characterized by consumer-packaged goods (CPG) (Geisler, 34). However, trends show that there are future signs of a reverse. Similar to the GCC countries, there has been increased purchase of goods and services in online channels rather than offline channels. Activist investors are trying hard to consolidate and slash their overall cost and the governments in western countries continue to impose more regulation on CPG manufacturers (Geisler, 36). In these senses, CPG investors are being forced to adapt to e-commerce as it is effective as well as a means for them to thrive.\nIn 2013, Brazil's e-commerce was growing quickly with retail e-commerce sales expected to grow at a double-digit pace through 2014. By 2016, eMarketer expected retail e-commerce sales in Brazil to reach $17.3 billion. India has an Internet user base of about 460 million as of December 2017. Despite being the third largest user base in the world, the penetration of the Internet is low compared to markets like the United States, United Kingdom or France but is growing at a much faster rate, adding around 6 million new entrants every month. In India, cash on delivery is the most preferred payment method, accumulating 75% of the e-retail activities. The India retail market is expected to rise from 2.5% in 2016 to 5% in 2020.\nThe future trends in the GCC countries will be similar to that of the western countries. Despite the forces that push business to adapt e-commerce as a means to sell goods and products, the manner in which customers make purchases is similar in countries from these two regions. For instance, there has been an increased usage of smartphones which comes in conjunction with an increase in the overall internet audience from the regions. Yuldashev writes that consumers are scaling up to more modern technology that allows for mobile marketing.\nHowever, the percentage of smartphone and internet users who make online purchases is expected to vary in the first few years. It will be independent on the willingness of the people to adopt this new trend (The Statistics Portal). For example, UAE has the greatest smartphone penetration of 73.8 per cent and has 91.9 per cent of its population has access to the internet. On the other hand, smartphone penetration in Europe has been reported to be at 64.7 per cent (The Statistics Portal). Regardless, the disparity in percentage between these regions is expected to level out in future because e-commerce technology is expected to grow to allow for more users.\nThe e-commerce business within these two regions will result in competition. Government bodies at the country level will enhance their measures and strategies to ensure sustainability and consumer protection (Krings, et al.). These increased measures will raise the environmental and social standards in the countries, factors that will determine the success of the e-commerce market in these countries. For example, an adoption of tough sanctions will make it difficult for companies to enter the e-commerce market while lenient sanctions will allow ease of companies. As such, the future trends between GCC countries and the Western countries will be independent of these sanctions (Krings, et al.). These countries need to make rational conclusions in coming up with effective sanctions.\nThe rate of growth of the number of internet users in the Arab countries has been rapid \u2013 13.1% in 2015. A significant portion of the e-commerce market in the Middle East comprises people in the 30\u201334 year age group. Egypt has the largest number of internet users in the region, followed by Saudi Arabia and Morocco; these constitute 3/4th of the region's share. Yet, internet penetration is low: 35% in Egypt and 65% in Saudi Arabia.\nE-commerce has become an important tool for small and large businesses worldwide, not only to sell to customers, but also to engage them.\nCross-border e-Commerce is also an essential field for e-Commerce businesses. \u00a0It has responded to the trend of globalization. It shows that numerous firms have opened up new businesses, expanded new markets, and overcome trade barriers; more and more enterprises have started exploring the cross-border cooperation field. In addition, compared with traditional cross-border trade, the information on cross-border e-commerce is more concealed. In the era of globalization, cross-border e-commerce for inter-firm companies means the activities, interactions, or social relations of two or more e-commerce enterprises. However, the success of cross-border e-commerce promotes the development of small and medium-sized firms, and it has finally become a new transaction mode. It has helped the companies solve financial problems and realize the reasonable allocation of resources field. SMEs ( small and medium enterprises) can also precisely match the demand and supply in the market, having the industrial chain majorization and creating more revenues for companies.\nIn 2012, e-commerce sales topped $1 trillion for the first time in history.\nMobile devices are playing an increasing role in the mix of e-commerce, this is also commonly called mobile commerce, or m-commerce. In 2014, one estimate saw purchases made on mobile devices making up 25% of the market by 2017.\nFor traditional businesses, one research stated that information technology and cross-border e-commerce is a good opportunity for the rapid development and growth of enterprises. Many companies have invested an enormous volume of investment in mobile applications. The DeLone and McLean Model stated that three perspectives contribute to a successful e-business: information system quality, service quality and users' satisfaction. There is no limit of time and space, there are more opportunities to reach out to customers around the world, and to cut down unnecessary intermediate links, thereby reducing the cost price, and can benefit from one on one large customer data analysis, to achieve a high degree of personal customization strategic plan, in order to fully enhance the core competitiveness of the products in the company.\nModern 3D graphics technologies, such as Facebook 3D Posts, are considered by some social media marketers and advertisers as a preferable way to promote consumer goods than static photos, and some brands like Sony are already paving the way for augmented reality commerce. Wayfair now lets you inspect a 3D version of its furniture in a home setting before buying.\nLogistics.\nLogistics in e-commerce mainly concerns fulfillment. Online markets and retailers have to find the best possible way to fill orders and deliver products. Small companies usually control their own logistic operation because they do not have the ability to hire an outside company. Most large companies hire a fulfillment service that takes care of a company's logistic needs.\nImpacts.\nImpact on markets and retailers.\nE-commerce markets are growing at noticeable rates. The online market is expected to grow by 56% in 2015\u20132020. In 2017, retail e-commerce sales worldwide amounted to 2.3 trillion US dollars and e-retail revenues are projected to grow to 4.891 trillion US dollars in 2021. Traditional markets are only expected 2% growth during the same time. Brick and mortar retailers are struggling because of online retailer's ability to offer lower prices and higher efficiency. Many larger retailers are able to maintain a presence offline and online by linking physical and online offerings.\nE-commerce allows customers to overcome geographical barriers and allows them to purchase products anytime and from anywhere. Online and traditional markets have different strategies for conducting business. Traditional retailers offer fewer assortment of products because of shelf space where, online retailers often hold no inventory but send customer orders directly to the manufacture. The pricing strategies are also different for traditional and online retailers. Traditional retailers base their prices on store traffic and the cost to keep inventory. Online retailers base prices on the speed of delivery.\nThere are two ways for marketers to conduct business through e-commerce: fully online or online along with a brick and mortar store. Online marketers can offer lower prices, greater product selection, and high efficiency rates. Many customers prefer online markets if the products can be delivered quickly at relatively low price. However, online retailers cannot offer the physical experience that traditional retailers can. It can be difficult to judge the quality of a product without the physical experience, which may cause customers to experience product or seller uncertainty. Another issue regarding the online market is concerns about the security of online transactions. Many customers remain loyal to well-known retailers because of this issue.\nSecurity is a primary problem for e-commerce in developed and developing countries. E-commerce security is protecting businesses' websites and customers from unauthorized access, use, alteration, or destruction. The type of threats include: malicious codes, unwanted programs (ad ware, spyware), phishing, hacking, and cyber vandalism. E-commerce websites use different tools to avert security threats. These tools include firewalls, encryption software, digital certificates, and passwords.\nImpact on supply chain management.\nFor a long time, companies had been troubled by the gap between the benefits which supply chain technology has and the solutions to deliver those benefits. However, the emergence of e-commerce has provided a more practical and effective way of delivering the benefits of the new supply chain technologies.\nE-commerce has the capability to integrate all inter-company and intra-company functions, meaning that the three flows (physical flow, financial flow and information flow) of the supply chain could be also affected by e-commerce. The affections on physical flows improved the way of product and inventory movement level for companies. For the information flows, e-commerce optimized the capacity of information processing than companies used to have, and for the financial flows, e-commerce allows companies to have more efficient payment and settlement solutions.\nIn addition, e-commerce has a more sophisticated level of impact on supply chains: Firstly, the performance gap will be eliminated since companies can identify gaps between different levels of supply chains by electronic means of solutions; Secondly, as a result of e-commerce emergence, new capabilities such implementing ERP systems, like SAP ERP, Xero, or Megaventory, have helped companies to manage operations with customers and suppliers. Yet these new capabilities are still not fully exploited. Thirdly, technology companies would keep investing on new e-commerce software solutions as they are expecting investment return. Fourthly, e-commerce would help to solve many aspects of issues that companies may feel difficult to cope with, such as political barriers or cross-country changes. Finally, e-commerce provides companies a more efficient and effective way to collaborate with each other within the supply chain.\nImpact on employment.\nE-commerce helps create new job opportunities due to information related services, software app and digital products. It also causes job losses. The areas with the greatest predicted job-loss are retail, postal, and travel agencies. The development of e-commerce will create jobs that require highly skilled workers to manage large amounts of information, customer demands, and production processes. In contrast, people with poor technical skills cannot enjoy the wages welfare. On the other hand, because e-commerce requires sufficient stocks that could be delivered to customers in time, the warehouse becomes an important element. Warehouse needs more staff to manage, supervise and organize, thus the condition of warehouse environment will be concerned by employees.\nImpact on customers.\nE-commerce brings convenience for customers as they do not have to leave home and only need to browse websites online, especially for buying products which are not sold in nearby shops. It could help customers buy a wider range of products and save customers' time. Consumers also gain power through online shopping. They are able to research products and compare prices among retailers. Thanks to the practice of user-generated ratings and reviews from companies like Bazaarvoice, Trustpilot, and Yelp, customers can also see what other people think of a product, and decide before buying if they want to spend money on it. Also, online shopping often provides sales promotion or discounts code, thus it is more price effective for customers. Moreover, e-commerce provides products' detailed information; even the in-store staff cannot offer such detailed explanation. Customers can also review and track the order history online.\nE-commerce technologies cut transaction costs by allowing both manufactures and consumers to skip through the intermediaries. This is achieved through by extending the search area best price deals and by group purchase. The success of e-commerce in urban and regional levels depend on how the local firms and consumers have adopted to e-commerce.\nHowever, e-commerce lacks human interaction for customers, especially who prefer face-to-face connection. Customers are also concerned with the security of online transactions and tend to remain loyal to well-known retailers. In recent years, clothing retailers such as Tommy Hilfiger have started adding Virtual Fit platforms to their e-commerce sites to reduce the risk of customers buying the wrong sized clothes, although these vary greatly in their fit for purpose. When the customer regret the purchase of a product, it involves returning goods and refunding process. This process is inconvenient as customers need to pack and post the goods. If the products are expensive, large or fragile, it refers to safety issues.\nImpact on the environment.\nIn 2018, E-commerce generated of container cardboard in North America, an increase from ) in 2017. Only 35 percent of North American cardboard manufacturing capacity is from recycled content. The recycling rate in Europe is 80 percent and Asia is 93 percent. Amazon, the largest user of boxes, has a strategy to cut back on packing material and has reduced packaging material used by 19 percent by weight since 2016. Amazon is requiring retailers to manufacture their product packaging in a way that doesn't require additional shipping packaging. Amazon also has an 85-person team researching ways to reduce and improve their packaging and shipping materials.\nAccelerated movement of packages around the world includes accelerated movement of living things, with all its attendant risks. Weeds, pests, and diseases all sometimes travel in packages of seeds. Some of these packages are part of brushing manipulation of e-commerce reviews.\nImpact on traditional retail.\nE-commerce has been cited as a major force for the failure of major U.S. retailers in a trend frequently referred to as a \"retail apocalypse.\" The rise of e-commerce outlets like Amazon has made it harder for traditional retailers to attract customers to their stores and forced companies to change their sales strategies. Many companies have turned to sales promotions and increased digital efforts to lure shoppers while shutting down brick-and-mortar locations. The trend has forced some traditional retailers to shutter its brick and mortar operations.\nE-commerce during COVID-19.\nIn March 2020, global retail website traffic hit 14.3 billion visits signifying an unprecedented growth of e-commerce during the lockdown of 2020. Later studies show that online sales increased by 25% and online grocery shopping increased by over 100% during the crisis in the United States. Meanwhile, as many as 29% of surveyed shoppers state that they will never go back to shopping in person again; in the UK, 43% of consumers state that they expect to keep on shopping the same way even after the lockdown is over.\nRetail sales of e-commerce shows that COVID-19 has a significant impact on e-commerce and its sales are expected to reach $6.5 trillion by 2023.\nBusiness application.\nSome common applications related to electronic commerce are:\nTimeline.\nA timeline for the development of e-commerce:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9613", "revid": "84591", "url": "https://en.wikipedia.org/wiki?curid=9613", "title": "Euler's formula", "text": "Complex exponential in terms of sine and cosine\nEuler's formula, named after Leonhard Euler, is a mathematical formula in complex analysis that establishes the fundamental relationship between the trigonometric functions and the complex exponential function. Euler's formula states that for any real number\u00a0x:\nformula_1\nwhere e is the base of the natural logarithm, i is the imaginary unit, and cos and sin are the trigonometric functions cosine and sine respectively. This complex exponential function is sometimes denoted cis \"x\" (\"cosine plus \"i\" sine\"). The formula is still valid if x is a complex number, and so some authors refer to the more general complex version as Euler's formula.\nEuler's formula is ubiquitous in mathematics, physics, chemistry, and engineering. The physicist Richard Feynman called the equation \"our jewel\" and \"the most remarkable formula in mathematics\".\nWhen \"x\" = \"\u03c0\", Euler's formula may be rewritten as \"ei\u03c0\" + 1 = 0 or \"ei\u03c0\" = -1, which is known as Euler's identity.\nHistory.\nIn 1714, the English mathematician Roger Cotes presented a geometrical argument that can be interpreted (after correcting a misplaced factor of formula_2) as:\nformula_3\nExponentiating this equation yields Euler's formula. Note that the logarithmic statement is not universally correct for complex numbers, since a complex logarithm can have infinitely many values, differing by multiples of 2\"\u03c0i\".\nAround 1740 Leonhard Euler turned his attention to the exponential function and derived the equation named after him by comparing the series expansions of the exponential and trigonometric expressions. The formula was first published in 1748 in his foundational work \"Introductio in analysin infinitorum\".\nJohann Bernoulli had found that\nformula_4\nAnd since\nformula_5\nthe above equation tells us something about complex logarithms by relating natural logarithms to imaginary (complex) numbers. Bernoulli, however, did not evaluate the integral.\nBernoulli's correspondence with Euler (who also knew the above equation) shows that Bernoulli did not fully understand complex logarithms. Euler also suggested that complex logarithms can have infinitely many values.\nThe view of complex numbers as points in the complex plane was described about 50 years later by Caspar Wessel.\nDefinitions of complex exponentiation.\nThe exponential function \"ex\" for real values of x may be defined in a few different equivalent ways (see Characterizations of the exponential function). Several of these methods may be directly extended to give definitions of \"ez\" for complex values of z simply by substituting z in place of x and using the complex algebraic operations. In particular we may use any of the three following definitions, which are equivalent. From a more advanced perspective, each of these definitions may be interpreted as giving the unique analytic continuation of \"ex\" to the complex plane.\nDifferential equation definition.\nThe exponential function formula_6 is the unique differentiable function of a complex variable for which the derivative equals the function formula_7 and formula_8\nPower series definition.\nFor complex z\nformula_9\nUsing the ratio test, it is possible to show that this power series has an infinite radius of convergence and so defines \"ez\" for all complex z.\nLimit definition.\nFor complex z\nformula_10\nHere, n is restricted to positive integers, so there is no question about what the power with exponent n means.\nProofs.\nVarious proofs of the formula are possible.\nUsing differentiation.\nThis proof shows that the quotient of the trigonometric and exponential expressions is the constant function one, so they must be equal (the exponential function is never zero, so this is permitted).\nConsider the function \"f\"(\"\u03b8\") \nformula_11\nfor real \u03b8. Differentiating gives by the product rule\nformula_12\nThus, \"f\"(\"\u03b8\") is a constant. Since \"f\"(0) = 1, then \"f\"(\"\u03b8\") = 1 for all real \u03b8, and thus \nformula_13\nUsing power series.\nHere is a proof of Euler's formula using power-series expansions, as well as basic facts about the powers of i:\nformula_14\nUsing now the power-series definition from above, we see that for real values of x\nformula_15\nwhere in the last step we recognize the two terms are the Maclaurin series for cos \"x\" and sin \"x\". The rearrangement of terms is justified because each series is absolutely convergent.\nUsing polar coordinates.\nAnother proof is based on the fact that all complex numbers can be expressed in polar coordinates. Therefore, for some r and \u03b8 depending on x,\nformula_16\nNo assumptions are being made about r and \u03b8; they will be determined in the course of the proof. From any of the definitions of the exponential function it can be shown that the derivative of \"e\"\"ix\" is \"ie\"\"ix\". Therefore, differentiating both sides gives\nformula_17\nSubstituting \"r\"(cos \"\u03b8\" + \"i\" sin \"\u03b8\") for \"eix\" and equating real and imaginary parts in this formula gives ' = 0 and ' = 1. Thus, r is a constant, and \u03b8 is \"x\" + \"C\" for some constant C. The initial values \"r\"(0) = 1 and \"\u03b8\"(0) = 0 come from \"e\"0\"i\" = 1, giving \"r\" = 1 and \"\u03b8\" = \"x\". This proves the formula\nformula_18\nApplications.\nInterpretation of the formula.\nThis formula can be interpreted as saying that the function \"e\"\"i\u03c6\" is a unit complex number, i.e., it traces out the unit circle in the complex plane as \u03c6 ranges through the real numbers. Here \u03c6 is the angle that a line connecting the origin with a point on the unit circle makes with the positive real axis, measured counterclockwise and in radians.\nThe original proof is based on the Taylor series expansions of the exponential function \"e\"\"z\" (where z is a complex number) and of sin \"x\" and cos \"x\" for real numbers x (see below). In fact, the same proof shows that Euler's formula is even valid for all \"complex\" numbers\u00a0x.\nA point in the complex plane can be represented by a complex number written in cartesian coordinates. Euler's formula provides a means of conversion between cartesian coordinates and polar coordinates. The polar form simplifies the mathematics when used in multiplication or powers of complex numbers. Any complex number \"z\" = \"x\" + \"iy\", and its complex conjugate, \"z\" = \"x\" \u2212 \"iy\", can be written as\nformula_19\nwhere\n\u03c6 is the argument of z, i.e., the angle between the \"x\" axis and the vector \"z\" measured counterclockwise in radians, which is defined up to addition of 2\"\u03c0\". Many texts write \"\u03c6\" = tan\u22121 \"\" instead of \"\u03c6\" = atan2(\"y\", \"x\"), but the first equation needs adjustment when \"x\" \u2264 0. This is because for any real x and y, not both zero, the angles of the vectors (\"x\", \"y\") and (\u2212\"x\", \u2212\"y\") differ by \u03c0 radians, but have the identical value of tan \"\u03c6\" =.\nUse of the formula to define the logarithm of complex numbers.\nNow, taking this derived formula, we can use Euler's formula to define the logarithm of a complex number. To do this, we also use the definition of the logarithm (as the inverse operator of exponentiation):\nformula_20\nand that\nformula_21\nboth valid for any complex numbers a and b. Therefore, one can write:\nformula_22\nfor any \"z\" \u2260 0. Taking the logarithm of both sides shows that\nformula_23\nand in fact, this can be used as the definition for the complex logarithm. The logarithm of a complex number is thus a multi-valued function, because \u03c6 is multi-valued.\nFinally, the other exponential law\nformula_24\nwhich can be seen to hold for all integers k, together with Euler's formula, implies several trigonometric identities, as well as de Moivre's formula.\nRelationship to trigonometry.\nEuler's formula, the definitions of the trigonometric functions and the standard identities for exponentials are sufficient to easily derive most trigonometric identities. It provides a powerful connection between analysis and trigonometry, and provides an interpretation of the sine and cosine functions as weighted sums of the exponential function:\nformula_25\nThe two equations above can be derived by adding or subtracting Euler's formulas:\nformula_26\nand solving for either cosine or sine.\nThese formulas can even serve as the definition of the trigonometric functions for complex arguments x. For example, letting \"x\" = \"iy\", we have:\nformula_27\nComplex exponentials can simplify trigonometry, because they are easier to manipulate than their sinusoidal components. One technique is simply to convert sinusoids into equivalent expressions in terms of exponentials. After the manipulations, the simplified result is still real-valued. For example:\nformula_28\nAnother technique is to represent the sinusoids in terms of the real part of a complex expression and perform the manipulations on the complex expression. For example:\nformula_29\nThis formula is used for recursive generation of cos \"nx\" for integer values of n and arbitrary x (in radians).\nTopological interpretation.\nIn the language of topology, Euler's formula states that the imaginary exponential function formula_30 is a (surjective) morphism of topological groups from the real line formula_31 to the unit circle formula_32. In fact, this exhibits formula_31 as a covering space of formula_32. Similarly, Euler's identity says that the kernel of this map is formula_35, where formula_36. These observations may be combined and summarized in the commutative diagram below:\nOther applications.\nIn differential equations, the function \"eix\" is often used to simplify solutions, even if the final answer is a real function involving sine and cosine. The reason for this is that the exponential function is the eigenfunction of the operation of differentiation.\nIn electrical engineering, signal processing, and similar fields, signals that vary periodically over time are often described as a combination of sinusoidal functions (see Fourier analysis), and these are more conveniently expressed as the sum of exponential functions with imaginary exponents, using Euler's formula. Also, phasor analysis of circuits can include Euler's formula to represent the impedance of a capacitor or an inductor.\nIn the four-dimensional space of quaternions, there is a sphere of imaginary units. For any point r on this sphere, and x a real number, Euler's formula applies:\nformula_37\nand the element is called a versor in quaternions. The set of all versors forms a 3-sphere in the 4-space."}
{"id": "9614", "revid": "146242", "url": "https://en.wikipedia.org/wiki?curid=9614", "title": "Eductor-jet pump", "text": ""}
{"id": "9615", "revid": "998182", "url": "https://en.wikipedia.org/wiki?curid=9615", "title": "\u00c9douard Manet", "text": "French painter (1832\u20131883)\n\u00c9douard Manet (, ; ]; 23 January 1832\u00a0\u2013 30 April 1883) was a French modernist painter. He was one of the first 19th-century artists to paint modern life, as well as a pivotal figure in the transition from Realism to Impressionism.\nBorn into an upper-class household with strong political connections, Manet rejected the naval career originally envisioned for him; he became engrossed in the world of painting. His early masterworks, \"The Luncheon on the Grass\" (\"Le d\u00e9jeuner sur l'herbe\") and \"Olympia\", both 1863, caused great controversy and served as rallying points for the young painters who would create Impressionism. Today, these are considered watershed paintings that mark the start of modern art. The last 20 years of Manet's life saw him form bonds with other great artists of the time; he developed his own simple and direct style that would be heralded as innovative and serve as a major influence for future painters.\nEarly life.\n\u00c9douard Manet was born in Paris on 23 January 1832, in the ancestral h\u00f4tel particulier (mansion) on the Rue des Petits Augustins (now Rue Bonaparte) to an affluent and well-connected family. His mother, Eug\u00e9nie-Desir\u00e9e Fournier, was the daughter of a diplomat and goddaughter of the Swedish crown prince Charles Bernadotte, from whom the Swedish monarchs are descended. His father, Auguste Manet, was a French judge who expected \u00c9douard to pursue a career in law. His uncle, Edmond Fournier, encouraged him to pursue painting and took young Manet to the Louvre. In 1841 he enrolled at secondary school, the Coll\u00e8ge Rollin. In 1845, at the advice of his uncle, Manet enrolled in a special course of drawing where he met Antonin Proust, future Minister of Fine Arts and subsequent lifelong friend.\nAt his father's suggestion, in 1848 he sailed on a training vessel to Rio de Janeiro. After he twice failed the examination to join the Navy, his father relented to his wishes to pursue an art education. From 1850 to 1856, Manet studied under the academic painter Thomas Couture. In his spare time, Manet copied the Old Masters in the Louvre.\nFrom 1853 to 1856, Manet visited Germany, Italy, and the Netherlands, during which time he was influenced by the Dutch painter Frans Hals and the Spanish artists Diego Vel\u00e1zquez and Francisco Jos\u00e9 de Goya.\nCareer.\nIn 1856, Manet opened a studio. His style in this period was characterized by loose brush strokes, simplification of details, and the suppression of transitional tones. Adopting the current style of realism initiated by Gustave Courbet, he painted \"The Absinthe Drinker\" (1858\u201359) and other contemporary subjects such as beggars, singers, Gypsies, people in caf\u00e9s, and bullfights. After his early career, he rarely painted religious, mythological, or historical subjects; religious paintings from 1864 include his \"\", in the Art Institute of Chicago, and \"The Dead Christ with Angels\", in the Metropolitan Museum of Art, New York. Manet had two canvases accepted at the Salon in 1861. A portrait of his mother and father, who at the time was paralysed and robbed of speech by a stroke, was ill-received by critics. The other, \"The Spanish Singer\", was admired by Th\u00e9ophile Gautier, and placed in a more conspicuous location as a result of its popularity with Salon-goers. Manet's work, which appeared \"slightly slapdash\" when compared with the meticulous style of so many other Salon paintings, intrigued some young artists. \"The Spanish Singer\", painted in a \"strange new fashion[,] caused many painters' eyes to open and their jaws to drop.\"\n\"Music in the Tuileries\".\n\"Music in the Tuileries\" is an early example of Manet's painterly style. Inspired by Hals and Vel\u00e1zquez, it is a harbinger of his lifelong interest in the subject of leisure.\nWhile the picture was regarded as unfinished by some, the suggested atmosphere imparts a sense of what the Tuileries gardens were like at the time; one may imagine the music and conversation.\nHere, Manet has depicted his friends, artists, authors, and musicians who take part, and he has included a self-portrait among the subjects.\n\"Luncheon on the Grass \"(\"Le d\u00e9jeuner sur l'herbe\").\nA major early work is \"The Luncheon on the Grass (Le D\u00e9jeuner sur l'herbe)\", originally \"Le Bain\". The Paris Salon rejected it for exhibition in 1863, but Manet agreed to exhibit it at the Salon des Refus\u00e9s (Salon of the Rejected) which was a parallel exhibition to the official Salon, as an alternative exhibition in the Palais des Champs-\u00c9lys\u00e9es. The Salon des Refus\u00e9s was initiated by Emperor Napoleon III as a solution to a problematic situation which came about as the Selection Committee of the Salon that year rejected 2,783 paintings of the c. 5000. Each painter could decide whether to take the opportunity to exhibit at the Salon des Refus\u00e9s, although fewer than 500 of the rejected painters chose to do so.\nManet employed model Victorine Meurent, his wife Suzanne, future brother-in-law Ferdinand Leenhoff, and one of his brothers to pose. Meurent also posed for several more of Manet's important paintings including \"Olympia\"; and by the mid-1870s she became an accomplished painter in her own right.\nThe painting's juxtaposition of fully dressed men and a nude woman was controversial, as was its abbreviated, sketch-like handling, an innovation that distinguished Manet from Courbet. At the same time, Manet's composition reveals his study of the old masters, as the disposition of the main figures is derived from Marcantonio Raimondi's engraving of the \"Judgement of Paris\" (c.\u20091515) based on a drawing by Raphael.\nTwo additional works cited by scholars as important precedents for \"Le d\u00e9jeuner sur l'herbe\" are \"Pastoral Concert\" (c.\u20091510, The Louvre) and \"The Tempest\" (Gallerie dell'Accademia, Venice), both of which are attributed variously to Italian Renaissance masters Giorgione or Titian. \"The Tempest\" is an enigmatic painting featuring a fully dressed man and a nude woman in a rural setting. The man is standing to the left and gazing to the side, apparently at the woman, who is seated and breastfeeding a baby; the relationship between the two figures is unclear. In \"Pastoral Concert\", two clothed men and a nude woman are seated on the grass, engaged in music making, while a second nude woman stands beside them.\n\"Olympia\".\nAs he had in \"Luncheon on the Grass\", Manet again paraphrased a respected work by a Renaissance artist in the painting \"Olympia\" (1863), a nude portrayed in a style reminiscent of early studio photographs, but whose pose was based on Titian's \"Venus of Urbino\" (1538). The painting is also reminiscent of Francisco Goya's painting \"The Nude Maja\" (1800).\nManet embarked on the canvas after being challenged to give the Salon a nude painting to display. His uniquely frank depiction of a self-assured prostitute was accepted by the Paris Salon in 1865, where it created a scandal. According to Antonin Proust, \"only the precautions taken by the administration prevented the painting being punctured and torn\" by offended viewers. The painting was controversial partly because the nude is wearing some small items of clothing such as an orchid in her hair, a bracelet, a ribbon around her neck, and mule slippers, all of which accentuated her nakedness, sexuality, and comfortable courtesan lifestyle. The orchid, upswept hair, black cat, and bouquet of flowers were all recognized symbols of sexuality at the time. This modern Venus' body is thin, counter to prevailing standards; the painting's lack of idealism rankled viewers. The painting's flatness, inspired by Japanese wood block art, serves to make the nude more human and less voluptuous. A fully dressed black servant is featured, exploiting the then-current theory that black people were hyper-sexed. That she is wearing the clothing of a servant to a courtesan here furthers the sexual tension of the piece.\nOlympia's body as well as her gaze is unabashedly confrontational. She defiantly looks out as her servant offers flowers from one of her male suitors. Although her hand rests on her leg, hiding her pubic area, the reference to traditional female virtue is ironic; a notion of modesty is notoriously absent in this work. A contemporary critic denounced Olympia's \"shamelessly flexed\" left hand, which seemed to him a mockery of the relaxed, shielding hand of Titian's Venus. Likewise, the alert black cat at the foot of the bed strikes a sexually rebellious note in contrast to that of the sleeping dog in Titian's portrayal of the goddess in his \"Venus of Urbino\".\n\"Olympia\" was the subject of caricatures in the popular press, but was championed by the French avant-garde community, and the painting's significance was appreciated by artists such as Gustave Courbet, Paul C\u00e9zanne, Claude Monet, and later Paul Gauguin.\nAs with \"Luncheon on the Grass\", the painting raised the issue of prostitution within contemporary France and the roles of women within society.\nLife and times.\nAfter the death of his father in 1862, Manet married Suzanne Leenhoff in 1863 at a Protestant church. Leenhoff was a Dutch-born piano teacher two years Manet's senior with whom he had been romantically involved for approximately ten years. Leenhoff initially had been employed by Manet's father, Auguste, to teach Manet and his younger brother piano. She also may have been Auguste's mistress. In 1852, Leenhoff gave birth, out of wedlock, to a son, Leon Koella Leenhoff.\nManet painted his wife in \"The Reading\", among other paintings. Her son, Leon Leenhoff, whose father may have been either of the Manets, posed often for Manet. Most famously, he is the subject of the \"Boy Carrying a Sword\" of 1861 (Metropolitan Museum of Art, New York). He also appears as the boy carrying a tray in the background of \"The Balcony\" (1868\u201369).\nManet became friends with the Impressionists Edgar Degas, Claude Monet, Pierre-Auguste Renoir, Alfred Sisley, Paul C\u00e9zanne, and Camille Pissarro through another painter, Berthe Morisot, who was a member of the group and drew him into their activities. They later became widely known as the Batignolles group (Le groupe des Batignolles).\nThe supposed grand-niece of the painter Jean-Honor\u00e9 Fragonard, Morisot had her first painting accepted in the Salon de Paris in 1864, and she continued to show in the salon for the next ten years.\nManet became the friend and colleague of Morisot in 1868. She is credited with convincing Manet to attempt plein air painting, which she had been practicing since she was introduced to it by another friend of hers, Camille Corot. They had a reciprocating relationship and Manet incorporated some of her techniques into his paintings. In 1874, she became his sister-in-law when she married his brother, Eug\u00e8ne.\nUnlike the core Impressionist group, Manet maintained that modern artists should seek to exhibit at the Paris Salon rather than abandon it in favor of independent exhibitions. Nevertheless, when Manet was excluded from the International Exhibition of 1867, he set up his own exhibition. His mother worried that he would waste all his inheritance on this project, which was enormously expensive. While the exhibition earned poor reviews from the major critics, it also provided his first contacts with several future Impressionist painters, including Degas.\nAlthough his own work influenced and anticipated the Impressionist style, Manet resisted involvement in Impressionist exhibitions, partly because he did not wish to be seen as the representative of a group identity, and partly because he preferred to exhibit at the Salon. Eva Gonzal\u00e8s, a daughter of the novelist Emmanuel Gonzal\u00e8s, was his only formal student.\nHe was influenced by the Impressionists, especially Monet and Morisot. Their influence is seen in Manet's use of lighter colors: after the early 1870s he made less use of dark backgrounds but retained his distinctive use of black, uncharacteristic of Impressionist painting. He painted many outdoor (plein air) pieces, but always returned to what he considered the serious work of the studio.\nManet enjoyed a close friendship with composer Emmanuel Chabrier, painting two portraits of him; the musician owned 14 of Manet's paintings and dedicated his \"Impromptu\" to Manet's wife.\nOne of Manet's frequent models at the beginning of the 1880s was the \"semimondaine\" M\u00e9ry Laurent, who posed for seven portraits in pastel. Laurent's salons hosted many French (and even American) writers and painters of her time; Manet had connections and influence through such events.\nThroughout his life, although resisted by art critics, Manet could number as his champions \u00c9mile Zola, who supported him publicly in the press, St\u00e9phane Mallarm\u00e9, and Charles Baudelaire, who challenged him to depict life as it was. Manet, in turn, drew or painted each of them.\nCaf\u00e9 scenes.\nManet's paintings of caf\u00e9 scenes are observations of social life in 19th-century Paris. People are depicted drinking beer, listening to music, flirting, reading, or waiting. Many of these paintings were based on sketches executed on the spot. Manet often visited the Brasserie Reichshoffen on boulevard de Rochechourt, upon which he based \"At the Cafe\" in 1878. Several people are at the bar, and one woman confronts the viewer while others wait to be served. Such depictions represent the painted journal of a fl\u00e2neur. These are painted in a style which is loose, referencing Hals and Vel\u00e1zquez, yet they capture the mood and feeling of Parisian night life. They are painted snapshots of bohemianism, urban working people, as well as some of the bourgeoisie.\nIn \"Corner of a Caf\u00e9-Concert\", a man smokes while behind him a waitress serves drinks. In \"The Beer Drinkers\" a woman enjoys her beer in the company of a friend. In \"The Caf\u00e9-Concert\", shown at right, a sophisticated gentleman sits at a bar while a waitress stands resolutely in the background, sipping her drink. In \"The Waitress\", a serving woman pauses for a moment behind a seated customer smoking a pipe, while a ballet dancer, with arms extended as she is about to turn, is on stage in the background.\nManet also sat at the restaurant on the Avenue de Clichy called Pere Lathuille's, which had a garden in addition to the dining area. One of the paintings he produced here was \"Chez le p\u00e8re Lathuille\" (At Pere Lathuille's), in which a man displays an unrequited interest in a woman dining near him.\nIn \"Le Bon Bock\" (1873), a large, cheerful, bearded man sits with a pipe in one hand and a glass of beer in the other, looking straight at the viewer.\nPaintings of social activities.\nManet painted the upper class enjoying more formal social activities. In \"Masked Ball at the Opera\", Manet shows a lively crowd of people enjoying a party. Men stand with top hats and long black suits while talking to women with masks and costumes. He included portraits of his friends in this picture.\nHis 1868 painting \"The Luncheon\" was posed in the dining room of the Manet house.\nManet depicted other popular activities in his work. In \"The Races at Longchamp\", an unusual perspective is employed to underscore the furious energy of racehorses as they rush toward the viewer. In \"Skating\", Manet shows a well dressed woman in the foreground, while others skate behind her. Always there is the sense of active urban life continuing behind the subject, extending outside the frame of the canvas.\nIn \"View of the International Exhibition\", soldiers relax, seated and standing, prosperous couples are talking. There is a gardener, a boy with a dog, a woman on horseback\u2014in short, a sample of the classes and ages of the people of Paris.\nWar.\nManet's response to modern life included works devoted to war, in subjects that may be seen as updated interpretations of the genre of \"history painting\". The first such work was \"The Battle of the Kearsarge and the Alabama\" (1864), a sea skirmish known as the \"Battle of Cherbourg\" from the American Civil War which took place off the French coast, and may have been witnessed by the artist.\nOf interest next was the French intervention in Mexico; from 1867 to 1869 Manet painted three versions of the \"Execution of Emperor Maximilian\", an event which raised concerns regarding French foreign and domestic policy. The several versions of the \"Execution\" are among Manet's largest paintings, which suggests that the theme was one which the painter regarded as most important. Its subject is the execution by Mexican firing squad of a Habsburg emperor who had been installed by Napoleon III. Neither the paintings nor a lithograph of the subject were permitted to be shown in France. As an indictment of formalized slaughter, the paintings look back to Goya, and anticipate Picasso's \"Guernica\".\nIn January 1871, Manet traveled to Oloron-Sainte-Marie in the Pyrenees. In his absence his friends added his name to the \"F\u00e9d\u00e9ration des artistes\" (see: Courbet) of the Paris Commune. Manet stayed away from Paris, perhaps, until after the \"semaine sanglante\": in a letter to Berthe Morisot at Cherbourg (10 June 1871) he writes, \"We came back to Paris a few days ago...\" (the semaine sanglante ended on 28 May).\nThe prints and drawings collection of the Museum of Fine Arts (Budapest) has a watercolour/gouache by Manet, \"The Barricade\", depicting a summary execution of Communards by Versailles troops based on a lithograph of the execution of Maximilian. A similar piece, \"The Barricade\" (oil on plywood), is held by a private collector.\nOn 18 March 1871, he wrote to his (confederate) friend F\u00e9lix Bracquemond in Paris about his visit to Bordeaux, the provisional seat of the French National Assembly of the Third French Republic where \u00c9mile Zola introduced him to the sites: \"I never imagined that France could be represented by such doddering old fools, not excepting that little twit Thiers...\" If this could be interpreted as support of the Commune, a following letter to Bracquemond (21 March 1871) expressed his idea more clearly: \"Only party hacks and the ambitious, the Henrys of this world following on the heels of the Milli\u00e9res, the grotesque imitators of the Commune of 1793\". He knew the communard Lucien Henry to have been a former painter's model and Milli\u00e8re, an insurance agent. \"What an encouragement all these bloodthirsty caperings are for the arts! But there is at least one consolation in our misfortunes: that we're not politicians and have no desire to be elected as deputies\".\nThe public figure Manet admired most was the republican L\u00e9on Gambetta. In the heat of the \"seize mai\" coup in 1877, Manet opened up his atelier to a republican electoral meeting chaired by Gambetta's friend Eug\u00e8ne Spuller.\nParis.\nManet depicted many scenes of the streets of Paris in his works. \"The Rue Mosnier Decked with Flags\" depicts red, white, and blue pennants covering buildings on either side of the street; another painting of the same title features a one-legged man walking with crutches. Again depicting the same street, but this time in a different context, is \"Rue Mosnier with Pavers\", in which men repair the roadway while people and horses move past.\n\"The Railway\", widely known as \"The Gare Saint-Lazare\", was painted in 1873. The setting is the urban landscape of Paris in the late 19th century. Using his favorite model in his last painting of her, a fellow painter, Victorine Meurent, also the model for \"Olympia\" and the \"Luncheon on the Grass\", sits before an iron fence holding a sleeping puppy and an open book in her lap. Next to her is a little girl with her back to the painter, watching a train pass beneath them.\nInstead of choosing the traditional natural view as background for an outdoor scene, Manet opts for the iron grating which \"boldly stretches across the canvas\" The only evidence of the train is its white cloud of steam. In the distance, modern apartment buildings are seen. This arrangement compresses the foreground into a narrow focus. The traditional convention of deep space is ignored.\nHistorian Isabelle Dervaux has described the reception this painting received when it was first exhibited at the official Paris Salon of 1874: \"Visitors and critics found its subject baffling, its composition incoherent, and its execution sketchy. Caricaturists ridiculed Manet's picture, in which only a few recognized the symbol of modernity that it has become today\". The painting is currently in the National Gallery of Art in Washington, D.C.\nManet painted several boating subjects in 1874. \"Boating\", now in the Metropolitan Museum of Art, exemplifies in its conciseness the lessons Manet learned from Japanese prints, and the abrupt cropping by the frame of the boat and sail adds to the immediacy of the image.\nIn 1875, a book-length French edition of Edgar Allan Poe's \"The Raven\" included lithographs by Manet and translation by Mallarm\u00e9.\nIn 1881, with pressure from his friend Antonin Proust, the French government awarded Manet the L\u00e9gion d'honneur.\nLate works.\nIn his mid-forties Manet's health deteriorated, and he developed severe pain and partial paralysis in his legs. In 1879 he began receiving hydrotherapy treatments at a spa near Meudon intended to improve what he believed was a circulatory problem, but in reality he was suffering from locomotor ataxia, a known side-effect of syphilis. In 1880, he painted a portrait there of the opera singer \u00c9milie Ambre as Carmen. Ambre and her lover Gaston de Beauplan had an estate in Meudon and had organized the first exhibition of Manet's \"The Execution of Emperor Maximilian\" in New York in December 1879.\nIn his last years Manet painted many small-scale still lifes of fruits and vegetables, such as \"A\" \"Bunch of Asparagus\" and \"The Lemon\" (both 1880). He completed his last major work, \"A Bar at the Folies-Berg\u00e8re (Un Bar aux Folies-Berg\u00e8re)\", in 1882, and it hung in the Salon that year. Afterwards, he limited himself to small formats. His last paintings were of flowers in glass vases.\nDeath.\nIn April 1883, his left foot was amputated because of gangrene caused by complications from syphilis and rheumatism. He died eleven days later on 30 April in Paris. He is buried in the Passy Cemetery in the city.\nLegacy.\nManet's public career lasted from 1861, the year of his first participation in the Salon, until his death in 1883. His known extant works, as catalogued in 1975 by Denis Rouart and Daniel Wildenstein, comprise 430 oil paintings, 89 pastels, and more than 400 works on paper.\nAlthough harshly condemned by critics who decried its lack of conventional finish, Manet's work had admirers from the beginning. One was \u00c9mile Zola, who wrote in 1867: \"We are not accustomed to seeing such simple and direct translations of reality. Then, as I said, there is such a surprisingly elegant awkwardness ... it is a truly charming experience to contemplate this luminous and serious painting which interprets nature with a gentle brutality.\"\nThe roughly painted style and photographic lighting in Manet's paintings was seen as specifically modern, and as a challenge to the Renaissance works he copied or used as source material. He rejected the technique he had learned in the studio of Thomas Couture \u2013 in which a painting was constructed using successive layers of paint on a dark-toned ground \u2013 in favor of a direct, \"alla prima\" method using opaque paint on a light ground. Novel at the time, this method made possible the completion of a painting in a single sitting. It was adopted by the Impressionists, and became the prevalent method of painting in oils for generations that followed. Manet's work is considered \"early modern\", partially because of the opaque flatness of his surfaces, the frequent sketch-like passages, and the black outlining of figures, all of which draw attention to the surface of the picture plane and the material quality of paint.\nThe art historian Beatrice Farwell says Manet \"has been universally regarded as the Father of Modernism. With Courbet he was among the first to take serious risks with the public whose favour he sought, the first to make \"alla prima\" painting the standard technique for oil painting and one of the first to take liberties with Renaissance perspective and to offer \"pure painting\" as a source of aesthetic pleasure. He was a pioneer, again with Courbet, in the rejection of humanistic and historical subject-matter, and shared with Degas the establishment of modern urban life as acceptable material for high art.\"\nArt market.\nThe late Manet painting, \"Le Printemps\" (1881), sold to the J. Paul Getty Museum for $65.1 million, setting a new auction record for Manet, exceeding its pre-sale estimate of $25\u201335 million at Christie's on 5 November 2014. The previous auction record was held by \"Self-Portrait With Palette\" which sold for $33.2 million at Sotheby's on 22 June 2010.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9616", "revid": "36222423", "url": "https://en.wikipedia.org/wiki?curid=9616", "title": "Evolutionarily stable strategy", "text": "Solution concept in game theory\nAn evolutionarily stable strategy (ESS) is a strategy (or set of strategies) that is \"impermeable\" when adopted by a population in adaptation to a specific environment, that is to say it cannot be displaced by an alternative strategy (or set of strategies) which may be novel or initially rare. Introduced by John Maynard Smith and George R. Price in 1972/3, it is an important concept in behavioural ecology, evolutionary psychology, mathematical game theory and economics, with applications in other fields such as anthropology, philosophy and political science.\nIn game-theoretical terms, an ESS is an equilibrium refinement of the Nash equilibrium, being a Nash equilibrium that is also \"evolutionarily stable.\" Thus, once fixed in a population, natural selection alone is sufficient to prevent alternative (mutant) strategies from replacing it (although this does not preclude the possibility that a better strategy, or set of strategies, will emerge in response to selective pressures resulting from environmental change).\nHistory.\nEvolutionarily stable strategies were defined and introduced by John Maynard Smith and George R. Price in a 1973 \"Nature\" paper. Such was the time taken in peer-reviewing the paper for \"Nature\" that this was preceded by a 1972 essay by Maynard Smith in a book of essays titled \"On Evolution\". The 1972 essay is sometimes cited instead of the 1973 paper, but university libraries are much more likely to have copies of \"Nature\". Papers in \"Nature\" are usually short; in 1974, Maynard Smith published a longer paper in the \"Journal of Theoretical Biology\". Maynard Smith explains further in his 1982 book \"Evolution and the Theory of Games\". Sometimes these are cited instead. In fact, the ESS has become so central to game theory that often no citation is given, as the reader is assumed to be familiar with it.\nMaynard Smith mathematically formalised a verbal argument made by Price, which he read while peer-reviewing Price's paper. When Maynard Smith realized that the somewhat disorganised Price was not ready to revise his article for publication, he offered to add Price as co-author.\nThe concept was derived from R. H. MacArthur and W. D. Hamilton's work on sex ratios, derived from Fisher's principle, especially Hamilton's (1967) concept of an unbeatable strategy. Maynard Smith was jointly awarded the 1999 Crafoord Prize for his development of the concept of evolutionarily stable strategies and the application of game theory to the evolution of behaviour.\nUses of ESS:\nMotivation.\nThe Nash equilibrium is the traditional solution concept in game theory. It depends on the cognitive abilities of the players. It is assumed that players are aware of the structure of the game and consciously try to predict the moves of their opponents and to maximize their own payoffs. In addition, it is presumed that all the players know this (see common knowledge). These assumptions are then used to explain why players choose Nash equilibrium strategies.\nEvolutionarily stable strategies are motivated entirely differently. Here, it is presumed that the players' strategies are biologically encoded and heritable. Individuals have no control over their strategy and need not be aware of the game. They reproduce and are subject to the forces of natural selection, with the payoffs of the game representing reproductive success (biological fitness). It is imagined that alternative strategies of the game occasionally occur, via a process like mutation. To be an ESS, a strategy must be resistant to these alternatives.\nGiven the radically different motivating assumptions, it may come as a surprise that ESSes and Nash equilibria often coincide. In fact, every ESS corresponds to a Nash equilibrium, but some Nash equilibria are not ESSes.\nNash equilibrium.\nAn ESS is a refined or modified form of a Nash equilibrium. (See the next section for examples which contrast the two.) In a Nash equilibrium, if all players adopt their respective parts, no player can \"benefit\" by switching to any alternative strategy. In a two player game, it is a strategy pair. Let E(\"S\",\"T\") represent the payoff for playing strategy \"S\" against strategy \"T\". The strategy pair (\"S\", \"S\") is a Nash equilibrium in a two player game if and only if for both players, for any strategy \"T\":\nE(\"S\",\"S\") \u2265 E(\"T\",\"S\")\nIn this definition, a strategy \"T\"\u2260\"S\" can be a neutral alternative to \"S\" (scoring equally well, but not better). \nA Nash equilibrium is presumed to be stable even if \"T\" scores equally, on the assumption that there is no long-term incentive for players to adopt \"T\" instead of \"S\". This fact represents the point of departure of the ESS.\nMaynard Smith and Price specify two conditions for a strategy \"S\" to be an ESS. For all \"T\"\u2260\"S\", either\nThe first condition is sometimes called a \"strict\" Nash equilibrium. The second is sometimes called \"Maynard Smith's second condition\". The second condition means that although strategy \"T\" is neutral with respect to the payoff against strategy \"S\", the population of players who continue to play strategy \"S\" has an advantage when playing against \"T\".\nThere is also an alternative, stronger definition of ESS, due to Thomas. This places a different emphasis on the role of the Nash equilibrium concept in the ESS concept. Following the terminology given in the first definition above, this definition requires that for all \"T\"\u2260\"S\"\nIn this formulation, the first condition specifies that the strategy is a Nash equilibrium, and the second specifies that Maynard Smith's second condition is met. Note that the two definitions are not precisely equivalent: for example, each pure strategy in the coordination game below is an ESS by the first definition but not the second.\nIn words, this definition looks like this: The payoff of the first player when both players play strategy S is higher than (or equal to) the payoff of the first player when he changes to another strategy T and the second player keeps his strategy S \"and\" the payoff of the first player when only his opponent changes his strategy to T is higher than his payoff in case that both of players change their strategies to T.\nThis formulation more clearly highlights the role of the Nash equilibrium condition in the ESS. It also allows for a natural definition of related concepts such as a weak ESS or an evolutionarily stable set.\nExamples of differences between Nash equilibria and ESSes.\nIn most simple games, the ESSes and Nash equilibria coincide perfectly. For instance, in the prisoner's dilemma there is only one Nash equilibrium, and its strategy (\"Defect\") is also an ESS.\nSome games may have Nash equilibria that are not ESSes. For example, in harm thy neighbor (whose payoff matrix is shown here) both (\"A\", \"A\") and (\"B\", \"B\") are Nash equilibria, since players cannot do better by switching away from either. However, only \"B\" is an ESS (and a strong Nash). \"A\" is not an ESS, so \"B\" can neutrally invade a population of \"A\" strategists and predominate, because \"B\" scores higher against \"B\" than \"A\" does against \"B\". This dynamic is captured by Maynard Smith's second condition, since E(\"A\", \"A\") = E(\"B\", \"A\"), but it is not the case that E(\"A\",\"B\") &gt; E(\"B\",\"B\").\nNash equilibria with equally scoring alternatives can be ESSes. For example, in the game \"Harm everyone\", \"C\" is an ESS because it satisfies Maynard Smith's second condition. \"D\" strategists may temporarily invade a population of \"C\" strategists by scoring equally well against \"C\", but they pay a price when they begin to play against each other; \"C\" scores better against \"D\" than does \"D\". So here although E(\"C\", \"C\") = E(\"D\", \"C\"), it is also the case that E(\"C\",\"D\") &gt; E(\"D\",\"D\"). As a result, \"C\" is an ESS.\nEven if a game has pure strategy Nash equilibria, it might be that none of those pure strategies are ESS. Consider the Game of chicken. There are two pure strategy Nash equilibria in this game (\"Swerve\", \"Stay\") and (\"Stay\", \"Swerve\"). However, in the absence of an uncorrelated asymmetry, neither \"Swerve\" nor \"Stay\" are ESSes. There is a third Nash equilibrium, a mixed strategy which is an ESS for this game (see Hawk-dove game and Best response for explanation).\nThis last example points to an important difference between Nash equilibria and ESS. Nash equilibria are defined on \"strategy sets\" (a specification of a strategy for each player), while ESS are defined in terms of strategies themselves. The equilibria defined by ESS must always be symmetric, and thus have fewer equilibrium points.\nVs. evolutionarily stable state.\nIn population biology, the two concepts of an \"evolutionarily stable strategy\" (ESS) and an \"evolutionarily stable state\" are closely linked but describe different situations.\nIn an evolutionarily stable \"strategy,\" if all the members of a population adopt it, no mutant strategy can invade. Once virtually all members of the population use this strategy, there is no 'rational' alternative. ESS is part of classical game theory.\nIn an evolutionarily stable \"state,\" a population's genetic composition is restored by selection after a disturbance, if the disturbance is not too large. An evolutionarily stable state is a dynamic property of a population that returns to using a strategy, or mix of strategies, if it is perturbed from that initial state. It is part of population genetics, dynamical system, or evolutionary game theory. This is now called convergent stability.\nB. Thomas (1984) applies the term ESS to an individual strategy which may be mixed, and evolutionarily stable population state to a population mixture of pure strategies which may be formally equivalent to the mixed ESS.\nWhether a population is evolutionarily stable does not relate to its genetic diversity: it can be genetically monomorphic or polymorphic.\nStochastic ESS.\nIn the classic definition of an ESS, no mutant strategy can invade. In finite populations, any mutant could in principle invade, albeit at low probability, implying that no ESS can exist. In an infinite population, an ESS can instead be defined as a strategy which, should it become invaded by a new mutant strategy with probability p, would be able to counterinvade from a single starting individual with probability &gt;p, as illustrated by the evolution of bet-hedging.\nPrisoner's dilemma.\nA common model of altruism and social cooperation is the Prisoner's dilemma. Here a group of players would collectively be better off if they could play \"Cooperate\", but since \"Defect\" fares better each individual player has an incentive to play \"Defect\". One solution to this problem is to introduce the possibility of retaliation by having individuals play the game repeatedly against the same player. In the so-called \"iterated\" Prisoner's dilemma, the same two individuals play the prisoner's dilemma over and over. While the Prisoner's dilemma has only two strategies (\"Cooperate\" and \"Defect\"), the iterated Prisoner's dilemma has a huge number of possible strategies. Since an individual can have different contingency plan for each history and the game may be repeated an indefinite number of times, there may in fact be an infinite number of such contingency plans.\nThree simple contingency plans which have received substantial attention are \"Always Defect\", \"Always Cooperate\", and \"Tit for Tat\". The first two strategies do the same thing regardless of the other player's actions, while the latter responds on the next round by doing what was done to it on the previous round\u2014it responds to \"Cooperate\" with \"Cooperate\" and \"Defect\" with \"Defect\".\nIf the entire population plays \"Tit-for-Tat\" and a mutant arises who plays \"Always Defect\", \"Tit-for-Tat\" will outperform \"Always Defect\". If the population of the mutant becomes too large \u2014 the percentage of the mutant will be kept small. \"Tit for Tat\" is therefore an ESS, \"with respect to only these two strategies\". On the other hand, an island of \"Always Defect\" players will be stable against the invasion of a few \"Tit-for-Tat\" players, but not against a large number of them. If we introduce \"Always Cooperate\", a population of \"Tit-for-Tat\" is no longer an ESS. Since a population of \"Tit-for-Tat\" players always cooperates, the strategy \"Always Cooperate\" behaves identically in this population. As a result, a mutant who plays \"Always Cooperate\" will not be eliminated. However, even though a population of \"Always Cooperate\" and \"Tit-for-Tat\" can coexist, if there is a small percentage of the population that is \"Always Defect\", the selective pressure is against \"Always Cooperate\", and in favour of \"Tit-for-Tat\". This is due to the lower payoffs of cooperating than those of defecting in case the opponent defects.\nThis demonstrates the difficulties in applying the formal definition of an ESS to games with large strategy spaces, and has motivated some to consider alternatives.\nHuman behavior.\nThe fields of sociobiology and evolutionary psychology attempt to explain animal and human behavior and social structures, largely in terms of evolutionarily stable strategies. Sociopathy (chronic antisocial or criminal behavior) may be a result of a combination of two such strategies.\nEvolutionarily stable strategies were originally considered for biological evolution, but they can apply to other contexts. In fact, there are stable states for a large class of adaptive dynamics. As a result, they can be used to explain human behaviours that lack any genetic influences.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9617", "revid": "19089174", "url": "https://en.wikipedia.org/wiki?curid=9617", "title": "Element", "text": "Element or elements may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "9618", "revid": "644038553", "url": "https://en.wikipedia.org/wiki?curid=9618", "title": "Emission line", "text": ""}
{"id": "9619", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=9619", "title": "Extremophile", "text": "Organisms capable of living in extreme environments\nAn extremophile (from Latin ' meaning \"extreme\" and Greek ' () meaning \"love\") is an organism that is able to live (or in some cases thrive) in extreme environments, i.e. environments with conditions approaching or expanding the limits of what known life can adapt to, such as extreme temperature, radiation, salinity, or pH level.\nSince the definition of an extreme environment is relative to an arbitrarily defined standard, often an anthropocentric one, these organisms can be considered ecologically dominant in the evolutionary history of the planet. Some spores and cocooned bacteria samples have been dormant for more than 40 million years, extremophiles have continued to thrive in the most extreme conditions, making them one of the most abundant lifeforms. The study of extremophiles has expanded human knowledge of the limits of life, and informs speculation about extraterrestrial life. Extremophiles are also of interest because of their potential for bioremediation of environments made hazardous to humans due to pollution or contamination.\nCharacteristics.\nIn the 1980s and 1990s, biologists found that microbial life has great flexibility for surviving in extreme environments\u2014niches that are acidic, extraordinarily hot or within irregular air pressure for example\u2014that would be completely inhospitable to complex organisms. Some scientists even concluded that life may have begun on Earth in hydrothermal vents far under the ocean's surface.\nAccording to astrophysicist Steinn Sigurdsson, \"There are viable bacterial spores that have been found that are 40 million years old on Earth\u2014and we know they're very hardened to radiation.\" Some bacteria were found living in the cold and dark in a lake buried a half-mile deep under the ice in Antarctica, and in the Marianas Trench, the deepest place in Earth's oceans. Expeditions of the International Ocean Discovery Program found microorganisms in sediment that is below seafloor in the Nankai Trough subduction zone. Some microorganisms have been found thriving inside rocks up to below the sea floor under of ocean off the coast of the northwestern United States. According to one of the researchers, \"You can find microbes everywhere\u2014they're extremely adaptable to conditions, and survive wherever they are.\" A key to extremophile adaptation is their amino acid composition, affecting their protein folding ability under particular conditions. Studying extreme environments on Earth can help researchers understand the limits of habitability on other worlds.\nTom Gheysens from Ghent University in Belgium and some of his colleagues have presented research findings that show spores from a species of Bacillus bacteria survived and were still viable after being heated to temperatures of .\nClassifications.\nThere are many classes of extremophiles that range all around the globe; each corresponding to the way its environmental niche differs from mesophilic conditions. These classifications are not exclusive. Many extremophiles fall under multiple categories and are classified as polyextremophiles. For example, organisms living inside hot rocks deep under Earth's surface are thermophilic and piezophilic such as \"Thermococcus barophilus\". A polyextremophile living at the summit of a mountain in the Atacama Desert might be a radioresistant xerophile, a psychrophile, and an oligotroph. Polyextremophiles are well known for their ability to tolerate both high and low pH levels.\nAn organism that lives in microscopic spaces within rocks, such as pores between aggregate grains. These may also be called endolith, a term that also includes organisms populating fissures, aquifers, and faults filled with groundwater in the deep subsurface.\nIn astrobiology.\nAstrobiology is the multidisciplinary field that investigates the deterministic conditions and contingent events with which life arises, distributes, and evolves in the universe. Astrobiology makes use of physics, chemistry, astronomy, solar physics, biology, molecular biology, ecology, planetary science, geography, and geology to investigate the possibility of life on other worlds and help recognize biospheres that might be different from that on Earth. Astrobiologists are particularly interested in studying extremophiles, as it allows them to map what is known about the limits of life on Earth to potential extraterrestrial environments For example, analogous deserts of Antarctica are exposed to harmful UV radiation, low temperature, high salt concentration and low mineral concentration. These conditions are similar to those on Mars. Therefore, finding viable microbes in the subsurface of Antarctica suggests that there may be microbes surviving in endolithic communities and living under the Martian surface. Research indicates it is unlikely that Martian microbes exist on the surface or at shallow depths, but may be found at subsurface depths of around 100 meters.\nRecent research carried out on extremophiles in Japan involved a variety of bacteria including \"Escherichia coli\" and \"Paracoccus denitrificans\" being subject to conditions of extreme gravity. The bacteria were cultivated while being rotated in an ultracentrifuge at high speeds corresponding to 403,627 g (i.e. 403,627 times the gravity experienced on Earth). \"P.\u00a0denitrificans\" was one of the bacteria which displayed not only survival but also robust cellular growth under these conditions of hyperacceleration which are usually found only in cosmic environments, such as on very massive stars or in the shock waves of supernovas. Analysis showed that the small size of prokaryotic cells is essential for successful growth under hypergravity. The research has implications on the feasibility of panspermia.\nOn 26 April 2012, scientists reported that lichen survived and showed remarkable results on the adaptation capacity of photosynthetic activity within the simulation time of 34 days under Martian conditions in the Mars Simulation Laboratory (MSL) maintained by the German Aerospace Center (DLR).\nOn 29 April 2013, scientists at Rensselaer Polytechnic Institute, funded by NASA, reported that, during spaceflight on the International Space Station, microbes seem to adapt to the space environment in ways \"not observed on Earth\" and in ways that \"can lead to increases in growth and virulence\".\nOn 19 May 2014, scientists announced that numerous microbes, like \"Tersicoccus phoenicis\", may be resistant to methods usually used in spacecraft assembly clean rooms. It is not currently known if such resistant microbes could have withstood space travel and are present on the \"Curiosity\" rover now on the planet Mars.\nOn 20 August 2014, scientists confirmed the existence of microorganisms living half a mile below the ice of Antarctica.\nIn September 2015, scientists from CNR-National Research Council of Italy reported that \"S.\u00a0soflataricus\" was able to survive under Martian radiation at a wavelength that was considered extremely lethal to most bacteria. This discovery is significant because it indicates that not only bacterial spores, but also growing cells can be remarkably resistant to strong UV radiation.\nIn June 2016, scientists from Brigham Young University conclusively reported that endospores of \"Bacillus subtilis\" were able to survive high speed impacts up to 299\u00b128\u00a0m/s, extreme shock, and extreme deceleration. They pointed out that this feature might allow endospores to survive and to be transferred between planets by traveling within meteorites or by experiencing atmosphere disruption. Moreover, they suggested that the landing of spacecraft may also result in interplanetary spore transfer, given that spores can survive high-velocity impact while ejected from the spacecraft onto the planet surface. This is the first study which reported that bacteria can survive in such high-velocity impact. However, the lethal impact speed is unknown, and further experiments should be done by introducing higher-velocity impact to bacterial endospores.\nIn August 2020 scientists reported that bacteria that feed on air discovered 2017 in Antarctica are likely not limited to Antarctica after discovering the two genes previously linked to their \"atmospheric chemosynthesis\" in soil of two other similar cold desert sites, which provides further information on this carbon sink and further strengthens the extremophile evidence that supports the potential existence of microbial life on alien planets.\nThe same month, scientists reported that bacteria from Earth, particularly \"Deinococcus radiodurans\", were found to survive for three years in outer space, based on studies on the International Space Station. These findings support the notion of panspermia.\nBioremediation.\nExtremophiles can also be useful players in the bioremediation of contaminated sites as some species are capable of biodegradation under conditions too extreme for classic bioremediation candidate species. Anthropogenic activity causes the release of pollutants that may potentially settle in extreme environments as is the case with tailings and sediment released from deep-sea mining activity. While most bacteria would be crushed by the pressure in these environments, piezophiles can tolerate these depths and can metabolize pollutants of concern if they possess bioremediation potential.\nHydrocarbons.\nThere are multiple potential destinations for hydrocarbons after an oil spill has settled and currents routinely deposit them in extreme environments. Methane bubbles resulting from the Deepwater Horizon oil spill were found 1.1 kilometers below water surface level and at concentrations as high as 183 \"\u03bc\"mol per kilogram. The combination of low temperatures and high pressures in this environment result in low microbial activity. However, bacteria that are present including species of \"Pseudomonas\", \"Aeromonas\" and \"Vibrio\" were found to be capable of bioremediation, albeit at a tenth of the speed they would perform at sea level pressure. Polycyclic aromatic hydrocarbons increase in solubility and bioavailability with increasing temperature. Thermophilic \"Thermus\" and \"Bacillus\" species have demonstrated higher gene expression for the alkane mono-oxygenase \"alkB\" at temperatures exceeding . The expression of this gene is a crucial precursor to the bioremediation process. Fungi that have been genetically modified with cold-adapted enzymes to tolerate differing pH levels and temperatures have been shown to be effective at remediating hydrocarbon contamination in freezing conditions in the Antarctic.\nMetals.\n\"Acidithiubacillus ferroxidans\" has been shown to be effective in remediating mercury in acidic soil due to its \"merA\" gene making it mercury resistant. Industrial effluent contain high levels of metals that can be detrimental to both human and ecosystem health. In extreme heat environments the extremophile \"Geobacillus thermodenitrificans\" has been shown to effectively manage the concentration of these metals within twelve hours of introduction. Some acidophilic microorganisms are effective at metal remediation in acidic environments due to proteins found in their periplasm, not present in any mesophilic organisms, allowing them to protect themselves from high proton concentrations. Rice paddies are highly oxidative environments that can produce high levels of lead or cadmium. \"Deinococcus radiodurans\" are resistant to the harsh conditions of the environment and are therefore candidate species for limiting the extent of contamination of these metals.\nSome bacteria are known to also use rare earth elements on their biological processes for example Methylacidiphilum fumariolicum, Methylorubrum extorquens and Methylobacterium radiotolerans are known to be able to use lanthanides as cofactors to increase their methanol dehydrogenase activity.\nAcid mine drainage.\nAcid mine drainage is a major environmental concern associated with many metal mines. One of the most productive methods of its remediation is through the introduction of the extremophile organism \"Thiobacillus ferrooxidans.\"\nRadioactive materials.\nAny bacteria capable of inhabiting radioactive mediums can be classified as an extremophile. Radioresistant organisms are therefore critical in the bioremediation of radionuclides. Uranium is particularly challenging to contain when released into an environment and very harmful to both human and ecosystem health. The NANOBINDERS project is equipping bacteria that can survive in uranium rich environments with gene sequences that enable proteins to bind to uranium in mining effluent, making it more convenient to collect and dispose of. Some examples are \"Shewanella putrefaciens\", \"Geobacter metallireducens\" and some strains of \"Burkholderia fungorum.\"\nRadiotrophic fungus, which use radiation as an energy source have been found inside and around the Chernobyl Nuclear Power Plant.\nRadioresistance has also been observed in certain species of macroscopic lifeforms. The lethal dose required to kill up to 50% of a tortoise population is 40,000 roentgens, compared to only 800 roentgens needed to kill 50% of a human population. In experiments exposing lepidopteran insects to gamma radiation, significant DNA damage was detected only at 20\"\u00a0\"Gy and higher doses, in contrast with human cells that showed similar damage at only 2\"\u00a0\"Gy.\nExamples and recent findings.\nNew sub-types of extremophiles are identified frequently and the sub-category list for extremophiles is always growing. For example, microbial life lives in the liquid asphalt lake, Pitch Lake. Research indicates that extremophiles inhabit the asphalt lake in populations ranging between 106 and 107 cells/gram. Likewise, until recently boron tolerance was unknown but a strong borophile was discovered in bacteria. With the recent isolation of \"Bacillus boroniphilus\", borophiles came into discussion. Studying these borophiles may help illuminate the mechanisms of both boron toxicity and boron deficiency.\nIn July 2019, a scientific study of Kidd Mine in Canada discovered sulfur-breathing organisms which live below the surface, and which breathe sulfur in order to survive. These organisms are also remarkable due to eating rocks such as pyrite as their regular food source.\nBiotechnology.\nThe thermoalkaliphilic catalase, which initiates the breakdown of hydrogen peroxide into oxygen and water, was isolated from an organism, \"Thermus brockianus\", found in Yellowstone National Park by Idaho National Laboratory researchers. The catalase operates over a temperature range from 30\u00a0\u00b0C to over 94\u00a0\u00b0C and a pH range from 6\u201310. This catalase is extremely stable compared to other catalases at high temperatures and pH. In a comparative study, the \"T. brockianus\" catalase exhibited a half life of 15 days at 80\u00a0\u00b0C and pH 10 while a catalase derived from \"Aspergillus niger\" had a half life of 15 seconds under the same conditions. The catalase will have applications for removal of hydrogen peroxide in industrial processes such as pulp and paper bleaching, textile bleaching, food pasteurization, and surface decontamination of food packaging.\nDNA modifying enzymes such as \"Taq\" DNA polymerase and some \"Bacillus\" enzymes used in clinical diagnostics and starch liquefaction are produced commercially by several biotechnology companies.\nDNA transfer.\nOver 65 prokaryotic species are known to be naturally competent for genetic transformation, the ability to transfer DNA from one cell to another cell followed by integration of the donor DNA into the recipient cell's chromosome. Several extremophiles are able to carry out species-specific DNA transfer, as described below. However, it is not yet clear how common such a capability is among extremophiles.\nThe bacterium \"Deinococcus radiodurans\" is one of the most radioresistant organisms known. This bacterium can also survive cold, dehydration, vacuum and acid and is thus known as a polyextremophile. \"D.\u00a0radiodurans\" is competent to perform genetic transformation. Recipient cells are able to repair DNA damage in donor transforming DNA that had been UV irradiated as efficiently as they repair cellular DNA when the cells themselves are irradiated. The extreme thermophilic bacterium \"Thermus thermophilus\" and other related \"Thermus\" species are also capable of genetic transformation.\n\"Halobacterium volcanii\", an extreme halophilic (saline tolerant) archaeon, is capable of natural genetic transformation. Cytoplasmic bridges are formed between cells that appear to be used for DNA transfer from one cell to another in either direction.\n\"Sulfolobus solfataricus\" and \"Sulfolobus acidocaldarius\" are hyperthermophilic archaea. Exposure of these organisms to the DNA damaging agents UV irradiation, bleomycin or mitomycin C induces species-specific cellular aggregation. UV-induced cellular aggregation of \"S. acidocaldarius\" mediates chromosomal marker exchange with high frequency. Recombination rates exceed those of uninduced cultures by up to three orders of magnitude. Frols et al. and Ajon et al. hypothesized that cellular aggregation enhances species-specific DNA transfer between \"Sulfolobus\" cells in order to repair damaged DNA by means of homologous recombination. Van Wolferen et al. noted that this DNA exchange process may be crucial under DNA damaging conditions such as high temperatures. It has also been suggested that DNA transfer in \"Sulfolobus\" may be an early form of sexual interaction similar to the more well-studied bacterial transformation systems that involve species-specific DNA transfer leading to homologous recombinational repair of DNA damage (and see Transformation (genetics)).\nExtracellular membrane vesicles (MVs) might be involved in DNA transfer between different hyperthermophilic archaeal species. It has been shown that both plasmids and viral genomes can be transferred via MVs. Notably, a horizontal plasmid transfer has been documented between hyperthermophilic \"Thermococcus\" and \"Methanocaldococcus\" species, respectively belonging to the orders \"Thermococcales\" and \"Methanococcales\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9620", "revid": "12023796", "url": "https://en.wikipedia.org/wiki?curid=9620", "title": "Education reform", "text": "Changing how people are taught, especially on a mass scale\nEducation reform is the name given to the goal of changing public education. The meaning and education methods have changed through debates over what content or experiences result in an educated individual or an educated society. Historically, the motivations for reform have not reflected the current needs of society. A consistent theme of reform includes the idea that large systematic changes to educational standards will produce social returns in citizens' health, wealth, and well-being.\nAs part of the broader social and political processes, the term education reform refers to the chronology of significant, systematic revisions made to amend the educational legislation, standards, methodology, and policy affecting a nation's public school system to reflect the needs and values of contemporary society. 18th century, classical education instruction from an in-home personal tutor, hired at the family's expense, was primarily a privilege for children from wealthy families. Innovations such as encyclopedias, public libraries, and grammar schools all aimed to relieve some of the financial burden associated with the expenses of the classical education model. Motivations during the Victorian era emphasized the importance of self-improvement. Victorian education focused on teaching commercially valuable topics, such as modern languages and mathematics, rather than classical liberal arts subjects, such as Latin, art, and history.\nMotivations for education reformists like Horace Mann and his proponents focused on making schooling more accessible and developing a robust state-supported common school system. John Dewey, an early 20th-century reformer, focused on improving society by advocating for a scientific, pragmatic, or democratic principle-based curriculum. Whereas Maria Montessori incorporated humanistic motivations to \"meet the needs of the child\". In historic Prussia, a motivation to foster national unity led to formal education concentrated on teaching national language literacy to young children, resulting in Kindergarten.\nThe history of educational pedagogy in the United States has ranged from teaching literacy and proficiency of religious doctrine to establishing cultural literacy, assimilating immigrants into a democratic society, producing a skilled labor force for the industrialized workplace, preparing students for careers, and competing in a global marketplace. Education inequality is also a motivation for education reform, seeking to address problems of a community.\nMotivations for education reform.\nEducation reform, in general, implies a continual effort to modify and improve the institution of education. Over time, as the needs and values of society change, attitudes towards public education change. As a social institution, education plays an integral role in the process of socialization. \"Socialization is broadly composed of distinct inter- and intra-generational processes. Both involve the harmonization of an individual's attitudes and behaviors with that of their socio-cultural milieu.\" Educational matrices mean to reinforce those socially acceptable informal and formal norms, values, and beliefs that individuals need to learn in order to be accepted as good, functioning, and productive members of their society. Education reform is the process of constantly renegotiating and restructuring the educational standards to reflect the ever-evolving contemporary ideals of social, economic, and political culture. Reforms can be based on bringing education into alignment with a society's core values. Reforms that attempt to change a society's core values can connect alternative education initiatives with a network of other alternative institutions.\nEducation reform has been pursued for a variety of specific reasons, but generally most reforms aim at redressing some societal ills, such as poverty-, gender-, or class-based inequities, or perceived ineffectiveness. Current education trends in the United States represent multiple achievement gaps across ethnicities, income levels, and geographies. As McKinsey and Company reported in a 2009 analysis, \"These educational gaps impose on the United States the economic equivalent of a permanent national recession.\" Reforms are usually proposed by thinkers who aim to redress societal ills or institute societal changes, most often through a change in the education of the members of a class of people\u2014the preparation of a ruling class to rule or a working class to work, the social hygiene of a lower or immigrant class, the preparation of citizens in a democracy or republic, etc. The idea that all children should be provided with a high level of education is a relatively recent idea, and has arisen largely in the context of Western democracy in the 20th century.\nThe \"beliefs\" of school districts are optimistic that quite literally \"all students will succeed\", which in the context of high school graduation examination in the United States, all students in all groups, regardless of heritage or income will pass tests that in the introduction typically fall beyond the ability of all but the top 20 to 30 percent of students. The claims clearly renounce historical research that shows that all ethnic and income groups score differently on all standardized tests and standards based assessments and that students will achieve on a bell curve. Instead, education officials across the world believe that by setting clear, achievable, higher standards, aligning the curriculum, and assessing outcomes, learning can be increased for all students, and more students can succeed than the 50 percent who are defined to be above or below grade level by norm referenced standards.\nStates have tried to use state schools to increase state power, especially to make better soldiers and workers. This strategy was first adopted to unify related linguistic groups in Europe, including France, Germany and Italy. Exact mechanisms are unclear, but it often fails in areas where populations are culturally segregated, as when the U.S. Indian school service failed to suppress Lakota and Navaho, or when a culture has widely respected autonomous cultural institutions, as when the Spanish failed to suppress Catalan.\nMany students of democracy have desired to improve education in order to improve the quality of governance in democratic societies; the necessity of good public education follows logically if one believes that the quality of democratic governance depends on the ability of citizens to make informed, intelligent choices, and that education can improve these abilities.\nPolitically motivated educational reforms of the democratic type are recorded as far back as Plato in \"The Republic\". In the United States, this lineage of democratic education reform was continued by Thomas Jefferson, who advocated ambitious reforms partly along Platonic lines for public schooling in Virginia.\nAnother motivation for reform is the desire to address socio-economic problems, which many people see as having significant roots in lack of education. Starting in the 20th century, people have attempted to argue that small improvements in education can have large returns in such areas as health, wealth and well-being. For example, in Kerala, India in the 1950s, increases in women's health were correlated with increases in female literacy rates. In Iran, increased primary education was correlated with increased farming efficiencies and income. In both cases some researchers have concluded these correlations as representing an underlying causal relationship: education causes socio-economic benefits. In the case of Iran, researchers concluded that the improvements were due to farmers gaining reliable access to national crop prices and scientific farming information.\nHistory.\nClassical education.\nAs taught from the 18th to the 19th century, Western classical education curriculums focused on concrete details like \"Who?\", \"What?\", \"When?\", \"Where?\". Unless carefully taught, large group instruction naturally neglects asking the theoretical \"Why?\" and \"Which?\" questions that can be discussed in smaller groups.\nClassical education in this period also did not teach local (vernacular) languages and culture. Instead, it taught high-status ancient languages (Greek and Latin) and their cultures. This produced odd social effects in which an intellectual class might be more loyal to ancient cultures and institutions than to their native vernacular languages and their actual governing authorities.\n18th century.\nChild-study.\nJean-Jacques Rousseau, father of the Child Study Movement, centered the child as an object of study.\nIn \"\", Rousseau's principal work on education lays out an educational program for a hypothetical newborn's education through adulthood.\nRousseau provided a dual critique of the educational vision outlined in Plato's Republic and that of his society in contemporary Europe. He regarded the educational methods contributing to the child's development; he held that a person could either be a man or a citizen. While Plato's plan could have brought the latter at the expense of the former, contemporary education failed at both tasks. He advocated a radical withdrawal of the child from society and an educational process that utilized the child's natural potential and curiosity, teaching the child by confronting them with simulated real-life obstacles and conditioning the child through experience rather intellectual instruction.\nRousseau ideas were rarely implemented directly, but influenced later thinkers, particularly Johann Heinrich Pestalozzi and Friedrich Wilhelm August Fr\u00f6bel, the inventor of the kindergarten.\nNational identity.\nEuropean and Asian nations regard education as essential to maintaining national, cultural, and linguistic unity. In the late 18th century (~1779), Prussia instituted primary school reforms expressly to teach a unified version of the national language, \"Hochdeutsch\".\nOne significant reform was kindergarten whose purpose was to have the children participate in supervised activities taught by instructors who spoke the national language. The concept embraced the idea that children absorb new language skills more easily and quickly when they are young\nThe current model of kindergarten is reflective of the Prussian model.\nIn other countries, such as the Soviet Union, France, Spain, and Germany, the Prussian model has dramatically improved reading and math test scores for linguistic minorities.\n19th century England.\nIn the 19th century, before the advent of government-funded public schools, Protestant organizations established Charity Schools to educate the lower social classes. The Roman Catholic Church and governments later adopted the model.\nDesigned to be inexpensive, Charity schools operated on minimal budgets and strived to serve as many needy children as possible. This led to the development of grammar schools, which primarily focused on teaching literacy, grammar, and bookkeeping skills so that the students could use books as an inexpensive resource to continue their education. \"Grammar\" was the first third of the then-prevalent system of classical education..\nEducators Joseph Lancaster and Andrew Bell developed the monitorial system, also known as \"mutual instruction\" or the \"Bell\u2013Lancaster method\". Their contemporary, educationalist and writer Elizabeth Hamilton, suggested that in some important aspects the method had been \"anticipated\" by the Belfast schoolmaster David Manson. In the 1760s Manson had developed a peer-teaching and monitoring system within the context of what he called a \"play school\" that dispensed with \"the discipline of the rod\". (More radically, Manson proposed the \"liberty of each [child] to take the quantity [of lessons] agreeable to his inclination\").\nLancaster, an impoverished Quaker during the early 19th century in London and Bell at the Madras School of India developed this model independent of one another. However, by design, their model utilizes more advanced students as a resource to teach the less advanced students; achieving student-teacher ratios as small as 1:2 and educating more than 1000 students per adult. The lack of adult supervision at the Lancaster school resulted in the older children acting as disciplinary monitors and taskmasters.\nTo provide order and promote discipline the school implemented a unique internal economic system, inventing a currency called a \"Scrip.\" Although the currency was worthless in the outside world, it was created at a fixed exchange rate from a student's tuition and student's could use scrip to buy food, school supplies, books, and other items from the school store. Students could earn scrip through tutoring. To promote discipline, the school adopted a work-study model. Every job of the school was bid-for by students, with the largest bid winning. However, any student tutor could auction positions in his or her classes to earn scrip. The bids for student jobs paid for the adult supervision.\nLancaster promoted his system in a piece called Improvements in Education that spread widely throughout the English-speaking world. Lancaster schools provided a grammar-school education with fully developed internal economies for a cost per student near $40 per year in 1999 U.S. dollars. To reduce cost and motivated to save up scrip, Lancaster students rented individual pages of textbooks from the school library instead of purchasing the textbook. Student's would read aloud their pages to groups. Students commonly exchanged tutoring and paid for items and services with receipts from \"down tutoring\".\nThe schools did not teach submission to orthodox Christian beliefs or government authorities. As a result, most English-speaking countries developed mandatory publicly paid education explicitly to keep public education in \"responsible\" hands. These elites said that Lancaster schools might become dishonest, provide poor education, and were not accountable to established authorities. Lancaster's supporters responded that any child could cheat given the opportunity, and that the government was not paying for the education and thus deserved no say in their composition.\nThough motivated by charity, Lancaster claimed in his pamphlets to be surprised to find that he lived well on the income of his school, even while the low costs made it available to the most impoverished street children. Ironically, Lancaster lived on the charity of friends in his later life.\nModern reformist.\nAlthough educational reform occurred on a local level at various points throughout history, the modern notion of education reform is tied with the spread of compulsory education. Economic growth and the spread of democracy raised the value of education and increased the importance of ensuring that all children and adults have access to free, high-quality, effective education. Modern education reforms are increasingly driven by a growing understanding of what works in education and how to go about successfully improving teaching and learning in schools. However, in some cases, the reformers' goals of \"high-quality education\" has meant \"high-intensity education\", with a narrow emphasis on teaching individual, test-friendly subskills quickly, regardless of long-term outcomes, developmental appropriateness, or broader educational goals.\nHorace Mann.\nIn the United States, Horace Mann (1796 \u2013 1859) of Massachusetts used his political base and role as Secretary of the Massachusetts State Board of Education to promote public education in his home state and nationwide. Advocating a substantial public investment be made in education, Mann and his proponents developed a strong system of state supported common schools..\nHis crusading style attracted wide middle class support. Historian Ellwood P. Cubberley asserts:\n No one did more than he to establish in the minds of the American people the conception that education should be universal, non-sectarian, free, and that its aims should be social efficiency, civic virtue, and character, rather than mere learning or the advancement of sectarian ends.\nIn 1852, Massachusetts passed a law making education mandatory. This model of free, accessible education spread throughout the country and in 1917 Mississippi was the final state to adopt the law.\nJohn Dewey.\nJohn Dewey, a philosopher and educator based in Chicago and New York, helped conceptualize the role of American and international education during the first four decades of the 20th century. An important member of the American Pragmatist movement, he carried the subordination of knowledge to action into the educational world by arguing for experiential education that would enable children to learn theory and practice simultaneously; a well-known example is the practice of teaching elementary physics and biology to students while preparing a meal. He was a harsh critic of \"dead\" knowledge disconnected from practical human life.\nDewey criticized the rigidity and volume of humanistic education, and the emotional idealizations of education based on the child-study movement that had been inspired by Rousseau and those who followed him. Dewey understood that children are naturally active and curious and learn by doing. Dewey's understanding of logic is presented in his work \"Logic, the Theory of Inquiry\" (1938). His educational philosophies were presented in \"My Pedagogic Creed\", \"The School and Society\", \"The Child and Curriculum\", and \"Democracy and Education\" (1916). Bertrand Russell criticized Dewey's conception of logic, saying \"What he calls \"logic\" does not seem to me to be part of logic at all; I should call it part of psychology.\"\nDewey left the University of Chicago in 1904 over issues relating to the Dewey School.\nDewey's influence began to decline in the time after the Second World War and particularly in the Cold War era, as more conservative educational policies came to the fore.\nAdministrative progressives.\nThe form of educational progressivism which was most successful in having its policies implemented has been dubbed \"administrative progressivism\" by historians. This began to be implemented in the early 20th century. While influenced particularly in its rhetoric by Dewey and even more by his popularizers, administrative progressivism was in its practice much more influenced by the Industrial Revolution and the concept economies of scale.\nThe administrative progressives are responsible for many features of modern American education, especially American high schools: counseling programs, the move from many small local high schools to large centralized high schools, curricular differentiation in the form of electives and tracking, curricular, professional, and other forms of standardization, and an increase in state and federal regulation and bureaucracy, with a corresponding reduction of local control at the school board level. (Cf. \"State, federal, and local control of education in the United States\", below) (Tyack and Cuban, pp.\u00a017\u201326)\nThese reforms have since become heavily entrenched, and many today who identify themselves as progressives are opposed to many of them, while conservative education reform during the Cold War embraced them as a framework for strengthening traditional curriculum and standards.\nMore recent methods, instituted by groups such as the think tank Reform's education division, and S.E.R. have attempted to pressure the government of the U.K. into more modernist educational reform, though this has met with limited success.\nPublic school reform in the United States.\nIn the United States, public education is characterized as \"any federally funded primary or secondary school, administered to some extent by the government, and charged with educating all citizens. Although there is typically a cost to attend some public higher education institutions, they are still considered part of public education.\"\nColonial America.\nIn what would become the United States, the first public school was established in Boston, Massachusetts, on April 23, 1635. Puritan schoolmaster Philemon Pormont led instruction at the Boston Latin School. During this time, post-secondary education was a commonly utilized tool to distinguish one's social class and social status. Access to education was the \"privilege of white, upper-class, Christian male children\" in preparation for university education in ministry.\nIn colonial America, to maintain Puritan religious traditions, formal and informal education instruction focused on teaching literacy. All colonists needed to understand the written language on some fundamental level in order to read the Bible and the colony's written secular laws. Religious leaders recognized that each person should be \"educated enough to meet the individual needs of their station in life and social harmony.\" The first compulsory education laws were passed in Massachusetts between 1642 and 1648 when religious leaders noticed not all parents were providing their children with \"proper\" education. These laws stated that all towns with 50 or more families were obligated to hire a schoolmaster to teach children reading, writing, and basic arithmetic.\"In 1642 the General Court passed a law that required heads of households to teach all their dependents \u2014 apprentices and servants as well as their own children \u2014 to read English or face a fine. Parents could provide the instruction themselves or hire someone else to do it. Selectmen were to keep 'a vigilant eye over their brethren and neighbors,' young people whose education was neglected could be removed from their parents or masters.\"The 1647 law eventually led to establishing publicly funded district schools in all Massachusetts towns, although, despite the threat of fines, compliance and quality of public schools were less than satisfactory.\"Many towns were 'shamefully neglectful' of children's education. In 1718 '...by sad experience, it is found that many towns that not only are obliged by law, but are very able to support a grammar school, yet choose rather to incur and pay the fine or penalty than maintain a grammar school.\"When John Adams drafted the Massachusetts Constitution in 1780, he included provisions for a comprehensive education law that guaranteed public education to \"all\" citizens. However, access to formal education in secondary schools and colleges was reserved for free, white males. During the 17th and 18th centuries, females received little or no formal education except for home learning or attending Dame Schools. Likewise, many educational institutions maintained a policy of refusing to admit Black applicants. The Virginia Code of 1819 outlawed teaching enslaved people to read or write.\nPost-revolution.\nSoon after the American Revolution, early leaders, like Thomas Jefferson and John Adams, proposed the creation of a more \"formal and unified system of publicly funded schools\" to satiate the need to \"build and maintain commerce, agriculture and shipping interests\". Their concept of free public education was not well received and did not begin to take hold on until the 1830s. However, in 1790, evolving socio-cultural ideals in the Commonwealth of Pennsylvania led to the first significant and systematic reform in education legislation that mandated economic conditions would not inhibit a child's access to education:\"Constitution of the Commonwealth of Pennsylvania \u2013 1790 \"ARTICLE VII Section I. The legislature shall, as soon as conveniently may be, provide, by law, for the establishment of schools throughout the state, in such manner that the poor may be taught gratis.\"\"\nReconstruction and the American Industrial Revolution.\nDuring Reconstruction, from 1865 to 1877, African Americans worked to encourage public education in the South. With the U.S. Supreme Court decision in Plessy v. Ferguson, which held that \"segregated public facilities were constitutional so long as the black and white facilities were equal to each other\", this meant that African American children were legally allowed to attend public schools, although these schools were still segregated based on race. However, by the mid-twentieth century, civil rights groups would challenge racial segregation.\nDuring the second half of the nineteenth century (1870 and 1914), America's Industrial Revolution refocused the nation's attention on the need for a universally accessible public school system. Inventions, innovations, and improved production methods were critical to the continued growth of American manufacturing. To compete in the global economy, an overwhelming demand for literate workers that possessed practical training emerged. Citizens argued, \"educating children of the poor and middle classes would prepare them to obtain good jobs, thereby strengthen the nation's economic position.\" Institutions became an essential tool in yielding ideal factory workers with sought-after attitudes and desired traits such as dependability, obedience, and punctuality. Vocationally oriented schools offered practical subjects like shop classes for students who were not planning to attend college for financial or other reasons. Not until the latter part of the 19th century did public elementary schools become available throughout the country. Although, it would be longer for children of color, girls, and children with special needs to attain access free public education.\nMid 20th and early 21st century (United states).\nCivil rights reform.\nSystemic bias remained a formidable barrier. From the 1950s to the 1970s, many of the proposed and implemented reforms in U.S. education stemmed from the civil rights movement and related trends; examples include ending racial segregation, and busing for the purpose of desegregation, affirmative action, and banning of school prayer.\nIn the early 1950s, most U.S. public schools operated under a legally sanctioned racial segregation system. Civil Rights reform movements sought to address the biases that ensure unequal distribution of academic resources such as school funding, qualified and experienced teachers, and learning materials to those socially excluded communities. In the early 1950s, the NAACP lawyers brought class-action lawsuits on behalf of black schoolchildren and their families in Kansas, South Carolina, Virginia, and Delaware, petitioning court orders to compel school districts to let black students attend white public schools. Finally, in 1954, the U.S. Supreme Court rejected that framework with Brown v. Board of Education and declared state-sponsored segregation of public schools unconstitutional.\nIn 1964, Title VI of the Civil Rights Act \"prohibited discrimination on the basis of race, color, and national origin in programs and activities receiving federal financial assistance.\" Educational institutions could now utilize public funds to implement in-service training programs to assist teachers and administrators in establishing desegregation plans.\nIn 1965, the Higher Education Act (HEA) authorizes federal aid for postsecondary students.\nThe Elementary and Secondary Education Act of 1965 (ESEA) represents the federal government's commitment to providing equal access to quality education; including those children from low-income families, limited English proficiency, and other minority groups. This legislation had positive retroactive implications for Historically Black Colleges and Universities, more commonly known as HBCUs.\"The Higher Education Act of 1965, as amended, defines an HBCU as: \"\u2026any historically black college or university that was established prior to 1964, whose principal mission was, and is, the education of black Americans, and that is accredited by a nationally recognized accrediting agency or association determined by the Secretary [of Education] to be a reliable authority as to the quality of training offered or is, according to such an agency or association, making reasonable progress toward accreditation.\"Known as the Bilingual Education Act, Title VII of ESEA, offered federal aid to school districts to provide bilingual instruction for students with limited English speaking ability.\nThe Education Amendments of 1972 (Public Law 92-318, 86 Stat. 327) establishes the Education Division in the U.S. Department of Health, Education, and Welfare and the National Institute of Education. Title IX of the Education Amendments of 1972 states, \"No person in the United States shall, on the basis of sex, be excluded from participation in, be denied the benefits of, or be subjected to discrimination under any education program or activity receiving Federal financial assistance.\"\nEqual Educational Opportunities Act of 1974 - Civil Rights Amendments to the Elementary and Secondary Education Act of 1965:\"Title I: Bilingual Education Act - Authorizes appropriations for carrying out the provisions of this Act. Establishes, in the Office of Education, an Office of Bilingual Education through which the Commissioner of Education shall carry out his functions relating to bilingual education. Authorizes appropriations for school nutrition and health services, correction education services, and ethnic heritage studies centers.\nTitle II: Equal Educational Opportunities and the Transportation of Students: Equal Educational Opportunities Act - Provides that no state shall deny equal educational opportunity to an individual on account of his or her race, color, sex, or national origin by means of specified practices...\nTitle IV: Consolidation of Certain Education Programs: Authorizes appropriations for use in various education programs including libraries and learning resources, education for use of the metric system of measurement, gifted and talented children programs, community schools, career education, consumers' education, women's equity in education programs, and arts in education programs.\nCommunity Schools Act - Authorizes the Commissioner to make grants to local educational agencies to assist in planning, establishing, expanding, and operating community education programs\nWomen's Educational Equity Act - Establishes the Advisory Council on Women's Educational Programs and sets forth the composition of such Council. Authorizes the Commissioner of Education to make grants to, and enter into contracts with, public agencies, private nonprofit organizations, and individuals for activities designed to provide educational equity for women in the United States.\nTitle V: Education Administration: Family Educational Rights and Privacy Act (FERPA)- Provides that no funds shall be made available under the General Education Provisions Act to any State or local educational agency or educational institution which denies or prevents the parents of students to inspect and review all records and files regarding their children.\nTitle VII: National Reading Improvement Program: Authorizes the Commissioner to contract with State or local educational agencies for the carrying out by such agencies, in schools having large numbers of children with reading deficiencies, of demonstration projects involving the use of innovative methods, systems, materials, or programs which show promise of overcoming such reading deficiencies.\"In 1975, The Education for All Handicapped Children Act (Public Law 94-142) ensured that all handicapped children (age 3-21) receive a \"free, appropriate public education\" designed to meet their special needs.\n1980-1989: A Nation at Risk.\nDuring the 1980s, some of the momentum of education reform moved from the left to the right, with the release of \"A Nation at Risk\", Ronald Reagan's efforts to reduce or eliminate the United States Department of Education. \"[T]he federal government and virtually all state governments, teacher training institutions, teachers' unions, major foundations, and the mass media have all pushed strenuously for higher standards, greater accountability, more \"time on task,\" and more impressive academic results\".\nPer the shift in educational motivation, families sought institutional alternatives, including \"charter schools, progressive schools, Montessori schools, Waldorf schools, Afrocentric schools, religious schools - or home school instruction in their communities.\"\nIn 1984 President Reagan enacted the Education for Economic Security Act\nIn 1989, the Child Development and Education Act of 1989 authorized funds for Head Start Programs to include child care services.\nIn the latter half of the decade, E. D. Hirsch put forth an influential attack on one or more versions of progressive education. Advocating an emphasis on \"cultural literacy\"\u2014the facts, phrases, and texts.\nSee also Uncommon Schools.\n1990-1999: standards-based education model.\nIn 1994, the land grant system was expanded via the Elementary and Secondary Education Act to include tribal colleges.\nMost states and districts in the 1990s adopted outcome-based education (OBE) in some form or another. A state would create a committee to adopt standards, and choose a quantitative instrument to assess whether the students knew the required content or could perform the required tasks.\nIn 1992 The National Commission on Time and Learning, Extension revise funding for civic education programs and those educationally disadvantaged children.\"\nIn 1994 the Improving America's Schools Act (IASA) reauthorized the Elementary and Secondary Education Act of 1965; amended as The Eisenhower Professional Development Program; IASA designated Title I funds for low income and otherwise marginalized groups; i.e., females, minorities, individuals with disabilities, individuals with limited English proficiency (LEP). By tethering federal funding distributions to student achievement, IASA meant use high stakes testing and curriculum standards to hold schools accountable for their results at the same level as other students. The Act significantly increased impact aid for the establishment of the Charter School Program, drug awareness campaigns, bilingual education, and technology.\nIn 1998 The Charter School Expansion Act amended the Charter School Program, enacted in 1994.\n2000-2015: No Child Left Behind.\nConsolidated Appropriations Act of 2001 appropriated funding to repair educational institution's buildings as well as repair and renovate charter school facilities, reauthorized the Even Start program, and enacted the Children's Internet Protection Act.\nThe standards-based National Education Goals 2000, set by the U.S. Congress in the 1990s, were based on the principles of outcomes-based education. In 2002, the standards-based reform movement culminated as the No Child left Behind Act of 2001 where achievement standard were set by each individual state. This federal policy was active until 2015 in the United States .\nAn article released by CBNC.com said a principal Senate Committee will take into account legislation that reauthorizes and modernizes the Carl D. Perkins Act. President George Bush approved this statute in 2006 on August 12, 2006. This new bill will emphasize the importance of federal funding for various Career and Technical (CTE) programs that will better provide learners with in-demand skills. Pell Grants are specific amount of money is given by the government every school year for disadvantaged students who need to pay tuition fees in college.\nAt present, there are many initiatives aimed at dealing with these concerns like innovative cooperation between federal and state governments, educators, and the business sector. One of these efforts is the Pathways to Technology Early College High School (P-TECH). This six-year program was launched in cooperation with IBM, educators from three cities in New York, Chicago, and Connecticut, and over 400 businesses. The program offers students in high school and associate programs focusing on the STEM curriculum. The High School Involvement Partnership, private and public venture, was established through the help of Northrop Grumman, a global security firm. It has given assistance to some 7,000 high school students (juniors and seniors) since 1971 by means of one-on-one coaching as well as exposure to STEM areas and careers.\n2016-2021: Every Student Succeeds Act.\nThe American Reinvestment and Recovery Act, enacted in 2009, reserved more than $85 billion in public funds to be used for education.\nThe 2009 Council of Chief State School Officers and the National Governors Association launch the Common Core State Standards Initiative.\nIn 2012 the Obama administration launched the Race to the Top competition aimed at spurring K\u201312 education reform through higher standards.\"The Race to the Top \u2013 District competition will encourage transformative change within schools, targeted toward leveraging, enhancing, and improving classroom practices and resources.\nThe four key areas of reform include:\nIn 2015, under the Obama administration, many of the more restrictive elements that were enacted under No Child Left Behind (NCLB, 2001), were removed in the Every Student Succeeds Act (ESSA, 2015) which limits the role of the federal government in school liability. Every Student Succeeds Act reformed educational standards by \"moving away from such high stakes and assessment based accountability models\" and focused on assessing student achievement from a holistic approach by utilizing qualitative measures. Some argue that giving states more authority can help prevent considerable discrepancies in educational performance across different states. ESSA was approved by former President Obama in 2015 which amended and empowered the Elementary and Secondary Education Act of 1965. The Department of Education has the choice to carry out measures in drawing attention to said differences by pinpointing lowest-performing state governments and supplying information on the condition and progress of each state on different educational parameters. It can also provide reasonable funding along with technical aid to help states with similar demographics collaborate in improving their public education programs.\nSocial and emotional learning: strengths-based education model.\nThis uses a methodology that values purposeful engagement in activities that turn students into self-reliant and efficient learners. Holding on to the view that everyone possesses natural gifts that are unique to one's personality (e.g. computational aptitude, musical talent, visual arts abilities), it likewise upholds the idea that children, despite their inexperience and tender age, are capable of coping with anguish, able to survive hardships, and can rise above difficult times.\nTrump administration.\nIn 2017, Betsy DeVos was instated as the 11th Secretary of Education. A strong proponent of school choice, school voucher programs, and charter schools, DeVos was a much-contested choice as her own education and career had little to do with formal experience in the US education system. In a Republican-dominated senate, she received a 50\u201350 vote - a tie that was broken by Vice President Mike Pence. Prior to her appointment, DeVos received a BA degree in business economics from Calvin College in Grand Rapids, Michigan and she served as chairman of an investment management firm, The Windquest Group. She supported the idea of leaving education to state governments under the new K-12 legislation. DeVos cited the interventionist approach of the federal government to education policy following the signing of the ESSA. The primary approach to that rule has not changed significantly. Her opinion was that the education movement populist politics or populism encouraged reformers to commit promises which were not very realistic and therefore difficult to deliver.\nOn July 31, 2018, President Donald Trump signed the Strengthening Career and Technical Education for the 21st Century Act (HR 2353) The Act reauthorized the Carl D. Perkins Career and Technical Education Act, a $1.2 billion program modified by the United States Congress in 2006. A move to change the Higher Education Act was also deferred.\nThe legislation enacted on July 1, 2019, replaced the Carl D. Perkins Career and Technical Education (Perkins IV) Act of 2006. Stipulations in Perkins V enables school districts to make use of federal subsidies for all students' career search and development activities in the middle grades as well as comprehensive guidance and academic mentoring in the upper grades. At the same time, this law revised the meaning of \"special populations\" to include homeless persons, foster youth, those who left the foster care system, and children with parents on active duty in the United States armed forces.\nBarriers to reform.\nEducation inequalities facing students of color.\nAnother factor to consider in education reform is that of equity and access. Contemporary issues in the United States regarding education faces a history of inequalities that come with consequences for education attainment across different social groups.\nRacial and socioeconomic class segregation.\nA history of racial, and subsequently class, segregation in the U.S. resulted from practices of law. Residential segregation is a direct result of twentieth century policies that separated by race using zoning and redlining practices, in addition to other housing policies, whose effects continue to endure in the United States. These neighborhoods that have been segregated de jure\u2014by force of purposeful public policy at the federal, state, and local levels\u2014disadvantage people of color as students must attend school near their homes.\nWith the inception of the New Deal between 1933 and 1939, and during and following World War II, federally funded public housing was explicitly racially segregated by the local government in conjunction with federal policies through projects that were designated for Whites or Black Americans in the South, Northeast, Midwest, and West. Following an ease on the housing shortage post-World War II, the federal government subsidized the relocation of Whites to suburbs. The Federal Housing and Veterans Administration constructed such developments on the East Coast in towns like Levittown on Long Island, New Jersey, Pennsylvania, and Delaware. On the West Coast, there was Panorama City, Lakewood, Westlake, and Seattle suburbs developed by Bertha and William Boeing. As White families left for the suburbs, Black families remained in public housing and were explicitly placed in Black neighborhoods. Policies such as public housing director, Harold Ickes', \"neighborhood composition rule\" maintained this segregation by establishing that public housing must not interfere with pre-existing racial compositions of neighborhoods. Federal loan guarantees were given to builders who adhered to the condition that no sales were made to Black families and each deed prohibited re-sales to Black families, what the Federal Housing Administration (FHA) described as an \"incompatible racial element\". In addition, banks and savings intuitions refused loans to Black families in White suburbs and Black families in Black neighborhoods. In the mid-twentieth century, urban renewal programs forced low-income black residents to reside in places farther from universities, hospitals, or business districts and relocation options consisted of public housing high-rises and ghettos.\nThis history of de jure segregation has impacted resource allocation for public education in the United States, with schools continuing to be segregated by race and class. Low-income White students are more likely than Black students to be integrated into middle-class neighborhoods and less likely to attend schools with other predominantly disadvantaged students. Students of color disproportionately attend underfunded schools and Title I schools in environments entrenched in environmental pollution and stagnant economic mobility with limited access to college readiness resources. According to research, schools attended by primarily Hispanic or African American students often have high turnover of teaching staff and are labeled high-poverty schools, in addition to having limited educational specialists, less available extracurricular opportunities, greater numbers of provisionally licensed teachers, little access to technology, and buildings that are not well maintained. With this segregation, more local property tax is allocated to wealthier communities and public schools' dependence on local property taxes has led to large disparities in funding between neighboring districts. The top 10% of wealthiest school districts spend approximately ten times more per student than the poorest 10% of school districts.\nRacial wealth gap.\nThis history of racial and socioeconomic class segregation in the U.S. has manifested into a racial wealth divide. With this history of geographic and economic segregation, trends illustrate a racial wealth gap that has impacted educational outcomes and its concomitant economic gains for minorities. Wealth or net worth\u2014the difference between gross assets and debt\u2014is a stock of financial resources and a significant indicator of financial security that offers a more complete measure of household capability and functioning than income. Within the same income bracket, the chance of completing college differs for White and Black students. Nationally, White students are at least 11% more likely to complete college across all four income groups. Intergenerational wealth is another result of this history, with White college-educated families three times as likely as Black families to get an inheritance of $10,000 or more. 10.6% of White children from low-income backgrounds and 2.5% of Black children from low-income backgrounds reach the top 20% of income distribution as adults. Less than 10% of Black children from low-income backgrounds reach the top 40%.\nAccess to early childhood education.\nThese disadvantages facing students of color are apparent early on in early childhood education. By the age of five, children of color are impacted by opportunity gaps indicated by poverty, school readiness gap, segregated low-income neighborhoods, implicit bias, and inequalities within the justice system as Hispanic and African American boys account for as much as 60% of total prisoners within the incarceration population. These populations are also more likely to experience adverse childhood experiences (ACEs).\nHigh-quality early care and education are less accessible to children of color, particularly African American preschoolers as findings from the National Center for Education Statistics show that in 2013, 40% of Hispanic and 36% White children were enrolled in learning center-based classrooms rated as high, while 25% of African American children were enrolled in these programs. 15% of African American children attended low ranking center-based classrooms. In home-based settings, 30% of White children and over 50% of Hispanic and African American children attended low rated programs.\nContemporary issues (United States).\nOverview.\nIn the first decade of the 21st century, several issues are salient in debates over further education reform:\nPrivate interest in American charter schools.\nCharter schools public independent institutions in which both the cost and risk are fully funded by the taxpayers. Some charter schools are nonprofit in name only and are structured in ways that individuals and private enterprises connected to them can make money. Other charter schools are for-profit. In many cases, the public is largely unaware of this rapidly changing educational landscape, the debate between public and private/market approaches, and the decisions that are being made that affect their children and communities. Critics have accused for-profit entities, (education management organizations, EMOs) and private foundations such as the Bill and Melinda Gates Foundation, the Eli and Edythe Broad Foundation, and the Walton Family Foundation of funding Charter school initiatives to undermine public education and turn education into a \"Business Model\" which can make a profit. In some cases a school's charter is held by a non-profit that chooses to contract all of the school's operations to a third party, often a for-profit, CMO. This arrangement is defined as a \"vendor-operated school\", (\"VOS\").\nSchool choice.\nEconomists such as Nobel laureate Milton Friedman advocate school choice to promote excellence in education through competition and choice. A competitive \"market\" for schools eliminates the need to otherwise attempt a workable method of accountability for results. Public education vouchers permit guardians to select and pay any school, public or private, with public funds currently allocated to local public schools. The theory is that children's guardians will naturally shop for the best schools, much as is already done at college level.\nThough appealing in theory, many reforms based on school choice have led to slight to moderate improvements\u2014which some teachers' union members see as insufficient to offset the decreased teacher pay and job security. For instance, New Zealand's landmark reform in 1989, during which schools were granted substantial autonomy, funding was devolved to schools, and parents were given a free choice of which school their children would attend, led to moderate improvements in most schools. It was argued that the associated increases in inequity and greater racial stratification in schools nullified the educational gains. Others, however, argued that the original system created more inequity (due to lower income students being required to attend poorer performing inner city schools and not being allowed school choice or better educations that are available to higher income inhabitants of suburbs). Instead, it was argued that the school choice promoted social mobility and increased test scores especially in the cases of low income students. Similar results have been found in other jurisdictions. Though discouraging, the merely slight improvements of some school choice policies often seems to reflect weaknesses in the way that choice is implemented rather than a failure of the basic principle itself.\nTeacher tenure.\nCritics of teacher tenure claim that the laws protect ineffective teachers from being fired, which can be detrimental to student success. Tenure laws vary from state to state, but generally they set a probationary period during which the teacher proves themselves worthy of the lifelong position. Probationary periods range from one to three years. Advocates for tenure reform often consider these periods too short to make such an important decision; especially when that decision is exceptionally hard to revoke. Due process restriction protect tenured teachers from being wrongfully fired; however these restrictions can also prevent administrators from removing ineffective or inappropriate teachers. A 2008 survey conducted by the US Department of Education found that, on average, only 2.1% of teachers are dismissed each year for poor performance.\nIn October 2010 Apple Inc. CEO Steve Jobs had a consequential meeting with U.S. President Barack Obama to discuss U.S. competitiveness and the nation's education system. During the meeting Jobs recommended pursuing policies that would make it easier for school principals to hire and fire teachers based on merit.\nIn 2012 tenure for school teachers was challenged in a California lawsuit called \"Vergara v. California\". The primary issue in the case was the impact of tenure on student outcomes and on equity in education. On June 10, 2014, the trial judge ruled that California's teacher tenure statute produced disparities that \" shock the conscience\" and violate the equal protection clause of the California Constitution. On July 7, 2014, U.S. Secretary of Education Arne Duncan commented on the \"Vergara\" decision during a meeting with President Barack Obama and representatives of teacher's unions. Duncan said that tenure for school teachers \"should be earned through demonstrated effectiveness\" and should not be granted too quickly. Specifically, he criticized the 18-month tenure period at the heart of the \"Vergara\" case as being too short to be a \"meaningful bar.\"\nFunding levels.\nAccording to a 2005 report from the OECD, the United States is tied for first place with Switzerland when it comes to annual spending per student on its public schools, with each of those two countries spending more than $11,000 (in U.S.\u00a0currency).\nDespite this high level of funding, U.S.\u00a0public schools lag behind the schools of other rich countries in the areas of reading, math, and science. A further analysis of developed countries shows no correlation between per student spending and student performance, suggesting that there are other factors influencing education. Top performers include Singapore, Finland and Korea, all with relatively low spending on education, while high spenders including Norway and Luxembourg have relatively low performance. One possible factor is the distribution of the funding.\nIn the US, schools in wealthy areas tend to be over-funded while schools in poorer areas tend to be underfunded. These differences in spending between schools or districts may accentuate inequalities, if they result in the best teachers moving to teach in the most wealthy areas. The inequality between districts and schools led to 23 states instituting school finance reform based on adequacy standards that aim to increase funding to low-income districts. A 2018 study found that between 1990 and 2012, these finance reforms led to an increase in funding and test scores in the low income districts; which suggests finance reform is effective at bridging inter-district performance inequalities. It has also been shown that the socioeconomic situation of the students family has the most influence in determining success; suggesting that even if increased funds in a low income area increase performance, they may still perform worse than their peers from wealthier districts.\nStarting in the early 1980s, a series of analyses by Eric Hanushek indicated that the amount spent on schools bore little relationship to student learning. This controversial argument, which focused attention on how money was spent instead of how much was spent, led to lengthy scholarly exchanges. In part the arguments fed into the class size debates and other discussions of \"input policies.\" It also moved reform efforts towards issues of school accountability (including No Child Left Behind) and the use of merit pay and other incentives.\nThere have been studies that show smaller class sizes and newer buildings (both of which require higher funding to implement) lead to academic improvements. It should also be noted that many of the reform ideas that stray from the traditional format require greater funding.\nAccording to a 1999 article, William J. Bennett, former U.S.\u00a0Secretary of Education, argued that increased levels of spending on public education have not made the schools better, citing the following statistics:\nInternationally.\nEducation for All.\nEducation 2030 Agenda refers to the global commitment of the Education for All movement to ensure access to basic education for all. It is an essential part of the 2030 Agenda for Sustainable Development. The roadmap to achieve the Agenda is the Education 2030 Incheon Declaration and Framework for Action, which outlines how countries, working with UNESCO and global partners, can translate commitments into action.\nThe United Nations, over 70 ministers, representatives of member-countries, bilateral and multilateral agencies, regional organizations, academic institutions, teachers, civil society, and the youth supported the Framework for Action of the Education 2030 platform. The Framework was described as the outcome of continuing consultation to provide guidance for countries in implementing this Agenda. At the same time, it mobilizes various stakeholders in the new education objectives, coordination, implementation process, funding, and review of Education 2030.\nThailand.\nIn 1995, the minister of education, Sukavich Rangsitpol, launched a series of education reforms in 1995 with the intention of the education reform is to realize the potential of Thai people to develop themselves for a better quality of life and to develop the nation for a peaceful co-existence in the global community. The follow-on Reform Program of 1996 is built around four major improvements:\nSchool-based management (SBM) in Thailand implemented in 1997 in the course of a reform aimed at overcoming a profound crisis in the educaci\u00f3n system.\nAccording to UNESCO, Thailand education reform has led to the following results:\nWorld Bank report that after the 1997 Asian financial crisis Income in the northeast, the poorest part of Thailand, has risen by 46 percent from 1998 to 2006. Nationwide poverty fell from 21.3 to 11.3 percent.\nLearning crisis.\nThe learning crisis is the reality that while the majority of children around the world attend school, a large proportion of them are not learning. A World Bank study found that \"53 percent of children in low- and middle-income countries cannot read and understand a simple story by the end of primary school.\" While schooling has increased rapidly over the last few decades, learning has not followed suit. Many practitioners and academics call for education system reform in order to address the learning needs of all children.\nDigital education.\nThe movement to use computers more in education naturally includes many unrelated ideas, methods, and pedagogies since there are many uses for digital computers. For example, the fact that computers are naturally good at math leads to the question of the use of calculators in math education. The Internet's communication capabilities make it potentially useful for collaboration, and foreign language learning. The computer's ability to simulate physical systems makes it potentially useful in teaching science. More often, however, debate of digital education reform centers around more general applications of computers to education, such as electronic test-taking and online classes.\nAnother viable addition to digital education has been blended learning. In 2009, over 3 million K-12 students took an online course, compared to 2000 when 45,000 took an online course. Blended learning examples include pure online, blended, and traditional education. Research results show that the most effective learning takes place in a blended format. This allows children to view the lecture ahead of time and then spend class time practicing, refining, and applying what they have previously learned.\nThe idea of creating artificial intelligence led some computer scientists to believe that teachers could be replaced by computers, through something like an expert system; however, attempts to accomplish this have predictably proved inflexible. The computer is now more understood to be a tool or assistant for the teacher and students.\nHarnessing the richness of the Internet is another goal. In some cases classrooms have been moved entirely online, while in other instances the goal is more to learn how the Internet can be more than a classroom.\nWeb-based international educational software is under development by students at New York University, based on the belief that current educational institutions are too rigid: effective teaching is not routine, students are not passive, and questions of practice are not predictable or standardized. The software allows for courses tailored to an individual's abilities through frequent and automatic multiple intelligences assessments. Ultimate goals include assisting students to be intrinsically motivated to educate themselves, and aiding the student in self-actualization. Courses typically taught only in college are being reformatted so that they can be taught to any level of student, whereby elementary school students may learn the foundations of any topic they desire. Such a program has the potential to remove the bureaucratic inefficiencies of education in modern countries, and with the decreasing digital divide, help developing nations rapidly achieve a similar quality of education. With an open format similar to Wikipedia, any teacher may upload their courses online and a feedback system will help students choose relevant courses of the highest quality. Teachers can provide links in their digital courses to webcast videos of their lectures. Students will have personal academic profiles and a forum will allow students to pose complex questions, while simpler questions will be automatically answered by the software, which will bring you to a solution by searching through the knowledge database, which includes all available courses and topics.\nThe 21st century ushered in the acceptance and encouragement of internet research conducted on college and university campuses, in homes, and even in gathering areas of shopping centers. Addition of cyber cafes on campuses and coffee shops, loaning of communication devices from libraries, and availability of more portable technology devices, opened up a world of educational resources. Availability of knowledge to the elite had always been obvious, yet provision of networking devices, even wireless gadget sign-outs from libraries, made availability of information an expectation of most persons. Cassandra B. Whyte researched the future of computer use on higher education campuses focusing on student affairs. Though at first seen as a data collection and outcome reporting tool, the use of computer technology in the classrooms, meeting areas, and homes continued to unfold. The sole dependence on paper resources for subject information diminished and e-books and articles, as well as online courses, were anticipated to become increasingly staple and affordable choices provided by higher education institutions according to Whyte in a 2002 presentation.\nDigitally \"flipping\" classrooms is a trend in digital education that has gained significant momentum. Will Richardson, author and visionary for the digital education realm, points to the not-so-distant future and the seemingly infinite possibilities for digital communication linked to improved education. Education on the whole, as a stand-alone entity, has been slow to embrace these changes. The use of web tools such as wikis, blogs, and social networking sites is tied to increasing overall effectiveness of digital education in schools. Examples exist of teacher and student success stories where learning has transcended the classroom and has reached far out into society.\nThe media has been instrumental in pushing formal educational institutions to become savvier in their methods. Additionally, advertising has been (and continues to be) a vital force in shaping students and parents thought patterns.\nTechnology is a dynamic entity that is constantly in flux. As time presses on, new technologies will continue to break paradigms that will reshape human thinking regarding technological innovation. This concept stresses a certain disconnect between teachers and learners and the growing chasm that started some time ago. Richardson asserts that traditional classroom's will essentially enter entropy unless teachers increase their comfort and proficiency with technology.\nAdministrators are not exempt from the technological disconnect. They must recognize the existence of a younger generation of teachers who were born during the Digital Age and are very comfortable with technology. However, when old meets new, especially in a mentoring situation, conflict seems inevitable. Ironically, the answer to the outdated mentor may be digital collaboration with worldwide mentor webs; composed of individuals with creative ideas for the classroom.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n\u00a0This article incorporates text from a free content work. Licensed under CC-BY-SA IGO 3.0 (license statement/permission). Text taken from \"Education Transforms Lives\u200b\", 6, 8-9, UNESCO, UNESCO. UNESCO. "}
{"id": "9621", "revid": "18265218", "url": "https://en.wikipedia.org/wiki?curid=9621", "title": "Ellensburg, Washington", "text": "City in Washington, United States\nEllensburg is a city in and the county seat of Kittitas County, Washington, United States. It is located just east of the Cascade Range near the junction of Interstate 90 and Interstate 82. The population was 18,666 at the 2020 census. and was estimated to be 19,596 in 2021.\nThe city is located along the Yakima River in the Kittitas Valley, an agricultural region that extends east towards the Columbia River. The valley is a major producer of timothy hay, which is processed and shipped internationally. Ellensburg is also the home of Central Washington University (CWU).\nEllensburg, originally named Ellensburgh for the wife of town founder John Alden Shoudy, was founded in 1871 and grew rapidly in the 1880s following the arrival of the Northern Pacific Railway. The city was once a leading candidate to become the state capital of Washington, but its campaign was scuppered by a major fire in 1889.\nHistory.\nJohn Alden Shoudy arrived in the Kittitas Valley in 1871 and purchased a small trading post from Andrew Jackson \"A.J.\" Splawn, called \"Robber's Roost\". Robber's Roost was the first business in the valley, aside from the early trading that occurred among Native Americans, cattle drivers, trappers, and miners. A small stone monument to Robber's Roost with a placard can be found at its original location, present-day 3rd Avenue, just west of Main Street near the alley.\nShoudy named the new town after his wife, Mary Ellen, thus officially starting the city of Ellensburgh around 1872. Shoudy had not been the first settler nor the first business person in the Kittitas Valley, but he was responsible for platting the city of Ellensburgh in the 1870s and also named the streets in the downtown district. Ellensburgh was officially incorporated on November 26, 1883. In 1894, the final -\"h\" was dropped under standardization pressure from the United States Postal Service and Board of Geography Names. Ellensburg was an early center of commerce in Washington and was among the first cities in the state to have electrical service.\nThe city launched a bid to become Washington state's capital in 1889, preparing a site in the Capital Hill neighborhood for government offices. On July 4 that year, however, a major fire destroyed much of the downtown area and stalled the campaign, which resumed with a series of referendums, in which Washington voters chose Olympia. The state legislature selected Ellensburg as the location for the State Normal School (now Central Washington University).\nThere were several early newspapers in Ellensburg. \"The Daily Record\", which started in 1909, is the publication which serves the city and county today. Concerns over the state of Ellensburg's historic downtown led to the formation of the Ellensburg Downtown Association to work on revitalizing the area.\nArts and culture.\nThe City of Ellensburg is home to a number of local art museums and galleries: \nEvery first Friday of each month, Ellensburg hosts First Friday Art Walk from 5:00 to 7:00 pm.\nGeography.\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water.\nClimate.\nOwing to the strong Cascade rain shadow, Ellensburg experiences a typical Intermountain cool semi-arid climate (K\u00f6ppen \"BSk\"). The hottest temperature recorded in Ellensburg was on July 26, 1928, while the coldest temperature recorded was on December 12, 1919.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2010 census.\nAs of the census of 2010, there were 18,174 people, 7,301 households, and 2,889 families living in the city. The population density was . There were 7,867 housing units at an average density of . The racial makeup of the city was 85.7% White, 1.5% African American, 1.0% Native American, 3.2% Asian, 0.2% Pacific Islander, 4.6% from other races, and 3.7% from two or more races. Hispanic or Latino of any race were 9.7% of the population.\nThere were 7,301 households, of which 19.3% had children under the age of 18 living with them, 28.2% were married couples living together, 8.2% had a female householder with no husband present, 3.1% had a male householder with no wife present, and 60.4% were non-families. 35.1% of all households were made up of individuals, and 9.6% had someone living alone who was 65 years of age or older. The average household size was 2.16 and the average family size was 2.86.\nThe median age in the city was 23.5 years. 14.2% of residents were under the age of 18; 41.2% were between the ages of 18 and 24; 21.8% were from 25 to 44; 13.9% were from 45 to 64; and 8.9% were 65 years of age or older. The gender makeup of the city was 50.1% male and 49.9% female.\n2000 census.\nAs of the census of 2000, there were 15,414 people, 6,249 households, and 2,649 families living in the city. The population density was . There were 6,732 housing units at an average density of . The racial makeup of the city was 88.07% White, 1.17% Black or African American, 0.95% Native American, 4.09% Asian, 0.16% Pacific Islander, 2.86% from other races, and 2.69% from two or more races. 6.33% of the population were Hispanic or Latino of any race.\nThere were 6,249 households, of which 20.8% had children under the age of 18 living with them, 31.4% were married couples living together, 8.1% had a female householder with no husband present, and 57.6% were non-families. 35.5% of all households were made up of individuals, and 9.1% had someone living alone who was 65 years of age or older. The average household size was 2.12 and the average family size was 2.84.\nIn the city, the population was spread out, with 15.8% under the age of 18, 39.3% from 18 to 24, 22.7% from 25 to 44, 12.8% from 45 to 64, and 9.4% who were 65 years of age or older. The median age was 24 years. For every 100 females, there were 95.0 males. For every 100 females age 18 and over, there were 93.1 males.\nThe median income for a household in the city was $20,034, and the median income for a family was $37,625. Males had a median income of $31,022 versus $22,829 for females. The per capita income for the city was $13,662. About 18.8% of families and 34.3% of the population were below the poverty line, including 29.0% of those under age 18 and 11.2% of those age 65 or over.\nPolitics and government.\nThe City of Ellensburg uses the Manager/Council form of government with a City Manager hired by the City Council. The seven-member City Council is elected at large and serve 4-year terms. The City Council elects a Mayor and Deputy Mayor from the council to serve 2-year terms. The Council meets the first and third Monday of each month, at 7:00 pm, in the City Council Chambers at City Hall.\nOn the state legislative level, Ellensburg is in the 13th district. As of May, 2018, its state senator is Republican Judy Warnick, and its two state representatives are Republicans Alex Ybarra and Tom Dent. On the congressional level, Ellensburg is located in Washington's 8th congressional district and is represented by Democrat Kim Schrier.\nMedia.\nKittitas County is served by the \"Daily Record\", a newspaper published in Ellensburg five days a week.\nThe city maintains its own public library, which opened on January 20, 1910, using funds donated by Andrew Carnegie.\nEducation.\nPublic schools.\nPublic schools are operated by Ellensburg School District 401. The district includes one high school (Ellensburg High School), one middle school, and three elementary schools.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9623", "revid": "1156579935", "url": "https://en.wikipedia.org/wiki?curid=9623", "title": "Eugene, Oregon", "text": "City in Oregon, U.S.\nEugene ( ) is the second largest city in the U.S. state of Oregon and the seat of Lane County. It is located at the southern end of the Willamette Valley, near the confluence of the McKenzie and Willamette rivers, about east of the Oregon Coast.\nAs of the 2020 United States Census, Eugene had a population of 176,654 and covers city area of . The Eugene-Springfield metropolitan statistical area is the second largest in Oregon behind Portland. In 2022, Eugene's population was estimated to have reached 179,887.\nEugene is home to the University of Oregon, Bushnell University, and Lane Community College. The city is noted for its natural environment, recreational opportunities (especially bicycling, running/jogging, rafting, and kayaking), and focus on the arts, along with its history of civil unrest, protests, and green activism. Eugene's official slogan is \"A Great City for the Arts and Outdoors\". It is also referred to as the \"Emerald City\" and as \"Track Town, USA\". The Nike corporation had its beginnings in Eugene. In July 2022, the city hosted the 18th World Athletics Championship.\nHistory.\nIndigenous presence.\nThe first people to settle in the Eugene area were the Kalapuyans, also written Calapooia or Calapooya. They made \"seasonal rounds,\" moving around the countryside to collect and preserve local foods, including acorns, the bulbs of the wapato and camas plants, and berries. They stored these foods in their permanent winter village. When crop activities waned, they returned to their winter villages and took up hunting, fishing, and trading. They were known as the Chifin Kalapuyans and called the Eugene area where they lived \"Chifin\", sometimes recorded as \"Chafin\" or \"Chiffin\".\nOther Kalapuyan tribes occupied villages that are also now within Eugene city limits. Pee-you or Mohawk Calapooians, Winefelly or Pleasant Hill Calapooians, and the Lungtum or Long Tom. They were close-neighbors to the Chifin, intermarried, and were political allies. Some authorities suggest the Brownsville Kalapuyans (Calapooia Kalapuyans) were related to the Pee-you. It is likely that since the Santiam had an alliance with the Brownsville Kalapuyans that the Santiam influence also went as far at Eugene.\nAccording to archeological evidence, the ancestors of the Kalapuyans may have been in Eugene for as long as 10,000 years. In the 1800s their traditional way of life faced significant changes due to devastating epidemics and settlement, first by French fur traders and later by an overwhelming number of American settlers.\nSettlement and impact.\nFrench fur traders had settled seasonally in the Willamette Valley by the beginning of the 19th century. Their settlements were concentrated in the \"French Prairie\" community in Northern Marion County but may have extended south to the Eugene area. Having already developed relationships with Native communities through intermarriage and trade, they negotiated for land from the Kalapuyans. By 1828 to 1830 they and their Native wives began year-round occupation of the land, raising crops and tending animals. In this process, the mixed race families began to impact Native access to land, food supply, and traditional materials for trade and religious practices.\nIn July 1830, \"intermittent fever\" struck the lower Columbia region and a year later, the Willamette Valley. Natives traced the arrival of the disease, then new to the Pacific Northwest, to the \"USS Owyhee\", captained by John Dominis. \"Intermittent fever\" is thought by researchers now to be malaria. According to Robert T. Boyd, an anthropologist at Portland State University, the first three years of the epidemic, \"probably constitute the single most important epidemiological event in the recorded history of what would eventually become the state of Oregon\". In his book \"The Coming of the Spirit Pestilence\" Boyd reports there was a 92% population loss for the Kalapuyans between 1830 and 1841. This catastrophic event shattered the social fabric of Kalapuyan society and altered the demographic balance in the Valley. This balance was further altered over the next few years by the arrival of Anglo-American settlers, beginning in 1840 with 13 people and growing steadily each year until within 20 years more than 11,000 American settlers, including Eugene Skinner, had arrived.\nAs the demographic pressure from the settlers grew, the remaining Kalapuyans were forcibly removed to Indian reservations. Though some Natives escaped being swept into the reservation, most were moved to the Grand Ronde reservation in 1856. Strict racial segregation was enforced and mixed race people, known as M\u00e9tis in French, had to make a choice between the reservation and Anglo society. Native Americans could not leave the reservation without traveling papers and white people could not enter the reservation.\nEugene Franklin Skinner, after whom Eugene is named, arrived in the Willamette Valley in 1846 with 1,200 other settlers that year. Advised by the Kalapuyans to build on high ground to avoid flooding, he erected the first Anglo cabin on south or west slope of what the Kalapuyans called Ya-po-ah. The \"isolated hill\" is now known as Skinner's Butte. The cabin was used as a trading post and was registered as an official post office on January 8, 1850.\nAt this time the settlement was known by Anglos as Skinner's Mudhole. It was relocated in 1853 and named Eugene City in 1853. Formally incorporated as a city in 1862, it was named simply Eugene in 1889. Skinner ran a ferry service across the Willamette River where the Ferry Street Bridge now stands.\nEducational institutions.\nThe first major educational institution in the area was Columbia College, founded a few years earlier than the University of Oregon. It fell victim to two major fires in four years, and after the second fire, the college decided not to rebuild again. The part of south Eugene known as College Hill was the former location of Columbia College. There is no college there today.\nThe town raised the initial funding to start a public university, which later became the University of Oregon, with the hope of turning the small town into a center of learning. In 1872, the Legislative Assembly passed a bill creating the University of Oregon as a state institution. Eugene bested the nearby town of Albany in the competition for the state university. In 1873, community member J.H.D. Henderson donated the hilltop land for the campus, overlooking the city. The university first opened in 1876 with the regents electing the first faculty and naming John Wesley Johnson as president. The first students registered on October 16, 1876. The first building was completed in 1877; it was named Deady Hall in honor of the first Board of Regents President and community leader Judge Matthew P. Deady.\nOther universities in Eugene include Bushnell University and New Hope Christian College.\nTwentieth century.\nEugene grew rapidly throughout most of the twentieth century, with the exception being the early 1980s when a downturn in the timber industry caused high unemployment. By 1985, the industry had recovered and Eugene began to attract more high-tech industries, earning it the moniker the \"Emerald Shire\". In 2012, Eugene and the surrounding metro area was dubbed the Silicon shire.\nThe first Nike shoe was used in 1972 during the US Olympic trials held in Eugene.\nActivism.\nThe 1970s saw an increase in community activism. Local activists stopped a proposed freeway and lobbied for the construction of the Washington Jefferson Park beneath the Washington-Jefferson Street Bridge. Community Councils soon began to form as a result of these efforts. A notable impact of the turn to community-organized politics came with Eugene Local Measure 51, a ballot measure in 1978 that repealed a gay rights ordinance approved by the Eugene City Council in 1977 that prohibited discrimination by sexual orientation. Eugene is also home to Beyond Toxics, a nonprofit environmental justice organization founded in 2000.\nOne hotspot for protest activity since the 1990s has been the Whitaker district, located in the northwest of downtown Eugene. Whitaker is primarily a working-class neighborhood that has become a vibrant cultural hub, center of community and activism and home to alternative artists. It saw an increase of activity in the 1990s after many young people drawn to Eugene's political climate relocated there. Animal rights groups have had a heavy presence in the Whiteaker, and several vegan restaurants are located there. According to David Samuels, the Animal Liberation Front and the Earth Liberation Front have had an underground presence in the neighborhood. The neighborhood is home to a number of communal apartment buildings, which are often organized by anarchist or environmentalist groups. Local activists have also produced independent films and started art galleries, community gardens, and independent media outlets. Copwatch, Food Not Bombs, and Critical Mass are also active in the neighborhood.\nGeography.\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water. Eugene is at an elevation of .\nTo the north of downtown is Skinner Butte. Northeast of the city is the Coburg Hills. Spencer Butte is a prominent landmark south of the city. Mount Pisgah is southeast of Eugene and includes Mount Pisgah Arboretum and Howard Buford Recreation Area, a Lane County Park. Eugene is surrounded by foothills and forests to the south, east, and west, while to the north the land levels out into the Willamette Valley and consists of mostly farmland.\nThe Willamette and McKenzie Rivers run through Eugene and its neighboring city, Springfield. Another important stream is Amazon Creek, whose headwaters are near Spencer Butte. The creek discharges into the Long Tom River north Fern Ridge Reservoir, maintained for winter flood control by the Army Corps of Engineers. The Eugene Yacht Club hosts a sailing school and sailing regattas at Fern Ridge during summer months.\nNeighborhoods.\nEugene has 23 neighborhood associations:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nThe River Road and Santa Clara sections, which make up the northwestern part of the city, are within the urban growth boundary and generally perceived as part of Eugene, but are largely outside of the city limits.\nClimate.\nLike the rest of the Willamette Valley, Eugene lies in the Marine West Coast climate zone, with Mediterranean characteristics. Under the K\u00f6ppen climate classification scheme, Eugene has a warm-summer Mediterranean climate (K\u00f6ppen: \"Csb\"). Temperatures can vary from cool to warm, with warm, dry summers and cool, wet winters. Spring and fall are also moist seasons, with light rain falling for long periods. The average rainfall is , with the wettest \"rain year\" being from July 1973 to June 1974 with and the driest from July 2000 to June 2001 with . Measurements taken by NOAA over the past four decades have indicated a significant decline in average annual precipitation. From 1981 to 2010 inclusive, the reported annual average precipitation was , but for the thirty-year period ending in 2020, the annual average had declined , to . The figures from the second half of that period, or 2006 - 2020 inclusive, pointed to a further decline of more than , down to an annual average of .\nWinter snowfall does occur, but it is sporadic and rarely accumulates in large amounts: the normal seasonal amount is , but the median is zero. The record snowfall was of accumulation due to a pineapple express on January 25\u201329, 1969. Ice storms, like snowfall, are rare, but occur sporadically.\nThe hottest months are July and August, with a normal monthly mean temperature of , with an average of 16\u00a0days per year reaching . The coolest month is December, with a mean temperature of , and there are 52 mornings per year with a low at or below freezing, and 2 afternoons with highs not exceeding the freezing mark. The coldest daytime high of the year averages , reaching the freezing point.\nEugene's average annual temperature is , and annual precipitation at . Eugene is slightly cooler on average than Portland. Despite being located about south and at an only slightly higher elevation, Eugene has a more continental climate than Portland, less subject to the maritime air that blows inland from the Pacific Ocean via the Columbia River. Eugene's normal annual mean minimum is , compared to in Portland; in August, the gap in the normal mean minimum widens to for Eugene and Portland, respectively. Eugene's warmest night annually averages a modest . Average winter temperatures (and summer high temperatures) are similar for the two cities.\nExtreme temperatures range from , recorded on December 8, 1972, to on June 27, 2021; the record cold daily maximum is , recorded on December 13, 1919, while, conversely, the record warm daily minimum is on July 22, 2006.\nAir quality and allergies.\nEugene is downwind of Willamette Valley grass seed farms. The combination of summer grass pollen and the confining shape of the hills around Eugene make it \"the area of the highest grass pollen counts in the USA (&gt;1,500 pollen grains/m3 of air).\" These high pollen counts have led to difficulties for some track athletes who compete in Eugene. In the Olympic trials in 1972, \"Jim Ryun won the 1,500 after being flown in by helicopter because he was allergic to Eugene's grass seed pollen.\" Further, six-time Olympian Maria Mutola abandoned Eugene as a training area \"in part to avoid allergies\".\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2010 census.\nAccording to the 2010 census, Eugene's population was 156,185. The population density was 3,572.2 people per square mile. There were 69,951 housing units at an average density of 1,600 per square mile. Those age 18 and over accounted for 81.8% of the total population.\nThe racial makeup of the city was 85.8% White, 4.0% Asian, 1.4% Black or African American, 1.0% Native American, 0.2% Pacific Islander, and 4.7% from other races.\nHispanics and Latinos of any race accounted for 7.8% of the total population. Of the non-Hispanics, 82% were White, 1.3% Black or African American, 0.8% Native American, 4% Asian, 0.2% Pacific Islander, 0.2% some other race alone, and 3.4% were of two or more races.\nFemales represented 51.1% of the total population, and males represented 48.9%. The median age in the city was 33.8 years.\n2000 census.\nThe census of 2000 showed there were 137,893 people, 58,110 households, and 31,321 families residing in the city of Eugene. The population density was . There were 61,444 housing units at an average density of . The racial makeup of the city was 88.15% White, down from 99.5% in 1950, 3.57% Asian, 1.25% Black or African American, 0.93% Native American, 0.21% Pacific Islander, 2.18% from other races, and 3.72% from two or more races. 4.96% of the population were Hispanic or Latino of any race.\nThere were 58,110 households, of which 25.8% had children under the age of 18 living with them, 40.6% were married couples living together, 9.7% had a female householder with no husband present, and 46.1% were non-families. 31.7% of all households were made up of individuals, and 9.4% had someone living alone who was 65 years of age or older. The average household size was 2.27 and the average family size was 2.87. In the city, the population was 20.3% under the age of 18, 17.3% from 18 to 24, 28.5% from 25 to 44, 21.8% from 45 to 64, and 12.1% who were 65 years of age or older. The median age was 33 years. For every 100 females, there were 96.0 males. For every 100 females age 18 and over, there were 94.0 males. The median income for a household in the city was $35,850, and the median income for a family was $48,527. Males had a median income of $35,549 versus $26,721 for females. The per capita income for the city was $21,315. About 8.7% of families and 17.1% of the population were below the poverty line, including 14.8% of those under age 18 and 7.1% of those age 65 or over.\nEconomy.\nEugene's largest employers are PeaceHealth Medical Group, the University of Oregon, and the Eugene School District. Eugene's largest industries are wood products manufacturing and recreational vehicle manufacturing.\nLuckey's Club Cigar Store is one of the oldest bars in Oregon. Tad Luckey Sr. purchased it in 1911, making it one of the oldest businesses in Eugene. The \"Club Cigar\", as it was called in the late 19th century, was for many years a men-only salon. It survived both the Great Depression and Prohibition, partly because Eugene was a \"dry town\" before the end of Prohibition.\nCorporate headquarters for the employee-owned Bi-Mart corporation and family-owned supermarket Market of Choice remain in Eugene. \nThe city has over 25 breweries, offers a variety of dining options with a local focus; the city is surrounded by wineries. The most notable fungi here is the truffle; Eugene hosts the annual Oregon Truffle Festival in January.\nOrganically Grown Company, the largest distributor of organic fruits and vegetables in the northwest, started in Eugene in 1978 as a non-profit co-op for organic farmers. Notable local food processors, many of whom manufacture certified organic products, include Golden Temple (Yogi Tea), Merry Hempsters and Springfield Creamery (Nancy's Yogurt &amp; owned by the Kesey Family), and Mountain Rose Herbs.\nUntil July 2008, Hynix Semiconductor America had operated a large semiconductor plant in west Eugene. In late September 2009, Uni-Chem of South Korea announced its intention to purchase the Hynix site for solar cell manufacturing. However, this deal fell through and as of late 2012, is no longer planned. In 2015, semiconductor manufacturer Broadcom purchased the plant with plans to upgrade and reopen it. The company abandoned these plans and put it up for sale in November 2016.\nThe footwear repair product Shoe Goo is manufactured by Eclectic Products, based in Eugene.\nRun Gum, an energy gum created for runners, also began its life in Eugene. Run Gum was created by track athlete Nick Symmonds and track and field coach Sam Lapray in 2014.\nBurley Design LLC produces bicycle trailers and was founded in Eugene by Alan Scholz out of a Saturday Market business in 1978. Eugene is also the birthplace and home of Bike Friday bicycle manufacturer Green Gear Cycling.\nMany multinational businesses were launched in Eugene. Some of the most famous include Nike, Taco Time, and Br\u00f8derbund Software.\nIn 2012, the Eugene metro region was dubbed the Silicon Shire for its growing tech industry.\nTop employers.\nAccording to Eugene's 2017 Comprehensive Annual Financial Report, the city's top employers are:\nHomelessness.\nEugene has a growing problem with homelessness. The problem has been referenced in popular culture, including in the episode The 30% Iron Chef in Futurama. During the COVID-19 pandemic, the city experienced a controversy over its continuing policy of homeless removal, despite CDC guidelines to not engage in homeless removal.\nArts and culture.\nEugene has a significant population of people in pursuit of alternative ideas and a large original hippie population. Beginning in the 1960s, the countercultural ideas and viewpoints espoused by area native Ken Kesey became established as the seminal elements of the vibrant social tapestry that continue to define Eugene. The Merry Prankster, as Kesey was known, has arguably left the most indelible imprint of any cultural icon in his hometown. He is best known as the author of \"One Flew Over the Cuckoo's Nest\" and as the male protagonist in Tom Wolfe's \"The Electric Kool-Aid Acid Test\".\nIn 2005, the city council unanimously approved a new slogan for the city: \"World's Greatest City for the Arts &amp; Outdoors\". While Eugene has a vibrant arts community for a city its size, and is well situated near many outdoor opportunities, this slogan was frequently criticized by locals as embarrassing and ludicrous. In early 2010, the slogan was changed to \"A Great City for the Arts &amp; Outdoors.\"\nEugene's Saturday Market, open every Saturday from April through November, was founded in 1970 as the first \"Saturday Market\" in the United States. It is adjacent to the Lane County Farmer's Market in downtown Eugene. All vendors must create or grow all their own products. The market reappears as the \"Holiday Market\" between Thanksgiving and New Year's in the Lane County Events Center at the fairgrounds.\nCommunity.\nEugene is noted for its \"community inventiveness.\" Many U.S. trends in community development originated in Eugene. The University of Oregon's participatory planning process, known as The Oregon Experiment, was the result of student protests in the early 1970s. The book of the same name is a major document in modern enlightenment thinking in planning and architectural circles. The process, still used by the university in modified form, was created by Christopher Alexander, whose works also directly inspired the creation of the Wiki. Some research for the book \"A Pattern Language\", which inspired the Design Patterns movement and Extreme Programming, was done by Alexander in Eugene. Not coincidentally, those engineering movements also had origins here. Decades after its publication, \"A Pattern Language\" is still one of the best-selling books on urban design.\nIn the 1970s, Eugene was packed with cooperative and community projects. It still has small natural food stores in many neighborhoods, some of the oldest student cooperatives in the country, and alternative schools have been part of the school district since 1971. The old Grower's Market, downtown near the Amtrak depot, is the only food cooperative in the U.S. with no employees. It is possible to see Eugene's trend-setting non-profit tendencies in much newer projects, such as Square One Villages and the Center for Appropriate Transport. In 2006, an initiative began to create a tenant-run development process for downtown Eugene.\nIn the fall of 2003, neighbors noticed \"an unassuming two-acre remnant orchard tucked into the Friendly Area Neighborhood\" had been put up for sale by its owner, a resident of New York City. Learning a prospective buyer had plans to build several houses on the property, they formed a nonprofit organization called Madison Meadow in June 2004 in order to buy the property and \"preserve it as undeveloped space in perpetuity.\" In 2007 their effort was named Third Best Community Effort by the \"Eugene Weekly\", and by the end of 2008 they had raised enough money to purchase the property.\nThe City of Eugene has an active Neighborhood Program. Several neighborhoods are known for their green activism. Friendly Neighborhood has a highly popular neighborhood garden established on the right of way of a street never built. There are a number of community gardens on public property. Amazon Neighborhood has a former church turned into a community center. Whiteaker hosts a housing co-op that dates from the early 1970s that has re-purposed both their parking lots into food production and play space. An unusual eco-village with natural building techniques and large shared garden can be found in Jefferson Westside neighborhood. A several block area in the River Road Neighborhood is known as a permaculture hotspot with an increasing number of suburban homes trading grass for garden, installing rain water catchment systems, food producing landscapes and solar retrofits. Several sites have planted gardens by removing driveways. Citizen volunteers are working with the City of Eugene to restore a 65-tree filbert grove on public property. There are deepening social and economic networks in the neighborhood.\nMuseums.\nEugene museums include the University of Oregon's Jordan Schnitzer Museum of Art and Museum of Natural and Cultural History, the Oregon Air and Space Museum, Lane County History Museum, Maude Kerns Art Center, Shelton McMurphey Johnson House, and the Eugene Science Center.\nPerforming arts.\nEugene is home to numerous cultural organizations, including the Eugene Symphony (whose previous music directors include Marin Alsop, Giancarlo Guerrero, and Miguel Harth-Bedoya); the Eugene Ballet, a professional full-time touring company; the Eugene Opera, the Eugene Concert Choir, the Bushnell University Community Choir, the Oregon Mozart Players, the Oregon Bach Festival, the Oregon Children's Choir, the Eugene-Springfield Youth Orchestras, Ballet Fantastique and Oregon Festival of American Music. Principal performing arts venues include the Hult Center for the Performing Arts, The John G. Shedd Institute for the Arts (\"The Shedd\"), the McDonald Theatre, and W.O.W. Hall.\nThe University of Oregon School of Music and Dance also attracts world class performers and teaching artists throughout the year, many of whom perform at Beall Concert Hall. The university campus also frequently hosts performances at Matthew Knight Arena and the Erb Memorial Union ballroom.\nA number of live theater groups are based in Eugene, including Free Shakespeare in the Park, Oregon Contemporary Theatre, The Very Little Theatre, Actors Cabaret, LCC Theatre, Rose Children's Theatre, and University Theatre. Each has its own performance venue.\nMusic.\nBecause of its status as a college town, Eugene has been home to many music genres, musicians and bands, ranging from electronic dance music such as dubstep and drum and bass to garage rock, hip hop, folk and heavy metal. Eugene also has growing reggae and street-performing bluegrass and jug band scenes. Multi-genre act the Cherry Poppin' Daddies became a prominent figure in Eugene's music scene and became the house band at Eugene's W.O.W. Hall. In the late 1990s, their contributions to the swing revival movement propelled them to national stardom. Rock band Floater originated in Eugene as did the Robert Cray blues band. Doom metal band YOB is among the leaders of the Eugene heavy music scene.\nEugene is home to \"Classical Gas\" Composer and two-time Grammy award winner Mason Williams who spent his years as a youth living between his parents in Oakridge, Oregon and Oklahoma. Mason Williams puts on a yearly Christmas show at the Hult center for performing arts with a full orchestra produced by author, audio engineer and University of Oregon professor Don Latarski.\nDick Hyman, noted jazz pianist and musical director for many of Woody Allen's films, designs and hosts the annual Now Hear This! jazz festival at the Oregon Festival of American Music (OFAM). OFAM and the Hult Center routinely draw major jazz talent for concerts.\nEugene is also home to a large Zimbabwean music community. Kutsinhira Cultural Arts Center, which is \"dedicated to the music and people of Zimbabwe,\" is based in Eugene.\nVisual arts.\nEugene's visual arts community is supported by over 20 private art galleries and several organizations, including Maude Kerns Art Center, Lane Arts Council, DIVA (the Downtown Initiative for the Visual Arts) and the Eugene Glass School.\nIn 2015 installations from a group of Eugene-based artists known as Light At Play were showcased in several events around the world as part of the International Year of Light, including displays at the Smithsonian and the National Academy of Sciences.\nFilm.\nThe Eugene area has been used as a filming location for several Hollywood films, most famously for 1978's \"National Lampoon's Animal House\", which was also filmed in nearby Cottage Grove. John Belushi had the idea for the film \"The Blues Brothers\" during filming of \"Animal House\" when he happened to meet Curtis Salgado at what was then the Eugene Hotel.\n\"Getting Straight\", starring Elliott Gould and Candice Bergen, was filmed at Lane Community College in 1969. As the campus was still under construction at the time, the \"occupation scenes\" were easier to shoot.\nThe \"Chicken Salad on Toast\" scene in the 1970 Jack Nicholson movie \"Five Easy Pieces\" was filmed at the Denny's restaurant at the southern I-5 freeway interchange near Glenwood. Nicholson directed the 1971 film \"Drive, He Said\" in Eugene.\n\"How to Beat the High Co$t of Living\", starring Jane Curtin, Jessica Lange and Susan St. James, was filmed in Eugene in the fall of 1979. Locations visible in the film include Valley River Center (which is a driving force in the plot), Skinner Butte and Ya-Po-Ah Terrace, the Willamette River and River Road Hardware.\nSeveral track and field movies have used Eugene as a setting and/or a filming location. \"Personal Best\", starring Mariel Hemingway, was filmed in Eugene in 1982. The film centered on a group of women who are trying to qualify for the Olympic track and field team. Two track and field movies about the life of Steve Prefontaine, \"Prefontaine\" and \"Without Limits\", were released within a year of each other in 1997\u20131998. Kenny Moore, Eugene-trained Olympic runner and co-star in \"Prefontaine\", co-wrote the screenplay for \"Without Limits\". \"Prefontaine\" was filmed in Washington because the \"Without Limits\" production bought out Hayward Field for the summer to prevent its competition from shooting there. Kenny Moore also wrote a biography of Bill Bowerman, played in \"Without Limits\" by Donald Sutherland back in Eugene 20 years after he had appeared in \"Animal House\". Moore had also had a role in \"Personal Best\".\n\"Stealing Time\", a 2003 independent film, was partially filmed in Eugene. When the film premiered in June 2001 at the Seattle International Film Festival, it was titled \"Rennie's Landing\" after a popular bar near the University of Oregon campus. The title was changed for its DVD release. \"Zerophilia\" was filmed in Eugene in 2006.\nThe 2016 \"Tracktown\" was about a distance runner training for the Olympics in Eugene.\nReligion.\nReligious institutions of higher learning in Eugene include Bushnell University and New Hope Christian College. Bushnell University (formerly Northwest Christian University), founded in 1895, has ties with the Christian Church (Disciples of Christ). New Hope Christian College (formerly Eugene Bible College) originated with the Bible Standard Conference in 1915, which joined with Open Bible Evangelistic Association to create Open Bible Standard Churches in 1932. Eugene Bible College was started from this movement by Fred Hornshuh in 1925.\nThere are two Eastern Orthodox Church parishes in Eugene: St John the Wonderworker Orthodox Christian Church in the Historic Whiteaker Neighborhood and Saint George Greek Orthodox Church.\nThere are six Roman Catholic parishes in Eugene as well: St. Mary Catholic Church, St. Jude Catholic Church, St. Mark Catholic Church, St. Peter Catholic Church, St. Paul Catholic Church, and St. Thomas More Catholic Church.\nEugene also has a Ukrainian Catholic Church named Nativity of the Mother of God.\nThere is a mainline Protestant contingency in the city as well\u2014such as the largest of the Lutheran Churches, Central Lutheran near the U of O Campus and the Episcopal Church of the Resurrection.\nThe Eugene area has a sizeable LDS Church presence, with three stakes, consisting of 23 congregations (wards and branches). The Church of Jesus Christ announced plans in April 2020 to build a temple in Eugene.\nThe greater Eugene-Springfield area also has a Jehovah's Witnesses presence with five Kingdom Halls, several having multiple congregations in one Kingdom Hall.\nThe Reconstructionist Temple Beth Israel is Eugene's largest Jewish congregation. It was also, for many decades, Eugene's only synagogue, until Orthodox members broke away in 1992 and formed \"Congregation Ahavas Torah\".\nEugene has a community of some 140 Sikhs, who have established a Sikh temple.\nThe 340-member congregation of the Unitarian Universalist Church in Eugene (UUCE) purchased the former Eugene Scottish Rite Temple in May 2010, renovated it, and began services there in September 2012.\nSaraha Nyingma Buddhist Temple in Eugene opened in 2012 in the former site of the Unitarian Universalist Church.\nThe First Congregational Church, UCC is a large progressive Christian Church with a long history of justice focused ministries and a very active membership. Three years ago, the congregation coordinated with the Connections Program of the St Vincent DePaul organization to provide transitional homes for two unhoused families on the church's property. Through life - skills support and training and a more stable housing situation these families are then able to make their way into independent living.\nSports.\nEugene markets itself as \"Track Town USA\". There are close links between the University of Oregon's successful track &amp; field program, the Oregon Track Club, and Nike, Inc, who were founded by University of Oregon track athlete Phil Knight and his coach, Bill Bowerman.\nEugene's miles of running trails, through its unusually large park system, are among the most extensive in the U.S. Notable trails include Pre's Trail in Alton Baker Park, Rexius Trail, the Adidas Oregon Trail, and the Ridgeline Trail. There is also an extensive network of trails along the Willamette River that reaches into neighboring Springfield, as well as along Amazon Creek in the southern and western parts of town.\nJogging was introduced to the U.S. through Eugene, brought from New Zealand by Bill Bowerman, who wrote the best-selling book \"Jogging\", and coached the champion University of Oregon track and cross country teams. During Bowerman's tenure, his \"Men of Oregon\" won 24 individual NCAA titles, including titles in 15 out of the 19 events contested. During Bowerman's 24 years at Oregon, his track teams finished in the top ten at the NCAA championships 16 times, including four team titles (1962, '64, '65, '70), and two second-place trophies. His teams also posted a dual meet record of 114\u201320.\nBowerman also invented the waffle sole for running shoes in Eugene, and with Oregon alumnus Phil Knight founded shoe giant Nike. The city has dozens of running clubs. The climate is cool and temperate, good both for jogging and record-setting. Eugene is home to the University of Oregon's Hayward Field track, which hosts numerous collegiate and amateur track and field meets throughout the year, most notably the Prefontaine Classic. Hayward Field was host to the 2004 AAU Junior Olympic Games, the 1989 World Masters Athletics Championships, the track and field events of the 1998 World Masters Games, the 2006 Pacific-10 track and field championships, the 1971, 1975, 1986, 1993, 1999, 2001, 2009, and 2011 USA Track &amp; Field Outdoor Championships and the 1972, 1976, 1980, 2008, 2012, and 2016 U.S. Olympic trials. Eugene is the host of the delayed 2021 World Athletics Championships. The city bid for the 2019 event but lost narrowly to Doha, Qatar.\nEugene's Oregon Ducks are part of the Pac-12 Conference (Pac-12). American football is especially popular, with intense rivalries between the Ducks and both the Oregon State University Beavers and the University of Washington Huskies. Autzen Stadium is home to Duck football, with a seating capacity of 54,000 but has had over 60,000 with standing room only. The basketball arena, McArthur Court, was built in 1926. The arena was replaced by the Matthew Knight Arena in late 2010.\nThe Nationwide Tour's golfing event Oregon Classic takes place at Shadow Hills Country Club, just north of Eugene. The event has been played every year since 1998, except in 2001 when it was slated to begin the day after the 9/11 terrorist attacks. The top 20 players from the Nationwide Tour are promoted to the PGA Tour for the following year.\nEugene is also home to the Eugene Emeralds, a short-season Class A minor-league baseball team. The \"Ems\" play their home games in PK Park, also the home of the University of Oregon baseball team. The Eugene Jr. Generals, a Tier III Junior \"A\" ice hockey team belonging to the Northern Pacific Hockey League (NPHL) consisting of 8 teams throughout Oregon and Washington, plays at the Lane County Ice Center. Lane United FC, a soccer club that participates in the Northwest Division of USL League Two, was founded in 2013 and plays its home games at Civic Park.\nThe following table lists some sports clubs in Eugene and their usual home venue:\nParks and recreation.\nSpencer Butte Park at the southern edge of town provides access to Spencer Butte, a dominant feature of Eugene's skyline. Hendricks Park, situated on a knoll to the east of downtown, is known for its rhododendron garden and nearby memorial to Steve Prefontaine, known as Pre's Rock, where the legendary University of Oregon runner was killed in an auto accident. Alton Baker Park, next to the Willamette River, contains Pre's Trail. Also next to the Willamette are Skinner Butte Park and the Owen Memorial Rose Garden, which contains more than 4,500 roses of over 400 varieties, as well as the 150-year-old Black Tartarian Cherry tree, an Oregon Heritage Tree.\nThe city of Eugene maintains an urban forest. The University of Oregon campus is an arboretum, with over 500 species of trees. The city operates and maintains scenic hiking trails that pass through and across the ridges of a cluster of hills in the southern portion of the city, on the fringe of residential neighborhoods. Some trails allow biking, and others are for hikers and runners only.\nThe nearest ski resort, Willamette Pass, is one hour from Eugene by car. On the way, along Oregon Route 58, are several reservoirs and lakes, the Oakridge mountain bike trails, hot springs, and waterfalls within Willamette National Forest. Eugene residents also frequent the Hoodoo and Mount Bachelor ski resorts. The Three Sisters Wilderness, the Oregon Dunes National Recreation Area, and Smith Rock are just a short drive away.\nGovernment.\nIn 1944, Eugene adopted a council\u2013manager form of government, replacing the day-to-day management of city affairs by the part-time mayor and volunteer city council with a full-time professional city manager. The subsequent history of Eugene city government has largely been one of the dynamics\u2014often contentious\u2014between the city manager, the mayor and city council.\nAccording to statute, all Eugene and Lane County elections are officially non-partisan, with a primary containing all candidates in May. If a candidate gets more than 50% of the vote in the primary, they win the election outright, otherwise the top two candidates face off in a November runoff. This allows candidates to win seats during the lower-turnout primary election.\nThe mayor of Eugene is Lucy Vinis, who has been in office since winning the popular vote in May 2016, and who was re-elected in May 2020. Recent mayors include Edwin Cone (1958\u201369), Les Anderson (1969\u201377) Gus Keller (1977\u201384), Brian Obie (1985\u201388), Jeff Miller (1989\u201392), Ruth Bascom (1993\u201396), Jim Torrey (1997\u20132004) and Kitty Piercy (2005-2017).\nEugene City Council.\nMayor: Lucy Vinis\nPublic safety.\nThe Eugene Police Department is the city's law enforcement and public safety agency. The Lane County Sheriff's Office also has its headquarters in Eugene.\nThe University of Oregon is served by the University of Oregon Police Department, and Eugene Police Department also has a police station in the West University District near campus. Lane Community College is served by the Lane Community College Public Safety Department. The Oregon State Police have a presence in the rural areas and highways around the Eugene metro area. The LTD downtown station, and the EmX lines are patrolled by LTD Transit Officers. Since 1989 the mental health crisis intervention non-governmental agency CAHOOTS has responded to Eugene's mental health 911 calls.\nEugene-Springfield Fire Department is the agency responsible for emergency medical services, fire suppression, HAZMAT operations and water/Confined spaces rescues in the combined Eugene-Springfield metropolitan area.\nEugene used to have an ordinance which prohibited car horn usage for non-driving purposes. After several residents were cited for this offense during the anti-Gulf War demonstrations in January 1991, the city was taken to court and in 1992 the Oregon Court of Appeals overturned the ordinance, finding it unconstitutionally vague. Eugene City Hall was abandoned in 2012 for reasons of structural integrity, energy efficiency, and obsolete size. Various offices of city government became tenants in eight other buildings.\nPolitics.\nBeing the largest city by far in Lane County, Eugene's voters almost always decide the county's partisan tilt. While Eugene has historically been a counter-culture-heavy and left-leaning college town, the county's partisan leanings have intensified in recent decades, mirroring the general polarization of Oregon voters along urban (pro-Democratic) and rural (pro-Republican) lines.\nLane County voted for Bernie Sanders over eventual 2016 nominee Hillary Clinton by 60.6-38.1%, and Eugene offered Sanders an even larger share of its vote.\nEducation.\nEugene is home to the University of Oregon. Other institutions of higher learning include Bushnell University, Lane Community College, New Hope Christian College, Gutenberg College, and Pacific University's Eugene campus.\nSchools.\nThe Eugene School District includes four full-service high schools (Churchill, North Eugene, Sheldon, and South Eugene) and many alternative education programs, such as international schools and charter schools. Foreign language immersion programs in the district are available in Spanish, French, Chinese, and Japanese.\nThe Bethel School District serves children in the Bethel neighborhood on the northwest edge of Eugene. The district is home to the traditional Willamette High School and the alternative Kalapuya High School. There are 11 schools in this district.\nEugene also has several private schools, including the Eugene Waldorf School, the Outdoor High School, Eugene Montessori, Far Horizon Montessori, Eugene Sudbury School, Wellsprings Friends School, Oak Hill School, and The Little French School.\nParochial schools in Eugene include Marist Catholic High School, O'Hara Catholic Elementary School, Eugene Christian School, and St. Paul Parish School.\nLibraries.\nThe largest library in Oregon is the University of Oregon's Knight Library, with collections totaling more than 3 million volumes and over 100,000 audio and video items. The Eugene Public Library moved into a new, larger building downtown in 2002. The four-story library is an increase from . There are also two branches of the Eugene Public Library, the Sheldon Branch Library in the neighborhood of Cal Young/Sheldon, and the Bethel Branch Library, in the neighborhood of Bethel. Eugene also has the Lane County Law Library.\nMedia.\nPrint.\nThe largest newspaper serving the area is \"The Register-Guard\", a daily newspaper with a circulation of about 70,000, published independently by the Baker family of Eugene until 2018, before being acquired by GateHouse Media, (now owned by Gannett Company). Other newspapers serving the area include the \"Eugene Weekly\", the \"Emerald\", the student-run independent newspaper at the University of Oregon, now published on Mondays and Thursdays;\"The Torch\", the student-run newspaper at Lane Community College, the \"Ignite\", the newspaper at New Hope Christian College and \"The Beacon Bolt,\" the student-run newspaper at Bushnell University. \"Eugene Magazine\", \"Lifestyle Quarterly\", \"Eugene Living\", and \"Sustainable Home and Garden\" magazines also serve the area. \"Adelante Latino\" is a Spanish language newspaper in Eugene that serves all of Lane County.\nTelevision.\nLocal television stations include KMTR (NBC), KVAL (CBS), KLSR-TV (Fox), KEVU-CD, KEZI (ABC), KEPB (PBS), and KTVC (independent).\nRadio.\nThe local NPR affiliates are KOPB, and KLCC. Radio station KRVM-AM is an affiliate of Jefferson Public Radio, based at Southern Oregon University. The Pacifica Radio affiliate is the University of Oregon student-run radio station, KWVA. Additionally, the community supports two other radio stations: KWAX (classical) and KRVM-FM (alternative).\nAM stations\nFM stations\nInfrastructure.\nTransportation.\nBus.\nLane Transit District (LTD), a public transportation agency formed in 1970, covers of Lane County, including Creswell, Cottage Grove, Junction City, Veneta, and Blue River. Operating more than 90 buses during peak hours, LTD carries riders on 3.7 million trips every year. LTD also operates a bus rapid transit line that runs between Eugene and Springfield\u2014Emerald Express (EmX)\u2014much of which runs in its own lane, with stations providing for off-board fare payment. LTD's main terminus in Eugene is at the Eugene Station. LTD also offers paratransit.\nGreyhound Lines provides service between Los Angeles and Portland on the I-5 corridor.\nCycling.\nCycling is popular in Eugene and many people commute via bicycle. Summertime events and festivals frequently have valet bicycle parking corrals that are often filled to capacity by three hundred or more bikes. Many people commute to work by bicycle every month of the year. PeaceHealth Rides, a bike share system formerly operated by Uber subsidiary JUMP, and currently operated by non-profit Cascadia Mobility, offers 300 city-owned bicycles available to the public for a small fee. Bike trails take commuting and recreational bikers along the Willamette River past a scenic rose garden, along Amazon Creek, through the downtown, and through the University of Oregon campus. Eugene is close to many popular mountain bike trails, and Disciples of Dirt is the local mountain bike club that organizes group rides and promotes trail stewardship.\nIn 2009, the League of American Bicyclists cited Eugene as 1 of 10 \"Gold-level\" cities in the U.S. because of its \"remarkable commitments to bicycling.\" In 2010, \"Bicycling\" magazine named Eugene the 5th most bike-friendly city in America. The U.S. Census Bureau's annual American Community Survey reported that Eugene had a bicycle commuting mode share of 7.3% in 2011, the fifth highest percentage nationwide among U.S. cities with 65,000 people or more, and 13 times higher than the national average of 0.56%.\nRail.\nThe 1908 Amtrak depot downtown was restored in 2004; it is the southern terminus for two daily runs of the Amtrak \"Cascades\", and a stop along the route in each direction for the daily \"Coast Starlight\".\nAir travel.\nAir travel is served by the Eugene Airport, also known as Mahlon Sweet Field, which is the fifth largest airport in the Northwest and second largest airport in Oregon. The Eugene Metro area also has numerous private airports. The Eugene Metro area also has several heliports, such as the Sacred Heart Medical Center Heliport and Mahlon Sweet Field Heliport, and many single helipads.\nHighways.\nHighways traveling within and through Eugene include:\nUtilities.\nEugene is the home of Oregon's largest publicly owned water and power utility, the Eugene Water &amp; Electric Board (EWEB). EWEB got its start in the first decade of the 20th century, after an epidemic of typhoid found in the groundwater supply. The City of Eugene condemned Eugene's private water utility and began treating river water (first the Willamette; later the McKenzie) for domestic use. EWEB got into the electric business when power was needed for the water pumps. Excess electricity generated by the EWEB's hydropower plants was used for street lighting.\nNatural gas service is provided by NW Natural.\nWastewater treatment services are provided by the Metropolitan Wastewater Management Commission, a partnership between the Cities of Eugene and Springfield and Lane County.\nHealthcare.\nThree hospitals serve the Eugene-Springfield area. Sacred Heart Medical Center University District is the only one within Eugene city limits. McKenzie-Willamette Medical Center and Sacred Heart Medical Center at RiverBend are in Springfield. Oregon Medical Group, a primary care based multi-specialty group, operates several clinics in Eugene, as does PeaceHealth Medical Group. White Bird Clinic provides a broad range of health and human services, including low-cost clinics. The Volunteers in Medicine &amp; Occupy Medical clinics provide free medical and mental care to low-income adults without health insurance.\nEugene is one of the few municipalities in the US that does not fluoridate its water supply.\nSister cities.\nEugene has four sister cities:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9624", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9624", "title": "Early Music", "text": ""}
{"id": "9625", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=9625", "title": "Eigenstate", "text": ""}
{"id": "9627", "revid": "45969386", "url": "https://en.wikipedia.org/wiki?curid=9627", "title": "Elizabeth Barrett Browning", "text": "English poet (1806\u20131861)\nElizabeth Barrett Browning (n\u00e9e Moulton-Barrett; 6 March 1806 \u2013 29 June 1861) was an English poet of the Victorian era, popular in Britain and the United States during her lifetime.\nBorn in County Durham, the eldest of 12 children, Elizabeth Barrett wrote poetry from the age of eleven. Her mother's collection of her poems forms one of the largest extant collections of juvenilia by any English writer. At 15, she became ill, suffering intense head and spinal pain for the rest of her life. Later in life, she also developed lung problems, possibly tuberculosis. She took laudanum for the pain from an early age, which is likely to have contributed to her frail health.\nIn the 1840s, Elizabeth was introduced to literary society through her distant cousin and patron John Kenyon. Her first adult collection of poems was published in 1838, and she wrote prolifically between 1841 and 1844, producing poetry, translation, and prose. She campaigned for the abolition of slavery, and her work helped influence reform in the child labour legislation. Her prolific output made her a rival to Tennyson as a candidate for poet laureate on the death of Wordsworth.\nElizabeth's volume \"Poems\" (1844) brought her great success, attracting the admiration of the writer Robert Browning. Their correspondence, courtship, and marriage were carried out in secret, for fear of her father's disapproval. Following the wedding, she was indeed disinherited by her father. In 1846, the couple moved to Italy, where she would live for the rest of her life. They had a son, known as \"Pen\" (Robert Wiedeman Barrett Browning) (1849\u20131912). Pen devoted himself to painting until his eyesight began to fail later in life; he also built up a large collection of manuscripts and memorabilia of his parents; however, since he died intestate, it was sold by public auction to various bidders, and scattered upon his death. The Armstrong Browning Library has tried to recover some of his collection, and now houses the world's largest collection of Browning memorabilia. Elizabeth died in Florence in 1861. A collection of her last poems was published by her husband shortly after her death.\nElizabeth's work had a major influence on prominent writers of the day, including the American poets Edgar Allan Poe and Emily Dickinson. She is remembered for such poems as \"How Do I Love Thee?\" (Sonnet 43, 1845) and \"Aurora Leigh \"(1856).\nLife and career.\nFamily background.\nSome of Elizabeth Barrett's family had lived in Jamaica since 1655. Their wealth derived mainly from slave labour from their plantations in the Caribbean. Edward Barrett (1734\u20131798) was owner of in the estates of Cinnamon Hill, Cornwall, Cambridge, and Oxford in northern Jamaica. Elizabeth's maternal grandfather owned sugar plantations farmed by slaves they bought from Africa, mills, glassworks, and ships that traded between Jamaica and Newcastle in the United Kingdom.\nThe family wished to hand down their name, stipulating that Barrett should always be held as a surname. In some cases inheritance was given on condition that the name was used by the beneficiary; the English gentry and \"squirearchy\" had long encouraged this sort of name changing. Given this strong tradition, Elizabeth used \"Elizabeth Barrett Moulton Barrett\" on legal documents, and before she was married often signed herself \"Elizabeth Barrett Barrett\" or \"EBB\" (initials which she was able to keep after her wedding). Elizabeth's father chose to raise his family in England, while his business enterprises remained in Jamaica. Elizabeth's mother, Mary Graham Clarke, also owned plantations farmed by enslaved people in the British West Indies.\nEarly life.\nElizabeth Barrett Moulton-Barrett was born on (it is supposed) 6 March 1806, in Coxhoe Hall, between the villages of Coxhoe and Kelloe in County Durham, England. Her parents were Edward Barrett Moulton-Barrett and Mary Graham Clarke. However, it has been suggested that, when she was christened on 9 March, she was already three or four months old, and that this was concealed because her parents had married only on 14 May 1805. Although she had already been baptised by a family friend in that first week of her life, she was baptised again, more publicly, on 10 February 1808 at Kelloe parish church, at the same time as her younger brother, Edward (known as \"Bro\"). He had been born in June 1807, only fifteen months after Elizabeth's stated date of birth. A private christening might seem unlikely for a family of standing and, while Bro's birth was celebrated with a holiday on the family's Caribbean plantations, Elizabeth's was not.\nElizabeth was the eldest of 12 children (eight boys and four girls). Eleven lived to adulthood; one daughter died at the age of three, when Elizabeth was eight. The children all had nicknames: Elizabeth was \"Ba\". She rode her pony, went for family walks and picnics, socialised with other county families, and participated in home theatrical productions. But unlike her siblings, she immersed herself in books as often as she could get away from the social rituals of her family.\nIn 1809, the family moved to Hope End, a estate near the Malvern Hills in Ledbury, Herefordshire. Her father converted the Georgian house into stables and built a new mansion of opulent Turkish design, which his wife described as something from the \"Arabian Nights Entertainments\".\nThe interior's brass balustrades, mahogany doors inlaid with mother-of-pearl, and finely carved fireplaces were eventually complemented by lavish landscaping: ponds, grottos, kiosks, an ice house, a hothouse, and a subterranean passage from house to gardens. Her time at Hope End would inspire her in later life to write her most ambitious work, \"Aurora Leigh\" (1856), which went through more than 20 editions by 1900, but none between 1905 and 1978.\nShe was educated at home and tutored by Daniel McSwiney with her oldest brother. She began writing verses at the age of four. During the Hope End period, she was an intensely studious, precocious child. She claimed that at the age of six, she was reading novels, at eight entranced by Pope's translations of Homer, studying Greek at ten, and at eleven, writing her own Homeric epic, \"\".\nIn 1820, Mr Barrett privately published \"The Battle of Marathon\", an epic-style poem, though all copies remained within the family. Her mother compiled the child's poetry into collections of \"Poems by Elizabeth B. Barrett\". Her father called her the \"Poet Laureate of Hope End\" and encouraged her work. The result is one of the largest collections of juvenilia of any English writer. Mary Russell Mitford described the young Elizabeth at this time, as having \"a slight, delicate figure, with a shower of dark curls falling on each side of a most expressive face; large, tender eyes, richly fringed by dark eyelashes, and a smile like a sunbeam.\"\nAt about this time, Elizabeth began to battle an illness, which the medical science of the time was unable to diagnose. All three sisters came down with the syndrome although it lasted only with Elizabeth. She had intense head and spinal pain with loss of mobility. Various biographies link this to a riding accident at the time (she fell while trying to dismount a horse), but there is no evidence to support the link. Sent to recover at the Gloucester spa, she was treated \u2013 in the absence of symptoms supporting another diagnosis \u2013 for a spinal problem. Though this illness continued for the rest of her life, it is believed to be unrelated to the lung disease which she developed in 1837.\nShe began to take opiates for the pain, laudanum (an opium concoction) followed by morphine, then commonly prescribed. She would become dependent on them for much of her adulthood; the use from an early age may well have contributed to her frail health. Biographers such as Alethea Hayter have suggested this may also have contributed to the wild vividness of her imagination and the poetry that it produced.\nBy 1821, she had read Mary Wollstonecraft's \"A Vindication of the Rights of Woman\" (1792), and become a passionate supporter of Wollstonecraft's political ideas. The child's intellectual fascination with the classics and metaphysics was reflected in a religious intensity which she later described as \"not the deep persuasion of the mild Christian but the wild visions of an enthusiast.\" The Barretts attended services at the nearest Dissenting chapel, and Edward was active in Bible and missionary societies.\nElizabeth's mother died in 1828, and is buried at St Michael's Church, Ledbury, next to her daughter Mary. Sarah Graham-Clarke, Elizabeth's aunt, helped to care for the children, and she had clashes with Elizabeth's strong will. In 1831, Elizabeth's grandmother, Elizabeth Moulton, died. Following lawsuits and the abolition of slavery, Mr Barrett incurred great financial and investment losses that forced him to sell Hope End. Although the family was never poor, the place was seized, and put up for sale to satisfy creditors. Always secret in his financial dealings, he would not discuss his situation and the family was haunted by the idea that they might have to move to Jamaica.\nBetween 1833 and 1835, she was living with her family at Belle Vue in Sidmouth. The site has now been renamed Cedar Shade and redeveloped. A blue plaque at the entrance to the site attests to this. In 1838, some years after the sale of Hope End, the family settled at 50 Wimpole Street.\nDuring 1837\u201338, the poet was struck with illness again, with symptoms today suggesting tuberculous ulceration of the lungs. That same year, at her physician's insistence, she moved from London to Torquay, on the Devonshire coast. Her former home now forms part of the Regina Hotel. Two tragedies then struck. In February 1840, her brother Samuel died of a fever in Jamaica. Then her favourite brother Edward (\"Bro\") was drowned in a sailing accident in Torquay in July. This had a serious effect on her already fragile health. She felt guilty as her father had disapproved of Edward's trip to Torquay. She wrote to Mitford, \"That was a very near escape from madness, absolute hopeless madness\". The family returned to Wimpole Street in 1841.\nSuccess.\nAt Wimpole Street, Elizabeth spent most of her time in her upstairs room. Her health began to improve, though she saw few people other than her immediate family. One of those was John Kenyon, a wealthy friend and distant cousin of the family and patron of the arts. She received comfort from a spaniel named Flush, a gift from Mary Mitford. (Virginia Woolf later fictionalised the life of the dog, making him the protagonist of her 1933 novel \"\").\nBetween 1841 and 1844, Elizabeth was prolific in poetry, translation, and prose. The poem \"The Cry of the Children\", published in 1842 in \"Blackwood's\", condemned child labour and helped bring about child-labour reforms by raising support for Lord Shaftesbury's Ten Hours Bill (1844). At about the same time, she contributed critical prose pieces to Richard Henry Horne's \"A New Spirit of the Age\", including a laudatory essay on Thomas Carlyle.\nIn 1844, she published the two-volume \"Poems\", which included \"A Drama of Exile\", \"A Vision of Poets\", and \"Lady Geraldine's Courtship\", and two substantial critical essays for 1842 issues of \"The Athenaeum\". A self-proclaimed \"adorer of Carlyle\", she sent a copy to him as \"a tribute of admiration &amp; respect\", which began a correspondence between them. \"Since she was not burdened with any domestic duties expected of her sisters, Barrett Browning could now devote herself entirely to the life of the mind, cultivating an enormous correspondence, reading widely\". Her prolific output made her a rival to Tennyson as a candidate for poet laureate in 1850 on the death of Wordsworth.\nA Royal Society of Arts blue plaque now commemorates Elizabeth at 50 Wimpole Street.\nRobert Browning and Italy.\nHer 1844 volume \"Poems\" made her one of the most popular writers in the country, and inspired Robert Browning to write to her. He wrote, \"I love your verses with all my heart, dear Miss Barrett,\" praising their \"fresh strange music, the affluent language, the exquisite pathos and true new brave thought.\"\nKenyon arranged for Browning to meet Elizabeth on 20 May 1845, in her rooms, and so began one of the most famous courtships in literature. Elizabeth had already produced a large amount of work, but Browning had a great influence on her subsequent writing, as did she on his: two of Barrett's most famous pieces were written after she met Browning, \"Sonnets from the Portuguese\" and \"Aurora Leigh\". Robert's \"Men and Women\" is also a product of that time.\nSome critics state that her activity was, in some ways, in decay before she met Browning: \"Until her relationship with Robert Browning began in 1845, Barrett's willingness to engage in public discourse about social issues and about aesthetic issues in poetry, which had been so strong in her youth, gradually diminished, as did her physical health. As an intellectual presence and a physical being, she was becoming a shadow of herself.\"\nThe courtship and marriage between Robert Browning and Elizabeth were carried out secretly, as she knew her father would disapprove. After a private marriage at St Marylebone Parish Church, they honeymooned in Paris before moving, in September 1846, to Italy, which became their home almost continuously until her death. Elizabeth's loyal lady's maid, Elizabeth Wilson, witnessed the marriage and accompanied the couple to Italy.\nMr Barrett disinherited Elizabeth, as he did each of his children who married. Elizabeth had foreseen her father's anger but had not anticipated her brothers' rejection. As Elizabeth had some money of her own, the couple were reasonably comfortable in Italy. The Brownings were well respected, and even famous. Elizabeth grew stronger and in 1849, at the age of 43, between four miscarriages, she gave birth to a son, Robert Wiedeman Barrett Browning, whom they called Pen. Their son later married, but had no legitimate children.\nAt her husband's insistence, Elizabeth's second edition of \"Poems\" included her love sonnets; as a result, her popularity increased (as did critical regard), and her artistic position was confirmed. During the years of her marriage, her literary reputation far surpassed that of her poet-husband; when visitors came to their home in Florence, she was invariably the greater attraction.\nThe couple came to know a wide circle of artists and writers including William Makepeace Thackeray, sculptor Harriet Hosmer (who, she wrote, seemed to be the \"perfectly emancipated female\") and Harriet Beecher Stowe. In 1849, she met Margaret Fuller; Carlyle, in 1851; in 1852, French novelist George Sand, whom she had long admired. Among her intimate friends in Florence was the writer Isa Blagden, whom she encouraged to write novels. They met Alfred Tennyson in Paris, and John Forster, Samuel Rogers and the Carlyles in London, later befriending Charles Kingsley and John Ruskin.\nDecline and death.\nAfter the death of an old friend, G. B. Hunter, and then of her father, Barrett Browning's health started to deteriorate. The Brownings moved from Florence to Siena, residing at the \"Villa Alberti\". Engrossed in Italian politics, she issued a small volume of political poems titled \"Poems before Congress\" (1860) \"most of which were written to express her sympathy with the Italian cause after the outbreak of fighting in 1859\". They caused a furore in England, and the conservative magazines \"Blackwood's\" and the \"Saturday Review\" labelled her a fanatic. She dedicated this book to her husband. Her last work was \"A Musical Instrument\", published posthumously.\nBarrett Browning's sister Henrietta died in November 1860. The couple spent the winter of 1860\u201361 in Rome where Barrett Browning's health further deteriorated and they returned to Florence in early June 1861. She became gradually weaker, using morphine to ease her pain. She died on 29 June 1861 in her husband's arms. Browning said that she died \"smilingly, happily, and with a face like a girl's... Her last word was... 'Beautiful' \". She was buried in the Protestant English Cemetery of Florence. \"On Monday July 1 the shops in the area around Casa Guidi were closed, while Elizabeth was mourned with unusual demonstrations.\" The nature of her illness is still unclear. Some modern scientists speculate her illness may have been hypokalemic periodic paralysis, a genetic disorder that causes weakness and many of the other symptoms she described.\nPublications.\nBarrett Browning's first known poem was written at the age of six or eight, \"On the Cruelty of Forcement to Man\". The manuscript, which protests against impressment, is currently in the Berg Collection of the New York Public Library; the exact date is controversial because the \"2\" in the date 1812 is written over something else that is scratched out.\nHer first independent publication was \"Stanzas Excited by Reflections on the Present State of Greece\" in \"The New Monthly Magazine\" of May 1821; followed two months later by \"Thoughts Awakened by Contemplating a Piece of the Palm which Grows on the Summit of the Acropolis at Athens\".\nHer first collection of poems, \"An Essay on Mind, with Other Poems,\" was published in 1826 and reflected her passion for Byron and Greek politics. Its publication drew the attention of a blind scholar of the Greek language, Hugh Stuart Boyd, and of another Greek scholar, Uvedale Price, with whom she maintained sustained correspondence. Among other neighbours was Mrs James Martin from Colwall, with whom she also corresponded throughout her life. Later, at Boyd's suggestion, she translated Aeschylus' \"Prometheus Bound\" (published in 1833; retranslated in 1850). During their friendship Barrett studied Greek literature, including Homer, Pindar and Aristophanes.\nElizabeth opposed slavery and published two poems highlighting the barbarity of the institution and her support for the abolitionist cause: \"The Runaway Slave at Pilgrim's Point\" and \"A Curse for a Nation\". The first depicts an enslaved woman whipped, raped, and made pregnant cursing her enslavers. Elizabeth declared herself glad that the slaves were \"virtually free\" when the Slavery Abolition Act passed in the British Parliament, despite the fact that her father believed that abolition would ruin his business.\nThe date of publication of these poems is in dispute, but her position on slavery in the poems is clear and may have led to a rift between Elizabeth and her father. She wrote to John Ruskin in 1855 \"I belong to a family of West Indian slaveholders, and if I believed in curses, I should be afraid\". Her father and uncle were unaffected by the Baptist War (1831\u20131832) and continued to own slaves until passage of the Slavery Abolition Act.\nIn London, John Kenyon introduced Elizabeth to literary figures including William Wordsworth, Mary Russell Mitford, Samuel Taylor Coleridge, Alfred Tennyson and Thomas Carlyle. Elizabeth continued to write, contributing \"The Romaunt of Margaret\", \"The Romaunt of the Page\", \"The Poet's Vow\" and other pieces to various periodicals. She corresponded with other writers, including Mary Russell Mitford, who would become a close friend and who would support Elizabeth's literary ambitions.\nIn 1838 \"The Seraphim and Other Poems\" appeared, the first volume of Elizabeth's mature poetry to appear under her own name.\n\"Sonnets from the Portuguese\" was published in 1850. There is debate about the origin of the title. Some say it refers to the series of sonnets of the 16th-century Portuguese poet Lu\u00eds de Cam\u00f5es. However, \"my little Portuguese\" was a pet name that Browning had adopted for Elizabeth and this may have some connection.\nThe verse-novel \"Aurora Leigh,\" her most ambitious and perhaps the most popular of her longer poems, appeared in 1856. It is the story of a female writer making her way in life, balancing work and love, and based on Elizabeth's own experiences. \"Aurora Leigh\" was an important influence on Susan B. Anthony's thinking about the traditional roles of women, with regard to marriage versus independent individuality. The \"North American Review\" praised Elizabeth's poem: \"Mrs. Browning's poems are, in all respects, the utterance of a woman \u2014 of a woman of great learning, rich experience, and powerful genius, uniting to her woman's nature the strength which is sometimes thought peculiar to a man.\"\nSpiritual influence.\nMuch of Barrett Browning's work carries a religious theme. She had read and studied such works as Milton's \"Paradise Lost\" and Dante's \"Inferno\". She says in her writing, \"We want the sense of the saturation of Christ's blood upon the souls of our poets, that it may cry through them in answer to the ceaseless wail of the Sphinx of our humanity, expounding agony into renovation. Something of this has been perceived in art when its glory was at the fullest. Something of a yearning after this may be seen among the Greek Christian poets, something which would have been much with a stronger faculty\". She believed that \"Christ's religion is essentially poetry \u2013 poetry glorified\". She explored the religious aspect in many of her poems, especially in her early work, such as the sonnets.\nShe was interested in theological debate, had learned Hebrew and read the Hebrew Bible. Her seminal \"Aurora Leigh\", for example, features religious imagery and allusion to the apocalypse. The critic Cynthia Scheinberg notes that female characters in \"Aurora Leigh\" and her earlier work \"The Virgin Mary to the Child Jesus\" allude to Miriam, sister and caregiver to Moses. These allusions to Miriam in both poems mirror the way in which Barrett Browning herself drew from Jewish history, while distancing herself from it, in order to maintain the cultural norms of a Christian woman poet of the Victorian Age.\nIn the correspondence Barrett Browning kept with the Reverend William Merry from 1843 to 1844 on predestination and salvation by works, she identifies herself as a Congregationalist: \"I am not a Baptist \u2014 but a Congregational Christian, \u2014 in the holding of my private opinions.\"\nBarrett Browning Institute.\nIn 1892, Ledbury, Herefordshire, held a design competition to build an Institute in honour of Barrett Browning. Brightwen Binyon beat 44 other designs. It was based on the timber-framed Market House, which was opposite the site, and was completed in 1896. However, Nikolaus Pevsner was not impressed by its style. It was used as a public library from 1938, until new library facilities were provided for the town, and is now the headquarters of the Ledbury Poetry Festival. It has been Grade II-listed since 2007.\nCritical reception.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n&lt;poem&gt;\nHow Do I Love Thee?\nHow do I love thee? Let me count the ways.\nI love thee to the depth and breadth and height\nMy soul can reach, when feeling out of sight\nFor the ends of being and ideal grace.\nI love thee to the level of every day's\nMost quiet need, by sun and candle-light.\nI love thee freely, as men strive for right.\nI love thee purely, as they turn from praise.\nI love thee with the passion put to use\nIn my old griefs, and with my childhood's faith.\nI love thee with a love I seemed to lose\nWith my lost saints. I love thee with the breath,\nSmiles, tears, of all my life; and, if God choose,\nI shall but love thee better after death.\n&lt;/poem&gt;\n Sonnet XLIII from \"Sonnets from the Portuguese\", 1845 (published 1850)\nBarrett Browning was widely popular in the United Kingdom and the United States during her lifetime. Edgar Allan Poe was inspired by her poem \"Lady Geraldine's Courtship\" and specifically borrowed the poem's metre for his poem \"The Raven\". Poe had reviewed Barrett Browning's work in the January 1845 issue of the \"Broadway Journal\", saying that \"her poetic inspiration is the highest \u2013 we can conceive of nothing more august. Her sense of Art is pure in itself.\" In return, she praised \"The Raven\", and Poe dedicated his 1845 collection \"The Raven and Other Poems\" to her, referring to her as \"the noblest of her sex\".\nBarrett Browning's poetry greatly influenced Emily Dickinson, who admired her as a woman of achievement. Her popularity in the United States and Britain was further advanced by her stands against social injustice, including slavery in the United States, injustice toward Italians from their foreign rulers, and child labour.\nLilian Whiting published a biography of Barrett Browning (1899) which describes her as \"the most philosophical poet\" and depicts her life as \"a Gospel of applied Christianity\". To Whiting, the term \"art for art's sake\" did not apply to Barrett Browning's work, as each poem, distinctively purposeful, was borne of a more \"honest vision\". In this critical analysis, Whiting portrays Barrett Browning as a poet who uses knowledge of Classical literature with an \"intuitive gift of spiritual divination\". In \"Elizabeth Barrett Browning\", Angela Leighton suggests that the portrayal of Barrett Browning as the \"pious iconography of womanhood\" has distracted us from her poetic achievements. Leighton cites the 1931 play by Rudolf Besier \"The Barretts of Wimpole Street\" as evidence that 20th-century literary criticism of Barrett Browning's work has suffered more as a result of her popularity than poetic ineptitude. The play was popularized by actress Katharine Cornell, for whom it became a signature role. It was an enormous success, both artistically and commercially, and was revived several times and adapted twice into movies. Sampson, however, considers the play to have been the most damaging cause of false myths about Elizabeth, and particularly the relationship with her, allegedly 'tyrannical', father.\nThroughout the 20th century, literary criticism of Barrett Browning's poetry remained sparse until her poems were discovered by the women's movement. She once described herself as being inclined to reject several women's rights principles, suggesting in letters to Mary Russell Mitford and her husband that she believed that there was an inferiority of intellect in women. In \"Aurora Leigh\", however, she created a strong and independent woman who embraces both work and love. Leighton writes that because Elizabeth participates in the literary world, where voice and diction are dominated by perceived masculine superiority, she \"is defined only in mysterious opposition to everything that distinguishes the male subject who writes...\" A five-volume scholarly edition of her works was published in 2010, the first in over a century.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9628", "revid": "9813438", "url": "https://en.wikipedia.org/wiki?curid=9628", "title": "Enlil", "text": "Ancient Mesopotamian god\nEnlil, later known as Elil, is an ancient Mesopotamian god associated with wind, air, earth, and storms. He is first attested as the chief deity of the Sumerian pantheon, but he was later worshipped by the Akkadians, Babylonians, Assyrians, and Hurrians. Enlil's primary center of worship was the Ekur temple in the city of Nippur, which was believed to have been built by Enlil himself and was regarded as the \"mooring-rope\" of heaven and earth. He is also sometimes referred to in Sumerian texts as Nunamnir. According to one Sumerian hymn, Enlil himself was so holy that not even the other gods could look upon him. Enlil rose to prominence during the twenty-fourth century BC with the rise of Nippur. His cult fell into decline after Nippur was sacked by the Elamites in 1230 BC and he was eventually supplanted as the chief god of the Mesopotamian pantheon by the Babylonian national god Marduk.\nEnlil plays a vital role in the Sumerian creation myth; he separates An (heaven) from Ki (earth), thus making the world habitable for humans. In the Sumerian flood myth, Enlil rewards Ziusudra with immortality for having survived the flood and, in the Babylonian flood myth, Enlil is the cause of the flood himself, having sent the flood to exterminate the human race, who made too much noise and prevented him from sleeping. The myth of \"Enlil and Ninlil\" is about Enlil's serial seduction of the goddess Ninlil in various guises, resulting in the conception of the moon-god Nanna and the Underworld deities Nergal, Ninazu, and Enbilulu. Enlil was regarded as the inventor of the mattock and the patron of agriculture. Enlil also features prominently in several myths involving his son Ninurta, including \"Anz\u00fb and the Tablet of Destinies\" and \"Lugale\".\nEtymology.\nEnlil's name comes from ancient Sumerian EN (\ud808\udc97), meaning \"lord\" and L\u00cdL (\ud808\udda4), the meaning of which is contentious, and which has sometimes been interpreted as meaning winds as a weather phenomenon (making Enlil a weather and sky god, \"Lord Wind\" or \"Lord Storm\"), or alternatively as signifying a spirit or phantom whose presence may be felt as stirring of the air, or possibly as representing a partial Semitic loanword rather than a Sumerian word at all. Enlil's name is not a genitive construction, suggesting that Enlil was seen as the personification of L\u00cdL rather than merely the cause of L\u00cdL.\nPiotr Steinkeller has written that the meaning of L\u00cdL may not actually be a clue to a specific divine domain of Enlil's, whether storms, spirits, or otherwise, since Enlil may have been \"a typical universal god [...] without any specific domain.\"\nWorship.\n&lt;templatestyles src=\"Rquote/styles.css\"/&gt;{ class=\"rquote pullquote floatright\" role=\"presentation\" style=\"display:table; border-collapse:collapse; border-style:none; float:right; margin:0.5em 0.75em; width:33%; \"\nEnlil was the patron god of the Sumerian city-state of Nippur and his main center of worship was the Ekur temple located there. The name of the temple literally means \"Mountain House\" in ancient Sumerian. The Ekur was believed to have been built and established by Enlil himself. It was believed to be the \"mooring-rope\" of heaven and earth, meaning that it was seen as \"a channel of communication between earth and heaven\". A hymn written during the reign of Ur-Nammu, the founder of the Third Dynasty of Ur, describes the E-kur in great detail, stating that its gates were carved with scenes of Imdugud, a lesser deity sometimes shown as a giant bird, slaying a lion and an eagle snatching up a sinner.\nThe Sumerians believed that the sole purpose of humanity's existence was to serve the gods. They thought that a god's statue was a physical embodiment of the god himself. As such, cult statues were given constant care and attention and a set of priests were assigned to tend to them. People worshipped Enlil by offering food and other human necessities to him. The food, which was ritually laid out before the god's cult statue in the form of a feast, was believed to be Enlil's daily meal, but, after the ritual, it would be distributed among his priests. These priests were also responsible for changing the cult statue's clothing.\nThe Sumerians envisioned Enlil as a benevolent, fatherly deity, who watches over humanity and cares for their well-being. One Sumerian hymn describes Enlil as so glorious that even the other gods could not look upon him. The same hymn also states that, without Enlil, civilization could not exist. Enlil's epithets include titles such as \"the Great Mountain\" and \"King of the Foreign Lands\". Enlil is also sometimes described as a \"raging storm\", a \"wild bull\", and a \"merchant\". The Mesopotamians envisioned him as a creator, a father, a king, and the supreme lord of the universe. He was also known as \"Nunamnir\" and is referred to in at least one text as the \"East Wind and North Wind\".\nKings regarded Enlil as a model ruler and sought to emulate his example. Enlil was said to be supremely just and intolerant towards evil. Rulers from all over Sumer would travel to Enlil's temple in Nippur to be legitimized. They would return Enlil's favor by devoting lands and precious objects to his temple as offerings. Nippur was the only Sumerian city-state that never built a palace; this was intended to symbolize the city's importance as the center of the cult of Enlil by showing that Enlil himself was the city's king. Even during the Babylonian Period, when Marduk had superseded Enlil as the supreme god, Babylonian kings still traveled to the holy city of Nippur to seek recognition of their right to rule.\nEnlil first rose to prominence during the twenty-fourth century BC, when the importance of the god An began to wane. During this time period, Enlil and An are frequently invoked together in inscriptions. Enlil remained the supreme god in Mesopotamia throughout the Amorite Period, with Amorite monarchs proclaiming Enlil as the source of their legitimacy. Enlil's importance began to wane after the Babylonian king Hammurabi conquered Sumer. The Babylonians worshipped Enlil under the name \"Elil\" and the Hurrians syncretized him with their own god Kumarbi. In one Hurrian ritual, Enlil and Apantu are invoked as \"the father and mother of I\u0161\u1e2bara\". Enlil is also invoked alongside Ninlil as a member of \"the mighty and firmly established gods\".\nDuring the Kassite Period (c. 1592 BC \u2013 1155 BC), Nippur briefly managed to regain influence in the region and Enlil rose to prominence once again. From around 1300 BC onwards, Enlil was syncretized with the Assyrian national god A\u0161\u0161ur, who was the most important deity in the Assyrian pantheon. Then, in 1230 BC, the Elamites attacked Nippur and the city fell into decline, taking the cult of Enlil along with it. Approximately one hundred years later, Enlil's role as the head of the pantheon was given to Marduk, the national god of the Babylonians.\nIconography.\nEnlil was represented by the symbol of a horned cap, which consisted of up to seven superimposed pairs of ox-horns. Such crowns were an important symbol of divinity; gods had been shown wearing them ever since the third millennium BC. The horned cap remained consistent in form and meaning from the earliest days of Sumerian prehistory up until the time of the Persian conquest and beyond.\nThe Sumerians had a complex numerological system, in which certain numbers were believed to hold special ritual significance. Within this system, Enlil was associated with the number fifty, which was considered sacred to him. Enlil was part of a triad of deities, which also included An and Enki. These three deities together were the embodiment of all the fixed stars in the night sky. An was identified with all the stars of the equatorial sky, Enlil with those of the northern sky, and Enki with those of the southern sky. The path of Enlil's celestial orbit was a continuous, symmetrical circle around the north celestial pole, but those of An and Enki were believed to intersect at various points. Enlil was associated with the constellation Bo\u00f6tes.\nMythology.\nOrigins myths.\nThe main source of information about the Sumerian creation myth is the prologue to the epic poem \"Gilgamesh, Enkidu, and the Netherworld\" (ETCSL 1.8.1.4), which briefly describes the process of creation: originally, there was only Nammu, the primeval sea. Then, Nammu gave birth to An, the sky, and Ki, the earth. An and Ki mated with each other, causing Ki to give birth to Enlil. Enlil separated An from Ki and carried off the earth as his domain, while An carried off the sky. Enlil marries his mother, Ki, and from this union all the plant and animal life on earth is produced.\n\"Enlil and Ninlil\" (ETCSL 1.2.1) is a nearly complete 152-line Sumerian poem describing the affair between Enlil and the goddess Ninlil. First, Ninlil's mother Nunbarshegunu instructs Ninlil to go bathe in the river. Ninlil goes to the river, where Enlil seduces her and impregnates her with their son, the moon-god Nanna. Because of this, Enlil is banished to Kur, the Sumerian underworld. Ninlil follows Enlil to the underworld, where he impersonates the \"man of the gate\". Ninlil demands to know where Enlil has gone, but Enlil, still impersonating the gatekeeper, refuses to answer. He then seduces Ninlil and impregnates her with Nergal, the god of death. The same scenario repeats, only this time Enlil instead impersonates the \"man of the river of the nether world, the man-devouring river\"; once again, he seduces Ninlil and impregnates her with the god Ninazu. Finally, Enlil impersonates the \"man of the boat\"; once again, he seduces Ninlil and impregnates her with Enbilulu, the \"inspector of the canals\".\nThe story of Enlil's courtship with Ninlil is primarily a genealogical myth invented to explain the origins of the moon-god Nanna, as well as the various gods of the Underworld, but it is also, to some extent, a coming-of-age story describing Enlil and Ninlil's emergence from adolescence into adulthood. The story also explains Ninlil's role as Enlil's consort; in the poem, Ninlil declares, \"As Enlil is your master, so am I also your mistress!\" The story is also historically significant because, if the current interpretation of it is correct, it is the oldest known myth in which a god changes shape.\nFlood myth.\nIn the Sumerian version of the flood story (ETCSL 1.7.4), the causes of the flood are unclear because the portion of the tablet recording the beginning of the story has been destroyed. Somehow, a mortal known as Ziusudra manages to survive the flood, likely through the help of the god Enki. The tablet begins in the middle of the description of the flood. The flood lasts for seven days and seven nights before it subsides. Then, Utu, the god of the Sun, emerges. Ziusudra opens a window in the side of the boat and falls down prostrate before the god. Next, he sacrifices an ox and a sheep in honor of Utu. At this point, the text breaks off again. When it picks back up, Enlil and An are in the midst of declaring Ziusudra immortal as an honor for having managed to survive the flood. The remaining portion of the tablet after this point is destroyed.\nIn the later Akkadian version of the flood story, recorded in the \"Epic of Gilgamesh\", Enlil actually causes the flood, seeking to annihilate every living thing on earth because the humans, who are vastly overpopulated, make too much noise and prevent him from sleeping. In this version of the story, the hero is Utnapishtim, who is warned ahead of time by Ea, the Babylonian equivalent of Enki, that the flood is coming. The flood lasts for seven days; when it ends, Ishtar, who had mourned the destruction of humanity, promises Utnapishtim that Enlil will never cause a flood again. When Enlil sees that Utnapishtim and his family have survived, he is outraged, but his son Ninurta speaks up in favor of humanity, arguing that, instead of causing floods, Enlil should simply ensure that humans never become overpopulated by reducing their numbers using wild animals and famines. Enlil goes into the boat; Utnapishtim and his wife bow before him. Enlil, now appeased, grants Utnapishtim immortality as a reward for his loyalty to the gods.\nChief god and arbitrator.\n&lt;templatestyles src=\"Rquote/styles.css\"/&gt;{ class=\"rquote pullquote floatright\" role=\"presentation\" style=\"display:table; border-collapse:collapse; border-style:none; float:right; margin:0.5em 0.75em; width:33%; \"\nA nearly complete 108-line poem from the Early Dynastic Period (c. 2900 \u2013 2350 BC) describes Enlil's invention of the mattock, a key agricultural pick, hoe, ax, or digging tool of the Sumerians. In the poem, Enlil conjures the mattock into existence and decrees its fate. The mattock is described as gloriously beautiful; it is made of pure gold and its head is carved from lapis lazuli. Enlil gives the tool over to the humans, who use it to build cities, subjugate their people, and pull up weeds. Enlil was believed to aid in the growth of plants.\nThe Sumerian poem \"Enlil Chooses the Farmer-God\" (ETCSL 5.3.3) describes how Enlil, hoping \"to establish abundance and prosperity\", creates two gods Emesh and Enten, a shepherd and a farmer, respectively. The two gods argue and Emesh lays claim to Enten's position. They take the dispute before Enlil, who rules in favor of Enten; the two gods rejoice and reconcile.\nNinurta myths.\nIn the Sumerian poem \"Lugale\" (ETCSL 1.6.2), Enlil gives advice to his son, the god Ninurta, advising him on a strategy to slay the demon Asag. This advice is relayed to Ninurta by way of Sharur, his enchanted talking mace, which had been sent by Ninurta to the realm of the gods to seek counsel from Enlil directly.\nIn the Old, Middle, and Late Babylonian myth of \"Anz\u00fb and the Tablet of Destinies\", the Anz\u00fb, a giant, monstrous bird, betrays Enlil and steals the Tablet of Destinies, a sacred clay tablet belonging to Enlil that grants him his authority, while Enlil is preparing for a bath. The rivers dry up and the gods are stripped of their powers. The gods send Adad, Gerra, and Shara to defeat the Anz\u00fb, but all of them fail. Finally, Ea proposes that the gods should send Ninurta, Enlil's son. Ninurta successfully defeats the Anz\u00fb and returns the Tablet of Destinies to his father. As a reward, Ninurta is a granted a prominent seat on the council of the gods.\nWar of the gods.\nA badly damaged text from the Neo-Assyrian Period (911 \u2014 612 BC) describes Marduk leading his army of Anunnaki into the sacred city of Nippur and causing a disturbance. The disturbance causes a flood, which forces the resident gods of Nippur under the leadership of Enlil to take shelter in the Eshumesha temple to Ninurta. Enlil is enraged at Marduk's transgression and orders the gods of Eshumesha to take Marduk and the other Anunnaki as prisoners. The Anunnaki are captured, but Marduk appoints his front-runner Mushteshirhablim to lead a revolt against the gods of Eshumesha and sends his messenger Neretagmil to alert Nabu, the god of literacy. When the Eshumesha gods hear Nabu speak, they come out of their temple to search for him. Marduk defeats the Eshumesha gods and takes 360 of them as prisoners of war, including Enlil himself. Enlil protests that the Eshumesha gods are innocent, so Marduk puts them on trial before the Anunnaki. The text ends with a warning from Damkianna (another name for Ninhursag) to the gods and to humanity, pleading them not to repeat the war between the Anunnaki and the gods of Eshumesha.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9630", "revid": "23646674", "url": "https://en.wikipedia.org/wiki?curid=9630", "title": "Ecology", "text": "Study of organisms and their environment\nEcology (from grc \" ' ()\"\u00a0'house', and \" ' ()\"\u00a0'study of')[A] is the study of the relationships among living organisms, including humans, and their physical environment. Ecology considers organisms at the individual, population, community, ecosystem, and biosphere level. Ecology overlaps with the closely related sciences of biogeography, evolutionary biology, genetics, ethology, and natural history. Ecology is a branch of biology, and it is not synonymous with environmentalism.\nAmong other things, ecology is the study of:\nEcology has practical applications in conservation biology, wetland management, natural resource management (agroecology, agriculture, forestry, agroforestry, fisheries, mining, tourism), urban planning (urban ecology), community health, economics, basic and applied science, and human social interaction (human ecology).\nThe word \"ecology\" () was coined in 1866 by the German scientist Ernst Haeckel. The science of ecology as we know it today began with a group of American botanists in the 1890s. Evolutionary concepts relating to adaptation and natural selection are cornerstones of modern ecological theory.\nEcosystems are dynamically interacting systems of organisms, the communities they make up, and the non-living (abiotic) components of their environment. Ecosystem processes, such as primary production, nutrient cycling, and niche construction, regulate the flux of energy and matter through an environment. Ecosystems have biophysical feedback mechanisms that moderate processes acting on living (biotic) and abiotic components of the planet. Ecosystems sustain life-supporting functions and provide ecosystem services like biomass production (food, fuel, fiber, and medicine), the regulation of climate, global biogeochemical cycles, water filtration, soil formation, erosion control, flood protection, and many other natural features of scientific, historical, economic, or intrinsic value.\nLevels, scope, and scale of organization.\nThe scope of ecology contains a wide array of interacting levels of organization spanning micro-level (e.g., cells) to a planetary scale (e.g., biosphere) phenomena. Ecosystems, for example, contain abiotic resources and interacting life forms (i.e., individual organisms that aggregate into populations which aggregate into distinct ecological communities). Ecosystems are dynamic, they do not always follow a linear successional path, but they are always changing, sometimes rapidly and sometimes so slowly that it can take thousands of years for ecological processes to bring about certain successional stages of a forest. An ecosystem's area can vary greatly, from tiny to vast. A single tree is of little consequence to the classification of a forest ecosystem, but is critically relevant to organisms living in and on it. Several generations of an aphid population can exist over the lifespan of a single leaf. Each of those aphids, in turn, supports diverse bacterial communities. The nature of connections in ecological communities cannot be explained by knowing the details of each species in isolation, because the emergent pattern is neither revealed nor predicted until the ecosystem is studied as an integrated whole. Some ecological principles, however, do exhibit collective properties where the sum of the components explain the properties of the whole, such as birth rates of a population being equal to the sum of individual births over a designated time frame.\nThe main subdisciplines of ecology, population (or community) ecology and ecosystem ecology, exhibit a difference not only in scale but also in two contrasting paradigms in the field. The former focuses on organisms' distribution and abundance, while the latter focuses on materials and energy fluxes.\nHierarchy.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nSystem behaviors must first be arrayed into different levels of the organization. Behaviors corresponding to higher levels occur at slow rates. Conversely, lower organizational levels exhibit rapid rates. For example, individual tree leaves respond rapidly to momentary changes in light intensity, CO2 concentration, and the like. The growth of the tree responds more slowly and integrates these short-term changes.\nO'Neill et al. (1986)\nThe scale of ecological dynamics can operate like a closed system, such as aphids migrating on a single tree, while at the same time remaining open with regard to broader scale influences, such as atmosphere or climate. Hence, ecologists classify ecosystems hierarchically by analyzing data collected from finer scale units, such as vegetation associations, climate, and soil types, and integrate this information to identify emergent patterns of uniform organization and processes that operate on local to regional, landscape, and chronological scales.\nTo structure the study of ecology into a conceptually manageable framework, the biological world is organized into a nested hierarchy, ranging in scale from genes, to cells, to tissues, to organs, to organisms, to species, to populations, to communities, to ecosystems, to biomes, and up to the level of the biosphere. This framework forms a panarchy and exhibits non-linear behaviors; this means that \"effect and cause are disproportionate, so that small changes to critical variables, such as the number of nitrogen fixers, can lead to disproportionate, perhaps irreversible, changes in the system properties.\"\nBiodiversity.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n Biodiversity refers to the variety of life and its processes. It includes the variety of living organisms, the genetic differences among them, the communities and ecosystems in which they occur, and the ecological and evolutionary processes that keep them functioning, yet ever-changing and adapting.\nNoss &amp; Carpenter (1994)\nBiodiversity (an abbreviation of \"biological diversity\") describes the diversity of life from genes to ecosystems and spans every level of biological organization. The term has several interpretations, and there are many ways to index, measure, characterize, and represent its complex organization. Biodiversity includes species diversity, ecosystem diversity, and genetic diversity and scientists are interested in the way that this diversity affects the complex ecological processes operating at and among these respective levels. Biodiversity plays an important role in ecosystem services which by definition maintain and improve human quality of life. Conservation priorities and management techniques require different approaches and considerations to address the full ecological scope of biodiversity. Natural capital that supports populations is critical for maintaining ecosystem services and species migration (e.g., riverine fish runs and avian insect control) has been implicated as one mechanism by which those service losses are experienced. An understanding of biodiversity has practical applications for species and ecosystem-level conservation planners as they make management recommendations to consulting firms, governments, and industry.\nHabitat.\nThe habitat of a species describes the environment over which a species is known to occur and the type of community that is formed as a result. More specifically, \"habitats can be defined as regions in environmental space that are composed of multiple dimensions, each representing a biotic or abiotic environmental variable; that is, any component or characteristic of the environment related directly (e.g. forage biomass and quality) or indirectly (e.g. elevation) to the use of a location by the animal.\" For example, a habitat might be an aquatic or terrestrial environment that can be further categorized as a montane or alpine ecosystem. Habitat shifts provide important evidence of competition in nature where one population changes relative to the habitats that most other individuals of the species occupy. For example, one population of a species of tropical lizard (\"Tropidurus hispidus\") has a flattened body relative to the main populations that live in open savanna. The population that lives in an isolated rock outcrop hides in crevasses where its flattened body offers a selective advantage. Habitat shifts also occur in the developmental life history of amphibians, and in insects that transition from aquatic to terrestrial habitats. Biotope and habitat are sometimes used interchangeably, but the former applies to a community's environment, whereas the latter applies to a species' environment.\nNiche.\nDefinitions of the niche date back to 1917, but G. Evelyn Hutchinson made conceptual advances in 1957 by introducing a widely adopted definition: \"the set of biotic and abiotic conditions in which a species is able to persist and maintain stable population sizes.\" The ecological niche is a central concept in the ecology of organisms and is sub-divided into the \"fundamental\" and the \"realized\" niche. The fundamental niche is the set of environmental conditions under which a species is able to persist. The realized niche is the set of environmental plus ecological conditions under which a species persists. The Hutchinsonian niche is defined more technically as a \"Euclidean hyperspace whose \"dimensions\" are defined as environmental variables and whose \"size\" is a function of the number of values that the environmental values may assume for which an organism has \"positive fitness\".\"\nBiogeographical patterns and range distributions are explained or predicted through knowledge of a species' traits and niche requirements. Species have functional traits that are uniquely adapted to the ecological niche. A trait is a measurable property, phenotype, or characteristic of an organism that may influence its survival. Genes play an important role in the interplay of development and environmental expression of traits. Resident species evolve traits that are fitted to the selection pressures of their local environment. This tends to afford them a competitive advantage and discourages similarly adapted species from having an overlapping geographic range. The competitive exclusion principle states that two species cannot coexist indefinitely by living off the same limiting resource; one will always out-compete the other. When similarly adapted species overlap geographically, closer inspection reveals subtle ecological differences in their habitat or dietary requirements. Some models and empirical studies, however, suggest that disturbances can stabilize the co-evolution and shared niche occupancy of similar species inhabiting species-rich communities. The habitat plus the niche is called the ecotope, which is defined as the full range of environmental and biological variables affecting an entire species.\nNiche construction.\nOrganisms are subject to environmental pressures, but they also modify their habitats. The regulatory feedback between organisms and their environment can affect conditions from local (e.g., a beaver pond) to global scales, over time and even after death, such as decaying logs or silica skeleton deposits from marine organisms. The process and concept of ecosystem engineering are related to niche construction, but the former relates only to the physical modifications of the habitat whereas the latter also considers the evolutionary implications of physical changes to the environment and the feedback this causes on the process of natural selection. Ecosystem engineers are defined as: \"organisms that directly or indirectly modulate the availability of resources to other species, by causing physical state changes in biotic or abiotic materials. In so doing they modify, maintain and create habitats.\"\nThe ecosystem engineering concept has stimulated a new appreciation for the influence that organisms have on the ecosystem and evolutionary process. The term \"niche construction\" is more often used in reference to the under-appreciated feedback mechanisms of natural selection imparting forces on the abiotic niche. An example of natural selection through ecosystem engineering occurs in the nests of social insects, including ants, bees, wasps, and termites. There is an emergent homeostasis or homeorhesis in the structure of the nest that regulates, maintains and defends the physiology of the entire colony. Termite mounds, for example, maintain a constant internal temperature through the design of air-conditioning chimneys. The structure of the nests themselves is subject to the forces of natural selection. Moreover, a nest can survive over successive generations, so that progeny inherit both genetic material and a legacy niche that was constructed before their time.\nBiome.\nBiomes are larger units of organization that categorize regions of the Earth's ecosystems, mainly according to the structure and composition of vegetation. There are different methods to define the continental boundaries of biomes dominated by different functional types of vegetative communities that are limited in distribution by climate, precipitation, weather, and other environmental variables. Biomes include tropical rainforest, temperate broadleaf and mixed forest, temperate deciduous forest, taiga, tundra, hot desert, and polar desert. Other researchers have recently categorized other biomes, such as the human and oceanic microbiomes. To a microbe, the human body is a habitat and a landscape. Microbiomes were discovered largely through advances in molecular genetics, which have revealed a hidden richness of microbial diversity on the planet. The oceanic microbiome plays a significant role in the ecological biogeochemistry of the planet's oceans.\nBiosphere.\nThe largest scale of ecological organization is the biosphere: the total sum of ecosystems on the planet. Ecological relationships regulate the flux of energy, nutrients, and climate all the way up to the planetary scale. For example, the dynamic history of the planetary atmosphere's CO2 and O2 composition has been affected by the biogenic flux of gases coming from respiration and photosynthesis, with levels fluctuating over time in relation to the ecology and evolution of plants and animals. Ecological theory has also been used to explain self-emergent regulatory phenomena at the planetary scale: for example, the Gaia hypothesis is an example of holism applied in ecological theory. The Gaia hypothesis states that there is an emergent feedback loop generated by the metabolism of living organisms that maintains the core temperature of the Earth and atmospheric conditions within a narrow self-regulating range of tolerance.\nPopulation ecology.\nPopulation ecology studies the dynamics of species populations and how these populations interact with the wider environment. A population consists of individuals of the same species that live, interact, and migrate through the same niche and habitat.\nA primary law of population ecology is the Malthusian growth model which states, \"a population will grow (or decline) exponentially as long as the environment experienced by all individuals in the population remains constant.\" Simplified population models usually starts with four variables: death, birth, immigration, and emigration.\nAn example of an introductory population model describes a closed population, such as on an island, where immigration and emigration does not take place. Hypotheses are evaluated with reference to a null hypothesis which states that random processes create the observed data. In these island models, the rate of population change is described by:\n formula_1\nwhere \"N\" is the total number of individuals in the population, \"b\" and \"d\" are the per capita rates of birth and death respectively, and \"r\" is the per capita rate of population change.\nUsing these modeling techniques, Malthus' population principle of growth was later transformed into a model known as the logistic equation by Pierre Verhulst:\n formula_2\nwhere \"N(t)\" is the number of individuals measured as biomass density as a function of time, \"t\", \"r\" is the maximum per-capita rate of change commonly known as the intrinsic rate of growth, and formula_3 is the crowding coefficient, which represents the reduction in population growth rate per individual added. The formula states that the rate of change in population size (formula_4) will grow to approach equilibrium, where (formula_5), when the rates of increase and crowding are balanced, formula_6. A common, analogous model fixes the equilibrium, formula_6 as \"K\", which is known as the \"carrying capacity.\"\nPopulation ecology builds upon these introductory models to further understand demographic processes in real study populations. Commonly used types of data include life history, fecundity, and survivorship, and these are analyzed using mathematical techniques such as matrix algebra. The information is used for managing wildlife stocks and setting harvest quotas. In cases where basic models are insufficient, ecologists may adopt different kinds of statistical methods, such as the Akaike information criterion, or use models that can become mathematically complex as \"several competing hypotheses are simultaneously confronted with the data.\"\nMetapopulations and migration.\nThe concept of metapopulations was defined in 1969 as \"a population of populations which go extinct locally and recolonize\". Metapopulation ecology is another statistical approach that is often used in conservation research. Metapopulation models simplify the landscape into patches of varying levels of quality, and metapopulations are linked by the migratory behaviours of organisms. Animal migration is set apart from other kinds of movement because it involves the seasonal departure and return of individuals from a habitat. Migration is also a population-level phenomenon, as with the migration routes followed by plants as they occupied northern post-glacial environments. Plant ecologists use pollen records that accumulate and stratify in wetlands to reconstruct the timing of plant migration and dispersal relative to historic and contemporary climates. These migration routes involved an expansion of the range as plant populations expanded from one area to another. There is a larger taxonomy of movement, such as commuting, foraging, territorial behavior, stasis, and ranging. Dispersal is usually distinguished from migration because it involves the one-way permanent movement of individuals from their birth population into another population.\nIn metapopulation terminology, migrating individuals are classed as emigrants (when they leave a region) or immigrants (when they enter a region), and sites are classed either as sources or sinks. A site is a generic term that refers to places where ecologists sample populations, such as ponds or defined sampling areas in a forest. Source patches are productive sites that generate a seasonal supply of juveniles that migrate to other patch locations. Sink patches are unproductive sites that only receive migrants; the population at the site will disappear unless rescued by an adjacent source patch or environmental conditions become more favorable. Metapopulation models examine patch dynamics over time to answer potential questions about spatial and demographic ecology. The ecology of metapopulations is a dynamic process of extinction and colonization. Small patches of lower quality (i.e., sinks) are maintained or rescued by a seasonal influx of new immigrants. A dynamic metapopulation structure evolves from year to year, where some patches are sinks in dry years and are sources when conditions are more favorable. Ecologists use a mixture of computer models and field studies to explain metapopulation structure.\nCommunity ecology.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nCommunity ecology examines how interactions among species and their environment affect the abundance, distribution and diversity of species within communities.\nJohnson &amp; Stinchcomb (2007)\nCommunity ecology is the study of the interactions among a collection of species that inhabit the same geographic area. Community ecologists study the determinants of patterns and processes for two or more interacting species. Research in community ecology might measure species diversity in grasslands in relation to soil fertility. It might also include the analysis of predator-prey dynamics, competition among similar plant species, or mutualistic interactions between crabs and corals.\nEcosystem ecology.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThese ecosystems, as we may call them, are of the most various kinds and sizes. They form one category of the multitudinous physical systems of the universe, which range from the universe as a whole down to the atom.\nTansley (1935)\nEcosystems may be habitats within biomes that form an integrated whole and a dynamically responsive system having both physical and biological complexes. Ecosystem ecology is the science of determining the fluxes of materials (e.g. carbon, phosphorus) between different pools (e.g., tree biomass, soil organic material). Ecosystem ecologists attempt to determine the underlying causes of these fluxes. Research in ecosystem ecology might measure primary production (g C/m^2) in a wetland in relation to decomposition and consumption rates (g C/m^2/y). This requires an understanding of the community connections between plants (i.e., primary producers) and the decomposers (e.g., fungi and bacteria),\nThe underlying concept of an ecosystem can be traced back to 1864 in the published work of George Perkins Marsh (\"Man and Nature\"). Within an ecosystem, organisms are linked to the physical and biological components of their environment to which they are adapted. Ecosystems are complex adaptive systems where the interaction of life processes form self-organizing patterns across different scales of time and space. Ecosystems are broadly categorized as terrestrial, freshwater, atmospheric, or marine. Differences stem from the nature of the unique physical environments that shapes the biodiversity within each. A more recent addition to ecosystem ecology are technoecosystems, which are affected by or primarily the result of human activity.\nFood webs.\nA food web is the archetypal ecological network. Plants capture solar energy and use it to synthesize simple sugars during photosynthesis. As plants grow, they accumulate nutrients and are eaten by grazing herbivores, and the energy is transferred through a chain of organisms by consumption. The simplified linear feeding pathways that move from a basal trophic species to a top consumer is called the food chain. The larger interlocking pattern of food chains in an ecological community creates a complex food web. Food webs are a type of concept map or a heuristic device that is used to illustrate and study pathways of energy and material flows.\nFood webs are often limited relative to the real world. Complete empirical measurements are generally restricted to a specific habitat, such as a cave or a pond, and principles gleaned from food web microcosm studies are extrapolated to larger systems. Feeding relations require extensive investigations into the gut contents of organisms, which can be difficult to decipher, or stable isotopes can be used to trace the flow of nutrient diets and energy through a food web. Despite these limitations, food webs remain a valuable tool in understanding community ecosystems.\nFood webs exhibit principles of ecological emergence through the nature of trophic relationships: some species have many weak feeding links (e.g., omnivores) while some are more specialized with fewer stronger feeding links (e.g., primary predators). Theoretical and empirical studies identify non-random emergent patterns of few strong and many weak linkages that explain how ecological communities remain stable over time. Food webs are composed of subgroups where members in a community are linked by strong interactions, and the weak interactions occur between these subgroups. This increases food web stability. Step by step lines or relations are drawn until a web of life is illustrated.\nTrophic levels.\nA trophic level (from Greek \"troph\", \u03c4\u03c1\u03bf\u03c6\u03ae, troph\u0113, meaning \"food\" or \"feeding\") is \"a group of organisms acquiring a considerable majority of its energy from the lower adjacent level (according to ecological pyramids) nearer the abiotic source.\" Links in food webs primarily connect feeding relations or trophism among species. Biodiversity within ecosystems can be organized into trophic pyramids, in which the vertical dimension represents feeding relations that become further removed from the base of the food chain up toward top predators, and the horizontal dimension represents the abundance or biomass at each level. When the relative abundance or biomass of each species is sorted into its respective trophic level, they naturally sort into a 'pyramid of numbers'.\nSpecies are broadly categorized as autotrophs (or primary producers), heterotrophs (or consumers), and Detritivores (or decomposers). Autotrophs are organisms that produce their own food (production is greater than respiration) by photosynthesis or chemosynthesis. Heterotrophs are organisms that must feed on others for nourishment and energy (respiration exceeds production). Heterotrophs can be further sub-divided into different functional groups, including primary consumers (strict herbivores), secondary consumers (carnivorous predators that feed exclusively on herbivores), and tertiary consumers (predators that feed on a mix of herbivores and predators). Omnivores do not fit neatly into a functional category because they eat both plant and animal tissues. It has been suggested that omnivores have a greater functional influence as predators because compared to herbivores, they are relatively inefficient at grazing.\nTrophic levels are part of the holistic or complex systems view of ecosystems. Each trophic level contains unrelated species that are grouped together because they share common ecological functions, giving a macroscopic view of the system. While the notion of trophic levels provides insight into energy flow and top-down control within food webs, it is troubled by the prevalence of omnivory in real ecosystems. This has led some ecologists to \"reiterate that the notion that species clearly aggregate into discrete, homogeneous trophic levels is fiction.\" Nonetheless, recent studies have shown that real trophic levels do exist, but \"above the herbivore trophic level, food webs are better characterized as a tangled web of omnivores.\"\nKeystone species.\nA keystone species is a species that is connected to a disproportionately large number of other species in the food-web. Keystone species have lower levels of biomass in the trophic pyramid relative to the importance of their role. The many connections that a keystone species holds means that it maintains the organization and structure of entire communities. The loss of a keystone species results in a range of dramatic cascading effects (termed \"trophic cascades\") that alters trophic dynamics, other food web connections, and can cause the extinction of other species. The term keystone species was coined by Robert Paine in 1969 and is a reference to the keystone architectural feature as the removal of a keystone species can result in a community collapse just as the removal of the keystone in an arch can result in the arch's loss of stability.\nSea otters (\"Enhydra lutris\") are commonly cited as an example of a keystone species because they limit the density of sea urchins that feed on kelp. If sea otters are removed from the system, the urchins graze until the kelp beds disappear, and this has a dramatic effect on community structure. Hunting of sea otters, for example, is thought to have led indirectly to the extinction of the Steller's sea cow (\"Hydrodamalis gigas\"). While the keystone species concept has been used extensively as a conservation tool, it has been criticized for being poorly defined from an operational stance. It is difficult to experimentally determine what species may hold a keystone role in each ecosystem. Furthermore, food web theory suggests that keystone species may not be common, so it is unclear how generally the keystone species model can be applied.\nComplexity.\nComplexity is understood as a large computational effort needed to piece together numerous interacting parts exceeding the iterative memory capacity of the human mind. Global patterns of biological diversity are complex. This biocomplexity stems from the interplay among ecological processes that operate and influence patterns at different scales that grade into each other, such as transitional areas or ecotones spanning landscapes. Complexity stems from the interplay among levels of biological organization as energy, and matter is integrated into larger units that superimpose onto the smaller parts. \"What were wholes on one level become parts on a higher one.\" Small scale patterns do not necessarily explain large scale phenomena, otherwise captured in the expression (coined by Aristotle) 'the sum is greater than the parts'.[E]\n\"Complexity in ecology is of at least six distinct types: spatial, temporal, structural, process, behavioral, and geometric.\" From these principles, ecologists have identified emergent and self-organizing phenomena that operate at different environmental scales of influence, ranging from molecular to planetary, and these require different explanations at each integrative level. Ecological complexity relates to the dynamic resilience of ecosystems that transition to multiple shifting steady-states directed by random fluctuations of history. Long-term ecological studies provide important track records to better understand the complexity and resilience of ecosystems over longer temporal and broader spatial scales. These studies are managed by the International Long Term Ecological Network (LTER). The longest experiment in existence is the Park Grass Experiment, which was initiated in 1856. Another example is the Hubbard Brook study, which has been in operation since 1960.\nHolism.\nHolism remains a critical part of the theoretical foundation in contemporary ecological studies. Holism addresses the biological organization of life that self-organizes into layers of emergent whole systems that function according to non-reducible properties. This means that higher-order patterns of a whole functional system, such as an ecosystem, cannot be predicted or understood by a simple summation of the parts. \"New properties emerge because the components interact, not because the basic nature of the components is changed.\"\nEcological studies are necessarily holistic as opposed to reductionistic. Holism has three scientific meanings or uses that identify with ecology: 1) the mechanistic complexity of ecosystems, 2) the practical description of patterns in quantitative reductionist terms where correlations may be identified but nothing is understood about the causal relations without reference to the whole system, which leads to 3) a metaphysical hierarchy whereby the causal relations of larger systems are understood without reference to the smaller parts. Scientific holism differs from mysticism that has appropriated the same term. An example of metaphysical holism is identified in the trend of increased exterior thickness in shells of different species. The reason for a thickness increase can be understood through reference to principles of natural selection via predation without the need to reference or understand the biomolecular properties of the exterior shells.\nRelation to evolution.\nEcology and evolutionary biology are considered sister disciplines of the life sciences. Natural selection, life history, development, adaptation, populations, and inheritance are examples of concepts that thread equally into ecological and evolutionary theory. Morphological, behavioural, and genetic traits, for example, can be mapped onto evolutionary trees to study the historical development of a species in relation to their functions and roles in different ecological circumstances. In this framework, the analytical tools of ecologists and evolutionists overlap as they organize, classify, and investigate life through common systematic principles, such as phylogenetics or the Linnaean system of taxonomy. The two disciplines often appear together, such as in the title of the journal \"Trends in Ecology and Evolution\". There is no sharp boundary separating ecology from evolution, and they differ more in their areas of applied focus. Both disciplines discover and explain emergent and unique properties and processes operating across different spatial or temporal scales of organization. While the boundary between ecology and evolution is not always clear, ecologists study the abiotic and biotic factors that influence evolutionary processes, and evolution can be rapid, occurring on ecological timescales as short as one generation.\nBehavioural ecology.\nAll organisms can exhibit behaviours. Even plants express complex behaviour, including memory and communication. Behavioural ecology is the study of an organism's behaviour in its environment and its ecological and evolutionary implications. Ethology is the study of observable movement or behaviour in animals. This could include investigations of motile sperm of plants, mobile phytoplankton, zooplankton swimming toward the female egg, the cultivation of fungi by weevils, the mating dance of a salamander, or social gatherings of amoeba.\nAdaptation is the central unifying concept in behavioural ecology. Behaviours can be recorded as traits and inherited in much the same way that eye and hair colour can. Behaviours can evolve by means of natural selection as adaptive traits conferring functional utilities that increases reproductive fitness.\nPredator-prey interactions are an introductory concept into food-web studies as well as behavioural ecology. Prey species can exhibit different kinds of behavioural adaptations to predators, such as avoid, flee, or defend. Many prey species are faced with multiple predators that differ in the degree of danger posed. To be adapted to their environment and face predatory threats, organisms must balance their energy budgets as they invest in different aspects of their life history, such as growth, feeding, mating, socializing, or modifying their habitat. Hypotheses posited in behavioural ecology are generally based on adaptive principles of conservation, optimization, or efficiency. For example, \"[t]he threat-sensitive predator avoidance hypothesis predicts that prey should assess the degree of threat posed by different predators and match their behaviour according to current levels of risk\" or \"[t]he optimal flight initiation distance occurs where expected postencounter fitness is maximized, which depends on the prey's initial fitness, benefits obtainable by not fleeing, energetic escape costs, and expected fitness loss due to predation risk.\"\nElaborate sexual displays and posturing are encountered in the behavioural ecology of animals. The birds-of-paradise, for example, sing and display elaborate ornaments during courtship. These displays serve a dual purpose of signalling healthy or well-adapted individuals and desirable genes. The displays are driven by sexual selection as an advertisement of quality of traits among suitors.\nCognitive ecology.\nCognitive ecology integrates theory and observations from evolutionary ecology and neurobiology, primarily cognitive science, in order to understand the effect that animal interaction with their habitat has on their cognitive systems and how those systems restrict behavior within an ecological and evolutionary framework. \"Until recently, however, cognitive scientists have not paid sufficient attention to the fundamental fact that cognitive traits evolved under particular natural settings. With consideration of the selection pressure on cognition, cognitive ecology can contribute intellectual coherence to the multidisciplinary study of cognition.\" As a study involving the 'coupling' or interactions between organism and environment, cognitive ecology is closely related to enactivism, a field based upon the view that \"...we must see the organism and environment as bound together in reciprocal specification and selection...\".\nSocial ecology.\nSocial-ecological behaviours are notable in the social insects, slime moulds, social spiders, human society, and naked mole-rats where eusocialism has evolved. Social behaviours include reciprocally beneficial behaviours among kin and nest mates and evolve from kin and group selection. Kin selection explains altruism through genetic relationships, whereby an altruistic behaviour leading to death is rewarded by the survival of genetic copies distributed among surviving relatives. The social insects, including ants, bees, and wasps are most famously studied for this type of relationship because the male drones are clones that share the same genetic make-up as every other male in the colony. In contrast, group selectionists find examples of altruism among non-genetic relatives and explain this through selection acting on the group; whereby, it becomes selectively advantageous for groups if their members express altruistic behaviours to one another. Groups with predominantly altruistic members survive better than groups with predominantly selfish members.\nCoevolution.\nEcological interactions can be classified broadly into a host and an associate relationship. A host is any entity that harbours another that is called the associate. Relationships between species that are mutually or reciprocally beneficial are called mutualisms. Examples of mutualism include fungus-growing ants employing agricultural symbiosis, bacteria living in the guts of insects and other organisms, the fig wasp and yucca moth pollination complex, lichens with fungi and photosynthetic algae, and corals with photosynthetic algae. If there is a physical connection between host and associate, the relationship is called symbiosis. Approximately 60% of all plants, for example, have a symbiotic relationship with arbuscular mycorrhizal fungi living in their roots forming an exchange network of carbohydrates for mineral nutrients.\nIndirect mutualisms occur where the organisms live apart. For example, trees living in the equatorial regions of the planet supply oxygen into the atmosphere that sustains species living in distant polar regions of the planet. This relationship is called commensalism because many others receive the benefits of clean air at no cost or harm to trees supplying the oxygen. If the associate benefits while the host suffers, the relationship is called parasitism. Although parasites impose a cost to their host (e.g., via damage to their reproductive organs or propagules, denying the services of a beneficial partner), their net effect on host fitness is not necessarily negative and, thus, becomes difficult to forecast. Co-evolution is also driven by competition among species or among members of the same species under the banner of reciprocal antagonism, such as grasses competing for growth space. The Red Queen Hypothesis, for example, posits that parasites track down and specialize on the locally common genetic defense systems of its host that drives the evolution of sexual reproduction to diversify the genetic constituency of populations responding to the antagonistic pressure.\nBiogeography.\nBiogeography (an amalgamation of \"biology\" and \"geography\") is the comparative study of the geographic distribution of organisms and the corresponding evolution of their traits in space and time. The \"Journal of Biogeography\" was established in 1974. Biogeography and ecology share many of their disciplinary roots. For example, the theory of island biogeography, published by the Robert MacArthur and Edward O. Wilson in 1967 is considered one of the fundamentals of ecological theory.\nBiogeography has a long history in the natural sciences concerning the spatial distribution of plants and animals. Ecology and evolution provide the explanatory context for biogeographical studies. Biogeographical patterns result from ecological processes that influence range distributions, such as migration and dispersal. and from historical processes that split populations or species into different areas. The biogeographic processes that result in the natural splitting of species explain much of the modern distribution of the Earth's biota. The splitting of lineages in a species is called vicariance biogeography and it is a sub-discipline of biogeography. There are also practical applications in the field of biogeography concerning ecological systems and processes. For example, the range and distribution of biodiversity and invasive species responding to climate change is a serious concern and active area of research in the context of global warming.\nr/K selection theory.\nA population ecology concept is r/K selection theory,[D] one of the first predictive models in ecology used to explain life-history evolution. The premise behind the r/K selection model is that natural selection pressures change according to population density. For example, when an island is first colonized, density of individuals is low. The initial increase in population size is not limited by competition, leaving an abundance of available resources for rapid population growth. These early phases of population growth experience \"density-independent\" forces of natural selection, which is called \"r\"-selection. As the population becomes more crowded, it approaches the island's carrying capacity, thus forcing individuals to compete more heavily for fewer available resources. Under crowded conditions, the population experiences density-dependent forces of natural selection, called \"K\"-selection.\nIn the \"r/K\"-selection model, the first variable \"r\" is the intrinsic rate of natural increase in population size and the second variable \"K\" is the carrying capacity of a population. Different species evolve different life-history strategies spanning a continuum between these two selective forces. An \"r\"-selected species is one that has high birth rates, low levels of parental investment, and high rates of mortality before individuals reach maturity. Evolution favours high rates of fecundity in \"r\"-selected species. Many kinds of insects and invasive species exhibit \"r\"-selected characteristics. In contrast, a \"K\"-selected species has low rates of fecundity, high levels of parental investment in the young, and low rates of mortality as individuals mature. Humans and elephants are examples of species exhibiting \"K\"-selected characteristics, including longevity and efficiency in the conversion of more resources into fewer offspring.\nMolecular ecology.\nThe important relationship between ecology and genetic inheritance predates modern techniques for molecular analysis. Molecular ecological research became more feasible with the development of rapid and accessible genetic technologies, such as the polymerase chain reaction (PCR). The rise of molecular technologies and the influx of research questions into this new ecological field resulted in the publication \"Molecular Ecology\" in 1992. Molecular ecology uses various analytical techniques to study genes in an evolutionary and ecological context. In 1994, John Avise also played a leading role in this area of science with the publication of his book, \"Molecular Markers, Natural History and Evolution\". Newer technologies opened a wave of genetic analysis into organisms once difficult to study from an ecological or evolutionary standpoint, such as bacteria, fungi, and nematodes. Molecular ecology engendered a new research paradigm for investigating ecological questions considered otherwise intractable. Molecular investigations revealed previously obscured details in the tiny intricacies of nature and improved resolution into probing questions about behavioural and biogeographical ecology. For example, molecular ecology revealed promiscuous sexual behaviour and multiple male partners in tree swallows previously thought to be socially monogamous. In a biogeographical context, the marriage between genetics, ecology, and evolution resulted in a new sub-discipline called phylogeography.\nHuman ecology.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe history of life on Earth has been a history of interaction between living things and their surroundings. To a large extent, the physical form and the habits of the earth's vegetation and its animal life have been molded by the environment. Considering the whole span of earthly time, the opposite effect, in which life actually modifies its surroundings, has been relatively slight. Only within the moment of time represented by the present century has one species man acquired significant power to alter the nature of his world.\nRachel Carson, \"Silent Spring\"\nEcology is as much a biological science as it is a human science. Human ecology is an interdisciplinary investigation into the ecology of our species. \"Human ecology may be defined: (1) from a bioecological standpoint as the study of man as the ecological dominant in plant and animal communities and systems; (2) from a bioecological standpoint as simply another animal affecting and being affected by his physical environment; and (3) as a human being, somehow different from animal life in general, interacting with physical and modified environments in a distinctive and creative way. A truly interdisciplinary human ecology will most likely address itself to all three.\" The term was formally introduced in 1921, but many sociologists, geographers, psychologists, and other disciplines were interested in human relations to natural systems centuries prior, especially in the late 19th century.\nThe ecological complexities human beings are facing through the technological transformation of the planetary biome has brought on the Anthropocene. The unique set of circumstances has generated the need for a new unifying science called coupled human and natural systems that builds upon, but moves beyond the field of human ecology. Ecosystems tie into human societies through the critical and all-encompassing life-supporting functions they sustain. In recognition of these functions and the incapability of traditional economic valuation methods to see the value in ecosystems, there has been a surge of interest in social-natural capital, which provides the means to put a value on the stock and use of information and materials stemming from ecosystem goods and services. Ecosystems produce, regulate, maintain, and supply services of critical necessity and beneficial to human health (cognitive and physiological), economies, and they even provide an information or reference function as a living library giving opportunities for science and cognitive development in children engaged in the complexity of the natural world. Ecosystems relate importantly to human ecology as they are the ultimate base foundation of global economics as every commodity, and the capacity for exchange ultimately stems from the ecosystems on Earth.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nEcosystem management is not just about science nor is it simply an extension of traditional resource management; it offers a fundamental reframing of how humans may work with nature.\nGrumbine (1994)\nEcology is an employed science of restoration, repairing disturbed sites through human intervention, in natural resource management, and in environmental impact assessments. Edward O. Wilson predicted in 1992 that the 21st century \"will be the era of restoration in ecology\". Ecological science has boomed in the industrial investment of restoring ecosystems and their processes in abandoned sites after disturbance. Natural resource managers, in forestry, for example, employ ecologists to develop, adapt, and implement ecosystem based methods into the planning, operation, and restoration phases of land-use. Another example of conservation is seen on the east coast of the United States in Boston, MA. The city of Boston implemented the Wetland Ordinance, improving the stability of their wetland environments by implementing soil amendments that will improve groundwater storage and flow, and trimming or removal of vegetation that could cause harm to water quality. Ecological science is used in the methods of sustainable harvesting, disease, and fire outbreak management, in fisheries stock management, for integrating land-use with protected areas and communities, and conservation in complex geo-political landscapes.\nRelation to the environment.\nThe environment of ecosystems includes both physical parameters and biotic attributes. It is dynamically interlinked and contains resources for organisms at any time throughout their life cycle. Like ecology, the term environment has different conceptual meanings and overlaps with the concept of nature. Environment \"includes the physical world, the social world of human relations and the built world of human creation.\" The physical environment is external to the level of biological organization under investigation, including abiotic factors such as temperature, radiation, light, chemistry, climate and geology. The biotic environment includes genes, cells, organisms, members of the same species (conspecifics) and other species that share a habitat.\nThe distinction between external and internal environments, however, is an abstraction parsing life and environment into units or facts that are inseparable in reality. There is an interpenetration of cause and effect between the environment and life. The laws of thermodynamics, for example, apply to ecology by means of its physical state. With an understanding of metabolic and thermodynamic principles, a complete accounting of energy and material flow can be traced through an ecosystem. In this way, the environmental and ecological relations are studied through reference to conceptually manageable and isolated material parts. After the effective environmental components are understood through reference to their causes; however, they conceptually link back together as an integrated whole, or \"holocoenotic\" system as it was once called. This is known as the dialectical approach to ecology. The dialectical approach examines the parts but integrates the organism and the environment into a dynamic whole (or umwelt). Change in one ecological or environmental factor can concurrently affect the dynamic state of an entire ecosystem.\nDisturbance and resilience.\nEcosystems are regularly confronted with natural environmental variations and disturbances over time and geographic space. A disturbance is any process that removes biomass from a community, such as a fire, flood, drought, or predation. Disturbances occur over vastly different ranges in terms of magnitudes as well as distances and time periods, and are both the cause and product of natural fluctuations in death rates, species assemblages, and biomass densities within an ecological community. These disturbances create places of renewal where new directions emerge from the patchwork of natural experimentation and opportunity. Ecological resilience is a cornerstone theory in ecosystem management. Biodiversity fuels the resilience of ecosystems acting as a kind of regenerative insurance.\nMetabolism and the early atmosphere.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nMetabolism \u2013 the rate at which energy and material resources are taken up from the environment, transformed within an organism, and allocated to maintenance, growth and reproduction \u2013 is a fundamental physiological trait.\nErnest et al.\nThe Earth was formed approximately 4.5\u00a0billion years ago. As it cooled and a crust and oceans formed, its atmosphere transformed from being dominated by hydrogen to one composed mostly of methane and ammonia. Over the next billion years, the metabolic activity of life transformed the atmosphere into a mixture of carbon dioxide, nitrogen, and water vapor. These gases changed the way that light from the sun hit the Earth's surface and greenhouse effects trapped heat. There were untapped sources of free energy within the mixture of reducing and oxidizing gasses that set the stage for primitive ecosystems to evolve and, in turn, the atmosphere also evolved.\nThroughout history, the Earth's atmosphere and biogeochemical cycles have been in a dynamic equilibrium with planetary ecosystems. The history is characterized by periods of significant transformation followed by millions of years of stability. The evolution of the earliest organisms, likely anaerobic methanogen microbes, started the process by converting atmospheric hydrogen into methane (4H2 + CO2 \u2192 CH4 + 2H2O). Anoxygenic photosynthesis reduced hydrogen concentrations and increased atmospheric methane, by converting hydrogen sulfide into water or other sulfur compounds (for example, 2H2S + CO2 + h\"v\" \u2192 CH2O + H2O + 2S). Early forms of fermentation also increased levels of atmospheric methane. The transition to an oxygen-dominant atmosphere (the \"Great Oxidation\") did not begin until approximately 2.4\u20132.3\u00a0billion years ago, but photosynthetic processes started 0.3 to 1\u00a0billion years prior.\nRadiation: heat, temperature and light.\nThe biology of life operates within a certain range of temperatures. Heat is a form of energy that regulates temperature. Heat affects growth rates, activity, behaviour, and primary production. Temperature is largely dependent on the incidence of solar radiation. The latitudinal and longitudinal spatial variation of temperature greatly affects climates and consequently the distribution of biodiversity and levels of primary production in different ecosystems or biomes across the planet. Heat and temperature relate importantly to metabolic activity. Poikilotherms, for example, have a body temperature that is largely regulated and dependent on the temperature of the external environment. In contrast, homeotherms regulate their internal body temperature by expending metabolic energy.\nThere is a relationship between light, primary production, and ecological energy budgets. Sunlight is the primary input of energy into the planet's ecosystems. Light is composed of electromagnetic energy of different wavelengths. Radiant energy from the sun generates heat, provides photons of light measured as active energy in the chemical reactions of life, and also acts as a catalyst for genetic mutation. Plants, algae, and some bacteria absorb light and assimilate the energy through photosynthesis. Organisms capable of assimilating energy by photosynthesis or through inorganic fixation of H2S are autotrophs. Autotrophs\u2014responsible for primary production\u2014assimilate light energy which becomes metabolically stored as potential energy in the form of biochemical enthalpic bonds.\nPhysical environments.\nWater.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWetland conditions such as shallow water, high plant productivity, and anaerobic substrates provide a suitable environment for important physical, biological, and chemical processes. Because of these processes, wetlands play a vital role in global nutrient and element cycles.\nCronk &amp; Fennessy (2001)\nDiffusion of carbon dioxide and oxygen is approximately 10,000 times slower in water than in air. When soils are flooded, they quickly lose oxygen, becoming hypoxic (an environment with O2 concentration below 2\u00a0mg/liter) and eventually completely anoxic where anaerobic bacteria thrive among the roots. Water also influences the intensity and spectral composition of light as it reflects off the water surface and submerged particles. Aquatic plants exhibit a wide variety of morphological and physiological adaptations that allow them to survive, compete, and diversify in these environments. For example, their roots and stems contain large air spaces (aerenchyma) that regulate the efficient transportation of gases (for example, CO2 and O2) used in respiration and photosynthesis. Salt water plants (halophytes) have additional specialized adaptations, such as the development of special organs for shedding salt and osmoregulating their internal salt (NaCl) concentrations, to live in estuarine, brackish, or oceanic environments. Anaerobic soil microorganisms in aquatic environments use nitrate, manganese ions, ferric ions, sulfate, carbon dioxide, and some organic compounds; other microorganisms are facultative anaerobes and use oxygen during respiration when the soil becomes drier. The activity of soil microorganisms and the chemistry of the water reduces the oxidation-reduction potentials of the water. Carbon dioxide, for example, is reduced to methane (CH4) by methanogenic bacteria. The physiology of fish is also specially adapted to compensate for environmental salt levels through osmoregulation. Their gills form electrochemical gradients that mediate salt excretion in salt water and uptake in fresh water.\nGravity.\nThe shape and energy of the land are significantly affected by gravitational forces. On a large scale, the distribution of gravitational forces on the earth is uneven and influences the shape and movement of tectonic plates as well as influencing geomorphic processes such as orogeny and erosion. These forces govern many of the geophysical properties and distributions of ecological biomes across the Earth. On the organismal scale, gravitational forces provide directional cues for plant and fungal growth (gravitropism), orientation cues for animal migrations, and influence the biomechanics and size of animals. Ecological traits, such as allocation of biomass in trees during growth are subject to mechanical failure as gravitational forces influence the position and structure of branches and leaves. The cardiovascular systems of animals are functionally adapted to overcome the pressure and gravitational forces that change according to the features of organisms (e.g., height, size, shape), their behaviour (e.g., diving, running, flying), and the habitat occupied (e.g., water, hot deserts, cold tundra).\nPressure.\nClimatic and osmotic pressure places physiological constraints on organisms, especially those that fly and respire at high altitudes, or dive to deep ocean depths. These constraints influence vertical limits of ecosystems in the biosphere, as organisms are physiologically sensitive and adapted to atmospheric and osmotic water pressure differences. For example, oxygen levels decrease with decreasing pressure and are a limiting factor for life at higher altitudes. Water transportation by plants is another important ecophysiological process affected by osmotic pressure gradients. Water pressure in the depths of oceans requires that organisms adapt to these conditions. For example, diving animals such as whales, dolphins, and seals are specially adapted to deal with changes in sound due to water pressure differences. Differences between hagfish species provide another example of adaptation to deep-sea pressure through specialized protein adaptations.\nWind and turbulence.\nTurbulent forces in air and water affect the environment and ecosystem distribution, form, and dynamics. On a planetary scale, ecosystems are affected by circulation patterns in the global trade winds. Wind power and the turbulent forces it creates can influence heat, nutrient, and biochemical profiles of ecosystems. For example, wind running over the surface of a lake creates turbulence, mixing the water column and influencing the environmental profile to create thermally layered zones, affecting how fish, algae, and other parts of the aquatic ecosystem are structured. Wind speed and turbulence also influence evapotranspiration rates and energy budgets in plants and animals. Wind speed, temperature and moisture content can vary as winds travel across different land features and elevations. For example, the westerlies come into contact with the coastal and interior mountains of western North America to produce a rain shadow on the leeward side of the mountain. The air expands and moisture condenses as the winds increase in elevation; this is called orographic lift and can cause precipitation. This environmental process produces spatial divisions in biodiversity, as species adapted to wetter conditions are range-restricted to the coastal mountain valleys and unable to migrate across the xeric ecosystems (e.g., of the Columbia Basin in western North America) to intermix with sister lineages that are segregated to the interior mountain systems.\nFire.\nPlants convert carbon dioxide into biomass and emit oxygen into the atmosphere. By approximately 350 million years ago (the end of the Devonian period), photosynthesis had brought the concentration of atmospheric oxygen above 17%, which allowed combustion to occur. Fire releases CO2 and converts fuel into ash and tar. Fire is a significant ecological parameter that raises many issues pertaining to its control and suppression. While the issue of fire in relation to ecology and plants has been recognized for a long time, Charles Cooper brought attention to the issue of forest fires in relation to the ecology of forest fire suppression and management in the 1960s.\nNative North Americans were among the first to influence fire regimes by controlling their spread near their homes or by lighting fires to stimulate the production of herbaceous foods and basketry materials. Fire creates a heterogeneous ecosystem age and canopy structure, and the altered soil nutrient supply and cleared canopy structure opens new ecological niches for seedling establishment. Most ecosystems are adapted to natural fire cycles. Plants, for example, are equipped with a variety of adaptations to deal with forest fires. Some species (e.g., \"Pinus halepensis\") cannot germinate until after their seeds have lived through a fire or been exposed to certain compounds from smoke. Environmentally triggered germination of seeds is called serotiny. Fire plays a major role in the persistence and resilience of ecosystems.\nSoils.\nSoil is the living top layer of mineral and organic dirt that covers the surface of the planet. It is the chief organizing centre of most ecosystem functions, and it is of critical importance in agricultural science and ecology. The decomposition of dead organic matter (for example, leaves on the forest floor), results in soils containing minerals and nutrients that feed into plant production. The whole of the planet's soil ecosystems is called the pedosphere where a large biomass of the Earth's biodiversity organizes into trophic levels. Invertebrates that feed and shred larger leaves, for example, create smaller bits for smaller organisms in the feeding chain. Collectively, these organisms are the detritivores that regulate soil formation. Tree roots, fungi, bacteria, worms, ants, beetles, centipedes, spiders, mammals, birds, reptiles, amphibians, and other less familiar creatures all work to create the trophic web of life in soil ecosystems. Soils form composite phenotypes where inorganic matter is enveloped into the physiology of a whole community. As organisms feed and migrate through soils they physically displace materials, an ecological process called bioturbation. This aerates soils and stimulates heterotrophic growth and production. Soil microorganisms are influenced by and are fed back into the trophic dynamics of the ecosystem. No single axis of causality can be discerned to segregate the biological from geomorphological systems in soils. Paleoecological studies of soils places the origin for bioturbation to a time before the Cambrian period. Other events, such as the evolution of trees and the colonization of land in the Devonian period played a significant role in the early development of ecological trophism in soils.\nBiogeochemistry and climate.\nEcologists study and measure nutrient budgets to understand how these materials are regulated, flow, and recycled through the environment. This research has led to an understanding that there is global feedback between ecosystems and the physical parameters of this planet, including minerals, soil, pH, ions, water, and atmospheric gases. Six major elements (hydrogen, carbon, nitrogen, oxygen, sulfur, and phosphorus; H, C, N, O, S, and P) form the constitution of all biological macromolecules and feed into the Earth's geochemical processes. From the smallest scale of biology, the combined effect of billions upon billions of ecological processes amplify and ultimately regulate the biogeochemical cycles of the Earth. Understanding the relations and cycles mediated between these elements and their ecological pathways has significant bearing toward understanding global biogeochemistry.\nThe ecology of global carbon budgets gives one example of the linkage between biodiversity and biogeochemistry. It is estimated that the Earth's oceans hold 40,000 gigatonnes (Gt) of carbon, that vegetation and soil hold 2070 Gt, and that fossil fuel emissions are 6.3 Gt carbon per year. There have been major restructurings in these global carbon budgets during the Earth's history, regulated to a large extent by the ecology of the land. For example, through the early-mid Eocene volcanic outgassing, the oxidation of methane stored in wetlands, and seafloor gases increased atmospheric CO2 (carbon dioxide) concentrations to levels as high as 3500\u00a0ppm.\nIn the Oligocene, from twenty-five to thirty-two million years ago, there was another significant restructuring of the global carbon cycle as grasses evolved a new mechanism of photosynthesis, C4 photosynthesis, and expanded their ranges. This new pathway evolved in response to the drop in atmospheric CO2 concentrations below 550 ppm. The relative abundance and distribution of biodiversity alters the dynamics between organisms and their environment such that ecosystems can be both cause and effect in relation to climate change. Human-driven modifications to the planet's ecosystems (e.g., disturbance, biodiversity loss, agriculture) contributes to rising atmospheric greenhouse gas levels. Transformation of the global carbon cycle in the next century is projected to raise planetary temperatures, lead to more extreme fluctuations in weather, alter species distributions, and increase extinction rates. The effect of global warming is already being registered in melting glaciers, melting mountain ice caps, and rising sea levels. Consequently, species distributions are changing along waterfronts and in continental areas where migration patterns and breeding grounds are tracking the prevailing shifts in climate. Large sections of permafrost are also melting to create a new mosaic of flooded areas having increased rates of soil decomposition activity that raises methane (CH4) emissions. There is concern over increases in atmospheric methane in the context of the global carbon cycle, because methane is a greenhouse gas that is 23 times more effective at absorbing long-wave radiation than CO2 on a 100-year time scale. Hence, there is a relationship between global warming, decomposition and respiration in soils and wetlands producing significant climate feedbacks and globally altered biogeochemical cycles.\nHistory.\nEarly beginnings.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n By ecology, we mean the whole science of the relations of the organism to the environment including, in the broad sense, all the \"conditions of existence\". Thus, the theory of evolution explains the housekeeping relations of organisms mechanistically as the necessary consequences of effectual causes; and so forms the monistic groundwork of ecology.\n Ernst Haeckel (1866) [B]\nEcology has a complex origin, due in large part to its interdisciplinary nature. Ancient Greek philosophers such as Hippocrates and Aristotle were among the first to record observations on natural history. However, they viewed life in terms of essentialism, where species were conceptualized as static unchanging things while varieties were seen as aberrations of an idealized type. This contrasts against the modern understanding of ecological theory where varieties are viewed as the real phenomena of interest and having a role in the origins of adaptations by means of natural selection. Early conceptions of ecology, such as a balance and regulation in nature can be traced to Herodotus (died \"c\". 425 BC), who described one of the earliest accounts of mutualism in his observation of \"natural dentistry\". Basking Nile crocodiles, he noted, would open their mouths to give sandpipers safe access to pluck leeches out, giving nutrition to the sandpiper and oral hygiene for the crocodile. Aristotle was an early influence on the philosophical development of ecology. He and his student Theophrastus made extensive observations on plant and animal migrations, biogeography, physiology, and their behavior, giving an early analogue to the modern concept of an ecological niche.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nNowhere can one see more clearly illustrated what may be called the sensibility of such an organic complex, \u2013 expressed by the fact that whatever affects any species belonging to it, must speedily have its influence of some sort upon the whole assemblage. He will thus be made to see the impossibility of studying any form completely, out of relation to the other forms, \u2013 the necessity for taking a comprehensive survey of the whole as a condition to a satisfactory understanding of any part.\nStephen Forbes (1887)\n Ernst Haeckel (left) and Eugenius Warming (right), two founders of ecology\nEcological concepts such as food chains, population regulation, and productivity were first developed in the 1700s, through the published works of microscopist Antonie van Leeuwenhoek (1632\u20131723) and botanist Richard Bradley (1688?\u20131732). Biogeographer Alexander von Humboldt (1769\u20131859) was an early pioneer in ecological thinking and was among the first to recognize ecological gradients, where species are replaced or altered in form along environmental gradients, such as a cline forming along a rise in elevation. Humboldt drew inspiration from Isaac Newton, as he developed a form of \"terrestrial physics\". In Newtonian fashion, he brought a scientific exactitude for measurement into natural history and even alluded to concepts that are the foundation of a modern ecological law on species-to-area relationships. Natural historians, such as Humboldt, James Hutton, and Jean-Baptiste Lamarck (among others) laid the foundations of the modern ecological sciences. The term \"ecology\" () was coined by Ernst Haeckel in his book \"Generelle Morphologie der Organismen\" (1866). Haeckel was a zoologist, artist, writer, and later in life a professor of comparative anatomy.\nOpinions differ on who was the founder of modern ecological theory. Some mark Haeckel's definition as the beginning; others say it was Eugenius Warming with the writing of Oecology of Plants: An Introduction to the Study of Plant Communities (1895), or Carl Linnaeus' principles on the economy of nature that matured in the early 18th century. Linnaeus founded an early branch of ecology that he called the economy of nature. His works influenced Charles Darwin, who adopted Linnaeus' phrase on the \"economy or polity of nature\" in \"The Origin of Species\". Linnaeus was the first to frame the balance of nature as a testable hypothesis. Haeckel, who admired Darwin's work, defined ecology in reference to the economy of nature, which has led some to question whether ecology and the economy of nature are synonymous.\nFrom Aristotle until Darwin, the natural world was predominantly considered static and unchanging. Prior to \"The Origin of Species\", there was little appreciation or understanding of the dynamic and reciprocal relations between organisms, their adaptations, and the environment. An exception is the 1789 publication \"Natural History of Selborne\" by Gilbert White (1720\u20131793), considered by some to be one of the earliest texts on ecology. While Charles Darwin is mainly noted for his treatise on evolution, he was one of the founders of soil ecology, and he made note of the first ecological experiment in \"The Origin of Species\". Evolutionary theory changed the way that researchers approached the ecological sciences.\nSince 1900.\nModern ecology is a young science that first attracted substantial scientific attention toward the end of the 19th century (around the same time that evolutionary studies were gaining scientific interest). The scientist Ellen Swallow Richards adopted the term \"oekology\" (which eventually morphed into home economics) in the U.S. as early as 1892.\nIn the early 20th century, ecology transitioned from a more descriptive form of natural history to a more analytical form of \"scientific natural history\". Frederic Clements published the first American ecology book in 1905, presenting the idea of plant communities as a superorganism. This publication launched a debate between ecological holism and individualism that lasted until the 1970s. Clements' superorganism concept proposed that ecosystems progress through regular and determined stages of seral development that are analogous to the developmental stages of an organism. The Clementsian paradigm was challenged by Henry Gleason, who stated that ecological communities develop from the unique and coincidental association of individual organisms. This perceptual shift placed the focus back onto the life histories of individual organisms and how this relates to the development of community associations.\nThe Clementsian superorganism theory was an overextended application of an idealistic form of holism. The term \"holism\" was coined in 1926 by Jan Christiaan Smuts, a South African general and polarizing historical figure who was inspired by Clements' superorganism concept.[C] Around the same time, Charles Elton pioneered the concept of food chains in his classical book \"Animal Ecology\". Elton defined ecological relations using concepts of food chains, food cycles, and food size, and described numerical relations among different functional groups and their relative abundance. Elton's 'food cycle' was replaced by 'food web' in a subsequent ecological text. Alfred J. Lotka brought in many theoretical concepts applying thermodynamic principles to ecology.\nIn 1942, Raymond Lindeman wrote a landmark paper on the trophic dynamics of ecology, which was published posthumously after initially being rejected for its theoretical emphasis. Trophic dynamics became the foundation for much of the work to follow on energy and material flow through ecosystems. Robert MacArthur advanced mathematical theory, predictions, and tests in ecology in the 1950s, which inspired a resurgent school of theoretical mathematical ecologists. Ecology also has developed through contributions from other nations, including Russia's Vladimir Vernadsky and his founding of the biosphere concept in the 1920s and Japan's Kinji Imanishi and his concepts of harmony in nature and habitat segregation in the 1950s. Scientific recognition of contributions to ecology from non-English-speaking cultures is hampered by language and translation barriers.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThis whole chain of poisoning, then, seems to rest on a base of minute plants which must have been the original concentrators. But what of the opposite end of the food chain\u2014the human being who, in probable ignorance of all this sequence of events, has rigged his fishing tackle, caught a string of fish from the waters of Clear Lake, and taken them home to fry for his supper?\nRachel Carson (1962)\nEcology surged in popular and scientific interest during the 1960\u20131970s environmental movement. There are strong historical and scientific ties between ecology, environmental management, and protection. The historical emphasis and poetic naturalistic writings advocating the protection of wild places by notable ecologists in the history of conservation biology, such as Aldo Leopold and Arthur Tansley, have been seen as far removed from urban centres where, it is claimed, the concentration of pollution and environmental degradation is located. Palamar (2008) notes an overshadowing by mainstream environmentalism of pioneering women in the early 1900s who fought for urban health ecology (then called euthenics) and brought about changes in environmental legislation. Women such as Ellen Swallow Richards and Julia Lathrop, among others, were precursors to the more popularized environmental movements after the 1950s.\nIn 1962, marine biologist and ecologist Rachel Carson's book \"Silent Spring\" helped to mobilize the environmental movement by alerting the public to toxic pesticides, such as DDT, bioaccumulating in the environment. Carson used ecological science to link the release of environmental toxins to human and ecosystem health. Since then, ecologists have worked to bridge their understanding of the degradation of the planet's ecosystems with environmental politics, law, restoration, and natural resources management.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9631", "revid": "37664675", "url": "https://en.wikipedia.org/wiki?curid=9631", "title": "Glossary of country dance terms", "text": "An alphabetic list of modern country dance terminology:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9632", "revid": "1750837", "url": "https://en.wikipedia.org/wiki?curid=9632", "title": "Ecosystem", "text": "Community of living organisms together with the nonliving components of their environment\nAn ecosystem (or ecological system) consists of all the organisms and the physical environment with which they interact. These biotic and abiotic components are linked together through nutrient cycles and energy flows. Energy enters the system through photosynthesis and is incorporated into plant tissue. By feeding on plants and on one another, animals play an important role in the movement of matter and energy through the system. They also influence the quantity of plant and microbial biomass present. By breaking down dead organic matter, decomposers release carbon back to the atmosphere and facilitate nutrient cycling by converting nutrients stored in dead biomass back to a form that can be readily used by plants and microbes.\nEcosystems are controlled by external and internal factors. External factors such as climate, parent material which forms the soil and topography, control the overall structure of an ecosystem but are not themselves influenced by the ecosystem. Internal factors are controlled, for example, by decomposition, root competition, shading, disturbance, succession, and the types of species present. While the resource inputs are generally controlled by external processes, the availability of these resources within the ecosystem is controlled by internal factors. Therefore, internal factors not only control ecosystem processes but are also controlled by them.\nEcosystems are dynamic entities\u2014they are subject to periodic disturbances and are always in the process of recovering from some past disturbance. The tendency of an ecosystem to remain close to its equilibrium state, despite that disturbance, is termed its resistance. The capacity of a system to absorb disturbance and reorganize while undergoing change so as to retain essentially the same function, structure, identity, and feedbacks is termed its ecological resilience. Ecosystems can be studied through a variety of approaches\u2014theoretical studies, studies monitoring specific ecosystems over long periods of time, those that look at differences between ecosystems to elucidate how they work and direct manipulative experimentation. Biomes are general classes or categories of ecosystems. However, there is no clear distinction between biomes and ecosystems. Ecosystem classifications are specific kinds of ecological classifications that consider all four elements of the definition of ecosystems: a biotic component, an abiotic complex, the interactions between and within them, and the physical space they occupy.\nEcosystems provide a variety of goods and services upon which people depend. Ecosystem goods include the \"tangible, material products\" of ecosystem processes such as water, food, fuel, construction material, and medicinal plants. Ecosystem services, on the other hand, are generally \"improvements in the condition or location of things of value\". These include things like the maintenance of hydrological cycles, cleaning air and water, the maintenance of oxygen in the atmosphere, crop pollination and even things like beauty, inspiration and opportunities for research. Many ecosystems become degraded through human impacts, such as soil loss, air and water pollution, habitat fragmentation, water diversion, fire suppression, and introduced species and invasive species. These threats can lead to abrupt transformation of the ecosystem or to gradual disruption of biotic processes and degradation of abiotic conditions of the ecosystem. Once the original ecosystem has lost its defining features, it is considered \"collapsed\". Ecosystem restoration can contribute to achieving the Sustainable Development Goals.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nDefinition.\nAn ecosystem (or ecological system) consists of all the organisms and the abiotic pools (or physical environment) with which they interact. The biotic and abiotic components are linked together through nutrient cycles and energy flows.\n\"Ecosystem processes\" are the transfers of energy and materials from one pool to another. Ecosystem processes are known to \"take place at a wide range of scales\". Therefore, the correct scale of study depends on the question asked.\nOrigin and development of the term.\nThe term \"ecosystem\" was first used in 1935 in a publication by British ecologist Arthur Tansley. The term was coined by Arthur Roy Clapham, who came up with the word at Tansley's request. Tansley devised the concept to draw attention to the importance of transfers of materials between organisms and their environment. He later refined the term, describing it as \"The whole system, ... including not only the organism-complex, but also the whole complex of physical factors forming what we call the environment\". Tansley regarded ecosystems not simply as natural units, but as \"mental isolates\". Tansley later defined the spatial extent of ecosystems using the term \"ecotope\".\nG. Evelyn Hutchinson, a limnologist who was a contemporary of Tansley's, combined Charles Elton's ideas about trophic ecology with those of Russian geochemist Vladimir Vernadsky. As a result, he suggested that mineral nutrient availability in a lake limited algal production. This would, in turn, limit the abundance of animals that feed on algae. Raymond Lindeman took these ideas further to suggest that the flow of energy through a lake was the primary driver of the ecosystem. Hutchinson's students, brothers Howard T. Odum and Eugene P. Odum, further developed a \"systems approach\" to the study of ecosystems. This allowed them to study the flow of energy and material through ecological systems.\nProcesses.\nExternal and internal factors.\nEcosystems are controlled by both external and internal factors. External factors, also called state factors, control the overall structure of an ecosystem and the way things work within it, but are not themselves influenced by the ecosystem. On broad geographic scales, climate is the factor that \"most strongly determines ecosystem processes and structure\". Climate determines the biome in which the ecosystem is embedded. Rainfall patterns and seasonal temperatures influence photosynthesis and thereby determine the amount of energy available to the ecosystem.\nParent material determines the nature of the soil in an ecosystem, and influences the supply of mineral nutrients. Topography also controls ecosystem processes by affecting things like microclimate, soil development and the movement of water through a system. For example, ecosystems can be quite different if situated in a small depression on the landscape, versus one present on an adjacent steep hillside.\nOther external factors that play an important role in ecosystem functioning include time and potential biota, the organisms that are present in a region and could potentially occupy a particular site. Ecosystems in similar environments that are located in different parts of the world can end up doing things very differently simply because they have different pools of species present. The introduction of non-native species can cause substantial shifts in ecosystem function.\nUnlike external factors, internal factors in ecosystems not only control ecosystem processes but are also controlled by them. While the resource inputs are generally controlled by external processes like climate and parent material, the availability of these resources within the ecosystem is controlled by internal factors like decomposition, root competition or shading. Other factors like disturbance, succession or the types of species present are also internal factors.\nPrimary production.\nPrimary production is the production of organic matter from inorganic carbon sources. This mainly occurs through photosynthesis. The energy incorporated through this process supports life on earth, while the carbon makes up much of the organic matter in living and dead biomass, soil carbon and fossil fuels. It also drives the carbon cycle, which influences global climate via the greenhouse effect.\nThrough the process of photosynthesis, plants capture energy from light and use it to combine carbon dioxide and water to produce carbohydrates and oxygen. The photosynthesis carried out by all the plants in an ecosystem is called the gross primary production (GPP). About half of the gross GPP is respired by plants in order to provide the energy that supports their growth and maintenance. The remainder, that portion of GPP that is not used up by respiration, is known as the net primary production (NPP). Total photosynthesis is limited by a range of environmental factors. These include the amount of light available, the amount of leaf area a plant has to capture light (shading by other plants is a major limitation of photosynthesis), the rate at which carbon dioxide can be supplied to the chloroplasts to support photosynthesis, the availability of water, and the availability of suitable temperatures for carrying out photosynthesis.\nEnergy flow.\nEnergy and carbon enter ecosystems through photosynthesis, are incorporated into living tissue, transferred to other organisms that feed on the living and dead plant matter, and eventually released through respiration. The carbon and energy incorporated into plant tissues (net primary production) is either consumed by animals while the plant is alive, or it remains uneaten when the plant tissue dies and becomes detritus. In terrestrial ecosystems, the vast majority of the net primary production ends up being broken down by decomposers. The remainder is consumed by animals while still alive and enters the plant-based trophic system. After plants and animals die, the organic matter contained in them enters the detritus-based trophic system.\nEcosystem respiration is the sum of respiration by all living organisms (plants, animals, and decomposers) in the ecosystem. Net ecosystem production is the difference between gross primary production (GPP) and ecosystem respiration. In the absence of disturbance, net ecosystem production is equivalent to the net carbon accumulation in the ecosystem.\nEnergy can also be released from an ecosystem through disturbances such as wildfire or transferred to other ecosystems (e.g., from a forest to a stream to a lake) by erosion.\nIn aquatic systems, the proportion of plant biomass that gets consumed by herbivores is much higher than in terrestrial systems. In trophic systems, photosynthetic organisms are the primary producers. The organisms that consume their tissues are called primary consumers or secondary producers\u2014herbivores. Organisms which feed on microbes (bacteria and fungi) are termed microbivores. Animals that feed on primary consumers\u2014carnivores\u2014are secondary consumers. Each of these constitutes a trophic level.\nThe sequence of consumption\u2014from plant to herbivore, to carnivore\u2014forms a food chain. Real systems are much more complex than this\u2014organisms will generally feed on more than one form of food, and may feed at more than one trophic level. Carnivores may capture some prey that is part of a plant-based trophic system and others that are part of a detritus-based trophic system (a bird that feeds both on herbivorous grasshoppers and earthworms, which consume detritus). Real systems, with all these complexities, form food webs rather than food chains.\nDecomposition.\nThe carbon and nutrients in dead organic matter are broken down by a group of processes known as decomposition. This releases nutrients that can then be re-used for plant and microbial production and returns carbon dioxide to the atmosphere (or water) where it can be used for photosynthesis. In the absence of decomposition, the dead organic matter would accumulate in an ecosystem, and nutrients and atmospheric carbon dioxide would be depleted.\nDecomposition processes can be separated into three categories\u2014leaching, fragmentation and chemical alteration of dead material. As water moves through dead organic matter, it dissolves and carries with it the water-soluble components. These are then taken up by organisms in the soil, react with mineral soil, or are transported beyond the confines of the ecosystem (and are considered lost to it). Newly shed leaves and newly dead animals have high concentrations of water-soluble components and include sugars, amino acids and mineral nutrients. Leaching is more important in wet environments and less important in dry ones.\nFragmentation processes break organic material into smaller pieces, exposing new surfaces for colonization by microbes. Freshly shed leaf litter may be inaccessible due to an outer layer of cuticle or bark, and cell contents are protected by a cell wall. Newly dead animals may be covered by an exoskeleton. Fragmentation processes, which break through these protective layers, accelerate the rate of microbial decomposition. Animals fragment detritus as they hunt for food, as does passage through the gut. Freeze-thaw cycles and cycles of wetting and drying also fragment dead material.\nThe chemical alteration of the dead organic matter is primarily achieved through bacterial and fungal action. Fungal hyphae produce enzymes that can break through the tough outer structures surrounding dead plant material. They also produce enzymes that break down lignin, which allows them access to both cell contents and the nitrogen in the lignin. Fungi can transfer carbon and nitrogen through their hyphal networks and thus, unlike bacteria, are not dependent solely on locally available resources.\nDecomposition rates.\nDecomposition rates vary among ecosystems. The rate of decomposition is governed by three sets of factors\u2014the physical environment (temperature, moisture, and soil properties), the quantity and quality of the dead material available to decomposers, and the nature of the microbial community itself. Temperature controls the rate of microbial respiration; the higher the temperature, the faster the microbial decomposition occurs. Temperature also affects soil moisture, which affects decomposition. Freeze-thaw cycles also affect decomposition\u2014freezing temperatures kill soil microorganisms, which allows leaching to play a more important role in moving nutrients around. This can be especially important as the soil thaws in the spring, creating a pulse of nutrients that become available.\nDecomposition rates are low under very wet or very dry conditions. Decomposition rates are highest in wet, moist conditions with adequate levels of oxygen. Wet soils tend to become deficient in oxygen (this is especially true in wetlands), which slows microbial growth. In dry soils, decomposition slows as well, but bacteria continue to grow (albeit at a slower rate) even after soils become too dry to support plant growth.\nDynamics and resilience.\nEcosystems are dynamic entities. They are subject to periodic disturbances and are always in the process of recovering from past disturbances. When a perturbation occurs, an ecosystem responds by moving away from its initial state. The tendency of an ecosystem to remain close to its equilibrium state, despite that disturbance, is termed its resistance. The capacity of a system to absorb disturbance and reorganize while undergoing change so as to retain essentially the same function, structure, identity, and feedbacks is termed its ecological resilience. Resilience thinking also includes humanity as an integral part of the biosphere where we are dependent on ecosystem services for our survival and must build and maintain their natural capacities to withstand shocks and disturbances. Time plays a central role over a wide range, for example, in the slow development of soil from bare rock and the faster recovery of a community from disturbance.\nDisturbance also plays an important role in ecological processes. F. Stuart Chapin and coauthors define disturbance as \"a relatively discrete event in time that removes plant biomass\". This can range from herbivore outbreaks, treefalls, fires, hurricanes, floods, glacial advances, to volcanic eruptions. Such disturbances can cause large changes in plant, animal and microbe populations, as well as soil organic matter content. Disturbance is followed by succession, a \"directional change in ecosystem structure and functioning resulting from biotically driven changes in resource supply.\"\nThe frequency and severity of disturbance determine the way it affects ecosystem function. A major disturbance like a volcanic eruption or glacial advance and retreat leave behind soils that lack plants, animals or organic matter. Ecosystems that experience such disturbances undergo primary succession. A less severe disturbance like forest fires, hurricanes or cultivation result in secondary succession and a faster recovery. More severe and more frequent disturbance result in longer recovery times.\nFrom one year to another, ecosystems experience variation in their biotic and abiotic environments. A drought, a colder than usual winter, and a pest outbreak all are short-term variability in environmental conditions. Animal populations vary from year to year, building up during resource-rich periods and crashing as they overshoot their food supply. Longer-term changes also shape ecosystem processes. For example, the forests of eastern North America still show legacies of cultivation which ceased in 1850 when large areas were reverted to forests. Another example is the methane production in eastern Siberian lakes that is controlled by organic matter which accumulated during the Pleistocene.\nNutrient cycling.\nEcosystems continually exchange energy and carbon with the wider environment. Mineral nutrients, on the other hand, are mostly cycled back and forth between plants, animals, microbes and the soil. Most nitrogen enters ecosystems through biological nitrogen fixation, is deposited through precipitation, dust, gases or is applied as fertilizer. Most terrestrial ecosystems are nitrogen-limited in the short term making nitrogen cycling an important control on ecosystem production. Over the long term, phosphorus availability can also be critical.\nMacronutrients which are required by all plants in large quantities include the primary nutrients (which are most limiting as they are used in largest amounts): Nitrogen, phosphorus, potassium. Secondary major nutrients (less often limiting) include: Calcium, magnesium, sulfur. Micronutrients required by all plants in small quantities include boron, chloride, copper, iron, manganese, molybdenum, zinc. Finally, there are also beneficial nutrients which may be required by certain plants or by plants under specific environmental conditions: aluminum, cobalt, iodine, nickel, selenium, silicon, sodium, vanadium.\nUntil modern times, nitrogen fixation was the major source of nitrogen for ecosystems. Nitrogen-fixing bacteria either live symbiotically with plants or live freely in the soil. The energetic cost is high for plants that support nitrogen-fixing symbionts\u2014as much as 25% of gross primary production when measured in controlled conditions. Many members of the legume plant family support nitrogen-fixing symbionts. Some cyanobacteria are also capable of nitrogen fixation. These are phototrophs, which carry out photosynthesis. Like other nitrogen-fixing bacteria, they can either be free-living or have symbiotic relationships with plants. Other sources of nitrogen include acid deposition produced through the combustion of fossil fuels, ammonia gas which evaporates from agricultural fields which have had fertilizers applied to them, and dust. Anthropogenic nitrogen inputs account for about 80% of all nitrogen fluxes in ecosystems.\nWhen plant tissues are shed or are eaten, the nitrogen in those tissues becomes available to animals and microbes. Microbial decomposition releases nitrogen compounds from dead organic matter in the soil, where plants, fungi, and bacteria compete for it. Some soil bacteria use organic nitrogen-containing compounds as a source of carbon, and release ammonium ions into the soil. This process is known as nitrogen mineralization. Others convert ammonium to nitrite and nitrate ions, a process known as nitrification. Nitric oxide and nitrous oxide are also produced during nitrification. Under nitrogen-rich and oxygen-poor conditions, nitrates and nitrites are converted to nitrogen gas, a process known as denitrification.\nMycorrhizal fungi which are symbiotic with plant roots, use carbohydrates supplied by the plants and in return transfer phosphorus and nitrogen compounds back to the plant roots. This is an important pathway of organic nitrogen transfer from dead organic matter to plants. This mechanism may contribute to more than 70 Tg of annually assimilated plant nitrogen, thereby playing a critical role in global nutrient cycling and ecosystem function.\nPhosphorus enters ecosystems through weathering. As ecosystems age this supply diminishes, making phosphorus-limitation more common in older landscapes (especially in the tropics). Calcium and sulfur are also produced by weathering, but acid deposition is an important source of sulfur in many ecosystems. Although magnesium and manganese are produced by weathering, exchanges between soil organic matter and living cells account for a significant portion of ecosystem fluxes. Potassium is primarily cycled between living cells and soil organic matter.\nFunction and biodiversity.\nBiodiversity plays an important role in ecosystem functioning. Ecosystem processes are driven by the species in an ecosystem, the nature of the individual species, and the relative abundance of organisms among these species. Ecosystem processes are the net effect of the actions of individual organisms as they interact with their environment. Ecological theory suggests that in order to coexist, species must have some level of limiting similarity\u2014they must be different from one another in some fundamental way, otherwise, one species would competitively exclude the other. Despite this, the cumulative effect of additional species in an ecosystem is not linear: additional species may enhance nitrogen retention, for example. However, beyond some level of species richness, additional species may have little additive effect unless they differ substantially from species already present. This is the case for example for exotic species.\nThe addition (or loss) of species that are ecologically similar to those already present in an ecosystem tends to only have a small effect on ecosystem function. Ecologically distinct species, on the other hand, have a much larger effect. Similarly, dominant species have a large effect on ecosystem function, while rare species tend to have a small effect. Keystone species tend to have an effect on ecosystem function that is disproportionate to their abundance in an ecosystem.\nAn ecosystem engineer is any organism that creates, significantly modifies, maintains or destroys a habitat.\nStudy approaches.\nEcosystem ecology.\nEcosystem ecology is the \"study of the interactions between organisms and their environment as an integrated system\". The size of ecosystems can range up to ten orders of magnitude, from the surface layers of rocks to the surface of the planet.\nThe Hubbard Brook Ecosystem Study started in 1963 to study the White Mountains in New Hampshire. It was the first successful attempt to study an entire watershed as an ecosystem. The study used stream chemistry as a means of monitoring ecosystem properties, and developed a detailed biogeochemical model of the ecosystem. Long-term research at the site led to the discovery of acid rain in North America in 1972. Researchers documented the depletion of soil cations (especially calcium) over the next several decades.\nEcosystems can be studied through a variety of approaches\u2014theoretical studies, studies monitoring specific ecosystems over long periods of time, those that look at differences between ecosystems to elucidate how they work and direct manipulative experimentation. Studies can be carried out at a variety of scales, ranging from whole-ecosystem studies to studying or mesocosms (simplified representations of ecosystems). American ecologist Stephen R. Carpenter has argued that microcosm experiments can be \"irrelevant and diversionary\" if they are not carried out in conjunction with field studies done at the ecosystem scale. In such cases, microcosm experiments may fail to accurately predict ecosystem-level dynamics.\nClassifications.\nBiomes are general classes or categories of ecosystems. However, there is no clear distinction between biomes and ecosystems. Biomes are always defined at a very general level. Ecosystems can be described at levels that range from very general (in which case the names are sometimes the same as those of biomes) to very specific, such as \"wet coastal needle-leafed forests\".\nBiomes vary due to global variations in climate. Biomes are often defined by their structure: at a general level, for example, tropical forests, temperate grasslands, and arctic tundra. There can be any degree of subcategories among ecosystem types that comprise a biome, e.g., needle-leafed boreal forests or wet tropical forests. Although ecosystems are most commonly categorized by their structure and geography, there are also other ways to categorize and classify ecosystems such as by their level of human impact (see anthropogenic biome), or by their integration with social processes or technological processes or their novelty (e.g. novel ecosystem). Each of these taxonomies of ecosystems tends to emphasize different structural or functional properties. None of these is the \"best\" classification.\nEcosystem classifications are specific kinds of ecological classifications that consider all four elements of the definition of ecosystems: a biotic component, an abiotic complex, the interactions between and within them, and the physical space they occupy. Different approaches to ecological classifications have been developed in terrestrial, freshwater and marine disciplines, and a function-based typology has been proposed to leverage the strengths of these different approaches into a unified system.\nHuman interactions with ecosystems.\nHuman activities are important in almost all ecosystems. Although humans exist and operate within ecosystems, their cumulative effects are large enough to influence external factors like climate.\nEcosystem goods and services.\nEcosystems provide a variety of goods and services upon which people depend. Ecosystem goods include the \"tangible, material products\" of ecosystem processes such as water, food, fuel, construction material, and medicinal plants. They also include less tangible items like tourism and recreation, and genes from wild plants and animals that can be used to improve domestic species.\nEcosystem services, on the other hand, are generally \"improvements in the condition or location of things of value\". These include things like the maintenance of hydrological cycles, cleaning air and water, the maintenance of oxygen in the atmosphere, crop pollination and even things like beauty, inspiration and opportunities for research. While material from the ecosystem had traditionally been recognized as being the basis for things of economic value, ecosystem services tend to be taken for granted.\nThe \"Millennium Ecosystem Assessment\" is an international synthesis by over 1000 of the world's leading biological scientists that analyzes the state of the Earth's ecosystems and provides summaries and guidelines for decision-makers. The report identified four major categories of ecosystem services: provisioning, regulating, cultural and supporting services. It concludes that human activity is having a significant and escalating impact on the biodiversity of the world ecosystems, reducing both their resilience and biocapacity. The report refers to natural systems as humanity's \"life-support system\", providing essential ecosystem services. The assessment measures 24 ecosystem services and concludes that only four have shown improvement over the last 50 years, 15 are in serious decline, and five are in a precarious condition.\nThe Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services (IPBES) is an intergovernmental organization established to improve the interface between science and policy on issues of biodiversity and ecosystem services. It is intended to serve a similar role to the Intergovernmental Panel on Climate Change. The conceptual framework of the IPBES includes six primary interlinked elements: nature, nature\u2019s benefits to people, anthropogenic assets, institutions and governance systems and other indirect drivers of change, direct drivers of change, and good quality of life.\nEcosystem services are limited and also threatened by human activities. To help inform decision-makers, many ecosystem services are being assigned economic values, often based on the cost of replacement with anthropogenic alternatives. The ongoing challenge of prescribing economic value to nature, for example through biodiversity banking, is prompting transdisciplinary shifts in how we recognize and manage the environment, social responsibility, business opportunities, and our future as a species.\nDegradation and decline.\nAs human population and per capita consumption grow, so do the resource demands imposed on ecosystems and the effects of the human ecological footprint. Natural resources are vulnerable and limited. The environmental impacts of anthropogenic actions are becoming more apparent. Problems for all ecosystems include: environmental pollution, climate change and biodiversity loss. For terrestrial ecosystems further threats include air pollution, soil degradation, and deforestation. For aquatic ecosystems threats also include unsustainable exploitation of marine resources (for example overfishing), marine pollution, microplastics pollution, the effects of climate change on oceans (e.g. warming and acidification), and building on coastal areas.\nMany ecosystems become degraded through human impacts, such as soil loss, air and water pollution, habitat fragmentation, water diversion, fire suppression, and introduced species and invasive species.\nThese threats can lead to abrupt transformation of the ecosystem or to gradual disruption of biotic processes and degradation of abiotic conditions of the ecosystem. Once the original ecosystem has lost its defining features, it is considered \"collapsed\" (see also IUCN Red List of Ecosystems). Ecosystem collapse could be reversible and in this way differs from species extinction. Quantitative assessments of the risk of collapse are used as measures of conservation status and trends.\nManagement.\nWhen natural resource management is applied to whole ecosystems, rather than single species, it is termed ecosystem management. Although definitions of ecosystem management abound, there is a common set of principles which underlie these definitions: A fundamental principle is the long-term sustainability of the production of goods and services by the ecosystem; \"intergenerational sustainability [is] a precondition for management, not an afterthought\". While ecosystem management can be used as part of a plan for wilderness conservation, it can also be used in intensively managed ecosystems (see, for example, agroecosystem and close to nature forestry).\nRestoration and sustainable development.\nIntegrated conservation and development projects (ICDPs) aim to address conservation and human livelihood (sustainable development) concerns in developing countries together, rather than separately as was often done in the past.\nSee also.\nTypes.\nThe following articles are types of ecosystems for particular types of regions or zones:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nInstances.\nEcosystem instances in specific regions of the world:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9633", "revid": "41369960", "url": "https://en.wikipedia.org/wiki?curid=9633", "title": "E (mathematical constant)", "text": "2.71828..., base of natural logarithms\nThe number e, also known as Euler's number, is a mathematical constant approximately equal to 2.71828 that can be characterized in many ways. It is the base of natural logarithms. It is the limit of (1 + 1/\"n\")\"n\" as n approaches infinity, an expression that arises in the study of compound interest. It can also be calculated as the sum of the infinite series\nformula_1\nIt is also the unique positive number a such that the graph of the function \"y\" = \"a\"\"x\" has a slope of 1 at \"x\" = 0.\nThe (natural) exponential function \"f\"(\"x\") = \"e\"\"x\" is the unique function f that equals its own derivative and satisfies the equation \"f\"(0) = 1; hence one can also define e as \"f\"(1). The natural logarithm, or logarithm to base e, is the inverse function to the natural exponential function. The natural logarithm of a number \"k\" &gt; 1 can be defined directly as the area under the curve \"y\" = 1/\"x\" between \"x\" = 1 and \"x\" = \"k\", in which case e is the value of \"k\" for which this area equals 1 (see image). There are various other characterizations.\nThe number e is sometimes called Euler's number (not to be confused with Euler's constant formula_2)\u2014after the Swiss mathematician Leonhard Euler\u2014or Napier's constant\u2014after John Napier. The constant was discovered by the Swiss mathematician Jacob Bernoulli while studying compound interest.\nThe number e is of great importance in mathematics, alongside 0, 1, \u03c0, and i. All five appear in one formulation of Euler's identity formula_3 and play important and recurring roles across mathematics. Like the constant \u03c0, e is irrational (it cannot be represented as a ratio of integers) and transcendental (it is not a root of any non-zero polynomial with rational coefficients). To 50 decimal places, the value of e is:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;.\nHistory.\nThe first references to the constant were published in 1618 in the table of an appendix of a work on logarithms by John Napier. However, this did not contain the constant itself, but simply a list of logarithms to the base formula_4. It is assumed that the table was written by William Oughtred.\nThe constant itself was introduced by Jacob Bernoulli in 1683, for solving the problem of continuous compounding of interest. \nIn his solution, the constant e occurs as the limit \nformula_5\nwhere n represents the fraction of the year on which the compound interest is evaluated (for example, formula_6 for a month).\nThe first known use of the constant, represented by the letter \"b\", was in correspondence from Gottfried Leibniz to Christiaan Huygens in 1690 and 1691. \nLeonhard Euler started to use the letter e for the constant in 1727 or 1728, in an unpublished paper on explosive forces in cannons, and in a letter to Christian Goldbach on 25 November 1731. The first appearance of e in a printed publication was in Euler's \"Mechanica\" (1736). It is unknown why Euler chose the letter e. Although some researchers used the letter \"c\" in the subsequent years, the letter e was more common and eventually became standard.\nApplications.\nCompound interest.\nJacob Bernoulli discovered this constant in 1683, while studying a question about compound interest:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;An account starts with $1.00 and pays 100 percent interest per year. If the interest is credited once, at the end of the year, the value of the account at year-end will be $2.00. What happens if the interest is computed and credited more frequently during the year?\nIf the interest is credited twice in the year, the interest rate for each 6 months will be 50%, so the initial $1 is multiplied by 1.5 twice, yielding $1.00 \u00d7 1.52 = $2.25 at the end of the year. Compounding quarterly yields $1.00 \u00d7 1.254 = $2.44140625, and compounding monthly yields $1.00 \u00d7 (1 + 1/12)12 = $2.613035... If there are \"n\" compounding intervals, the interest for each interval will be 100%/\"n\" and the value at the end of the year will be $1.00\u00a0\u00d7\u00a0(1 + 1/\"n\")\"n\".\nBernoulli noticed that this sequence approaches a limit (the force of interest) with larger \"n\" and, thus, smaller compounding intervals. Compounding weekly (\"n\" = 52) yields $2.692596..., while compounding daily (\"n\" = 365) yields $2.714567... (approximately two cents more). The limit as \"n\" grows large is the number that came to be known as e. That is, with \"continuous\" compounding, the account value will reach $2.718281828...\nMore generally, an account that starts at $1 and offers an annual interest rate of \"R\" will, after \"t\" years, yield \"e\"\"Rt\" dollars with continuous compounding.\nBernoulli trials.\nThe number e itself also has applications in probability theory, in a way that is not obviously related to exponential growth. Suppose that a gambler plays a slot machine that pays out with a probability of one in \"n\" and plays it \"n\" times. As \"n\" increases, the probability that gambler will lose all n bets approaches 1/\"e\". For \"n\" = 20, this is already approximately 1/2.789509...\nThis is an example of a Bernoulli trial process. Each time the gambler plays the slots, there is a one in \"n\" chance of winning. Playing \"n\" times is modeled by the binomial distribution, which is closely related to the binomial theorem and Pascal's triangle. The probability of winning \"k\" times out of \"n\" trials is:\nformula_7\nIn particular, the probability of winning zero times (\"k\" = 0) is\nformula_8\nThe limit of the above expression, as \"n\" tends to infinity, is precisely 1/\"e\".\nStandard normal distribution.\nThe normal distribution with zero mean and unit standard deviation is known as the \"standard normal distribution\", given by the probability density function\nformula_9\nThe constraint of unit variance (and thus also unit standard deviation) results in the in the exponent, and the constraint of unit total area under the curve formula_10 results in the factor formula_11.[proof] This function is symmetric around \"x\" = 0, where it attains its maximum value formula_11, and has inflection points at \"x\" = \u00b11.\nDerangements.\nAnother application of e, also discovered in part by Jacob Bernoulli along with Pierre Remond de Montmort, is in the problem of derangements, also known as the \"hat check problem\": \"n\" guests are invited to a party and, at the door, the guests all check their hats with the butler, who in turn places the hats into \"n\" boxes, each labelled with the name of one guest. But the butler has not asked the identities of the guests, and so puts the hats into boxes selected at random. The problem of de Montmort is to find the probability that \"none\" of the hats gets put into the right box. This probability, denoted by formula_13, is:\nformula_14\nAs \"n\" tends to infinity, \"p\"\"n\" approaches 1/\"e\". Furthermore, the number of ways the hats can be placed into the boxes so that none of the hats are in the right box is \"n\"!/\"e\", rounded to the nearest integer, for every positive\u00a0\"n\".\nOptimal planning problems.\nThe maximum value of formula_15 occurs at formula_16. Equivalently, for any value of the base \"b\" &gt; 1, it is the case that the maximum value of formula_17 occurs at formula_16 (Steiner's problem, discussed below).\nThis is useful in the problem of a stick of length L that is broken into n equal parts. The value of n that maximizes the product of the lengths is then either\nformula_19 or formula_20\nThe quantity formula_17 is also a measure of information gleaned from an event occurring with probability formula_22, so that essentially the same optimal division appears in optimal planning problems like the secretary problem.\nAsymptotics.\nThe number e occurs naturally in connection with many problems involving asymptotics. An example is Stirling's formula for the asymptotics of the factorial function, in which both the numbers e and \u03c0 appear:\nformula_23\nAs a consequence,\nformula_24\nIn calculus.\nThe principal motivation for introducing the number e, particularly in calculus, is to perform differential and integral calculus with exponential functions and logarithms. A general exponential has a derivative, given by a limit:\nformula_25\nThe parenthesized limit on the right is independent of the Its value turns out to be the logarithm of \"a\" to base e. Thus, when the value of \"a\" is set this limit is equal and so one arrives at the following simple identity:\nformula_26\nConsequently, the exponential function with base e is particularly suited to doing calculus. (as opposed to some other number as the base of the exponential function) makes calculations involving the derivatives much simpler.\nAnother motivation comes from considering the derivative of the base-\"a\" logarithm (i.e., log\"a\" \"x\"), for\u00a0\"x\" &gt; 0:\nformula_27\nwhere the substitution \"u\" \n \"h\"/\"x\" was made. The base-a logarithm of e is 1, if a equals e. So symbolically,\nformula_28\nThe logarithm with this special base is called the natural logarithm, and is denoted as ln; it behaves well under differentiation since there is no undetermined limit to carry through the calculations.\nThus, there are two ways of selecting such special numbers a. One way is to set the derivative of the exponential function \"a\"\"x\" equal to \"a\"\"x\", and solve for \"a\". The other way is to set the derivative of the base \"a\" logarithm to 1/\"x\" and solve for \"a\". In each case, one arrives at a convenient choice of base for doing calculus. It turns out that these two solutions for a are actually \"the same\": the number e.\nAlternative characterizations.\nOther characterizations of e are also possible: one is as the limit of a sequence, another is as the sum of an infinite series, and still others rely on integral calculus. So far, the following two (equivalent) properties have been introduced:\nThe following four characterizations can be proved to be equivalent:\n&lt;/math&gt;\n | The number e is the sum of the infinite series\n formula_31\nwhere \"n\"! is the factorial of \"n\".\n | The number e is the unique positive real number such that\nformula_32\n | If \"f\"(\"t\") is an exponential function, then the quantity formula_33 is a constant, sometimes called the time constant (it is the reciprocal of the exponential growth constant or decay constant). The time constant is the time it takes for the exponential function to increase by a factor of \"e\": formula_34.\nProperties.\nCalculus.\nAs in the motivation, the exponential function \"e\"\"x\" is important in part because it is the unique function (up to multiplication by a constant K) that is equal to its own derivative:\nformula_35\nand therefore its own antiderivative as well:\nformula_36 \nEquivalently, the family of functions\nformula_37\nwhere K is any real or complex number, is the solution to the differential equation\nformula_38\nInequalities.\nThe number \"e\" is the unique real number such that\nformula_39\nfor all positive \"x\".\nAlso, we have the inequality\nformula_40\nfor all real \"x\", with equality if and only if \"x\" \n 0. Furthermore, \"e\" is the unique base of the exponential for which the inequality \"a\"\"x\" \u2265 \"x\" + 1 holds for all \"x\". This is a limiting case of Bernoulli's inequality.\nExponential-like functions.\nSteiner's problem asks to find the global maximum for the function\nformula_41\nThis maximum occurs precisely at \"x\" \n \"e\". (One can check that the derivative of ln \"f\"(\"x\") is zero only for this value of\u00a0x.)\nSimilarly, \"x\" \n 1/\"e\" is where the global minimum occurs for the function\nformula_42\nThe infinite tetration\nformula_43 or formula_44\nconverges if and only if \"x\" \u2208 [\"e\"\u2212\"e\", \"e\"1/\"e\"] \u2248 [0.06599, 1.4447], shown by a theorem of Leonhard Euler.\nNumber theory.\nThe real number e is irrational. Euler proved this by showing that its simple continued fraction expansion is infinite. (See also Fourier's proof that \"e\" is irrational.)\nFurthermore, by the Lindemann\u2013Weierstrass theorem, e is transcendental, meaning that it is not a solution of any non-zero polynomial equation with rational coefficients. It was the first number to be proved transcendental without having been specifically constructed for this purpose (compare with Liouville number); the proof was given by Charles Hermite in 1873.\nIt is conjectured that e is normal, meaning that when \"e\" is expressed in any base the possible digits in that base are uniformly distributed (occur with equal probability in any sequence of given length).\nIt is conjectured that e is not a Kontsevich-Zagier period.\nComplex numbers.\nThe exponential function \"e\"\"x\" may be written as a Taylor series\nformula_45\nBecause this series is convergent for every complex value of x, it is commonly used to extend the definition of \"e\"\"x\" to the complex numbers. This, with the Taylor series for sin and cos \"x\", allows one to derive Euler's formula:\nformula_46\nwhich holds for every complex \"x\". The special case with \"x\" \n \u03c0 is Euler's identity:\nformula_47\nfrom which it follows that, in the principal branch of the logarithm,\nformula_48\nFurthermore, using the laws for exponentiation,\nformula_49\nwhich is de Moivre's formula.\nThe expressions of cos \"x\" and sin \"x\" in terms of the exponential function can be deduced from the Taylor series:\nformula_50\nThe expression\nformula_51\nis sometimes abbreviated as cis(\"x\").\nRepresentations.\nThe number e can be represented in a variety of ways: as an infinite series, an infinite product, a continued fraction, or a limit of a sequence. Two of these representations, often used in introductory calculus courses, are the limit\nformula_52\ngiven above, and the series\nformula_53\nobtained by evaluating at \"x\" \n 1 the above power series representation of \"e\"\"x\".\nLess common is the continued fraction\nformula_54\nwhich written out looks like\nformula_55\nThis continued fraction for e converges three times as quickly:\nformula_56\nMany other series, sequence, continued fraction, and infinite product representations of e have been proved.\nStochastic representations.\nIn addition to exact analytical expressions for representation of e, there are stochastic techniques for estimating e. One such approach begins with an infinite sequence of independent random variables \"X\"1, \"X\"2..., drawn from the uniform distribution on [0, 1]. Let \"V\" be the least number \"n\" such that the sum of the first \"n\" observations exceeds 1:\nformula_57\nThen the expected value of \"V\" is e: E(\"V\") \n \"e\".\nKnown digits.\nThe number of known digits of e has increased substantially during the last decades. This is due both to the increased performance of computers and to algorithmic improvements.\nSince around 2010, the proliferation of modern high-speed desktop computers has made it feasible for most amateurs to compute trillions of digits of e within acceptable amounts of time. On Dec 5, 2020, a record-setting calculation was made, giving e to 31,415,926,535,897 (approximately \u03c0\u00d71013) digits.\nComputing the digits.\nOne way to compute the digits of e is with the series\nformula_58\nA faster method involves two recursive function formula_59 and formula_60. The functions are defined as formula_61.\nThe expression formula_62 produces the digits of e. This method uses binary splitting to compute e with fewer single-digit arithmetic operations and reduced bit complexity. Combining this with Fast Fourier Transform-based methods of multiplying integers makes computing the digits very fast.\nIn computer culture.\nDuring the emergence of internet culture, individuals and organizations sometimes paid homage to the number e.\nIn an early example, the computer scientist Donald Knuth let the version numbers of his program Metafont approach e. The versions are 2, 2.7, 2.71, 2.718, and so forth.\nIn another instance, the IPO filing for Google in 2004, rather than a typical round-number amount of money, the company announced its intention to raise 2,718,281,828 USD, which is e billion dollars rounded to the nearest dollar.\nGoogle was also responsible for a billboard\nthat appeared in the heart of Silicon Valley, and later in Cambridge, Massachusetts; Seattle, Washington; and Austin, Texas. It read \"{first 10-digit prime found in consecutive digits of e}.com\". The first 10-digit prime in e is 7427466391, which starts at the 99th digit. Solving this problem and visiting the advertised (now defunct) website led to an even more difficult problem to solve, which consisted in finding the fifth term in the sequence 7182818284, 8182845904, 8747135266, 7427466391. It turned out that the sequence consisted of 10-digit numbers found in consecutive digits of e whose digits summed to 49. The fifth term in the sequence is 5966290435, which starts at the 127th digit.\nSolving this second problem finally led to a Google Labs webpage where the visitor was invited to submit a r\u00e9sum\u00e9.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9635", "revid": "4626", "url": "https://en.wikipedia.org/wiki?curid=9635", "title": "Euler - Maclaurin formula", "text": ""}
{"id": "9637", "revid": "1157129224", "url": "https://en.wikipedia.org/wiki?curid=9637", "title": "Euler\u2013Maclaurin formula", "text": "Summation formula\nIn mathematics, the Euler\u2013Maclaurin formula is a formula for the difference between an integral and a closely related sum. It can be used to approximate integrals by finite sums, or conversely to evaluate finite sums and infinite series using integrals and the machinery of calculus. For example, many asymptotic expansions are derived from the formula, and Faulhaber's formula for the sum of powers is an immediate consequence.\nThe formula was discovered independently by Leonhard Euler and Colin Maclaurin around 1735. Euler needed it to compute slowly converging infinite series while Maclaurin used it to calculate integrals. It was later generalized to Darboux's formula.\nThe formula.\nIf m and n are natural numbers and \"f\"(\"x\") is a real or complex valued continuous function for real numbers x in the interval [\"m\",\"n\"], then the integral\nformula_1\ncan be approximated by the sum (or vice versa)\nformula_2\n(see rectangle method). The Euler\u2013Maclaurin formula provides expressions for the difference between the sum and the integral in terms of the higher derivatives \"f\"(\"k\")(\"x\") evaluated at the endpoints of the interval, that is to say \"x\" \n \"m\" and \"x\" \n \"n\".\nExplicitly, for p a positive integer and a function \"f\"(\"x\") that is p times continuously differentiable on the interval [\"m\",\"n\"], we have\nformula_3\nwhere Bk is the kth Bernoulli number (with \"B\"1 \n ) and Rp is an error term which depends on n, m, p, and f and is usually small for suitable values of p.\nThe formula is often written with the subscript taking only even values, since the odd Bernoulli numbers are zero except for \"B\"1. In this case we have\nformula_4\nor alternatively\nformula_5\nThe remainder term.\nThe remainder term arises because the integral is usually not exactly equal to the sum. The formula may be derived by applying repeated integration by parts to successive intervals [\"r\", \"r\" + 1] for \"r\" \n \"m\", \"m\" + 1, \u2026, \"n\" \u2212 1. The boundary terms in these integrations lead to the main terms of the formula, and the leftover integrals form the remainder term.\nThe remainder term has an exact expression in terms of the periodized Bernoulli functions \"Pk\"(\"x\"). The Bernoulli polynomials may be defined recursively by \"B\"0(\"x\") \n 1 and, for \"k\" \u2265 1,\nformula_6\nThe periodized Bernoulli functions are defined as\nformula_7\nwhere \u230a\"x\"\u230b denotes the largest integer less than or equal to x, so that \"x\" \u2212 \u230a\"x\"\u230b always lies in the interval [0,1).\nWith this notation, the remainder term Rp equals\nformula_8\nWhen \"k\" &gt; 0, it can be shown that\nformula_9\nwhere \u03b6 denotes the Riemann zeta function; one approach to prove this inequality is to obtain the Fourier series for the polynomials \"Bk\"(\"x\"). The bound is achieved for even k when x is zero. The term \"\u03b6\"(\"k\") may be omitted for odd k but the proof in this case is more complex (see Lehmer). Using this inequality, the size of the remainder term can be estimated as\nformula_10\nLow-order cases.\nThe Bernoulli numbers from \"B\"1 to \"B\"7 are , , 0, \u2212, 0, , 0. Therefore the low-order cases of the Euler\u2013Maclaurin formula are:\nformula_11\nApplications.\nThe Basel problem.\nThe Basel problem is to determine the sum\nformula_12\nEuler computed this sum to 20 decimal places with only a few terms of the Euler\u2013Maclaurin formula in 1735. This probably convinced him that the sum equals , which he proved in the same year.\nSums involving a polynomial.\nIf f is a polynomial and p is big enough, then the remainder term vanishes. For instance, if \"f\"(\"x\") \n \"x\"3, we can choose \"p\" \n 2 to obtain, after simplification,\nformula_13\nApproximation of integrals.\nThe formula provides a means of approximating a finite integral. Let \"a\" &lt; \"b\" be the endpoints of the interval of integration. Fix N, the number of points to use in the approximation, and denote the corresponding step size by \"h\" \n . Set \"xi\" \n \"a\" + (\"i\" \u2212 1)\"h\", so that \"x\"1 \n \"a\" and \"xN\" \n \"b\". Then:\nformula_14\nThis may be viewed as an extension of the trapezoid rule by the inclusion of correction terms. Note that this asymptotic expansion is usually not convergent; there is some p, depending upon f and h, such that the terms past order p increase rapidly. Thus, the remainder term generally demands close attention.\nThe Euler\u2013Maclaurin formula is also used for detailed error analysis in numerical quadrature. It explains the superior performance of the trapezoidal rule on smooth periodic functions and is used in certain extrapolation methods. Clenshaw\u2013Curtis quadrature is essentially a change of variables to cast an arbitrary integral in terms of integrals of periodic functions where the Euler\u2013Maclaurin approach is very accurate (in that particular case the Euler\u2013Maclaurin formula takes the form of a discrete cosine transform). This technique is known as a periodizing transformation.\nAsymptotic expansion of sums.\nIn the context of computing asymptotic expansions of sums and series, usually the most useful form of the Euler\u2013Maclaurin formula is\nformula_15\nwhere a and b are integers. Often the expansion remains valid even after taking the limits \"a\" \u2192 \u2212\u221e or \"b\" \u2192 +\u221e or both. In many cases the integral on the right-hand side can be evaluated in closed form in terms of elementary functions even though the sum on the left-hand side cannot. Then all the terms in the asymptotic series can be expressed in terms of elementary functions. For example,\nformula_16\nHere the left-hand side is equal to \"\u03c8\"(1)(\"z\"), namely the first-order polygamma function defined by\nformula_17\nthe gamma function \u0393(\"z\") is equal to (\"z\" \u2212 1)! when z is a positive integer. This results in an asymptotic expansion for \"\u03c8\"(1)(\"z\"). That expansion, in turn, serves as the starting point for one of the derivations of precise error estimates for Stirling's approximation of the factorial function.\nExamples.\nIf s is an integer greater than 1 we have:\nformula_18\nCollecting the constants into a value of the Riemann zeta function, we can write an asymptotic expansion:\nformula_19\nFor s equal to 2 this simplifies to\nformula_20\nor\nformula_21\nWhen \"s\" \n 1, the corresponding technique gives an asymptotic expansion for the harmonic numbers:\nformula_22\nwhere \"\u03b3\" \u2248 0.5772... is the Euler\u2013Mascheroni constant.\nProofs.\nDerivation by mathematical induction.\nWe outline the argument given in Apostol.\nThe Bernoulli polynomials \"Bn\"(\"x\") and the periodic Bernoulli functions \"Pn\"(\"x\") for \"n\" \n 0, 1, 2, ... were introduced above.\nThe first several Bernoulli polynomials are\nformula_23\nThe values \"Bn\"(1) are the Bernoulli numbers \"B\"\"n\". Notice that for \"n\" \u2260 1 we have\nformula_24\nand for \"n\" \n 1,\nformula_25\nThe functions \"P\"\"n\" agree with the Bernoulli polynomials on the interval [0,\u00a01] and are periodic with period 1. Furthermore, except when \"n\" \n 1, they are also continuous. Thus,\nformula_26\nLet \"k\" be an integer, and consider the integral\nformula_27\nwhere\nformula_28\nIntegrating by parts, we get\nformula_29\nUsing \"B\"1(0) \n \u2212, \"B\"1(1) \n , and summing the above from \"k\" \n 0 to \"k\" \n \"n\" \u2212 1, we get\nformula_30\nAdding to both sides and rearranging, we have\nformula_31\nThis is the \"p\" \n 1 case of the summation formula. To continue the induction, we apply integration by parts to the error term:\nformula_32\nwhere\nformula_33\nThe result of integrating by parts is\nformula_34\nSumming from \"k\" \n 0 to \"k\" \n \"n\" \u2212 1 and substituting this for the lower order error term results in the \"p\" \n 2 case of the formula,\nformula_35\nThis process can be iterated. In this way we get a proof of the Euler\u2013Maclaurin summation formula which can be formalized by mathematical induction, in which the induction step relies on integration by parts and on identities for periodic Bernoulli functions.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9638", "revid": "24198", "url": "https://en.wikipedia.org/wiki?curid=9638", "title": "Epimenides paradox", "text": "Paradox revealing a problem with self-reference in logic\nThe Epimenides paradox reveals a problem with self-reference in logic. It is named after the Cretan philosopher Epimenides of Knossos (alive circa 600 BC) who is credited with the original statement. A typical description of the problem is given in the book \"G\u00f6del, Escher, Bach\", by Douglas Hofstadter:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Epimenides was a Cretan who made the immortal statement: \"All Cretans are liars.\"\nA paradox of self-reference arises when one considers whether it is possible for Epimenides to have spoken the truth.\nMythology of lying Cretans.\nAccording to Ptolemaeus Chennus, Thetis and Medea had once argued in Thessaly over which was the most beautiful; they appointed the Cretan Idomeneus as the judge, who gave the victory to Thetis. In her anger, Medea called all Cretans liars, and cursed them to never say the truth.\nLogical paradox.\nThomas Fowler (1869) states the paradox as follows: \"Epimenides the Cretan says, 'that all the Cretans are liars,' but Epimenides is himself a Cretan; therefore he is himself a liar. But if he is a liar, what he says is untrue, and consequently, the Cretans are veracious; but Epimenides is a Cretan, and therefore what he says is true; saying the Cretans are liars, Epimenides is himself a liar, and what he says is untrue. Thus we may go on alternately proving that Epimenides and the Cretans are truthful and untruthful.\"\nIf we assume the statement is false and that Epimenides is lying about all Cretans being liars, then there must exist at least one Cretan who is honest. This does not lead to a contradiction since it is not required that this Cretan be Epimenides. This means that Epimenides can say the false statement that all Cretans are liars while knowing at least one honest Cretan and lying about this particular Cretan. Hence, from the assumption that the statement is false, it does not follow that the statement is true. So we can avoid a paradox as seeing the statement \"all Cretans are liars\" as a false statement, which is made by a lying Cretan, Epimenides. The mistake made by Thomas Fowler (and many other people) above is to think that the negation of \"all Cretans are liars\" is \"all Cretans are honest\" (a paradox) when in fact the negation is \"there exists a Cretan who is honest\", or \"not all Cretans are liars\". The Epimenides paradox can be slightly modified as to not allow the kind of solution described above, as it was in the first paradox of Eubulides but instead leading to a non-avoidable self-contradiction. Paradoxical versions of the Epimenides problem are closely related to a class of more difficult logical problems, including the liar paradox, Socratic paradox and the Burali-Forti paradox, all of which have self-reference in common with Epimenides. The Epimenides paradox is usually classified as a variation on the liar paradox, and sometimes the two are not distinguished. The study of self-reference led to important developments in logic and mathematics in the twentieth century.\nIn other words, it is not a paradox once one realizes \"All Cretans are liars\" being untrue only means \"Not all Cretans are liars\" instead of the assumption that \"All Cretans are honest\".\nPerhaps better put, for \"All Cretans are liars\" to be a true statement, it does not mean that all Cretans must lie all the time. In fact, Cretans could tell the truth quite often, but still all be liars in the sense that liars are people prone to deception for dishonest gain. Considering that \"All Cretans are liars\" has been seen as a paradox only since the 19th century, this seems to resolve the alleged paradox. If 'all Cretans are continuous liars' is actually true, then asking a Cretan if they are honest would always elicit the dishonest answer 'yes'. So arguably the original proposition is not so much paradoxical as invalid.\nA contextual reading of the contradiction may also provide an answer to the paradox. The original phrase, \"The Cretans, always liars, evil beasts, idle bellies!\" asserts not an intrinsic paradox, but rather an opinion of the Cretans from Epimenides. A stereotyping of his people not intended to be an absolute statement about the people as a whole. Rather it is a claim made about their position regarding their religious beliefs and socio-cultural attitudes. Within the context of his poem the phrase is specific to a certain belief, a context that Callimachus repeats in his poem regarding Zeus. Further, a more poignant answer to the paradox is simply that to be a \"liar\" is to state falsehoods, nothing in the statement asserts everything said is false, but rather they're \"always\" lying. This is not an absolute statement of fact and thus we cannot conclude there's a true contradiction made by Epimenides with this statement.\nOrigin of the phrase.\nEpimenides was a 6th-century BC philosopher and religious prophet who, against the general sentiment of Crete, proposed that Zeus was immortal, as in the following poem:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;They fashioned a tomb for thee, O holy and high one&lt;br&gt;The Cretans, always liars, evil beasts, idle bellies!&lt;br&gt;But thou art not dead: thou livest and abidest forever,&lt;br&gt;For in thee we live and move and have our being.\nDenying the immortality of Zeus, then, was the lie of the Cretans.\nThe phrase \"Cretans, always liars\" was quoted by the poet Callimachus in his \"Hymn to Zeus\", with the same theological intent as Epimenides:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;O Zeus, some say that thou wert born on the hills of Ida;&lt;br&gt; Others, O Zeus, say in Arcadia;&lt;br&gt; Did these or those, O Father lie? -- \"Cretans are ever liars\". &lt;br&gt;Yea, a tomb, O Lord, for thee the Cretans builded;&lt;br&gt; But thou didst not die, for thou art for ever.\nEmergence as a logical contradiction.\nThe logical inconsistency of a Cretan asserting all Cretans are always liars may not have occurred to Epimenides, nor to Callimachus, who both used the phrase to emphasize their point, without irony, perhaps meaning that all Cretans lie routinely, but not exclusively.\nIn the 1st century AD, the quote is mentioned by the author of the Epistle to Titus as having been spoken truly by \"one of their own prophets.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"One of Crete's own prophets has said it: 'Cretans are always liars, evil brutes, idle bellies'.&lt;br&gt;He has surely told the truth. For this reason correct them sternly, that they may be sound in faith instead of paying attention to Jewish fables and to commandments of people who turn their backs on the truth.\"\nClement of Alexandria, in the late 2nd century AD, fails to indicate that the concept of logical paradox is an issue:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In his epistle to Titus, Apostle Paul wants to warn Titus that Cretans don't believe in the one truth of Christianity, because \"Cretans are always liars\". To justify his claim, Apostle Paul cites Epimenides. \nDuring the early 4th century, Saint Augustine restates the closely related liar paradox in \"Against the Academicians\" (III.13.29), but without mentioning Epimenides.\nIn the Middle Ages, many forms of the liar paradox were studied under the heading of insolubilia, but these were not explicitly associated with Epimenides.\nFinally, in 1740, the second volume of Pierre Bayle's \"Dictionnaire Historique et Critique\" explicitly connects Epimenides with the paradox, though Bayle labels the paradox a \"sophisme\".\nReferences by other authors.\nAll of the works of Epimenides are now lost, and known only through quotations by other authors. The quotation from the \"Cretica\" of Epimenides is given by R.N. Longenecker, \"Acts of the Apostles\", in volume 9 of \"The Expositor's Bible Commentary\", Frank E. Gaebelein, editor (Grand Rapids, Michigan: Zondervan Corporation, 1976\u20131984), page 476. Longenecker in turn cites M.D. Gibson, \"Horae Semiticae X\" (Cambridge: Cambridge University Press, 1913), page 40, \"in Syriac\". Longenecker states the following in a footnote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Syr. version of the quatrain comes to us from the Syr. church father Isho'dad of Merv (probably based on the work of Theodore of Mopsuestia), which J.R. Harris translated back into Gr. in Exp [\"The Expositor\"] 7 (1907), p 336.\nAn oblique reference to Epimenides in the context of logic appears in \"The Logical Calculus\" by W. E. Johnson, \"Mind\" (New Series), volume 1, number 2 (April, 1892), pages 235\u2013250. Johnson writes in a footnote,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Compare, for example, such occasions for fallacy as are supplied by \"Epimenides is a liar\" or \"That surface is red,\" which may be resolved into \"All or some statements of Epimenides are false,\" \"All or some of the surface is red.\"\nThe Epimenides paradox appears explicitly in \"Mathematical Logic as Based on the Theory of Types\", by Bertrand Russell, in the \"American Journal of Mathematics\", volume 30, number 3 (July, 1908), pages 222\u2013262, which opens with the following:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The oldest contradiction of the kind in question is the Epimenides. Epimenides the Cretan said that all Cretans were liars, and all other statements made by Cretans were certainly lies. Was this a lie?\nIn that article, Russell uses the Epimenides paradox as the point of departure for discussions of other problems, including the Burali-Forti paradox and the paradox now called Russell's paradox. Since Russell, the Epimenides paradox has been referenced repeatedly in logic. Typical of these references is \"G\u00f6del, Escher, Bach\" by Douglas Hofstadter, which accords the paradox a prominent place in a discussion of self-reference.\nIt is also believed that the \"Cretan tales\" told by Odysseus in \"The Odyssey\" by Homer are a reference to this paradox.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9640", "revid": "8372814", "url": "https://en.wikipedia.org/wiki?curid=9640", "title": "Engine", "text": "Machine that converts one or more forms of energy into mechanical energy (of motion)\nAn engine or motor is a machine designed to convert one or more forms of energy into mechanical energy. \nAvailable energy sources include potential energy (e.g. energy of the Earth's gravitational field as exploited in hydroelectric power generation), heat energy (e.g. geothermal), chemical energy, electric potential and nuclear energy (from nuclear fission or nuclear fusion). Many of these processes generate heat as an intermediate energy form, so heat engines have special importance. Some natural processes, such as atmospheric convection cells convert environmental heat into motion (e.g. in the form of rising air currents). Mechanical energy is of particular importance in transportation, but also plays a role in many industrial processes such as cutting, grinding, crushing, and mixing.\nMechanical heat engines convert heat into work via various thermodynamic processes. The internal combustion engine is perhaps the most common example of a mechanical heat engine, in which heat from the combustion of a fuel causes rapid pressurisation of the gaseous combustion products in the combustion chamber, causing them to expand and drive a piston, which turns a crankshaft. Unlike internal combustion engines, a reaction engine (such as a jet engine) produces thrust by expelling reaction mass, in accordance with Newton's third law of motion.\nApart from heat engines, electric motors convert electrical energy into mechanical motion, pneumatic motors use compressed air, and clockwork motors in wind-up toys use elastic energy. In biological systems, molecular motors, like myosins in muscles, use chemical energy to create forces and ultimately motion (a chemical engine, but not a heat engine).\nChemical heat engines which employ air (ambient atmospheric gas) as a part of the fuel reaction are regarded as airbreathing engines. Chemical heat engines designed to operate outside of Earth's atmosphere (e.g. rockets, deeply submerged submarines) need to carry an additional fuel component called the oxidizer (although there exist super-oxidizers suitable for use in rockets, such as fluorine, a more powerful oxidant than oxygen itself); or the application needs to obtain heat by non-chemical means, such as by means of nuclear reactions.\nEmission/By products.\nAll chemically fueled heat engines emit exhaust gases. The cleanest engines emit water only. Strict zero-emissions generally means zero emissions other than water and water vapour. Only heat engines which combust pure hydrogen (fuel) and pure oxygen (oxidizer) achieve zero-emission by a strict definition (in practice, one type of rocket engine). If hydrogen is burnt in combination with air (all airbreathing engines), a side reaction occurs between atmospheric oxygen and atmospheric nitrogen resulting in small emissions of , which is adverse even in small quantities. If a hydrocarbon (such as alcohol or gasoline) is burnt as fuel, large quantities of CO2 are emitted, a potent greenhouse gas. Hydrogen and oxygen from air can be reacted into water by a fuel cell without side production of , but this is an electrochemical engine not a heat engine.\nTerminology.\nThe word \"engine\" derives from Old French , from the Latin \u2013the root of the word . Pre-industrial weapons of war, such as catapults, trebuchets and battering rams, were called \"siege engines\", and knowledge of how to construct them was often treated as a military secret. The word \"gin\", as in \"cotton gin\", is short for \"engine\". Most mechanical devices invented during the industrial revolution were described as engines\u2014the steam engine being a notable example. However, the original steam engines, such as those by Thomas Savery, were not mechanical engines but pumps. In this manner, a fire engine in its original form was merely a water pump, with the engine being transported to the fire by horses.\nIn modern usage, the term \"engine\" typically describes devices, like steam engines and internal combustion engines, that burn or otherwise consume fuel to perform mechanical work by exerting a torque or linear force (usually in the form of thrust). Devices converting heat energy into motion are commonly referred to simply as \"engines\". Examples of engines which exert a torque include the familiar automobile gasoline and diesel engines, as well as turboshafts. Examples of engines which produce thrust include turbofans and rockets.\nWhen the internal combustion engine was invented, the term \"motor\" was initially used to distinguish it from the steam engine\u2014which was in wide use at the time, powering locomotives and other vehicles such as steam rollers. The term \"motor\" derives from the Latin verb which means 'to set in motion', or 'maintain motion'. Thus a motor is a device that imparts motion.\n\"Motor\" and \"engine\" are interchangeable in standard English. In some engineering jargons, the two words have different meanings, in which \"engine\" is a device that burns or otherwise consumes fuel, changing its chemical composition, and a motor is a device driven by electricity, air, or hydraulic pressure, which does not change the chemical composition of its energy source. However, rocketry uses the term rocket motor, even though they consume fuel.\nA heat engine may also serve as a \"prime mover\"\u2014a component that transforms the flow or changes in pressure of a fluid into mechanical energy. An automobile powered by an internal combustion engine may make use of various motors and pumps, but ultimately all such devices derive their power from the engine. Another way of looking at it is that a motor receives power from an external source, and then converts it into mechanical energy, while an engine creates power from pressure (derived directly from the explosive force of combustion or other chemical reaction, or secondarily from the action of some such force on other substances such as air, water, or steam).\nHistory.\nAntiquity.\nSimple machines, such as the club and oar (examples of the lever), are prehistoric. More complex engines using human power, animal power, water power, wind power and even steam power date back to antiquity. Human power was focused by the use of simple engines, such as the capstan, windlass or treadmill, and with ropes, pulleys, and block and tackle arrangements; this power was transmitted usually with the forces multiplied and the speed reduced. These were used in cranes and aboard ships in Ancient Greece, as well as in mines, water pumps and siege engines in Ancient Rome. The writers of those times, including Vitruvius, Frontinus and Pliny the Elder, treat these engines as commonplace, so their invention may be more ancient. By the 1st century AD, cattle and horses were used in mills, driving machines similar to those powered by humans in earlier times.\nAccording to Strabo, a water-powered mill was built in Kaberia of the kingdom of Mithridates during the 1st century BC. Use of water wheels in mills spread throughout the Roman Empire over the next few centuries. Some were quite complex, with aqueducts, dams, and sluices to maintain and channel the water, along with systems of gears, or toothed-wheels made of wood and metal to regulate the speed of rotation. More sophisticated small devices, such as the Antikythera Mechanism used complex trains of gears and dials to act as calendars or predict astronomical events. In a poem by Ausonius in the 4th century AD, he mentions a stone-cutting saw powered by water. Hero of Alexandria is credited with many such wind and steam powered machines in the 1st century AD, including the Aeolipile and the vending machine, often these machines were associated with worship, such as animated altars and automated temple doors.\nMedieval.\nMedieval Muslim engineers employed gears in mills and water-raising machines, and used dams as a source of water power to provide additional power to watermills and water-raising machines. In the medieval Islamic world, such advances made it possible to mechanize many industrial tasks previously carried out by manual labour.\nIn 1206, al-Jazari employed a crank-conrod system for two of his water-raising machines. A rudimentary steam turbine device was described by Taqi al-Din in 1551 and by Giovanni Branca in 1629.\nIn the 13th century, the solid rocket motor was invented in China. Driven by gunpowder, this simplest form of internal combustion engine was unable to deliver sustained power, but was useful for propelling weaponry at high speeds towards enemies in battle and for fireworks. After invention, this innovation spread throughout Europe.\nIndustrial Revolution.\nThe Watt steam engine was the first type of steam engine to make use of steam at a pressure just above atmospheric to drive the piston helped by a partial vacuum. Improving on the design of the 1712 Newcomen steam engine, the Watt steam engine, developed sporadically from 1763 to 1775, was a great step in the development of the steam engine. Offering a dramatic increase in fuel efficiency, James Watt's design became synonymous with steam engines, due in no small part to his business partner, Matthew Boulton. It enabled rapid development of efficient semi-automated factories on a previously unimaginable scale in places where waterpower was not available. Later development led to steam locomotives and great expansion of railway transportation.\nAs for internal combustion piston engines, these were tested in France in 1807 by de Rivaz and independently, by the Ni\u00e9pce brothers. They were theoretically advanced by Carnot in 1824. In 1853\u201357 Eugenio Barsanti and Felice Matteucci invented and patented an engine using the free-piston principle that was possibly the first 4-cycle engine.\nThe invention of an internal combustion engine which was later commercially successful was made during 1860 by Etienne Lenoir.\nIn 1877 the Otto cycle was capable of giving a far higher power to weight ratio than steam engines and worked much better for many transportation applications such as cars and aircraft.\nAutomobiles.\nThe first commercially successful automobile, created by Karl Benz, added to the interest in light and powerful engines. The lightweight gasoline internal combustion engine, operating on a four-stroke Otto cycle, has been the most successful for light automobiles, while the more efficient Diesel engine is used for trucks and buses. However, in recent years, turbo Diesel engines have become increasingly popular, especially outside of the United States, even for quite small cars.\nHorizontally opposed pistons.\nIn 1896, Karl Benz was granted a patent for his design of the first engine with horizontally opposed pistons. His design created an engine in which the corresponding pistons move in horizontal cylinders and reach top dead center simultaneously, thus automatically balancing each other with respect to their individual momentum. Engines of this design are often referred to as flat engines because of their shape and lower profile. They were used in the Volkswagen Beetle, the Citro\u00ebn 2CV, some Porsche and Subaru cars, many BMW and Honda motorcycles, and propeller aircraft engines.\nAdvancement.\nContinuance of the use of the internal combustion engine for automobiles is partly due to the improvement of engine control systems (onboard computers providing engine management processes, and electronically controlled fuel injection). Forced air induction by turbocharging and supercharging have increased power outputs and engine efficiencies. Similar changes have been applied to smaller diesel engines giving them almost the same power characteristics as gasoline engines. This is especially evident with the popularity of smaller diesel engine propelled cars in Europe. Larger diesel engines are still often used in trucks and heavy machinery, although they require special machining not available in most factories. Diesel engines produce lower hydrocarbon and CO2 emissions, but greater particulate and pollution, than gasoline engines. Diesel engines are also 40% more fuel efficient than comparable gasoline engines.\nIncreasing power.\nIn the first half of the 20th century, a trend of increasing engine power occurred, particularly in the U.S models. Design changes incorporated all known methods of increasing engine capacity, including increasing the pressure in the cylinders to improve efficiency, increasing the size of the engine, and increasing the rate at which the engine produces work. The higher forces and pressures created by these changes created engine vibration and size problems that led to stiffer, more compact engines with V and opposed cylinder layouts replacing longer straight-line arrangements.\nCombustion efficiency.\nOptimal combustion efficiency in passenger vehicles is reached with a coolant temperature of around .\nEngine configuration.\nEarlier automobile engine development produced a much larger range of engines than is in common use today. Engines have ranged from 1- to 16-cylinder designs with corresponding differences in overall size, weight, engine displacement, and cylinder bores. Four cylinders and power ratings from 19 to 120\u00a0hp (14 to 90\u00a0kW) were followed in a majority of the models. Several three-cylinder, two-stroke-cycle models were built while most engines had straight or in-line cylinders. There were several V-type models and horizontally opposed two- and four-cylinder makes too. Overhead camshafts were frequently employed. The smaller engines were commonly air-cooled and located at the rear of the vehicle; compression ratios were relatively low. The 1970s and 1980s saw an increased interest in improved fuel economy, which caused a return to smaller V-6 and four-cylinder layouts, with as many as five valves per cylinder to improve efficiency. The Bugatti Veyron 16.4 operates with a W16 engine, meaning that two V8 cylinder layouts are positioned next to each other to create the W\u00a0shape sharing the same crankshaft.\nThe largest internal combustion engine ever built is the W\u00e4rtsil\u00e4-Sulzer RTA96-C, a 14-cylinder, 2-stroke turbocharged diesel engine that was designed to power the \"Emma M\u00e6rsk\", the largest container ship in the world when launched in 2006. This engine has a mass of 2,300 tonnes, and when running at 102\u00a0rpm (1.7\u00a0Hz) produces over 80 MW, and can use up to 250 tonnes of fuel per day.\nTypes.\nAn engine can be put into a category according to two criteria: the form of energy it accepts in order to create motion, and the type of motion it outputs.\nHeat engine.\nCombustion engine.\nCombustion engines are heat engines driven by the heat of a combustion process.\nInternal combustion engine.\nThe \"internal combustion engine\" is an engine in which the combustion of a fuel (generally, fossil fuel) occurs with an oxidizer (usually air) in a combustion chamber. In an internal combustion engine the expansion of the high temperature and high pressure gases, which are produced by the combustion, directly applies force to components of the engine, such as the pistons or turbine blades or a nozzle, and by moving it over a distance, generates mechanical work.\nExternal combustion engine.\nAn \"external combustion engine\" (EC engine) is a heat engine where an internal working fluid is heated by combustion of an external source, through the engine wall or a heat exchanger. The fluid then, by expanding and acting on the mechanism of the engine produces motion and usable work. The fluid is then cooled, compressed and reused (closed cycle), or (less commonly) dumped, and cool fluid pulled in (open cycle air engine).\n\"Combustion\" refers to burning fuel with an oxidizer, to supply the heat. Engines of similar (or even identical) configuration and operation may use a supply of heat from other sources such as nuclear, solar, geothermal or exothermic reactions not involving combustion; but are not then strictly classed as external combustion engines, but as external thermal engines.\nThe working fluid can be a gas as in a Stirling engine, or steam as in a steam engine or an organic liquid such as n-pentane in an Organic Rankine cycle. The fluid can be of any composition; gas is by far the most common, although even single-phase liquid is sometimes used. In the case of the steam engine, the fluid changes phases between liquid and gas.\nAir-breathing combustion engines.\n\"Air-breathing combustion engines\" are combustion engines that use the oxygen in atmospheric air to oxidise ('burn') the fuel, rather than carrying an oxidiser, as in a rocket. Theoretically, this should result in a better specific impulse than for rocket engines.\nA continuous stream of air flows through the air-breathing engine. This air is compressed, mixed with fuel, ignited and expelled as the exhaust gas. In reaction engines, the majority of the combustion energy (heat) exits the engine as exhaust gas, which provides thrust directly.\nTypical air-breathing engines include:\nEnvironmental effects.\nThe operation of engines typically has a negative impact upon air quality and ambient sound levels. There has been a growing emphasis on the pollution producing features of automotive power systems. This has created new interest in alternate power sources and internal-combustion engine refinements. Though a few limited-production battery-powered electric vehicles have appeared, they have not proved competitive owing to costs and operating characteristics. In the 21st century the diesel engine has been increasing in popularity with automobile owners. However, the gasoline engine and the Diesel engine, with their new emission-control devices to improve emission performance, have not yet been significantly challenged. A number of manufacturers have introduced hybrid engines, mainly involving a small gasoline engine coupled with an electric motor and with a large battery bank, these are starting to become a popular option because of their environment awareness.\nAir quality.\nExhaust gas from a spark ignition engine consists of the following: nitrogen 70 to 75% (by volume), water vapor 10 to 12%, carbon dioxide 10 to 13.5%, hydrogen 0.5 to 2%, oxygen 0.2 to 2%, carbon monoxide: 0.1 to 6%, unburnt hydrocarbons and partial oxidation products (e.g. aldehydes) 0.5 to 1%, nitrogen monoxide 0.01 to 0.4%, nitrous oxide &lt;100 ppm, sulfur dioxide 15 to 60 ppm, traces of other compounds such as fuel additives and lubricants, also halogen and metallic compounds, and other particles. Carbon monoxide is highly toxic, and can cause carbon monoxide poisoning, so it is important to avoid any build-up of the gas in a confined space. Catalytic converters can reduce toxic emissions, but not eliminate them. Also, resulting greenhouse gas emissions, chiefly carbon dioxide, from the widespread use of engines in the modern industrialized world is contributing to the global greenhouse effect \u2013 a primary concern regarding global warming.\nNon-combusting heat engines.\nSome engines convert heat from noncombustive processes into mechanical work, for example a nuclear power plant uses the heat from the nuclear reaction to produce steam and drive a steam engine, or a gas turbine in a rocket engine may be driven by decomposing hydrogen peroxide. Apart from the different energy source, the engine is often engineered much the same as an internal or external combustion engine.\nAnother group of noncombustive engines includes thermoacoustic heat engines (sometimes called \"TA engines\") which are thermoacoustic devices that use high-amplitude sound waves to pump heat from one place to another, or conversely use a heat difference to induce high-amplitude sound waves. In general, thermoacoustic engines can be divided into standing wave and travelling wave devices.\nStirling engines can be another form of non-combustive heat engine. They use the Stirling thermodynamic cycle to convert heat into work. An example is the alpha type Stirling engine, whereby gas flows, via a recuperator, between a hot cylinder and a cold cylinder, which are attached to reciprocating pistons 90\u00b0 out of phase. The gas receives heat at the hot cylinder and expands, driving the piston that turns the crankshaft. After expanding and flowing through the recuperator, the gas rejects heat at the cold cylinder and the ensuing pressure drop leads to its compression by the other (displacement) piston, which forces it back to the hot cylinder.\nNon-thermal chemically powered motor.\nNon-thermal motors usually are powered by a chemical reaction, but are not heat engines. Examples include:\nElectric motor.\nAn \"electric motor\" uses electrical energy to produce mechanical energy, usually through the interaction of magnetic fields and current-carrying conductors. The reverse process, producing electrical energy from mechanical energy, is accomplished by a generator or dynamo. Traction motors used on vehicles often perform both tasks. Electric motors can be run as generators and vice versa, although this is not always practical.\nElectric motors are ubiquitous, being found in applications as diverse as industrial fans, blowers and pumps, machine tools, household appliances, power tools, and disk drives. They may be powered by direct current (for example a battery powered portable device or motor vehicle), or by alternating current from a central electrical distribution grid. The smallest motors may be found in electric wristwatches. Medium-size motors of highly standardized dimensions and characteristics provide convenient mechanical power for industrial uses. The very largest electric motors are used for propulsion of large ships, and for such purposes as pipeline compressors, with ratings in the thousands of kilowatts. Electric motors may be classified by the source of electric power, by their internal construction, and by their application.\nThe physical principle of production of mechanical force by the interactions of an electric current and a magnetic field was known as early as 1821. Electric motors of increasing efficiency were constructed throughout the 19th century, but commercial exploitation of electric motors on a large scale required efficient electrical generators and electrical distribution networks.\nTo reduce the electric energy consumption from motors and their associated carbon footprints, various regulatory authorities in many countries have introduced and implemented legislation to encourage the manufacture and use of higher efficiency electric motors. A well-designed motor can convert over 90% of its input energy into useful power for decades. When the efficiency of a motor is raised by even a few percentage points, the savings, in kilowatt hours (and therefore in cost), are enormous. The electrical energy efficiency of a typical industrial induction motor can be improved by: 1) reducing the electrical losses in the stator windings (e.g., by increasing the cross-sectional area of the conductor, improving the winding technique, and using materials with higher electrical conductivities, such as copper), 2) reducing the electrical losses in the rotor coil or casting (e.g., by using materials with higher electrical conductivities, such as copper), 3) reducing magnetic losses by using better quality magnetic steel, 4) improving the aerodynamics of motors to reduce mechanical windage losses, 5) improving bearings to reduce friction losses, and 6) minimizing manufacturing tolerances. \"For further discussion on this subject, see Premium efficiency.)\"\nBy convention, \"electric engine\" refers to a railroad electric locomotive, rather than an electric motor.\nPhysically powered motor.\nSome motors are powered by potential or kinetic energy, for example some funiculars, gravity plane and ropeway conveyors have used the energy from moving water or rocks, and some clocks have a weight that falls under gravity. Other forms of potential energy include compressed gases (such as pneumatic motors), springs (clockwork motors) and elastic bands.\nHistoric military siege engines included large catapults, trebuchets, and (to some extent) battering rams were powered by potential energy.\nPneumatic motor.\nA \"pneumatic motor\" is a machine that converts potential energy in the form of compressed air into mechanical work. Pneumatic motors generally convert the compressed air to mechanical work through either linear or rotary motion. Linear motion can come from either a diaphragm or piston actuator, while rotary motion is supplied by either a vane type air motor or piston air motor. Pneumatic motors have found widespread success in the hand-held tool industry and continual attempts are being made to expand their use to the transportation industry. However, pneumatic motors must overcome efficiency deficiencies before being seen as a viable option in the transportation industry.\nHydraulic motor.\nA \"hydraulic motor\" derives its power from a pressurized liquid. This type of engine is used to move heavy loads and drive machinery.\nHybrid.\nSome motor units can have multiple sources of energy. For example, a plug-in hybrid electric vehicle's electric motor could source electricity from either a battery or from fossil fuels inputs via an internal combustion engine and a generator.\nPerformance.\nThe following are used in the assessment of the performance of an engine.\nSpeed.\nSpeed refers to crankshaft rotation in piston engines and the speed of compressor/turbine rotors and electric motor rotors. It is measured in revolutions per minute (rpm).\nThrust.\nThrust is the force exerted on an airplane as a consequence of its propeller or jet engine accelerating the air passing through it. It is also the force exerted on a ship as a consequence of its propeller accelerating the water passing through it.\nTorque.\nTorque is a turning moment on a shaft and is calculated by multiplying the force causing the moment by its distance from the shaft.\nPower.\nPower is the measure of how fast work is done.\nEfficiency.\nEfficiency is a measure of how much fuel is wasted in producing power.\nSound levels.\nVehicle noise is predominantly from the engine at low vehicle speeds and from tires and the air flowing past the vehicle at higher speeds. Electric motors are quieter than internal combustion engines. Thrust-producing engines, such as turbofans, turbojets and rockets emit the greatest amount of noise due to the way their thrust-producing, high-velocity exhaust streams interact with the surrounding stationary air.\nNoise reduction technology includes intake and exhaust system mufflers (silencers) on gasoline and diesel engines and noise attenuation liners in turbofan inlets.\nEngines by use.\nParticularly notable kinds of engines include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9642", "revid": "66", "url": "https://en.wikipedia.org/wiki?curid=9642", "title": "Extropian", "text": ""}
{"id": "9643", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=9643", "title": "Economic and monetary union", "text": "Trade bloc with a common tariff and currency\nAn economic and monetary union (EMU) is a type of trade bloc that features a combination of a common market, customs union, and monetary union. Established via a trade pact, an EMU constitutes the sixth of seven stages in the process of economic integration. An EMU agreement usually combines a customs union with a common market. A typical EMU establishes free trade and a common external tariff throughout its jurisdiction. It is also designed to protect freedom in the movement of goods, services, and people. This arrangement is distinct from a monetary union (e.g., the Latin Monetary Union), which does not usually involve a common market. As with the economic and monetary union established among the 27 member states of the European Union (EU), an EMU may affect different parts of its jurisdiction in different ways. Some areas are subject to separate customs regulations from other areas subject to the EMU. These various arrangements may be established in a formal agreement, or they may exist on a \"de facto\" basis. For example, not all EU member states use the Euro established by its currency union, and not all EU member states are part of the Schengen Area. Some EU members participate in both unions, and some in neither.\nTerritories of the United States, Australian External Territories and New Zealand territories each share a currency and, for the most part, the market of their respective mainland states. However, they are generally not part of the same customs territories.\nHistory.\nSeveral countries initially attempted to form an EMU at the Hague Summit in 1969. Afterward, a \"draft plan\" was announced. During this time, the main member presiding over this decision was Pierre Werner, Prime Minister of Luxembourg. The decision to form the Economic and Monetary Union of the European Union (EMU) was accepted in December 1991, which later became part of the Maastricht Treaty (the Treaty on European Union).\nProcesses in the European EMU.\nThe EMU involves four main activities.\nThe first responsibility is to be in charge of implementing effective monetary policy for the euro area with price stability. There is a group of economists whose only role is studying how to improve the monetary policy while maintaining price stability. They conduct research, and their results are presented to the leaders of the EMU. Thereafter, the role of the leaders is to find a suitable way to implement the economists' work into their country's policies. Maintaining price stability is a long-term goal for all states in the EU, due to the effects it might have on the Euro as a currency.\nSecondly, the EMU must coordinate economic and fiscal policies in EU countries. They must find an equilibrium between the implementation of monetary and fiscal policies. They will advise countries to have greater coordination, even if that means having countries tightly coupled with looser monetary and tighter fiscal policy. Not coordinating the monetary market could result in risking an unpredictable situation. The EMU also deliberates on a mixed policy option, which has been shown to be beneficial in some empirical studies.\nThirdly, the EMU ensures that the single market runs smoothly. The member countries respect the decisions made by the EMU and ensure that their actions will be in favor of a stable market.\nFinally, regulations of the EMU aid in supervising and monitoring financial institutions. There is an imperative need for all members of the EMU to act in unison. Therefore, the EMU has to have institutions supervising all the member states to protect the main aim of the EMU.\nRoles of national governments.\nThe economic roles of nations within the EMU are to:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9644", "revid": "2014336", "url": "https://en.wikipedia.org/wiki?curid=9644", "title": "European Environment Agency", "text": "Agency of the European Union\nThe European Environment Agency (EEA) is the agency of the European Union (EU) which provides independent information on the environment.\nDefinition.\nThe European Environment Agency (EEA) is the agency of the European Union (EU) which provides independent information on the environment. \nIts goal is to help those involved in developing, implementing and evaluating environmental policy, and to inform the general public.\nOrganization.\nThe EEA was established by the European Economic Community (EEC) Regulation 1210/1990 (amended by EEC Regulation 933/1999 and EC Regulation 401/2009) and became operational in 1994, headquartered in Copenhagen, Denmark.\nThe agency is governed by a management board composed of representatives of the governments of its 32 member states, a European Commission representative and two scientists appointed by the European Parliament, assisted by its Scientific Committee. \nThe current Executive Director of the agency is Professor Hans Bruyninckx, who has been appointed for a five-year term. He is the successor of Professor Jacqueline McGlade.\nMember countries.\nThe member states of the European Union are members; however other states may become members of it by means of agreements concluded between them and the EU.\nIt was the first EU body to open its membership to the 13 candidate countries (pre-2004 enlargement).\nThe EEA has 32 member countries and six cooperating countries. The members are the 27 European Union member states together with Iceland, Liechtenstein, Norway, Switzerland and Turkey.\nSince Brexit in 2020, the UK is not a member of the EU anymore and therefore not a member state of the EEA.\nThe six Western Balkan countries are cooperating countries: Albania, Bosnia and Herzegovina, Montenegro, North Macedonia, Serbia as well as Kosovo under the UN Security Council Resolution 1244/99. These cooperation activities are integrated into Eionet and are supported by the EU under the \"Instrument for Pre-Accession Assistance\".\nThe EEA is an active member of the EPA Network.\nReports, data and knowledge.\nThe European Environment Agency (EEA) produces assessments based on quality-assured data on a wide range of issues from biodiversity, air quality, transport to climate change. These assessments are closely linked to the European Union's environment policies and legislation and help monitor progress in some areas and indicate areas where additional efforts are needed. \nAs required in its founding regulation, the EEA publishes its flagship report the State and Outlook of Europe's environment (SOER), which is an integrated assessment, analysing trends, progress to targets as well as outlook for the mid- to long-term. \nThe EEA shares this information, including the datasets used in its assessments, through its main website and a number of thematic information platforms such as Biodiversity Information System for Europe (BISE), Water Information System for Europe (WISE) and ClimateADAPT. The Climate-ADAPT knowledge platform presents information and data on expected climatic changes, the vulnerability of regions and sectors, adaptation case studies, and adaptation options, adaptation planning tools, and EU policy.\nEuropean Nature Information System.\nThe European Nature Information System (EUNIS) provides access to the publicly available data in the EUNIS database for species, habitat types and protected sites across Europe. It is part of the European Biodiversity data centre (BDC), and is maintained by the EEA.\nThe database contains data\nEuropean environment information and observation network.\nThe European environment information and observation network (Eionet) is a partnership network of the EEA and the countries. The EEA is responsible for developing the network and coordinating its activities. To do so, the EEA works closely together with national focal points (NFPs), typically national environment agencies or environment ministries which are responsible for coordinating national networks of the National Reference Centres (NRCs) involving many institutions (about 350 in all).\nApart from the NFPs and NRCs, Eionet currently includes covers seven European Topic Centres (ETCs):\nThe European Environment Agency (EEA) implements the \"Shared Environmental Information System\" principles and best practices via projects such as the \"ENI SEIS II EAST PROJECT\" &amp; the \"ENI SEIS II SOUTH PROJECT\" to support environmental protection within the six eastern partnership countries (ENP) &amp; to contribute to the reduction in marine pollution in the Mediterranean through the shared availability and access to relevant environmental information. \nBudget management and discharge.\nAs for every EU body and institution, the EEA's budget is subject to a discharge process, consisting of external examination of its budget execution and financial management, to ensure sound financial management of its budget. Since its establishment, the EEA has been granted discharge for its budget without exception. The EEA provides full access to its administrative and budgetary documents in its public documents register. \nThe discharge process for the 2010 budget required additional clarifications. In February 2012, the European Parliament's Committee on Budgetary Control published a draft report, identifying areas of concern in the use of funds and its influence for the 2010 budget such as a 26% budget increase from 2009 to 2010 to \u20ac50 600 000. and questioned that maximum competition and value-for-money principles were honored in hiring, also possible fictitious employees.\nThe EEA's Executive Director refuted allegations of irregularities in a public hearing. On 27 March 2012 Members of the European Parliament (MEPs) voted on the report and commended the cooperation between the Agency and NGOs working in the environmental area. On 23 October 2012, the European Parliament voted and granted the discharge to the European Environment Agency for its 2010 budget.\nInternational cooperation.\nIn addition to its 32 members and six Balkan cooperating countries, the EEA also cooperates and fosters partnerships with its neighbours and other countries and regions, mostly in the context of the European Neighbourhood Policy:\nAdditionally the EEA cooperates with multiple international organizations and the corresponding agencies of the following countries:\nOfficial languages.\nThe 26 official languages used by the EEA are: Bulgarian, Czech, Croatian, Danish, German, Greek, English, Spanish, Estonian, Finnish, French, Hungarian, Icelandic, Italian, Lithuanian, Latvian, Malti, Dutch, Norwegian, Polish, Portuguese, Romanian, Slovak, Slovene, Swedish and Turkish.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9645", "revid": "37368051", "url": "https://en.wikipedia.org/wiki?curid=9645", "title": "EV", "text": "Ev or EV may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "9646", "revid": "10951369", "url": "https://en.wikipedia.org/wiki?curid=9646", "title": "Erlang (programming language)", "text": "Programming language\nErlang ( ) is a general-purpose, concurrent, functional high-level programming language, and a garbage-collected runtime system. The term Erlang is used interchangeably with Erlang/OTP, or Open Telecom Platform (OTP), which consists of the Erlang runtime system, several ready-to-use components (OTP) mainly written in Erlang, and a set of design principles for Erlang programs.\nThe Erlang runtime system is designed for systems with these traits:\nThe Erlang programming language has immutable data, pattern matching, and functional programming. The sequential subset of the Erlang language supports eager evaluation, single assignment, and dynamic typing.\nA normal Erlang application is built out of hundreds of small Erlang processes.\nIt was originally proprietary software within Ericsson, developed by Joe Armstrong, Robert Virding, and Mike Williams in 1986, but was released as free and open-source software in 1998. Erlang/OTP is supported and maintained by the Open Telecom Platform (OTP) product unit at Ericsson.\nHistory.\nThe name \"Erlang\", attributed to Bjarne D\u00e4cker, has been presumed by those working on the telephony switches (for whom the language was designed) to be a reference to Danish mathematician and engineer Agner Krarup Erlang and a syllabic abbreviation of \"Ericsson Language\". Erlang was designed with the aim of improving the development of telephony applications. The initial version of Erlang was implemented in Prolog and was influenced by the programming language PLEX used in earlier Ericsson exchanges. By 1988 Erlang had proven that it was suitable for prototyping telephone exchanges, but the Prolog interpreter was far too slow. One group within Ericsson estimated that it would need to be 40 times faster to be suitable for production use. In 1992, work began on the BEAM virtual machine (VM) which compiles Erlang to C using a mix of natively compiled code and threaded code to strike a balance between performance and disk space. According to co-inventor Joe Armstrong, the language went from lab product to real applications following the collapse of the next-generation AXE telephone exchange named in 1995. As a result, Erlang was chosen for the next Asynchronous Transfer Mode (ATM) exchange \"AXD\".\nIn February 1998, Ericsson Radio Systems banned the in-house use of Erlang for new products, citing a preference for non-proprietary languages. The ban caused Armstrong and others to make plans to leave Ericsson. In March 1998 Ericsson announced the AXD301 switch, containing over a million lines of Erlang and reported to achieve a high availability of nine \"9\"s. In December 1998, the implementation of Erlang was open-sourced and most of the Erlang team resigned to form a new company Bluetail AB. Ericsson eventually relaxed the ban and re-hired Armstrong in 2004.\nIn 2006, native symmetric multiprocessing support was added to the runtime system and VM.\nProcesses.\nErlang applications are built of very lightweight Erlang processes in the Erlang runtime system. Erlang processes can be seen as \"living\" objects (object-oriented programming), with data encapsulation and message passing, but capable of changing behavior during runtime. The Erlang runtime system provides strict process isolation between Erlang processes (this includes data and garbage collection, separated individually by each Erlang process) and transparent communication between processes (see Location transparency) on different Erlang nodes (on different hosts).\nJoe Armstrong, co-inventor of Erlang, summarized the principles of processes in his PhD thesis:\nJoe Armstrong remarked in an interview with Rackspace in 2013: \"If Java is 'write once, run anywhere', then Erlang is 'write once, run forever'.\"\nUsage.\nIn 2014, Ericsson reported Erlang was being used in its support nodes, and in GPRS, 3G and LTE mobile networks worldwide and also by Nortel and T-Mobile.\nErlang is used in RabbitMQ. As Tim Bray, director of Web Technologies at Sun Microsystems, expressed in his keynote at O'Reilly Open Source Convention (OSCON) in July 2008:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If somebody came to me and wanted to pay me a lot of money to build a large scale message handling system that really had to be up all the time, could never afford to go down for years at a time, I would unhesitatingly choose Erlang to build it in.\nErlang is the programming language used to code WhatsApp.\nElixir is a programming language that compiles into BEAM byte code (via Erlang Abstract Format).\nSince being released as open source, Erlang has been spreading beyond telecoms, establishing itself in other vertical markets such as FinTech, gaming, healthcare, automotive, internet of things and blockchain. Apart from WhatsApp, there are other companies listed as Erlang's success stories: Vocalink (a MasterCard company), Goldman Sachs, Nintendo, AdRoll, Grindr, BT Mobile, Samsung, OpenX, and SITA.\nFunctional programming examples.\nFactorial.\nA factorial algorithm implemented in Erlang:\n-module(fact). % This is the file 'fact.erl', the module and the filename must match\n-export([fac/1]). % This exports the function 'fac' of arity 1 (1 parameter, no type, no name)\nfac(0) -&gt; 1; % If 0, then return 1, otherwise (note the semicolon ; meaning 'else')\nfac(N) when N &gt; 0, is_integer(N) -&gt; N * fac(N-1).\n% Recursively determine, then return the result\n% (note the period . meaning 'endif' or 'function end')\n%% This function will crash if anything other than a nonnegative integer is given.\n%% It illustrates the \"Let it crash\" philosophy of Erlang.\nFibonacci sequence.\nA tail recursive algorithm that produces the Fibonacci sequence:\n%% The module declaration must match the file name \"series.erl\" \n-module(series).\n%% The export statement contains a list of all those functions that form\n%% the module's public API. In this case, this module exposes a single\n%% function called fib that takes 1 argument (I.E. has an arity of 1)\n%% The general syntax for -export is a list containing the name and\n%% arity of each public function\n-export([fib/1]).\n%% Public API\n%% Handle cases in which fib/1 receives specific values\n%% The order in which these function signatures are declared is a vital\n%% part of this module's functionality\n%% If fib/1 is passed precisely the integer 0, then return 0\nfib(0) -&gt; 0;\n%% If fib/1 receives a negative number, then return the atom err_neg_val\n%% Normally, such defensive coding is discouraged due to Erlang's 'Let\n%% it Crash' philosophy; however, in this case we should explicitly\n%% prevent a situation that will crash Erlang's runtime engine\nfib(N) when N &lt; 0 -&gt; err_neg_val;\n%% If fib/1 is passed an integer less than 3, then return 1\n%% The preceding two function signatures handle all cases where N &lt; 1,\n%% so this function signature handles cases where N = 1 or N = 2\nfib(N) when N &lt; 3 -&gt; 1;\n%% For all other values, call the private function fib_int/3 to perform\n%% the calculation\nfib(N) -&gt; fib_int(N, 0, 1).\n%% Private API\n%% If fib_int/3 receives a 1 as its first argument, then we're done, so\n%% return the value in argument B. Since we are not interested in the\n%% value of the second argument, we denote this using _ to indicate a\n%% \"don't care\" value\nfib_int(1, _, B) -&gt; B;\n%% For all other argument combinations, recursively call fib_int/3\n%% where each call does the following:\n%% - decrement counter N\n%% - Take the previous fibonacci value in argument B and pass it as\n%% argument A\n%% - Calculate the value of the current fibonacci number and pass it\n%% as argument B\nfib_int(N, A, B) -&gt; fib_int(N-1, B, A+B).\nHere's the same program without the explanatory comments:\n-module(series).\n-export([fib/1]).\nfib(0) -&gt; 0;\nfib(N) when N &lt; 0 -&gt; err_neg_val;\nfib(N) when N &lt; 3 -&gt; 1;\nfib(N) -&gt; fib_int(N, 0, 1).\nfib_int(1, _, B) -&gt; B;\nfib_int(N, A, B) -&gt; fib_int(N-1, B, A+B).\nQuicksort.\nQuicksort in Erlang, using list comprehension:\n%% qsort:qsort(List)\n%% Sort a list of items\n-module(qsort). % This is the file 'qsort.erl'\n-export([qsort/1]). % A function 'qsort' with 1 parameter is exported (no type, no name)\nqsort([]) -&gt; []; % If the list [] is empty, return an empty list (nothing to sort)\nqsort([Pivot|Rest]) -&gt;\n % Compose recursively a list with 'Front' for all elements that should be before 'Pivot'\n % then 'Pivot' then 'Back' for all elements that should be after 'Pivot'\n qsort([Front || Front &lt;- Rest, Front &lt; Pivot]) ++ \n [Pivot] ++\n qsort([Back || Back &lt;- Rest, Back &gt;= Pivot]).\nThe above example recursively invokes the function codice_1 until nothing remains to be sorted. The expression codice_2 is a list comprehension, meaning \"Construct a list of elements codice_3 such that codice_3 is a member of codice_5, and codice_3 is less than codice_7.\" codice_8 is the list concatenation operator.\nA comparison function can be used for more complicated structures for the sake of readability.\nThe following code would sort lists according to length:\n% This is file 'listsort.erl' (the compiler is made this way)\n-module(listsort).\n% Export 'by_length' with 1 parameter (don't care about the type and name)\n-export([by_length/1]).\nby_length(Lists) -&gt; % Use 'qsort/2' and provides an anonymous function as a parameter\n qsort(Lists, fun(A,B) -&gt; length(A) &lt; length(B) end).\nqsort([], _)-&gt; []; % If list is empty, return an empty list (ignore the second parameter)\nqsort([Pivot|Rest], Smaller) -&gt;\n % Partition list with 'Smaller' elements in front of 'Pivot' and not-'Smaller' elements\n % after 'Pivot' and sort the sublists.\n qsort([X || X &lt;- Rest, Smaller(X,Pivot)], Smaller)\n ++ [Pivot] ++\n qsort([Y || Y &lt;- Rest, not(Smaller(Y, Pivot))], Smaller).\nA codice_7 is taken from the first parameter given to codice_10 and the rest of codice_11 is named codice_5. Note that the expression\n[X || X &lt;- Rest, Smaller(X,Pivot)]\nis no different in form from\n[Front || Front &lt;- Rest, Front &lt; Pivot]\n(in the previous example) except for the use of a comparison function in the last part, saying \"Construct a list of elements codice_13 such that codice_13 is a member of codice_5, and codice_16 is true\", with codice_16 being defined earlier as\nfun(A,B) -&gt; length(A) &lt; length(B) end\nThe anonymous function is named codice_16 in the parameter list of the second definition of codice_1 so that it can be referenced by that name within that function. It is not named in the first definition of codice_1, which deals with the base case of an empty list and thus has no need of this function, let alone a name for it.\nData types.\nErlang has eight primitive data types:\nAnd three compound data types:\nTwo forms of syntactic sugar are provided:\nErlang has no method to define classes, although there are external libraries available.\n\"Let it crash\" coding style.\nErlang is designed with a mechanism that makes it easy for external processes to monitor for crashes (or hardware failures), rather than an in-process mechanism like exception handling used in many other programming languages. Crashes are reported like other messages, which is the only way processes can communicate with each other, and subprocesses can be spawned cheaply (see below). The \"let it crash\" philosophy prefers that a process be completely restarted rather than trying to recover from a serious failure. Though it still requires handling of errors, this philosophy results in less code devoted to defensive programming where error-handling code is highly contextual and specific.\nSupervisor trees.\nA typical Erlang application is written in the form of a supervisor tree. This architecture is based on a hierarchy of processes in which the top level process is known as a \"supervisor\". The supervisor then spawns multiple child processes that act either as workers or more, lower level supervisors. Such hierarchies can exist to arbitrary depths and have proven to provide a highly scalable and fault-tolerant environment within which application functionality can be implemented.\nWithin a supervisor tree, all supervisor processes are responsible for managing the lifecycle of their child processes, and this includes handling situations in which those child processes crash. Any process can become a supervisor by first spawning a child process, then calling codice_35 on that process. If the monitored process then crashes, the supervisor will receive a message containing a tuple whose first member is the atom codice_36. The supervisor is responsible firstly for listening for such messages and secondly, for taking the appropriate action to correct the error condition.\nConcurrency and distribution orientation.\nErlang's main strength is support for concurrency. It has a small but powerful set of primitives to create processes and communicate among them. Erlang is conceptually similar to the language occam, though it recasts the ideas of communicating sequential processes (CSP) in a functional framework and uses asynchronous message passing. Processes are the primary means to structure an Erlang application. They are neither operating system processes nor threads, but lightweight processes that are scheduled by BEAM. Like operating system processes (but unlike operating system threads), they share no state with each other. The estimated minimal overhead for each is 300 words. Thus, many processes can be created without degrading performance. In 2005, a benchmark with 20 million processes was successfully performed with 64-bit Erlang on a machine with 16 GB random-access memory (RAM; total 800 bytes/process). Erlang has supported symmetric multiprocessing since release R11B of May 2006.\nWhile threads need external library support in most languages, Erlang provides language-level features to create and manage processes with the goal of simplifying concurrent programming. Though all concurrency is explicit in Erlang, processes communicate using message passing instead of shared variables, which removes the need for explicit locks (a locking scheme is still used internally by the VM).\nInter-process communication works via a shared-nothing asynchronous message passing system: every process has a \"mailbox\", a queue of messages that have been sent by other processes and not yet consumed. A process uses the codice_37 primitive to retrieve messages that match desired patterns. A message-handling routine tests messages in turn against each pattern, until one of them matches. When the message is consumed and removed from the mailbox the process resumes execution. A message may comprise any Erlang structure, including primitives (integers, floats, characters, atoms), tuples, lists, and functions.\nThe code example below shows the built-in support for distributed processes:\n % Create a process and invoke the function web:start_server(Port, MaxConnections)\n ServerProcess = spawn(web, start_server, [Port, MaxConnections]),\n % Create a remote process and invoke the function\n % web:start_server(Port, MaxConnections) on machine RemoteNode\n RemoteProcess = spawn(RemoteNode, web, start_server, [Port, MaxConnections]),\n % Send a message to ServerProcess (asynchronously). The message consists of a tuple\n % with the atom \"pause\" and the number \"10\".\n ServerProcess ! {pause, 10},\n % Receive messages sent to this process\n receive\n a_message -&gt; do_something;\n {data, DataContent} -&gt; handle(DataContent);\n {hello, Text} -&gt; io:format(\"Got hello message: ~s\", [Text]);\n {goodbye, Text} -&gt; io:format(\"Got goodbye message: ~s\", [Text])\n end.\nAs the example shows, processes may be created on remote nodes, and communication with them is transparent in the sense that communication with remote processes works exactly as communication with local processes.\nConcurrency supports the primary method of error-handling in Erlang. When a process crashes, it neatly exits and sends a message to the controlling process which can then take action, such as starting a new process that takes over the old process's task.\nImplementation.\nThe official reference implementation of Erlang uses BEAM. BEAM is included in the official distribution of Erlang, called Erlang/OTP. BEAM executes bytecode which is converted to threaded code at load time. It also includes a native code compiler on most platforms, developed by the High Performance Erlang Project (HiPE) at Uppsala University. Since October 2001 the HiPE system is fully integrated in Ericsson's Open Source Erlang/OTP system. It also supports interpreting, directly from source code via abstract syntax tree, via script as of R11B-5 release of Erlang.\nHot code loading and modules.\nErlang supports language-level Dynamic Software Updating. To implement this, code is loaded and managed as \"module\" units; the module is a compilation unit. The system can keep two versions of a module in memory at the same time, and processes can concurrently run code from each. The versions are referred to as the \"new\" and the \"old\" version. A process will not move into the new version until it makes an external call to its module.\nAn example of the mechanism of hot code loading:\n %% A process whose only job is to keep a counter.\n %% First version\n -module(counter).\n -export([start/0, codeswitch/1]).\n start() -&gt; loop(0).\n loop(Sum) -&gt;\n receive\n {increment, Count} -&gt;\n loop(Sum+Count);\n {counter, Pid} -&gt;\n Pid ! {counter, Sum},\n loop(Sum);\n code_switch -&gt;\n ?MODULE:codeswitch(Sum)\n % Force the use of 'codeswitch/1' from the latest MODULE version\n end.\n codeswitch(Sum) -&gt; loop(Sum).\nFor the second version, we add the possibility to reset the count to zero.\n %% Second version\n -module(counter).\n -export([start/0, codeswitch/1]).\n start() -&gt; loop(0).\n loop(Sum) -&gt;\n receive\n {increment, Count} -&gt;\n loop(Sum+Count);\n reset -&gt;\n loop(0);\n {counter, Pid} -&gt;\n Pid ! {counter, Sum},\n loop(Sum);\n code_switch -&gt;\n ?MODULE:codeswitch(Sum)\n end.\n codeswitch(Sum) -&gt; loop(Sum).\nOnly when receiving a message consisting of the atom codice_38 will the loop execute an external call to codeswitch/1 (codice_39 is a preprocessor macro for the current module). If there is a new version of the \"counter\" module in memory, then its codeswitch/1 function will be called. The practice of having a specific entry-point into a new version allows the programmer to transform state to what is needed in the newer version. In the example, the state is kept as an integer.\nIn practice, systems are built up using design principles from the Open Telecom Platform, which leads to more code upgradable designs. Successful hot code loading is exacting. Code must be written with care to make use of Erlang's facilities.\nDistribution.\nIn 1998, Ericsson released Erlang as free and open-source software to ensure its independence from a single vendor and to increase awareness of the language. Erlang, together with libraries and the real-time distributed database Mnesia, forms the OTP collection of libraries. Ericsson and a few other companies support Erlang commercially.\nSince the open source release, Erlang has been used by several firms worldwide, including Nortel and T-Mobile. Although Erlang was designed to fill a niche and has remained an obscure language for most of its existence, its popularity is growing due to demand for concurrent services.\nErlang has found some use in fielding massively multiplayer online role-playing game (MMORPG) servers.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9647", "revid": "374440", "url": "https://en.wikipedia.org/wiki?curid=9647", "title": "Euphoria (programming language)", "text": "Euphoria is a programming language created by Robert Craig of Rapid Deployment Software in Toronto, Ontario, Canada. Initially developed (though not publicly released) on the Atari ST, the first commercial release was for MS-DOS as proprietary software. In 2006, with the release of version 3, Euphoria became open-source software. The openEuphoria Group continues to administer and develop the project. In December 2010, the openEuphoria Group released version 4 of openEuphoria along with a new identity and mascot for the project. OpenEuphoria is currently available for Windows, Linux, macOS and three flavors of *BSD.\nEuphoria is a general-purpose high-level imperative-procedural interpreted language. A translator generates C source code and the GNU compiler collection (GCC) and Open Watcom compilers are supported. Alternatively, Euphoria programs may be bound with the interpreter to create stand-alone executables. A number of graphical user interface (GUI) libraries are supported including Win32lib and wrappers for wxWidgets, GTK+ and IUP. Euphoria has a simple built-in database and wrappers for a variety of other databases.\nOverview.\nThe Euphoria language is a general purpose procedural language that focuses on simplicity, legibility, rapid development and performance via several means.\nHistory.\nDeveloped as a personal project to invent a programming language from scratch, Euphoria was created by Robert Craig on an Atari Mega-ST. Many design ideas for the language came from Craig's Master's thesis in computer science at the University of Toronto. Craig's thesis was heavily influenced by the work of John Backus on functional programming (FP) languages.\nCraig ported his original Atari implementation to the 16-bit DOS platform and Euphoria was first released, version 1.0, in July 1993 under a proprietary licence. The original Atari implementation is described by Craig as \"primitive\" and has not been publicly released. Euphoria continued to be developed and released by Craig via his company Rapid Deployment Software (RDS) and website rapideuphoria.com. In October 2006 RDS released version 3 of Euphoria and announced that henceforth Euphoria would be freely distributed under an open-source software licence.\nRDS continued to develop Euphoria, culminating with the release of version 3.1.1 in August, 2007. Subsequently, RDS ceased unilateral development of Euphoria and the openEuphoria Group took over ongoing development. The openEuphoria Group released version 4 in December, 2010 along with a new logo and mascot for the openEuphoria project.\nVersion 3.1.1 remains an important milestone release, being the last version of Euphoria which supports the DOS platform.\nEuphoria is an acronym for \"End-User Programming with Hierarchical Objects for Robust Interpreted Applications\" although there is some suspicion that this is a backronym.\nThe Euphoria interpreter was originally written in C. With the release of version 2.5 in November 2004 the Euphoria interpreter was split into two parts: a front-end parser, and a back-end interpreter. The front-end is now written in Euphoria (and used with the Euphoria-to-C translator and the Binder). The main back-end and run time library are written in C.\nFeatures.\nEuphoria was conceived and developed with the following design goals and features:\nUse.\nEuphoria is designed to readily facilitate handling of dynamic sets of data of varying types and is particularly useful for string and image processing. Euphoria has been used in artificial intelligence experiments, the study of mathematics, for teaching programming, and to implement fonts involving thousands of characters. A large part of the Euphoria interpreter is written in Euphoria.\nData types.\nEuphoria has two basic data types:\nAtom \u2013 A number, implemented as a 31-bit signed integer or a 64-bit IEEE floating-point. Euphoria dynamically changes between integer and floating point representation according to the current value.\nSequence \u2013 A vector (array) with zero or more elements. Each element may be an \"atom\" or another \"sequence\". The number of elements in a sequence is not fixed (i.e., the size of the vector/array does not have to be declared). The program may add or remove elements as needed during run-time. Memory allocation-deallocation is automatically handled by reference counting. Individual elements are referenced using an index value enclosed in square brackets. The first element in a sequence has an index of one [1]. Elements inside embedded sequences are referenced by additional bracked index values, thus X[3][2] refers to the second element contained in the sequence that is the third element of X. Each element of a sequence is an \"object\" type (see below).\nEuphoria has two additional data types predefined:\nInteger \u2013 An \"atom\", restricted to 31-bit signed integer values in the range to (} to ). \"Integer\" data types are more efficient than the \"atom\" data types, but cannot contain the same range of values. Characters are stored as integers, e.g., coding ASCII-'A' is exactly the same as coding 65.\nObject \u2013 A generic datatype which may contain any of the above (i.e., \"atom\", \"sequence\" or \"integer\") and which may be changed to another type during run-time.\nThere is no character string data type. Strings are represented by a \"sequence\" of \"integer\" values. However, because literal strings are so commonly used in programming, Euphoria interprets double-quote enclosed characters as a sequence of integers. Thus\n \"ABC\"\nis seen as if the coder had written:\nwhich is the same as:\nHello, World!\n puts(1, \"Hello, World!\\n\")\nExamples.\nProgram comments start with a double hyphen codice_1 and go through the end of line.\nThe following code looks for an old item in a group of items. If found, it removes it by concatenating all the elements before it with all the elements after it. Note that the first element in a sequence has the index one [1] and that $ refers to the length (i.e., total number of elements) of the sequence.\n global function delete_item( object old, sequence group )\n integer pos\n -- Code begins --\n pos = find( old, group )\n if pos &gt; 0 then\n group = group[1 .. pos-1] &amp; group[pos+1 .. $]\n end if\n return group\n end function\nThe following modification to the above example replaces an old item with a new item. As the variables \"old\" and \"new\" have been defined as objects, they could be \"atoms\" or \"sequences\". Type checking is not needed as the function will work with any sequence of data of any type and needs no external libraries.\n global function replace_item( object old, object new, sequence group )\n integer pos\n -- Code begins --\n pos = find( old, group )\n if pos &gt; 0 then\n group[pos] = new\n end if\n return group\n end function\nFurthermore, no pointers are involved and subscripts are automatically checked. Thus the function cannot access memory out-of-bounds. There is no need to allocate or deallocate memory explicitly and no chance of a memory leak.\nThe line\n group = group[1 .. pos-1] &amp; group[pos+1 .. $]\nshows some of the \"sequence\" handling facilities. A \"sequence\" may contain a set of any types, and this can be sliced (to take a subset of the data in a \"sequence\") and concatenated in expressions with no need for special functions.\nParameter passing.\nArguments to routines are always passed by value; there is no pass-by-reference facility. However, parameters are allowed to be modified \"locally\" (i.e., within the callee) which is implemented very efficiently as sequences have automatic copy-on-write semantics. In other words, when you pass a sequence to a routine, initially only a reference to it is passed, but at the point the routine modifies this sequence parameter the sequence is copied and the routine updates only a copy of the original.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nFree downloads of Euphoria for the various platforms, packages, Windows IDE, Windows API libraries, a cross-platform GTK3 wrapper for Linux and Windows, graphics libraries (DOS, OpenGL, etc.)."}
{"id": "9649", "revid": "9021902", "url": "https://en.wikipedia.org/wiki?curid=9649", "title": "Energy", "text": "Property that makes changes possible\nIn physics, energy (from grc \" \"\" ()\"\u00a0'activity') is the quantitative property that is transferred to a body or to a physical system, recognizable in the performance of work and in the form of heat and light. Energy is a conserved quantity\u2014the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The unit of measurement for energy in the International System of Units (SI) is the joule (J).\nCommon forms of energy include the kinetic energy of a moving object, the potential energy stored by an object (for instance due to its position in a field), the elastic energy stored in a solid object, chemical energy associated with chemical reactions, the radiant energy carried by electromagnetic radiation, and the internal energy contained within a thermodynamic system. All living organisms constantly take in and release energy.\nDue to mass\u2013energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. \nHuman civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The Earth's climate and ecosystems processes are driven by the energy the planet receives from the Sun (although a small amount is also contributed by geothermal energy).\nForms.\nThe total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object \u2013 or the composite motion of the components of an object \u2013 and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may be stored in the field itself.\nWhile these two categories are sufficient to describe all forms of energy, it is often convenient to refer to particular combinations of potential and kinetic energy as its own form. For example, the sum of translational and rotational kinetic and potential energy within a system is referred to as mechanical energy, whereas nuclear energy refers to the combined potentials within an atomic nucleus from either the nuclear force or the weak force, among other examples.\nHistory.\nThe word \"energy\" derives from the , which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.\nIn the late 17th century, Gottfried Leibniz proposed the idea of the , or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total \"vis viva\" was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the motions of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from \"vis viva\" only by a factor of two. Writing in the early 18th century, \u00c9milie du Ch\u00e2telet proposed the concept of conservation of energy in the marginalia of her French language translation of Newton's \"Principia Mathematica\", which represented the first formulation of a conserved measurable quantity that was distinct from momentum, and which would later be called \"energy\".\nIn 1807, Thomas Young was possibly the first to use the term \"energy\" instead of \"vis viva\", in its modern sense. Gustave-Gaspard Coriolis described \"kinetic energy\" in 1829 in its modern sense, and in 1853, William Rankine coined the term \"potential energy\". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.\nThese developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jo\u017eef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.\nUnits of measure.\nIn 1843, James Prescott Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the \"Joule apparatus\": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.\nIn the International System of Units (SI), the unit of energy is the joule, named after Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British thermal units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.\nThe SI unit of energy rate (energy per unit time) is the watt, which is a joule per second. Thus, one joule is one watt-second, and 3600 joules equal one watt-hour. The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.\nScientific use.\nClassical mechanics.\nIn classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.\nWork, a function of energy, is force times distance.\n formula_1\nThis says that the work (formula_2) is equal to the line integral of the force F along a path \"C\"; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.\nThe total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.\nAnother energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy \"minus\" the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).\nNoether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.\nChemistry.\nIn the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular, or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is usually accompanied by a decrease, and sometimes an increase, of the total energy of the substances involved. Some energy may be transferred between the surroundings and the reactants in the form of heat or light; thus the products of a reaction have sometimes more but usually less energy than the reactants. A reaction is said to be exothermic or exergonic if the final state is lower on the energy scale than the initial state; in the less common case of endothermic reactions the situation is the reverse. Chemical reactions are usually not possible unless the reactants surmount an energy barrier known as the activation energy. The \"speed\" of a chemical reaction (at a given temperature\u00a0\"T\") is related to the activation energy\u00a0\"E\" by the Boltzmann's population factor\u00a0e\u2212\"E\"/\"kT\"; that is, the probability of a molecule to have energy greater than or equal to\u00a0\"E\" at a given temperature\u00a0\"T\". This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction can be provided in the form of thermal energy.\nBiology.\nIn biology, energy is an attribute of all biological systems, from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or organelle of a biological organism. Energy used in respiration is stored in substances such as carbohydrates (including sugars), lipids, and proteins stored by cells. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, using as a standard an average human energy expenditure of 12,500\u00a0kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 \u00f7 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a \"feel\" for the use of a given amount of energy.\nSunlight's radiant energy is also captured by plants as \"chemical potential energy\" in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into carbohydrates, lipids, proteins and oxygen. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark in a forest fire, or it may be made available more slowly for animal or human metabolism when organic molecules are ingested and catabolism is triggered by enzyme action.\nAll living creatures rely on an external source of energy to be able to grow and reproduce \u2013 radiant energy from the Sun in the case of green plants and chemical energy (in some form) in the case of animals. The daily 1500\u20132000\u00a0Calories (6\u20138\u00a0MJ) recommended for a human adult are taken as food molecules, mostly carbohydrates and fats, of which glucose (C6H12O6) and stearin (C57H110O6) are convenient examples. The food molecules are oxidized to carbon dioxide and water in the mitochondria\n&lt;chem display=\"block\"&gt;C6H12O6 + 6O2 -&gt; 6CO2 + 6H2O&lt;/chem&gt;\n&lt;chem display=\"block\"&gt;C57H110O6 + (81 1/2) O2 -&gt; 57CO2 + 55H2O&lt;/chem&gt;\nand some of the energy is used to convert ADP into ATP:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;ADP + HPO42\u2212 \u2192 ATP + H2O\nThe rest of the chemical energy of the carbohydrate or fat are converted into heat: the ATP is used as a sort of \"energy currency\", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:\ngain in kinetic energy of a sprinter during a 100\u00a0m race: 4\u00a0kJ\ngain in gravitational potential energy of a 150\u00a0kg weight lifted through 2\u00a0metres: 3\u00a0kJ\nDaily food intake of a normal adult: 6\u20138\u00a0MJ\nIt would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy); most machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe (\"the surroundings\"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology. As an example, to take just the first step in the food chain: of the estimated 124.7\u00a0Pg/a of carbon that is fixed by photosynthesis, 64.3\u00a0Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.\nEarth sciences.\nIn geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations in our atmosphere brought about by solar energy.\nSunlight is the main input to Earth's energy budget which accounts for its temperature and climate stability. Sunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example when) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives most weather phenomena, save a few exceptions, like those generated by volcanic events for example. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, suddenly give up some of their thermal energy to power a few days of violent air movement.\nIn a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may later be transformed into active kinetic energy during landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars (which created these atoms).\nCosmology.\nIn cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.\nQuantum mechanics.\nIn quantum mechanics, energy is defined in terms of the energy operator\n(Hamiltonian) as a time derivative of the wave function. The Schr\u00f6dinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schr\u00f6dinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schr\u00f6dinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: formula_3 (where formula_4 is the Planck constant and formula_5 the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.\nRelativity.\nWhen calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically \u2013 using Lorentz transformations instead of Newtonian mechanics \u2013 Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:\nformula_6\nwhere\nFor example, consider electron\u2013positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles. This is a reversible process \u2013 the inverse process is called pair creation \u2013 in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.\nIn general relativity, the stress\u2013energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.\nEnergy and mass are manifestations of one and the same underlying physical property of a system. This property is responsible for the inertia and strength of gravitational interaction of the system (\"mass manifestations\"), and is also responsible for the potential ability of the system to perform work or heating (\"energy manifestations\"), subject to the limitations of other physical laws.\nIn classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy\u2013momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of spacetime (= boosts).\nTransformation.\nEnergy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery (from chemical energy to electric energy), a dam (from gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator), and a heat engine (from heat to work).\nExamples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. The Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that itself (since it still contains the same total energy even in different forms) but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.\nThere are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.\nEnergy transformations in the universe over time are characterized by various kinds of potential energy, that has been available since the Big Bang, being \"released\" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae to \"store\" energy in the creation of heavy isotopes (such as uranium and thorium), and nuclear decay, a process in which energy is released that was originally stored in these heavy elements, before they were incorporated into the Solar System and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic and thermal energy in a very short time.\nYet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at its maximum. At its lowest point the kinetic energy is at its maximum and is equal to the decrease in potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.\nEnergy is also transferred from potential energy (formula_8) to kinetic energy (formula_9) and then back to potential energy constantly. This is referred to as conservation of energy. In this isolated system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:\nThe equation can then be simplified further since formula_10 (mass times acceleration due to gravity times the height) and formula_11 (half\u00a0mass times velocity squared). Then the total amount of energy can be found by adding formula_12.\nConservation of energy and mass in transformation.\nEnergy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass\u2013energy equivalence. The formula \"E\"\u00a0=\u00a0\"mc\"\u00b2, derived by Albert Einstein (1905) quantifies the relationship between relativistic mass and energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J.J. Thomson (1881), Henri Poincar\u00e9 (1900), Friedrich Hasen\u00f6hrl (1904) and others (see Mass\u2013energy equivalence#History for further information).\nPart of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since formula_13 is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1\u00a0kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~formula_14 joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics. Often, however, the complete conversion of matter (such as atoms) to non-matter (such as photons) is forbidden by conservation laws.\nReversible and non-reversible transformations.\nThermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as thermal energy and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomization in a crystal).\nAs the universe evolves with time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or as other kinds of increases in disorder). This has led to the hypothesis of the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), continues to decrease.\nConservation of energy.\nThe fact that energy can be neither created nor destroyed is called the law of conservation of energy. In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out as work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.\nWhile heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.\nRichard Feynman said during a 1961 lecture:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There is a fact, or if you wish, a \"law\", governing all natural phenomena that are known to date. There is no known exception to this law \u2013 it is exact so far as we know. The law is called the \"conservation of energy\". It states that there is a certain quantity, which we call energy, that does not change in manifold changes which nature undergoes. That is a most abstract idea, because it is a mathematical principle; it says that there is a numerical quantity which does not change when something happens. It is not a description of a mechanism, or anything concrete; it is just a strange fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same.\nMost kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.\nThis law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle \u2013 it is impossible to define the exact amount of energy during any definite time interval (though this is practically significant only for very short time intervals). The uncertainty principle should not be confused with energy conservation \u2013 rather it provides mathematical limits to which energy can in principle be defined and measured.\nEach of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appear as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.\nIn quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by\n formula_15\nwhich is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since \"H\" and \"t\" are not dynamically conjugate variables, neither in classical nor in quantum mechanics).\nIn particle physics, this inequality permits a qualitative understanding of virtual particles, which carry momentum. The exchange of virtual particles with real particles is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons are also responsible for the electrostatic interaction between electric charges (which results in Coulomb's law), for spontaneous radiative decay of excited atomic and nuclear states, for the Casimir force, for the Van der Waals force and some other observable phenomena.\nEnergy transfer.\nClosed systems.\nEnergy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, tidal interactions, and the conductive transfer of thermal energy.\nEnergy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:\nwhere formula_16 is the amount of energy transferred, formula_2\u00a0 represents the work done on or by the system, and formula_18 represents the heat flow into or out of the system. As a simplification, the heat term, formula_18, can sometimes be ignored, especially for fast processes involving gases, which are poor conductors of heat, or when the thermal efficiency of the transfer is high. For such adiabatic processes,\nThis simplified equation is the one used to define the joule, for example.\nOpen systems.\nBeyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (this process is illustrated by injection of an air-fuel mixture into a car engine, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by formula_20, one may write\nThermodynamics.\nInternal energy.\nInternal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.\nFirst law of thermodynamics.\nThe first law of thermodynamics asserts that the total energy of a system and its surroundings (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a \"gain\" in energy signified by a positive quantity) is given as\nformula_21,\nwhere the first term on the right is the heat transferred into the system, expressed in terms of temperature \"T\" and entropy \"S\" (in which entropy increases and its change d\"S\" is positive when heat is added to the system), and the last term on the right hand side is identified as work done on the system, where pressure is \"P\" and volume \"V\" (the negative sign results since compression of the system requires work to be done on it and so the volume change, d\"V\", is negative when work is done on the system).\nThis equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and \"PV\"-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a \"closed\" system is expressed in a general form by\nformula_22\nwhere formula_23 is the heat supplied to the system and formula_24 is the work applied to the system.\nEquipartition of energy.\nThe energy of a mechanical harmonic oscillator (a mass on a spring) is alternately kinetic and potential energy. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over a whole cycle, or over many cycles, average energy is equally split between kinetic and potential. This is an example of the equipartition principle: the total energy of a system with many degrees of freedom is equally split among all available degrees of freedom, on average.\nThis principle is vitally important to understanding the behavior of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between \"new\" and \"old\" degrees. This mathematical result is part of the second law of thermodynamics. The second law of thermodynamics is simple only for systems which are near or in a physical equilibrium state. For non-equilibrium systems, the laws governing the systems' behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way as to maximize their entropy production.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9653", "revid": "19655214", "url": "https://en.wikipedia.org/wiki?curid=9653", "title": "Expected value", "text": "Average value of a random variable\nIn probability theory, the expected value (also called expectation, expectancy, mathematical expectation, mean, average, or first moment) is a generalization of the weighted average. Informally, the expected value is the arithmetic mean of a large number of independently selected outcomes of a random variable.\nThe expected value of a random variable with a finite number of outcomes is a weighted average of all possible outcomes. In the case of a continuum of possible outcomes, the expectation is defined by integration. In the axiomatic foundation for probability provided by measure theory, the expectation is given by Lebesgue integration.\nThe expected value of a random variable X is often denoted by E(\"X\"), E[\"X\"], or E\"X\", with E also often stylized as E or formula_1\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nThe idea of the expected value originated in the middle of the 17th century from the study of the so-called problem of points, which seeks to divide the stakes \"in a fair way\" between two players, who have to end their game before it is properly finished. This problem had been debated for centuries. Many conflicting proposals and solutions had been suggested over the years when it was posed to Blaise Pascal by French writer and amateur mathematician Chevalier de M\u00e9r\u00e9 in 1654. M\u00e9r\u00e9 claimed that this problem couldn't be solved and that it showed just how flawed mathematics was when it came to its application to the real world. Pascal, being a mathematician, was provoked and determined to solve the problem once and for all.\nHe began to discuss the problem in the famous series of letters to Pierre de Fermat. Soon enough, they both independently came up with a solution. They solved the problem in different computational ways, but their results were identical because their computations were based on the same fundamental principle. The principle is that the value of a future gain should be directly proportional to the chance of getting it. This principle seemed to have come naturally to both of them. They were very pleased by the fact that they had found essentially the same solution, and this in turn made them absolutely convinced that they had solved the problem conclusively; however, they did not publish their findings. They only informed a small circle of mutual scientific friends in Paris about it.\nIn Dutch mathematician Christiaan Huygens' book, he considered the problem of points, and presented a solution based on the same principle as the solutions of Pascal and Fermat. Huygens published his treatise in 1657, (see Huygens (1657)) \"De ratiociniis in ludo ale\u00e6\" on probability theory just after visiting Paris. The book extended the concept of expectation by adding rules for how to calculate expectations in more complicated situations than the original problem (e.g., for three or more players), and can be seen as the first successful attempt at laying down the foundations of the theory of probability.\nIn the foreword to his treatise, Huygens wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It should be said, also, that for some time some of the best mathematicians of France have occupied themselves with this kind of calculus so that no one should attribute to me the honour of the first invention. This does not belong to me. But these savants, although they put each other to the test by proposing to each other many questions difficult to solve, have hidden their methods. I have had therefore to examine and go deeply for myself into this matter by beginning with the elements, and it is impossible for me for this reason to affirm that I have even started from the same principle. But finally I have found that my answers in many cases do not differ from theirs.\nDuring his visit to France in 1655, Huygens learned about de M\u00e9r\u00e9's Problem. From his correspondence with Carcavine a year later (in 1656), he realized his method was essentially the same as Pascal's. Therefore, he knew about Pascal's priority in this subject before his book went to press in 1657.\nIn the mid-nineteenth century, Pafnuty Chebyshev became the first person to think systematically in terms of the expectations of random variables.\nEtymology.\nNeither Pascal nor Huygens used the term \"expectation\" in its modern sense. In particular, Huygens writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;That any one Chance or Expectation to win any thing is worth just such a Sum, as wou'd procure in the same Chance and Expectation at a fair Lay. ... If I expect a or b, and have an equal chance of gaining them, my Expectation is worth (a+b)/2.\nMore than a hundred years later, in 1814, Pierre-Simon Laplace published his tract \"Th\u00e9orie analytique des probabilit\u00e9s\", where the concept of expected value was defined explicitly:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2026 this advantage in the theory of chance is the product of the sum hoped for by the probability of obtaining it; it is the partial sum which ought to result when we do not wish to run the risks of the event in supposing that the division is made proportional to the probabilities. This division is the only equitable one when all strange circumstances are eliminated; because an equal degree of probability gives an equal right for the sum hoped for. We will call this advantage \"mathematical hope\".\nNotations.\nThe use of the letter E to denote \"expected value\" goes back to W. A. Whitworth in 1901. The symbol has become popular since then for English writers. In German, E stands for \"Erwartungswert\", in Spanish for \"esperanza matem\u00e1tica\", and in French for \"esp\u00e9rance math\u00e9matique\".\nWhen \"E\" is used to denote expected value, authors use a variety of stylization: the expectation operator can be stylized as E (upright), E (italic), or formula_2 (in blackboard bold), while a variety of bracket notations (such as E(\"X\"), E[\"X\"], and E\"X\") are all used.\nAnother popular notation is \u03bc\"X\", whereas \u27e8\"X\"\u27e9, \u27e8\"X\"\u27e9av, and formula_3 are commonly used in physics, and M(\"X\") in Russian-language literature.\nDefinition.\nAs discussed above, there are several context-dependent ways of defining the expected value. The simplest and original definition deals with the case of finitely many possible outcomes, such as in the flip of a coin. With the theory of infinite series, this can be extended to the case of countably many possible outcomes. It is also very common to consider the distinct case of random variables dictated by (piecewise-)continuous probability density functions, as these arise in many natural contexts. All of these specific definitions may be viewed as special cases of the general definition based upon the mathematical tools of measure theory and Lebesgue integration, which provide these different contexts with an axiomatic foundation and common language.\nAny definition of expected value may be extended to define an expected value of a multidimensional random variable, i.e. a random vector X. It is defined component by component, as E[\"X\"]\"i\" \n E[\"X\"\"i\"]. Similarly, one may define the expected value of a random matrix X with components \"X\"\"ij\" by E[\"X\"]\"ij\" \n E[\"X\"\"ij\"].\nRandom variables with finitely many outcomes.\nConsider a random variable X with a \"finite\" list \"x\"1, ..., \"x\"\"k\" of possible outcomes, each of which (respectively) has probability \"p\"1, ..., \"p\"\"k\" of occurring. The expectation of X is defined as\nformula_4\nSince the probabilities must satisfy \"p\"1 + \u22c5\u22c5\u22c5 + \"p\"\"k\" \n 1, it is natural to interpret E[\"X\"] as a weighted average of the \"x\"\"i\" values, with weights given by their probabilities \"p\"\"i\".\nIn the special case that all possible outcomes are equiprobable (that is, \"p\"1 \n \"p\"\"k\"), the weighted average is given by the standard average. In the general case, the expected value takes into account the fact that some outcomes are more likely than others.\n formula_9\nIf one rolls the die formula_10 times and computes the average (arithmetic mean) of the results, then as formula_10 grows, the average will almost surely converge to the expected value, a fact known as the strong law of large numbers.\n formula_13\nThat is, the expected value to be won from a $1 bet is \u2212$. Thus, in 190 bets, the net loss will probably be about $10.\nRandom variables with countably many outcomes.\nInformally, the expectation of a random variable with a countable set of possible outcomes is defined analogously as the weighted average of all possible outcomes, where the weights are given by the probabilities of realizing each given value. This is to say that\n formula_14\nwhere \"x\"1, \"x\"2, ... are the possible outcomes of the random variable X and \"p\"1, \"p\"2, ... are their corresponding probabilities. In many non-mathematical textbooks, this is presented as the full definition of expected values in this context.\nHowever, there are some subtleties with infinite summation, so the above formula is not suitable as a mathematical definition. In particular, the Riemann series theorem of mathematical analysis illustrates that the value of certain infinite sums involving positive and negative summands depends on the order in which the summands are given. Since the outcomes of a random variable have no naturally given order, this creates a difficulty in defining expected value precisely.\nFor this reason, many mathematical textbooks only consider the case that the infinite sum given above converges absolutely, which implies that the infinite sum is a finite number independent of the ordering of summands. In the alternative case that the infinite sum does not converge absolutely, one says the random variable \"does not have finite expectation.\"\nRandom variables with density.\nNow consider a random variable X which has a probability density function given by a function f on the real number line. This means that the probability of X taking on a value in any given open interval is given by the integral of f over that interval. The expectation of X is then given by the integral\n formula_20\nA general and mathematically precise formulation of this definition uses measure theory and Lebesgue integration, and the corresponding theory of \"absolutely continuous random variables\" is described in the next section. The density functions of many common distributions are piecewise continuous, and as such the theory is often developed in this restricted setting. For such functions, it is sufficient to only consider the standard Riemann integration. Sometimes \"continuous random variables\" are defined as those corresponding to this special class of densities, although the term is used differently by various authors.\nAnalogously to the countably-infinite case above, there are subtleties with this expression due to the infinite region of integration. Such subtleties can be seen concretely if the distribution of X is given by the Cauchy distribution Cauchy(0, \u03c0), so that \"f\"(\"x\") \n (\"x\"2 + \u03c02)\u22121. It is straightforward to compute in this case that\nformula_21\nThe limit of this expression as \"a\" \u2192 \u2212\u221e and \"b\" \u2192 \u221e does not exist: if the limits are taken so that \"a\" \n \u2212\"b\", then the limit is zero, while if the constraint 2\"a\" \n \u2212\"b\" is taken, then the limit is ln(2).\nTo avoid such ambiguities, in mathematical textbooks it is common to require that the given integral converges absolutely, with E[\"X\"] left undefined otherwise. However, measure-theoretic notions as given below can be used to give a systematic definition of E[\"X\"] for more general random variables X.\nArbitrary real-valued random variables.\nAll definitions of the expected value may be expressed in the language of measure theory. In general, if X is a real-valued random variable defined on a probability space (\u03a9, \u03a3, P), then the expected value of X, denoted by E[\"X\"], is defined as the Lebesgue integral\nformula_22\nDespite the newly abstract situation, this definition is extremely similar in nature to the very simplest definition of expected values, given above, as certain weighted averages. This is because, in measure theory, the value of the Lebesgue integral of X is defined via weighted averages of \"approximations\" of X which take on finitely many values. Moreover, if given a random variable with finitely or countably many possible values, the Lebesgue theory of expectation is identical with the summation formulas given above. However, the Lebesgue theory clarifies the scope of the theory of probability density functions. A random variable X is said to be \"absolutely continuous\" if any of the following conditions are satisfied:\nformula_23\nfor any Borel set A, in which the integral is Lebesgue.\nThese conditions are all equivalent, although this is nontrivial to establish. In this definition, f is called the \"probability density function\" of X (relative to Lebesgue measure). According to the change-of-variables formula for Lebesgue integration, combined with the law of the unconscious statistician, it follows that\nformula_24\nfor any absolutely continuous random variable X. The above discussion of continuous random variables is thus a special case of the general Lebesgue theory, due to the fact that every piecewise-continuous function is measurable.\nInfinite expected values.\nExpected values as defined above are automatically finite numbers. However, in many cases it is fundamental to be able to consider expected values of \u00b1\u221e. This is intuitive, for example, in the case of the St. Petersburg paradox, in which one considers a random variable with possible outcomes \"x\"\"i\" \n 2\"i\", with associated probabilities \"p\"\"i\" \n 2\u2212\"i\", for i ranging over all positive integers. According to the summation formula in the case of random variables with countably many outcomes, one has\nformula_25\nIt is natural to say that the expected value equals +\u221e.\nThere is a rigorous mathematical theory underlying such ideas, which is often taken as part of the definition of the Lebesgue integral. The first fundamental observation is that, whichever of the above definitions are followed, any \"nonnegative\" random variable whatsoever can be given an unambiguous expected value; whenever absolute convergence fails, then the expected value can be defined as +\u221e. The second fundamental observation is that any random variable can be written as the difference of two nonnegative random variables. Given a random variable X, one defines the positive and negative parts by \"X\" + \n max(\"X\", 0) and \"X\" \u2212 \n \u2212min(\"X\", 0). These are nonnegative random variables, and it can be directly checked that \"X\" \n \"X\" + \u2212 \"X\" \u2212. Since E[\"X\" +] and E[\"X\" \u2212] are both then defined as either nonnegative numbers or +\u221e, it is then natural to define:\nformula_26\nAccording to this definition, E[\"X\"] exists and is finite if and only if E[\"X\" +] and E[\"X\" \u2212] are both finite. Due to the formula |\"X\"| \n \"X\" + + \"X\" \u2212, this is the case if and only if E|\"X\"| is finite, and this is equivalent to the absolute convergence conditions in the definitions above. As such, the present considerations do not define finite expected values in any cases not previously considered; they are only useful for infinite expectations.\n 0 and so E[\"X\"] \n +\u221e as desired.\n \u221e and E[\"X\" \u2212] \n \u221e (see Harmonic series). Hence, in this case the expectation of X is undefined.\nExpected values of common distributions.\nThe following table gives the expected values of some commonly occurring probability distributions. The third column gives the expected values both in the form immediately given by the definition, as well as in the simplified form obtained by computation therefrom. The details of these computations, which are not always straightforward, can be found in the indicated references.\nProperties.\nThe basic properties below (and their names in bold) replicate or follow immediately from those of Lebesgue integral. Note that the letters \"a.s.\" stand for \"almost surely\"\u2014a central property of the Lebesgue integral. Basically, one says that an inequality like formula_27 is true almost surely, when the probability measure attributes zero-mass to the complementary event formula_28.\nwhenever the right-hand side is well-defined. By induction, this means that the expected value of the sum of any finite number of random variables is the sum of the expected values of the individual random variables, and the expected value scales linearly with a multiplicative constant. Symbolically, for formula_36 random variables formula_37 and constants formula_38, we have formula_39. If we think of the set of random variables with finite expected value as forming a vector space, then the linearity of expectation implies that the expected value is a linear form on this vector space.\n \"X\" + + \"X\" \u2212 as discussed above, together with the triangle inequality, it follows that for any random variable formula_5 with well-defined expectation, one has formula_55.\nformula_57 where the values on both sides are well defined or not well defined simultaneously, and the integral is taken in the sense of Lebesgue-Stieltjes. As a consequence of integration by parts as applied to this representation of E[\"X\"], it can be proved that formula_58 with the integrals taken in the sense of Lebesgue. As a special case, for any random variable X valued in the nonnegative integers {0, 1, 2, 3, ...}, one has formula_59\nwhere P denotes the underlying probability measure.\nInequalities.\nConcentration inequalities control the likelihood of a random variable taking on large values. Markov's inequality is among the best-known and simplest to prove: for a \"nonnegative\" random variable X and any positive number a, it states that formula_75\nIf X is any random variable with finite expectation, then Markov's inequality may be applied to the random variable |\"X\"\u2212E[\"X\"]|2 to obtain Chebyshev's inequality formula_76\nwhere Var is the variance. These inequalities are significant for their nearly complete lack of conditional assumptions. For example, for any random variable with finite expectation, the Chebyshev inequality implies that there is at least a 75% probability of an outcome being within two standard deviations of the expected value. However, in special cases the Markov and Chebyshev inequalities often give much weaker information than is otherwise available. For example, in the case of an unweighted dice, Chebyshev's inequality says that odds of rolling between 1 and 6 is at least 53%; in reality, the odds are of course 100%. The Kolmogorov inequality extends the Chebyshev inequality to the context of sums of random variables.\nThe following three inequalities are of fundamental importance in the field of mathematical analysis and its applications to probability theory.\nPart of the assertion is that the negative part of \"f\"(\"X\") has finite expectation, so that the right-hand side is well-defined (possibly infinite). Convexity of f can be phrased as saying that the output of the weighted average of \"two\" inputs under-estimates the same weighted average of the two outputs; Jensen's inequality extends this to the setting of completely general weighted averages, as represented by the expectation. In the special case that \"f\"(\"x\") \n |\"x\"|\"t\"/\"s\" for positive numbers \"s\" &lt; \"t\", one obtains the Lyapunov inequality formula_78\nThis can also be proved by the H\u00f6lder inequality. In measure theory, this is particularly notable for proving the inclusion L\"s\" \u2282 L\"t\" of L\"p\" spaces, in the special case of probability spaces.\n 1, then formula_79\n for any random variables X and Y. The special case of \"p\" \n \"q\" \n 2 is called the Cauchy\u2013Schwarz inequality, and is particularly well-known.\nThe H\u00f6lder and Minkowski inequalities can be extended to general measure spaces, and are often given in that context. By contrast, the Jensen inequality is special to the case of probability spaces.\nExpectations under convergence of random variables.\nIn general, it is not the case that formula_81 even if formula_82 pointwise. Thus, one cannot interchange limits and expectation, without additional conditions on the random variables. To see this, let formula_83 be a random variable distributed uniformly on formula_84. For formula_85 define a sequence of random variables\nformula_86\nwith formula_87 being the indicator function of the event formula_88. Then, it follows that formula_89 pointwise. But, formula_90 for each formula_10. Hence, formula_92\nAnalogously, for general sequence of random variables formula_93, the expected value operator is not formula_94-additive, i.e.\nformula_95\nAn example is easily obtained by setting formula_96 and formula_97 for formula_98, where formula_99 is as in the previous example.\nA number of convergence results specify exact conditions which allow one to interchange limits and expectations, as specified below.\nRelationship with characteristic function.\nThe probability density function formula_124 of a scalar random variable formula_5 is related to its characteristic function formula_126 by the inversion formula:\n formula_127\nFor the expected value of formula_67 (where formula_129 is a Borel function), we can use this inversion formula to obtain\nformula_130\nIf formula_131 is finite, changing the order of integration, we get, in accordance with Fubini\u2013Tonelli theorem,\nformula_132\nwhere\nformula_133\nis the Fourier transform of formula_134 The expression for formula_131 also follows directly from Plancherel theorem.\nUses and applications.\nThe expectation of a random variable plays an important role in a variety of contexts. For example, in decision theory, an agent making an optimal choice in the context of incomplete information is often assumed to maximize the expected value of their utility function.\nFor a different example, in statistics, where one seeks estimates for unknown parameters based on available data, the estimate itself is a random variable. In such settings, a desirable criterion for a \"good\" estimator is that it is \"unbiased\"; that is, the expected value of the estimate is equal to the true value of the underlying parameter.\nIt is possible to construct an expected value equal to the probability of an event, by taking the expectation of an indicator function that is one if the event has occurred and zero otherwise. This relationship can be used to translate properties of expected values into properties of probabilities, e.g. using the law of large numbers to justify estimating probabilities by frequencies.\nThe expected values of the powers of \"X\" are called the moments of \"X\"; the moments about the mean of \"X\" are expected values of powers of \"X\" \u2212 E[\"X\"]. The moments of some random variables can be used to specify their distributions, via their moment generating functions.\nTo empirically estimate the expected value of a random variable, one repeatedly measures observations of the variable and computes the arithmetic mean of the results. If the expected value exists, this procedure estimates the true expected value in an unbiased manner and has the property of minimizing the sum of the squares of the residuals (the sum of the squared differences between the observations and the estimate). The law of large numbers demonstrates (under fairly mild conditions) that, as the size of the sample gets larger, the variance of this estimate gets smaller.\nThis property is often exploited in a wide variety of applications, including general problems of statistical estimation and machine learning, to estimate (probabilistic) quantities of interest via Monte Carlo methods, since most quantities of interest can be written in terms of expectation, e.g. formula_136, where formula_137 is the indicator function of the set formula_138.\n In classical mechanics, the center of mass is an analogous concept to expectation. For example, suppose \"X\" is a discrete random variable with values \"xi\" and corresponding probabilities \"pi\". Now consider a weightless rod on which are placed weights, at locations \"xi\" along the rod and having masses \"pi\" (whose sum is one). The point at which the rod balances is E[\"X\"].\nExpected values can also be used to compute the variance, by means of the computational formula for the variance\nformula_139\nA very important application of the expectation value is in the field of quantum mechanics. The expectation value of a quantum mechanical operator formula_140 operating on a quantum state vector formula_141 is written as formula_142. The uncertainty in formula_140 can be calculated by the formula formula_144.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nLiterature.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9656", "revid": "27810432", "url": "https://en.wikipedia.org/wiki?curid=9656", "title": "Electric light", "text": "Device for producing light from electricity\nAn electric light, lamp, or light bulb is an electrical component that produces light. It is the most common form of artificial lighting. Lamps usually have a base made of ceramic, metal, glass, or plastic, which secures the lamp in the socket of a light fixture, which is often called a \"lamp\" as well. The electrical connection to the socket may be made with a screw-thread base, two metal pins, two metal caps or a bayonet mount.\nThe three main categories of electric lights are incandescent lamps, which produce light by a filament heated white-hot by electric current, gas-discharge lamps, which produce light by means of an electric arc through a gas, such as fluorescent lamps, and LED lamps, which produce light by a flow of electrons across a band gap in a semiconductor.\nBefore electric lighting became common in the early 20th century, people used candles, gas lights, oil lamps, and fires. Vasily Vladimirovich Petrov developed the first persistent electric arc in 1802, and English chemist Humphry Davy gave a practical demonstration of an arc light in 1806. By the 1870s, Davy's arc lamp had been successfully commercialized, and was used to light many public spaces. Efforts by Joseph Swan and Thomas Edison\nled to commercial incandescent light bulbs becoming widely available in the 1880s, and by the early twentieth century these had completely replaced arc lamps.\nThe energy efficiency of electric lighting has increased radically since the first demonstration of arc lamps and the incandescent light bulb of the 19th century. Modern electric light sources come in a profusion of types and sizes adapted to many applications. Most modern electric lighting is powered by centrally generated electric power, but lighting may also be powered by mobile or standby electric generators or battery systems. Battery-powered light is often reserved for when and where stationary lights fail, often in the form of flashlights or electric lanterns, as well as in vehicles.\nHistory.\nWhile the ability of wires to illuminate when supplied with current was first discovered during the Enlightenment, it took more than a century of continuous and incremental improvement, including numerous designs, patents, and resulting intellectual property disputes, until incandescent light bulbs became commercially available in the 1920s. The first home to be lit by an electric light was Underhill, the home of Joseph Swan, around 1880.\nTypes.\nIncandescent.\nIn its modern form, the incandescent light bulb consists of a coiled filament of tungsten sealed in a globular glass chamber, either a vacuum or full of an inert gas such as argon. When an electric current is connected, the tungsten is heated to 2,000 to 3,300\u00a0K (1,730 to 3,030\u00a0\u00b0C; 3,140 to 5,480\u00a0\u00b0F) and glows, emitting light that approximates a continuous spectrum.\nIncandescent bulbs are highly inefficient, in that just 2\u20135% of the energy consumed is emitted as visible, usable light. The remaining 95% is lost as heat. In warmer climates, the emitted heat must then be removed, putting additional pressure on ventilation or air conditioning systems. In colder weather, the heat byproduct has some value, and has been successfully harnessed for warming in devices such as heat lamps. Incandescent bulbs are nonetheless being phased out in favor of technologies like CFLs and LED bulbs in many countries due to their low energy efficiency. The European Commission estimated in 2012 that a complete ban on incandescent bulbs would contribute 5 to 10 billion euros to the economy and save 15 billion metric tonnes of carbon dioxide emissions.\nHalogen.\nHalogen lamps are usually much smaller than standard incandescent lamps, because for successful operation a bulb temperature over 200\u00a0\u00b0C is generally necessary. For this reason, most have a bulb of fused silica (quartz) or aluminosilicate glass. This is often sealed inside an additional layer of glass. The outer glass is a safety precaution, to reduce ultraviolet emission and to contain hot glass shards should the inner envelope explode during operation. Oily residue from fingerprints may cause a hot quartz envelope to shatter due to excessive heat buildup at the contamination site. The risk of burns or fire is also greater with bare bulbs, leading to their prohibition in some places, unless enclosed by the luminaire.\nThose designed for 12- or 24-volt operation have compact filaments, useful for good optical control. Also, they have higher efficacies (lumens per watt) and better lives than non-halogen types. The light output remains almost constant throughout their life.\nFluorescent.\nFluorescent lamps consist of a glass tube that contains mercury vapour or argon under low pressure. Electricity flowing through the tube causes the gases to give off ultraviolet energy. The inside of the tubes are coated with phosphors that give off visible light when struck by ultraviolet photons. They have much higher efficiency than incandescent lamps. For the same amount of light generated, they typically use around one-quarter to one-third the power of an incandescent. The typical luminous efficacy of fluorescent lighting systems is 50\u2013100 lumens per watt, several times the efficacy of incandescent bulbs with comparable light output. Fluorescent lamp fixtures are more costly than incandescent lamps, because they require a ballast to regulate the current through the lamp, but the lower energy cost typically offsets the higher initial cost. Compact fluorescent lamps are available in the same popular sizes as incandescent lamps and are used as an energy-saving alternative in homes. Because they contain mercury, many fluorescent lamps are classified as hazardous waste. The United States Environmental Protection Agency recommends that fluorescent lamps be segregated from general waste for recycling or safe disposal, and some jurisdictions require recycling of them.\nLED.\nThe solid-state light-emitting diode (LED) has been popular as an indicator light in consumer electronics and professional audio gear since the 1970s. In the 2000s, efficacy and output have risen to the point where LEDs are now being used in lighting applications such as car headlights and brake lights, in flashlights and bicycle lights, as well as in decorative applications, such as holiday lighting. Indicator LEDs are known for their extremely long life, up to 100,000 hours, but lighting LEDs are operated much less conservatively, and consequently have shorter lives. LED technology is useful for lighting designers, because of its low power consumption, low heat generation, instantaneous on/off control, and in the case of single color LEDs, continuity of color throughout the life of the diode and relatively low cost of manufacture. LED lifetime depends strongly on the temperature of the diode. Operating an LED lamp in conditions that increase the internal temperature can greatly shorten the lamp's life.\nCarbon arc.\nCarbon arc lamps consist of two carbon rod electrodes in open air, supplied by a current-limiting ballast. The electric arc is struck by touching the rod tips then separating them. The ensuing arc produces a white-hot plasma between the rod tips. These lamps have higher efficacy than filament lamps, but the carbon rods are short-lived and require constant adjustment in use, as the intense heat of the arc erodes them. The lamps produce significant ultraviolet output, they require ventilation when used indoors, and due to their intensity they need protection from direct sight.\nInvented by Humphry Davy around 1805, the carbon arc was the first practical electric light. It was used commercially beginning in the 1870s for large building and street lighting until it was superseded in the early 20th century by the incandescent light. Carbon arc lamps operate at high power and produce high intensity white light. They also are a point source of light. They remained in use in limited applications that required these properties, such as movie projectors, stage lighting, and searchlights, until after World War II.\nDischarge.\nA discharge lamp has a glass or silica envelope containing two metal electrodes separated by a gas. Gases used include, neon, argon, xenon, sodium, metal halide, and mercury. The core operating principle is much the same as the carbon arc lamp, but the term \"arc lamp\" normally refers to carbon arc lamps, with more modern types of gas discharge lamp normally called discharge lamps. With some discharge lamps, very high voltage is used to strike the arc. This requires an electrical circuit called an igniter, which is part of the electrical ballast circuitry. After the arc is struck, the internal resistance of the lamp drops to a low level, and the ballast limits the current to the operating current. Without a ballast, excess current would flow, causing rapid destruction of the lamp.\nSome lamp types contain a small amount of neon, which permits striking at normal running voltage with no external ignition circuitry. Low-pressure sodium lamps operate this way. The simplest ballasts are just an inductor, and are chosen where cost is the deciding factor, such as street lighting. More advanced electronic ballasts may be designed to maintain constant light output over the life of the lamp, may drive the lamp with a square wave to maintain completely flicker-free output, and shut down in the event of certain faults.\nThe most efficient source of electric light is the low-pressure sodium lamp. It produces, for all practical purposes, a monochromatic orange-yellow light, which gives a similarly monochromatic perception of any illuminated scene. For this reason, it is generally reserved for outdoor public lighting applications. Low-pressure sodium lights are favoured for public lighting by astronomers, since the light pollution that they generate can be easily filtered, contrary to broadband or continuous spectra.\nForm factor.\nMany lamp units, or light bulbs, are specified in standardized shape codes and socket names. Incandescent bulbs and their retrofit replacements are often specified as \"A19/A60 E26/E27\", a common size for these kind of light bulbs. In this example, the \"A\" parameters describe the bulb size and shape within the A-series light bulb while the \"E\" parameters describe the Edison screw base size and thread characteristics.\nComparison parameters.\nCommon comparison parameters include:\nLess common parameters include color rendering index (CRI).\nLife expectancy.\nLife expectancy for many types of lamp is defined as the number of hours of operation at which 50% of them fail, that is the median life of the lamps. Production tolerances as low as 1% can create a variance of 25% in lamp life, so in general some lamps will fail well before the rated life expectancy, and some will last much longer. For LEDs, lamp life is defined as the operation time at which 50% of lamps have experienced a 70% decrease in light output. In the 1900s the Phoebus cartel formed in an attempt to reduce the life of electric light bulbs, an example of planned obsolescence. \nSome types of lamp are also sensitive to switching cycles. Rooms with frequent switching, such as bathrooms, can expect much shorter lamp life than what is printed on the box. Compact fluorescent lamps are particularly sensitive to switching cycles.\nUses.\nThe total amount of artificial light (especially from street light) is sufficient for cities to be easily visible at night from the air, and from space. External lighting grew at a rate of 3\u20136 percent for the later half of the 20th century and is the major source of light pollution that burdens astronomers and others with 80% of the world's population living in areas with night time light pollution. Light pollution has been shown to have a negative effect on some wildlife.\nElectric lamps can be used as heat sources, for example in incubators, as infrared lamps in fast food restaurants and toys such as the Kenner Easy-Bake Oven.\nLamps can also be used for light therapy to deal with such issues as vitamin D deficiency, skin conditions such as acne and dermatitis, skin cancers, and seasonal affective disorder. Lamps which emit a specific frequency of blue light are also used to treat neonatal jaundice with the treatment which was initially undertaken in hospitals being able to be conducted at home.\nElectric lamps can also be used as a grow light to aid in plant growth especially in indoor hydroponics and aquatic plants with recent research into the most effective types of light for plant growth.\nDue to their nonlinear resistance characteristics, tungsten filament lamps have long been used as fast-acting thermistors in electronic circuits. Popular uses have included:\nU.S. transition to LED bulbs.\nIn the United States, incandescent, halogen and compact fluorescent light bulbs will stop being sold effective as of August 2023, due to a ban by the U.S. Department of Energy. Compact fluorescent bulbs are included in the ban because of their toxic mercury that can be released into the home if broken and problems with disposal of mercury-containing bulbs in landfills.\nCircuit symbols.\nIn circuit diagrams, lamps have two main types of symbols, indicating their respective functions. These are:\nCultural symbolism.\nIn Western culture, a lightbulb \u2014 in particular, the appearance of an illuminated lightbulb above a person's head \u2014 signifies sudden inspiration.\nIn the Middle East, a light bulb symbol has a sexual connotation.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9657", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=9657", "title": "Edgar Rice Burroughs", "text": "American writer (1875\u20131950)\nEdgar Rice Burroughs (September 1, 1875\u00a0\u2013 March 19, 1950) was an American writer, best known for his prolific output in the adventure, science fiction, and fantasy genres. Best-known for creating the characters Tarzan and John Carter, he also wrote the \"Pellucidar\" series, the \"Amtor\" series, and the \"Caspak\" trilogy. \nTarzan was immediately popular, and Burroughs capitalized on it in every way possible, including a syndicated Tarzan comic strip, movies, and merchandise. Tarzan remains one of the most successful fictional characters to this day and is a cultural icon. Burroughs's California ranch is now the center of the Tarzana neighborhood in Los Angeles, named after the character. Burroughs was an explicit supporter of eugenics and scientific racism in both his fiction and nonfiction; Tarzan was meant to reflect these concepts.\nBiography.\nEarly life and family.\nBurroughs was born on September 1, 1875, in Chicago (he later lived for many years in the suburb of Oak Park), the fourth son of Major George Tyler Burroughs (1833\u20131913), a businessman and Civil War veteran, and his wife, Mary Evaline (Zieger) Burroughs (1840\u20131920). His middle name is from his paternal grandmother, Mary Coleman Rice Burroughs (1802\u20131889). He was of almost entirely English ancestry, with a family line that had been in North America since the Colonial era.\nThrough his Rice grandmother, Burroughs was descended from settler Edmund Rice, one of the English Puritans who moved to Massachusetts Bay Colony in the early 17th century. He once remarked, \"I can trace my ancestry back to Deacon Edmund Rice.\" The Burroughs side of the family was also of English origin and also emigrated to Massachusetts around the same time. Many of his ancestors fought in the American Revolution. Some of his ancestors settled in Virginia during the colonial period, and Burroughs often emphasized his connection with that side of his family, seeing it as romantic and warlike. As close cousins he had seven signatories of the U.S. Declaration of Independence, including his third cousin, four times removed, 2nd President of the United States John Adams.\nBurroughs was educated at a number of local schools. He then attended Phillips Academy, in Andover, Massachusetts, and then the Michigan Military Academy. Graduating in 1895, and failing the entrance exam for the United States Military Academy at West Point, he became an enlisted soldier with the 7th U.S. Cavalry in Fort Grant, Arizona Territory. After being diagnosed with a heart problem and thus ineligible to serve, he was discharged in 1897.\nAfter his discharge Burroughs worked at a number of different jobs. During the Chicago influenza epidemic of 1891, he spent half a year at his brother's ranch on the Raft River in Idaho, as a cowboy, drifted somewhat afterward, then worked at his father's Chicago battery factory in 1899, marrying his childhood sweetheart, Emma Hulbert (1876\u20131944), in January 1900.\nIn 1903, Burroughs joined his brothers, Yale graduates George and Harry, who were, by then, prominent Pocatello area ranchers in southern Idaho, and partners in the Sweetser-Burroughs Mining Company, where he took on managing their ill-fated Snake River gold dredge, a classic bucket-line dredge. The Burroughs brothers were also the sixth cousins, once removed, of famed miner Kate Rice who, in 1914, became the first female prospector in the Canadian North. Journalist and publisher C. Allen Thorndike Rice was also his third cousin.\nWhen the new mine proved unsuccessful, the brothers secured for Burroughs a position with the Oregon Short Line Railroad in Salt Lake City. Burroughs resigned from the railroad in October 1904.\nLater life.\nBy 1911, after seven years of low wages as a pencil-sharpener wholesaler, Burroughs began to write fiction. By this time, Emma and he had two children, Joan (1908\u20131972), and Hulbert (1909\u20131991). During this period, he had copious spare time and began reading pulp-fiction magazines. In 1929, he recalled thinking that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... if people were paid for writing rot such as I read in some of those magazines, that I could write stories just as rotten. As a matter of fact, although I had never written a story, I knew absolutely that I could write stories just as entertaining and probably a whole lot more so than any I chanced to read in those magazines.\nIn 1913, Burroughs and Emma had their third and last child, John Coleman Burroughs (1913\u20131979), later known for his illustrations of his father's books.\nIn the 1920s, Burroughs became a pilot, purchased a Security Airster S-1, and encouraged his family to learn to fly.\nDaughter Joan married \"Tarzan\" film actor, James Pierce, starring with her husband, as the voice of \"Jane\", during 1932\u20131934 for the \"Tarzan\" radio series. The pair were wed for more than forty years, until her death in 1972.\nBurroughs divorced Emma in 1934 and, in 1935, married the former actress Florence Gilbert Dearholt, who was the former wife of his friend (who was then himself remarrying), Ashton Dearholt, with whom he had co-founded Burroughs-Tarzan Enterprises while filming \"The New Adventures of Tarzan\". Burroughs adopted the Dearholts' two children. He and Florence divorced in 1942.\nBurroughs was in his late 60s and was in Honolulu at the time of the Japanese attack on Pearl Harbor. Despite his age, he applied for and received permission to become a war correspondent, becoming one of the oldest U.S. war correspondents during World War II. This period of his life is mentioned in William Brinkley's bestselling novel \"Don't Go Near the Water\".\nDeath.\nAfter the war ended, Burroughs moved back to Encino, California, where after many health problems, he died of a heart attack on March 19, 1950, having written almost 80 novels. He is buried in Tarzana, California, US.\nAt the time of his death he was believed to have been the writer who had made the most from films, earning over $2\u00a0million in royalties from 27 Tarzan pictures.\nThe Science Fiction Hall of Fame inducted Burroughs in 2003.\nLiterary career.\nAiming his work at the pulps\u2014under the name \"Norman Bean\" to protect his reputation\u2014Burroughs had his first story, \"Under the Moons of Mars\", serialized by Frank Munsey in the February to July 1912 issues of \"The All-Story\". \"Under the Moons of Mars\" inaugurated the \"Barsoom\" series and earned Burroughs US$ ($11,922 today). It was first published as a book by A. C. McClurg of Chicago in 1917, entitled \"A Princess of Mars\", after three Barsoom sequels had appeared as serials and McClurg had published the first four serial Tarzan novels as books.\nBurroughs soon took up writing full-time, and by the time the run of \"Under the Moons of Mars\" had finished, he had completed two novels, including \"Tarzan of the Apes\", published from October 1912 and one of his most successful series.\nBurroughs also wrote popular science fiction and fantasy stories involving adventurers from Earth transported to various planets (notably Barsoom, Burroughs's fictional name for Mars, and Amtor, his fictional name for Venus), lost islands (Caspak), and into the interior of the Hollow Earth in his \"Pellucidar\" stories. He also wrote Westerns and historical romances. Besides those published in \"All-Story\", many of his stories were published in \"The Argosy\" magazine.\nTarzan was a cultural sensation when introduced. Burroughs was determined to capitalize on Tarzan's popularity in every way possible. He planned to exploit Tarzan through several different media including a syndicated Tarzan comic strip, movies, and merchandise. Experts in the field advised against this course of action, stating that the different media would just end up competing against each other. Burroughs went ahead, however, and proved the experts wrong \u2013 the public wanted Tarzan in whatever fashion he was offered. Tarzan remains one of the most successful fictional characters to this day and is a cultural icon.\nIn either 1915 or 1919, Burroughs purchased a large ranch north of Los Angeles, California, which he named \"Tarzana\". The citizens of the community that sprang up around the ranch voted to adopt that name when their community, Tarzana, California, was formed in 1927. Also, the unincorporated community of Tarzan, Texas, was formally named in 1927 when the US Postal Service accepted the name, reputedly coming from the popularity of the first (silent) \"Tarzan of the Apes\" film, starring Elmo Lincoln, and an early \"Tarzan\" comic strip.\nIn 1923, Burroughs set up his own company, Edgar Rice Burroughs, Inc., and began printing his own books through the 1930s.\nReception and criticism.\nBecause of the part Burroughs's science fiction played in inspiring real exploration of Mars, an impact crater on Mars was named in his honor after his death. In a \"Paris Review\" interview, Ray Bradbury said of Burroughs that \"Edgar Rice Burroughs never would have looked upon himself as a social mover and shaker with social obligations. But as it turns out \u2013 and I love to say it because it upsets everyone terribly \u2013 Burroughs is probably the most influential writer in the entire history of the world.\" Bradbury continued that \"By giving romance and adventure to a whole generation of boys, Burroughs caused them to go out and decide to become special.\"\nIn \"Something of Myself\" (published posthumously in 1937) Rudyard Kipling wrote: \"My \"Jungle Books\" begat Zoos of [imitators]. But the genius of all the genii was one who wrote a series called \"Tarzan of the Apes\". I read it, but regret I never saw it on the films, where it rages most successfully. He had 'jazzed' the motif of the \"Jungle Books\" and, I imagine, had thoroughly enjoyed himself. He was reported to have said that he wanted to find out how bad a book he could write and 'get away with', which is a legitimate ambition.\"\nBy 1963, Floyd C. Gale of \"Galaxy Science Fiction\" wrote when discussing reprints of several Burroughs novels by Ace Books, \"an entire generation has grown up inexplicably Burroughs-less\". He stated that most of the author's books had been out of print for years and that only the \"occasional laughable Tarzan film\" reminded public of his fiction. Gale reported his surprise that after two decades his books were again available, with Canaveral Press, Dover Publications, and Ballantine Books also reprinting them.\nFew critical books have been written about Burroughs. From an academic standpoint, the most helpful are Erling Holtsmark's two books: \"Tarzan and Tradition\" and \"Edgar Rice Burroughs\"; Stan Galloway's \"The Teenage Tarzan: A Literary Analysis of Edgar Rice Burroughs' \"Jungle Tales of Tarzan; and Richard Lupoff's two books: \"Master of Adventure: Edgar Rice Burroughs\" and \"Barsoom: Edgar Rice Burroughs and the Martian Vision\". Galloway was identified by James Edwin Gunn as \"one of the half-dozen finest Burroughs scholars in the world\"; Galloway called Holtsmark his \"most important predecessor\".\nBurroughs strongly supported eugenics and scientific racism. His views held that English nobles made up a particular heritable elite among Anglo-Saxons. Tarzan was meant to reflect this, with him being born to English nobles and then adopted by talking apes (the Mangani). They express eugenicist views themselves, but Tarzan is permitted to live despite being deemed \"unfit\" in comparison, and grows up to surpass not only them but black Africans, whom Burroughs clearly presents as inherently inferior, even not wholly human. In one Tarzan story, he finds an ancient civilization where eugenics has been practiced for over 2,000 years, with the result that it is free of all crime. Criminal behavior is held to be entirely hereditary, with the solution having been to kill not only criminals but also their families. \"Lost on Venus\", a later novel, presents a similar utopia where forced sterilization is practiced and the \"unfit\" are killed. Burroughs explicitly supported such ideas in his unpublished nonfiction essay \"I See A New Race\". Additionally, his \"Pirate Blood\", which is not speculative fiction and remained unpublished after his death, portrayed the characters as victims of their hereditary criminal traits (one a descendant of the corsair Jean Lafitte, another from the Jukes family). These views have been compared with Nazi eugenics (though noting that they were popular and common at the time), with his \"Lost on Venus\" being released the same year the Nazis took power (in 1933).\nIn 2003, Burroughs was inducted into the Science Fiction and Fantasy Hall of Fame.\nSelected works.\n\"Moon\" series.\nThese three texts have been published by various houses in one or two volumes. Adding to the confusion, some editions have the original (significantly longer) introduction to Part I from the first publication as a magazine serial, and others have the shorter version from the first book publication, which included all three parts under the title \"The Moon Maid\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9658", "revid": "45651582", "url": "https://en.wikipedia.org/wiki?curid=9658", "title": "Eug\u00e8ne Viollet-le-Duc", "text": "French architect and author\nEug\u00e8ne Emmanuel Viollet-le-Duc (]; 27 January 1814\u00a0\u2013 17 September 1879) was a French architect and author, famous for his restoration of the most prominent medieval landmarks in France. His major restoration projects included Notre-Dame de Paris, the Basilica of Saint Denis, Mont Saint-Michel, Sainte-Chapelle, the medieval walls of the city of Carcassonne, and Roquetaillade castle in the Bordeaux region.\nHis writings on decoration and on the relationship between form and function in architecture had a fundamental influence on a whole new generation of architects, including all the major Art Nouveau artists : Antoni Gaud\u00ed,Victor Horta, Hector Guimard, Henry Van de Velde, Henry Sauvage and the Ecole de Nancy, Paul Hankar, Otto Wagner, Eugene Grasset, Emile Gall\u00e9, Hendrik Petrus Berlage... He also influences the first modern architects, Frank Lloyd Wright, Mies van der Rohe, Auguste Perret, Louis Sullivan... and Le Corbusier, who considered Viollet le Duc as the father of modern architecture : \"The roots of moderne architecture are to be found in Viollet le Duc\". His writings also influenced John Ruskin, William Morris and the Arts and Crafts mouvement. And at the 1862 international exhibition in London the esthetic works of Burne-Jones, Rossetti, Philip Webb, William Morris, Simeon Solomon et Edward Poynter are directly influenced from drawings in Viollet le Duc's Dictionnary\".\" The english architect William Burgess admitted in his late life \"\"We all cribbed on Viollet le Duc even though no one could read French\".\"\nYouth and education.\nViollet-le-Duc was born in Paris in 1814. His grandfather was an architect, and his father was a high-ranking civil servant, who in 1816 became the overseer of the royal residences of Louis XVIII. His uncle \u00c9tienne-Jean Del\u00e9cluze was a painter, a former student of Jacques-Louis David, an art critic and hosted a literary salon, which was attended by Stendhal and Sainte-Beuve. His mother hosted her own salon, which women could attend as well as men. There, in 1822 or 1823, Eug\u00e8ne met Prosper M\u00e9rim\u00e9e, a writer who would play a decisive role in his career.\nIn 1825 he began his education at the Pension Moran, in Fontenay-aux-Roses. He returned to Paris in 1829 as a student at the college de Bourbon (now the Lyc\u00e9e Condorcet). He passed his baccalaureate examination in 1830. His uncle urged him to enter the \u00c9cole des Beaux-Arts, which had been created in 1806, but the \"\u00c9cole \" had an extremely rigid system, based entirely on copying classical models, and Eug\u00e8ne was not interested. Instead he decided to get practical experience in the architectural offices of Jacques-Marie Huv\u00e9 and Achille Lecl\u00e8re, while devoting much of his time to drawing medieval churches and monuments around Paris.\nAt sixteen he participated in the July 1830 revolution which overthrew Charles X, building a barricade. Following the revolution, which brought Louis Philippe to power, his father became chief of the bureau of royal residences. The new government created, for the first time, the position of Inspector General of Historic Monuments. Eug\u00e8ne's uncle Del\u00e9cluze agreed to take Eug\u00e8ne on a long tour of France to see monuments. They travelled from July to October 1831 throughout the south of France, and he returned with a large collection of detailed paintings and watercolours of churches and monuments.\nOn his return to Paris, he moved with his family into the Tuileries Palace, where his father was now governor of royal residences. His family again urged him to attend the \u00c9cole des Beaux-Arts, but he still refused. He wrote in his journal in December 1831, \"the \"\u00c9cole\" is just a mould for architects. they all come out practically identical.\" He was a talented and meticulous artist; he travelled around France to visit monuments, cathedrals, and other medieval architecture, made detailed drawings and watercolours. In 1834, at the age of twenty, he married \u00c9lisabeth Templier, and in the same year he was named an associate professor of ornamental decoration at the Royal School of Decorative Arts, which gave him a more regular income. His first pupils there included L\u00e9on Gaucherel.\nWith the money from the sale of his drawings and paintings, Viollet-le-Duc set off on a long tour of the monuments of Italy, visiting Rome, Venice, Florence and other sites, drawing and painting. In 1838, he presented several of his drawings at the Paris Salon, and began making a travel book, \"Picturesque and romantic images of the old France\", for which, between 1838 and 1844, he made nearly three hundred engravings.\nFirst architectural restorations.\nIn October 1838, with the recommendation of Achille Lecl\u00e8re, the architect with whom he had trained, he was named deputy inspector of the enlargement of the H\u00f4tel Soubise, the new home of the French National Archives. His uncle, Del\u00e9cluze, then recommended him to the new Commission of Historic Monuments of France, led by Prosper M\u00e9rim\u00e9e, who had just published a book on medieval French monuments. Though he was just twenty-four years old and had no degree in architecture, he was asked to go to Narbonne to propose a plan for the completion of the cathedral there. The project was rejected by the local authorities as too ambitious and too expensive.\nHis first real project was a restoration of the V\u00e9zelay Abbey, which many considered as impossible. The church had been sacked by the Huguenots in 1569, and during the French Revolution, the facade and statuary on the facade were destroyed. The vaults of the roof were weakened, and many of the stones had been carried off for other projects. When M\u00e9rim\u00e9e visited to inspect the structure he heard stones falling around him. In February 1840 he gave Viollet-le-Duc the mission of restoring and reconstructing the church so it would not collapse, while \"respecting exactly in his project of restoration all the ancient dispositions of the church\".\nThe task was all the more difficult because up until that time no scientific studies had been made of medieval building techniques, and there were no schools of restoration. He had no plans for the original building to work from. Viollet-le-Duc had to discover the flaws of construction that had caused the building to start to collapse in the first place and to construct a more solid and stable structure. He lightened the roof and built new arches to stabilize the structure, and slightly changed the shape of the vaults and arches. He was criticized for these modifications in the 1960s, though, as his defenders pointed out, without them the roof would have collapsed under its own weight. M\u00e9rim\u00e9e's deputy, Lenormant, inspected the construction and reported to M\u00e9rim\u00e9e: \"The young Leduc seems entirely worthy of your confidence. He needed a magnificent audacity to take charge of such a desperate enterprise; it's certain that he arrived just in time, and if we had waited only ten years the church would have been a pile of stones.\" This restoration work lasted 19 years.\nSainte-Chapelle and Amboise.\nViollet-le-Duc's success at Vezelay led to a large series of projects. In 1840, in collaboration with his friend the architect Jean-Baptiste Lassus he began the restoration of Sainte-Chapelle in Paris, which had been turned into a storage depot after the Revolution. In February 1843, King Louis Philippe sent him to the Ch\u00e2teau of Amboise, to restore the stained glass windows in the chapel holding the tomb of Leonardo da Vinci. The windows were unfortunately destroyed in 1940 during World War\u00a0II.\nIn 1843, M\u00e9rim\u00e9e took Viollet-le-Duc with him to Burgundy and the south of France, on one of his long inspection tours of monuments. Viollet-le-Duc made drawings of the buildings and wrote detailed accounts of each site, illustrated with his drawing, which were published in architectural journals. With his experience he became the most prominent academic scholar on French medieval architecture and his Medieval Dictionnary, with over 4000 drawings, contains the largest iconography on the subject to this day.\nNotre-Dame de Paris.\nIn 1844, with the backing of M\u00e9rim\u00e9e, Viollet-le-Duc, just thirty years old, and Lassus, then thirty-seven, won a competition for the restoration of Notre-Dame Cathedral which lasted twenty-five years. Their project involved primarily the facade, where many of the statues over the portals had been beheaded or smashed during the Revolution. They proposed two major changes to the interior: rebuilding two of the bays to their original medieval height of four storeys, and removing the marble neoclassical structures and decoration which had been added to the choir during the reign of Louis XIV. M\u00e9rim\u00e9e warned them to be careful: \"In such a project, one cannot act with too much prudence or discretion...A restoration may be more disastrous for a monument than the ravages of centuries.\" The Commission on Historical Monuments approved most of Viollet-le-Duc's plans, but rejected his proposal to remove the choir built under Louis XIV. Viollet-le-Duc himself turned down a proposal to add two new spires atop the towers, arguing that such a monument \"would be remarkable but would not be Notre-Dame de Paris\". Instead, he proposed to rebuild the original medieval spire and bell tower over the transept, which had been removed in 1786 because it was unstable in the wind.\nOnce the project was approved, Viollet-le-Duc made drawings and photographs of the existing decorative elements; then they were removed and a stream of sculptors began making new statues of saints, gargoyles, chimeras and other architectural elements in a workshop he established, working from his drawings and photographs of similar works in other cathedrals of the same period. He also designed a new treasury in the Gothic style to serve as the museum of the cathedral, replacing the residence of the Archbishop, which had been destroyed in a riot in 1831.\nThe bells in the two towers had been taken out in 1791 and melted down to make cannons. Viollet-le-Duc had new bells cast for the north tower and a new structure built inside to support them. Viollet-le-Duc and Lassus also rebuilt the sacristy, on the south side of the church, which had been built in 1756, but had been burned by rioters during the July Revolution of 1830. The new spire was completed, taller and more strongly built to withstand the weather; it was decorated with statues of the apostles, and the face of Saint Thomas, patron saint of architects, bore a noticeable resemblance to Viollet-le-Duc. The spire was destroyed on 15 April 2019, as a result of the Notre-Dame de Paris fire.\nSaint Denis and Amiens.\nWhen not engaged in Paris, Viollet-le-Duc continued his long tours into the French provinces, inspecting and checking the progress of more than twenty different restoration projects that were under his control, including seven in Burgundy alone. New projects included the Basilica of Saint-Sernin, Toulouse, and the Basilica of Saint-Denis just outside Paris. Saint-Denis had undergone a restoration by a different architect, Francois Debret, who had rebuilt one of the two towers. However, in 1846, the new tower, overloaded with masonry, began to crack, and Viollet-le-Duc was called in. He found no way the building could be saved and had to oversee the demolition of the tower, saving the stones. He concentrated on restoring the interior of the church, and was able to restore the original burial chamber of the kings of France.\nIn May 1849, he was named the architect for the restoration of Amiens Cathedral, one of the largest in France, which had been built over many centuries in a variety of different styles. He wrote, \"his goal should be to save in each part of the monument its own character, and yet to make it so that the united parts don't conflict with each other; and that can be maintained in a state that is durable and simple.\"\nImperial projects: Carcassonne, Vincennes and Pierrefonds.\nThe French coup d'\u00e9tat of 1851 brought Napoleon III to power and transformed France from a republic to an empire. The coup accelerated some of Viollet-le-Duc's projects as his patron Prosper M\u00e9rim\u00e9e had introduced him to the new Emperor. He moved forward with the slow work of restoration of the Cathedral of Reims and Cathedral of Amiens. In Amiens, he cleared the interior of the French classical decoration added under Louis XIV, and proposed to make it resolutely Gothic. He gave the Emperor a tour of his project in September 1853; the Empress immediately offered to pay two-thirds of the cost of the restoration. In the same year he undertook the restoration of the Ch\u00e2teau de Vincennes, long occupied by the military, along with its chapel, similar to Sainte-Chapelle. A devotee of the pure Gothic, he described the chapel as \"one of the finest specimens of Gothic in decline\".\nIn November 1853, he provided the costs and plans for the medieval ramparts of Carcassonne which he had first begun planning in 1849. The first fortifications had been built by the Visigoths; on top of these, in the Middle Ages Louis\u00a0XI and then Philip the Bold had built a formidable series of towers, galleries, walls, gates and interlocking defences that resisted all sieges until 1355. The fortifications were largely intact, since the surroundings of the city were still a military defensive zone in the 19th century, but the towers were without tops and a large number of structures had been built up against the old walls. Once he obtained funding and made his plans, he began demolishing all structures which had been added to the ramparts over the centuries, and restored the gates, walls and towers to their original form, including the defence platforms, roofs on the towers and shelters for archers that would have been used during a siege. He found many of the original mountings for weapons still in place. To accompany his work, he published a detailed history of the city and its fortifications, with his drawings. Carcassonne became the best example of medieval military architecture in France, and also an important tourist attraction.\nNapoleon\u00a0III provided additional funding for the continued restoration of Notre-Dame. Viollet-le-Duc was also to replace the great bestiary of mythical beasts and animals which had decorated the cathedral in the 18th century. In 1856, using examples from other medieval churches and debris from Notre-Dame as his model, his workshop produced dragons, chimeras, grotesques, and gargoyles, as well as an assortment of picturesque pinnacles and fleurons. He engaged in a new project for restoration of the Cathedral of Clermont-Ferrand, a project which continued for ten years. He also undertook an unusual project for Napoleon\u00a0III; the design and construction of six railway coaches with neo-Gothic interior d\u00e9cor for the Emperor and his entourage. Two of the cars still exist; the salon of honour car, with a fresco on the ceiling, is at the Ch\u00e2teau de Compi\u00e8gne, and the dining car, with a massive golden eagle as the centrepiece of the d\u00e9cor, is at the Railroad Museum of Mulhouse.\nNapoleon\u00a0III asked Viollet-le-Duc if he could restore a medieval chateau for the Emperor's own use near Compi\u00e8gne, where the Emperor traditionally passed September and October. Viollet-le-Duc first studied a restoration of the Ch\u00e2teau de Coucy, which had the highest medieval tower in France. When this proved too complicated, he settled upon Ch\u00e2teau de Pierrefonds, a castle begun by Louis of Orleans in 1396, then dismantled in 1617 after several sieges by Louis XIII of France. Napoleon bought the ruin for 5000 francs in 1812, and M\u00e9rim\u00e9e declared it an historic monument in 1848. In 1857 Viollet-le-Duc began designing an entirely new chateau on the ruins. This structure was not designed to recreate anything exactly that had existed, but a castle which recaptured the spirit of the gothic, with lavish neo-gothic decoration and 19th-century comforts. Pierrefonds and its inside decorations would not only influence William Burgess and his Cardiff and Coch castles but also the castles of Ludwig II of Bavaria ( Neuschwanstein Castle) and the Haut-K\u0153nigsbourg of the Emperor Wilhelm II.\n----While most of his attention was devoted to restorations, Viollet-le-Duc designed and built a number of private residences and new buildings in Paris. He also participated in the most important competition of the period, for the new Paris Opera. There were one hundred seventy-one projects proposed in the original competition, presented the 1855 Paris Universal Exposition. A jury of noted architects narrowed it down to five, including projects from Viollet-le-Duc and Charles Garnier, age thirty-five. Viollet-le-Duc was finally eliminated and this put an end to Viollet le Duc's wish to construct public buildings.\nNapoleon\u00a0III also called upon Viollet-le-Duc for a wide variety of archeological and architectural tasks. When he wished to put up a monument to mark the Battle of Alesia, where Julius Caesar defeated the Gauls, a siege whose actual site was disputed by historians, he asked Viollet-le-Duc to locate the exact battlefield. Viollet-le-Duc conducted excavations at various purported sites, and finally found vestiges of the walls built at the time. He also designed the metal frame for the six-metre-high statue of the Gallic chief Vercing\u00e9torix that would be placed on the site. He later designed a similar frame for a much larger statue, the Statue of Liberty, but died before that statue was finished.\nEnd of the Empire and of Restoration.\nIn 1863, Viollet-le-Duc was named a professor at the \u00c9cole des Beaux-Arts, the school where he had refused to become a student. In the fortress of neoclassical Beaux-Arts architecture there was much resistance against him, but he attracted two hundred students to his course, who applauded his lecture at the end. But while he had many supporters, the faculty professors and certain students campaigned against him. His critics complained that, aside from having little formal architectural training himself, he had only built a handful of new buildings. He tired of the confrontations and resigned on 16 May 1863, and continued his writing and teaching outside the Beaux-Arts. In response to the Beaux-Arts he initiated the creation of the \u00c9cole Sp\u00e9ciale d'Architecture in Paris in 1865.\nIn the beginning of 1864, he celebrated the conclusion of his most important project, the restoration of Notre-Dame. In January of the same year he completed the first phase of the restoration of the Cathedral of Saint Sernin in Toulouse, one of the landmarks of French Romanesque architecture. Napoleon\u00a0III invited Viollet-le-Duc to study possible restorations overseas, including in Algeria, Corsica, and in Mexico, where Napoleon had installed a new Emperor, Maximilian, under French sponsorship. He also saw the consecration of the third church that he had designed, the neo-Gothic Church of Saint-Denis de l'Estree, in the Paris suburb of Saint-Denis. Between 1866 and 1870, his major project was the ongoing transformation of Pierrefonds from a ruin into a royal residence. His plans for the metal framework he had designed for Pierrefonds were displayed at the Paris Universal Exposition of 1867. He also began a new area of study, researching the geology and geography of the region around Mont Blanc in the Alps. While on his mapping excursion in the Alps in July 1870, he learned that war had been declared between Prussia and France.\nAs the Franco-Prussian War commenced, Viollet-le-Duc hurried back to Paris, and offered his services as a military engineer; he was put into service as a colonel of engineers, preparing the defenses of Paris. In September, the Emperor was captured at the Battle of Sedan, a new Republican government took power, and the Empress Eug\u00e9nie fled into exile, as Germans marched as far as Paris and put it under siege. At the same time, on September 23, Viollet-le-Duc's primary patron and supporter, Prosper M\u00e9rim\u00e9e, died peacefully in the south of France. Viollet-le-Duc supervised the construction of new defensive works outside Paris. The war was a disaster as he wrote in his journal on the 14th December 1870 : \"Disorganization is everywhere. The officers have no confidence in the troops, and the troops have no confidence in the officers. Each day, new orders and new projects which contravene those of the day before.\" He fought with the French army against the Germans at Buzenval on 24 January 1871. The battle was lost, and the French capitulated on 28 January. Viollet-le-Duc wrote to his wife on February 28, \"I don't know what will become of me, but I do not want to return any more to administration. I am disgusted by it forever, and want nothing more than to pass the years that remain to me in study and in the most modest possible life.\" Always the scholar, he wrote a detailed study of the effectiveness and deficiencies of the fortifications of Paris during the siege, which was to be used for the 1917 defense of Verdun and the construction of the Maginot line in 1938.\nIn May 1871 he left his home in Paris just before national guardsmen arrived to draft him into the armed force of the Paris Commune who subsequently condemned him to death. He escaped to Pierrefonds, where he had a small apartment before going in exile in Lausanne, where he engage in his passion for mountains, making detailed maps and a series of thirty-two drawings of the alpine scenery. While in Lausanne he was also asked to undertake the restoration of the cathedral.\nHe returned latter to Paris after the Commune had been suppressed and saw the ruins of most of the public buildings of the city, burned by the Commune in its last days. He received his only commission from the new government of the French Third Republic; Jules Simon, the new Minister of Culture and Public Instruction, asked him to design a plaque to be placed before Notre-Dame to honor the hostages killed by the Paris Commune in its final days.\nThe new government of the French Third Republic made little use of his expertise in the restoration of the major government buildings which had been burned by the Paris Commune, including the Tuileries Palace, the Palace of the Legion of Honor, the Palais Royale, the library of the Louvre, the Ministry of Justice and the Ministry of Finance. The only reconstruction on which he was consulted was that of the Hotel de Ville. The writer Edmond de Goncourt called for leaving the ruin of the Hotel de Ville exactly as it was, \"a ruin of a magical palace, A marvel of the picturesque. The country should not condemn it without appeal to restoration by Viollet-le-Duc.\" The government asked Viollet-le-Duc to organize a competition. He presented two options; to either restore the building to its original state, with its historic interior; or to demolish it and build a new city hall. In July 1872 the government decided to preserve the Renaissance facade, but otherwise to completely demolish and rebuild the building.\nAuthor and theorist.\nThroughout his life Viollet le Duc wrote over 100 publications on architecture, decoration, history, archeology etc... some of which would become international best-sellers : \"Dictionary of French Architecture from 11th to 16th Century\" (1854\u20131868), \"Entretiens sur l'architecture\" (1863\u20131872), \"L'histoire d'une Maison\" (1873) and \"Histoire d'un Dessinateur: Comment on Apprend \u00e0 Dessiner\" (1879).\nIn his \"Entretiens sur l'architecture\" he concentrated in particular on the use of iron and other new materials, and the importance of designing buildings whose architecture was adapted to their function, rather than to a particular style. The book was translated into English in 1881 and won a large following in the United States. The Chicago architect Louis Sullivan, one of the inventors of the skyscraper, often invoked the phrase, \"Form follows function.\"\nLausanne Cathedral was his final major restoration project; it was rebuilt following his plans between 1873 and 1876. Work continued after his death. His reconstruction of the bell tower was later criticized; he eliminated the original octagonal base and added a new spire, which rested on the walls, and not on the vaulting, like the original spire. He also added new decoration, crowning the spire at mid-height with gables, another original element, and removing the original tiles. He was also criticized for the materials and ornaments he added to the towers, including gargoyles. His structural design was preserved, but in 1925 his gargoyles and original ornamentation were removed, and the spire was recovered with tiles.\nHis reputation had reached outside of France. The spire and roof of Strasbourg Cathedral had been damaged by German artillery during the Franco-Prussian War, and the city was now part of Germany. The German government invited Viollet-le-Duc to comment on their plans for the restoration, which involved a more grandiose Romanesque tower. Viollet-le-Duc informed the German architect that the planned new tower was completely out of character with the original facade and style of the cathedral. His advice was accepted, and the church was restored to its original form.\nIn 1872 Viollet-le-Duc was engaged in the reconstruction of the Ch\u00e2teau d'Amboise, owned by the descendants of the former King, Louis-Philippe. The chateau had been confiscated by Napoleon\u00a0III in 1848 but was returned to the family in 1872. It was a massive project to turn it into a residence, involving at times three hundred workers. Viollet-le-Duc designed all the work to the finest details, including the floor tiles, the gas lights in the salons, the ovens in the kitchen, and the electric bells for summoning servants.\nIn 1874 Viollet-le-Duc resigned as diocesan architect of Paris and was succeeded by his contemporary, Paul Abadie. In his final years, he continued to supervise the restoration projects that were underway for the Commission of Historical Monuments. He engaged in polemics about architecture in the press, and was elected to the Paris municipal council.\nStatue of Liberty.\nWhile planning the design and construction of the Statue of Liberty (\"Liberty Enlightening the World\") sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi interested Viollet-le-Duc, his friend and mentor, in the project. As chief engineer, Viollet-le-Duc designed a brick pier within the statue, to which the skin would be anchored.\nAfter consultations with the metalwork foundry Gaget, Gauthier &amp; Co., Viollet-le-Duc chose the metal which would be used for the skin, copper sheets, and the method used to shape it, repouss\u00e9, in which the sheets were heated and then struck with wooden hammers. An advantage of this choice was that the entire statue would be light for its volume, as the copper need be only thick.\nNational Museum of French Monuments and final years.\nHe became engaged in the planning and construction of the Paris Universal Exposition of 1878. He proposed to the Minister of Education, Jules Ferry, that the Palais de Trocadero, the main building of the Exposition on the hilltop of Chaillot, be transformed after the Exposition into a museum of French monuments, displaying models of architecture and sculpture from landmarks around France. This idea was accepted. The National Museum of French Monuments opened in 1882, after his death. The Palais was reconstructed into the Palais de Chaillot in 1937, but the Museum of French Monuments was preserved and can be seen there today.\nIn his final years his son Eug\u00e8ne-Louis became the head of the Commission of Historic Monuments. He took on just one new project, the restoration of the cloister of the Augustines at Toulouse. He completed his series of dictionaries of architectural periods, designed for a general audience. He also devoted more time to studying the geography of the Alps around Mont-Blanc. He spent his summers hiking in the mountains and writing articles about his travels. He launched a public campaign for the re-forestation of the Alps, and published a detailed map of the area in 1876. He spent more and more time at \"La Vedette\", the villa he constructed in Lausanne, a house on the model of a Savoyard chalet, but with a minimum of decoration, illustrating his new doctrine of form following function. He made one last visit to inspect Carcassonne, whose work was now under his son's direction. After an exhausting summer of hiking in the Alps in 1879, he became ill and died in Lausanne on 17 September 1879. He was buried in the cemetery of La Sallaz in Lausanne. In 1946 his grave and monument were transferred to the Cemetery of Bois-le-Vaux (Section XVIII) in Lausanne.\nFamily.\nViollet-le-Duc married Elisabeth Tempier in Paris on 3 May 1834. The couple had two children, but separated a few years after marriage, and spent little time together; he was continually on the road. The writer Genevi\u00e8ve Viollet-le-Duc (winner of the prix Broquette-Gonin in 1978) was his great-granddaughter.\nDoctrine.\nViollet-le-Duc famously defined restoration in volume eight of his \"Dictionnaire raisonn\u00e9 de l'architecture fran\u00e7aise du XI au XVI siecle\" of 1858: \"To restore a building is not to maintain it, repair it or remake it: it is to re-establish it in a complete state which may never have existed at any given moment.\" He then explained that it had to meet four conditions: (1) The \"re-establishment\" had to be scientifically documented with plans and photographs and archeological records, which would guarantee exactness. (2) The restoration had to involve not just the appearance of the monument, or the effect that it produced, but also its structure; it had to use the most efficient means to assure the long life of the building, including using more solid materials, used more wisely. (3) the restoration had to exclude any modification contrary to obvious evidence; but the structure could be adapted to conform to more modern or rational uses and practices, which meant alterations to the original plan; and (4) The restoration should preserve older modifications made to the building, with the exception of those which compromised its stability or its conservation, or those which gravely violated the value of its historical presence.\nHe drew conclusions from medieval architecture that he applied to modern architecture. He noted that it was sometimes necessary to employ an iron frame in restoration to avoid the danger of fires, as long as the new structure was not heavier than the original, and kept the original balance of forces found in medieval structures. \"The monuments of the Middle Ages were carefully calculated, and their organism is delicate. There is nothing in excess in their works, nothing useless. If you change one of the conditions of these organisms, you change all the others. Many people consider this a fault; for us, this is a quality which we too often neglect in our modern construction...Why should we build expensive walls two meters thick, if walls fifty centimeters thick [with reinforced supports], offer sufficient stability? In the structure of the Middle Ages, every portion of a work fulfilled a function and possessed an action.\"\nGothic vs. Beaux-Arts.\nDuring the entire career of Viollet-le-Duc, he was engaged in a dispute with the doctrines of the \u00c9cole des Beaux-Arts, the leading architectural school of France, which he refused to attend as a student, and where he taught briefly as a professor, before being pressured to depart. In 1846 he engaged in a fervent exchange in print with Quatrem\u00e8re de Quincy, the Perpetual Secretary of the French Academy, on the question, \"Is it suitable, in the 19th century, to build churches in the gothic style?\" De Quincy and his followers denounced the gothic style as incoherent, disorderly, unintelligent, decadent and without taste. Viollet-le-Duc responded, \"What we want, \"messieurs\", is the return of an art which was born in our country...Leave to Rome what belongs to Rome, and to Athens what belongs to Athens. Rome didn't want our Gothic (and was perhaps the only one in Europe to reject it) and they were right, because when one has the good fortune to possess a national architecture, the best thing is to keep it.\"\n\"If you study for a moment a church of the 13th century\", he wrote, \"you see that all of the construction is carried out according to an invariable system. All the forces and the weights are thrust out to the exterior, a disposition which gives the interior the greatest open space possible. The flying buttresses and contreforts alone support the entire structure, and always have an aspect of resistance, of force and stability which reassures the eye and the spirit; The vaults, built with materials that are easy to mount and to place at a great height, are combined in a easy that places the totality of their weight on the piles; that the most simple means are always employed...and that all the parts of these constructions, independent of each other, even as they rely on each other, present an elasticity and a lightness needed in a building of such great dimensions. We can still see (and this is only found in gothic architecture) that human proportions are the one fixed rule.\"\nControversy.\nViollet-le-Duc was often accused by certain critics, in his own time and later, of pursuing the spirit of the gothic style in some of his restorations instead of strict historical accuracy. Many art historians also consider that the British architectural writer John Ruskin and William Morris were ferocious opponents of Viollet le Duc\u2019s restorations. But Ruskin never criticised of Viollet le Duc\u2019s restoration work in itself, but criticised the principal of restoration itself. Indeed at the beginning of his career Ruskin had a very radical opinion on restoration : \" a building should be looked after and if it not should be left to die \". Viollet le Duc's position on the subject was more nuanced : \" if a building has not been upkept it should be restored \".\nThe existence of an opposition between Ruskin and Viollet le Duc on restoration is today questioned by new research based on Ruskin's own writtings : \" there is no book on architecture which has everything correct apart from Viollet le Duc\u2019s Dictionnary \". And at the end of his life Ruskin expressed the regret that \" no one in England had done the work that Viollet le Duc had done in France \".\nViollet-le-Duc's restorations sometimes involved non-historical additions, either to assure the stability of the building, or sometimes simply to maintain the harmony of the design. The fl\u00e8che or spire of Notre-Dame de Paris, which had been constructed in about 1250, was removed in 1786 after it was damaged by the wind. Viollet-le-Duc designed and constructed a new spire, ornamented with statuary, which was taller than the original and modified to resist the weather, but in harmony with the rest of the design. In the 19th and 20th century, his fl\u00e8che was a target for critics.\nHe was also criticized later for his modifications of the choir of Notre-Dame, which had been rebuilt in the Louis XIV style during the reign of that king. Viollet-le-Duc took out the old choir, including the altar where Napoleon Bonaparte had been crowned Emperor and replaced them with a gothic altar and decoration which he designed. When he modified the choir, he also constructed new bays with small gothic rose windows modelled on those in the church of Chars, in the Oise Valley. Some historians condemned these restorations as non-historical invention. His defenders pointed out that Viollet-le-Duc did not make any decisions on the restoration of Notre-Dame by himself; all of his plans were approved by Prosper M\u00e9rim\u00e9e, the Inspector of Historical Monuments, and by the Commission of historic monuments.\nHe was criticized for the abundance of gothic gargoyles, chimeras, fleurons, and pinnacles which he added to Notre-Dame Cathedral. These decorations had existed in the Middle Ages but had largely been removed during the reign of Louis XIV. The last original gargoyles had been taken down in 1813. He modelled the new gargoyles and monsters on examples from other cathedrals of the period.\nHe was later criticized also for the stained glass windows he designed and had made for the chapels around the ground level of the cathedral, which feature intricate gothic designs in grisaille, which allow more light into the church. The contemporary view of the controversy of his restoration is summarized on a descriptive panel near the altar of the cathedral: \"The great restoration, carried to fruition by Viollet-le-Duc following the death of Lassus, supplied new radiance to the Cathedral \u2013 whatever reservations one might have about the choices that were made. The work of the nineteenth century is now as much a part of the architectural history of Notre-Dame as that undertaken in previous centuries.\"\nThe restoration of ramparts of Carcassonne was also criticized in the 20th century. His critics pointed out that the pointed caps of the towers he constructed were more typical of northern France, not the region where Carcassonne was located, near the Spanish border. Similarly he added roofs of northern slate tiles rather than southern clay tiles, a choice that has been reversed in more recent restorations. His critics also claimed that Viollet-le-Duc sought a \"condition of completeness\" which never actually existed at any given time.\nThe principal counter-argument made by Viollet-le-Duc's defenders was that, without his prompt restorations, many of the buildings that he restored would have been lost, and that he did the best that he could with the knowledge that was then available.\nMortimer Wheeler's entry on English archaeologist Charles R Peers for the Dictionary of National Biography (1971) is worth quoting for its critique of Viollet-le-Duc:\n\u201che [Peers] laid down the principles which have governed architectural conservation in the United Kingdom and have served as a model in other parts of the world. His cardinal principle was to retain but not to restore the surviving remains of an ancient structure; and in this respect he departed emphatically from the tradition of Viollet-le-Duc and his successors in France and Italy, where exuberant restoration frequently obscured the evidence upon which it was based ...\u201d\nPublications.\nThroughout his career Viollet-le-Duc made notes and drawings, not only for the buildings he was working on but also on Romanesque, Gothic and Renaissance buildings that were to be soon demolished. His notes were useful when preparing his published works. His study of medieval and Renaissance periods was not limited to architecture but extended also to such areas as furniture, clothing, musical instruments, armament, and geology.\nHis work was published, first in serial form, and then as full-scale books, as:\nArchitectural theory and new building projects.\nViollet-le-Duc is considered by many to be the first theorist of modern architecture. Sir John Summerson wrote that \"there have been two supremely eminent theorists in the history of European architecture \u2013 Leon Battista Alberti and Eug\u00e8ne Viollet-le-Duc.\"\nHis architectural theory was largely based on finding the ideal forms for specific materials and using these forms to create buildings. His writings centered on the idea that materials should be used \"honestly\". He believed that the outward appearance of a building should reflect the rational construction of the building. In \"Entretiens sur l'architecture\", Viollet-le-Duc praised the Greek temple for its rational representation of its construction. For him, \"Greek architecture served as a model for the correspondence of structure and appearance.\"\nAnother component in Viollet-le-Duc's theory was how the design of a building should start from its program and the plan, and end with its decorations. If this resulted in an asymmetrical exterior, so be it. He dismissed the symmetry of classicist buildings as vain, caring too much about appearances at the expense of practicality and convenience for the inhabitants of the house.\nIn several unbuilt projects for new buildings, Viollet-le-Duc applied the lessons he had derived from Gothic architecture, applying its rational structural systems to modern building materials such as cast iron. For inspiration, he also examined organic structures, such as leaves and animal skeletons. He was especially interested in the wings of bats, an influence represented by his Assembly Hall project.\nViollet-le-Duc's drawings of iron trusswork were innovative for the time. Many of his designs emphasizing iron would later influence the Art Nouveau movement, most noticeably in the work of Hector Guimard, Victor Horta, Antoni Gaud\u00ed and Hendrik Petrus Berlage. His writings inspired several American architects, including Frank Furness, John Wellborn Root, Louis Sullivan, and Frank Lloyd Wright.\nMilitary career and influence.\nViollet-le-Duc had a second career in the military, primarily in the defense of Paris during the Franco-Prussian War (1870\u201371). He was so influenced by the conflict that during his later years he described the idealized defense of France by the analogy of the military history of Le Roche-Pont, an imaginary castle, in his work \"Histoire d'une Forteresse\" (\"Annals of a Fortress\", twice translated into English). Accessible and well researched, it is partly fictional.\n\"Annals of a Fortress\" strongly influenced French military defensive thinking. Viollet-le-Duc's critique of the effect of artillery (applying his practical knowledge from the 1870\u20131871 war) is so complete that it accurately describes the principles applied to the defense of France until World War\u00a0II. The physical results of his theories are present in the fortification of Verdun prior to World War\u00a0I and the Maginot Line prior to World War\u00a0II. His theories are also represented by the French military theory of \"Deliberate Advance\", which stresses that artillery and a strong system of fortresses in the rear of an army are essential.\nLegacy.\nThe English architect Benjamin Bucknall (1833\u20131895) was a devotee of Viollet-le-Duc and during 1874 to 1881 translated several of his publications into English to popularise his principles in Great Britain. The later works of the English designer and architect William Burges were greatly influenced by Viollet-le-Duc, most strongly in Burges's designs for his own home, The Tower House in London's Holland Park district, and Burges's designs for Castell Coch near Cardiff, Wales.\nAn exhibition, \"Eug\u00e8ne Viollet-le-Duc 1814\u20131879\" was presented in Paris in 1965, and there was a larger, centennial exhibition in 1980.\nViollet-le-Duc was the subject of a Google Doodle on January 27, 2014.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9659", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=9659", "title": "Endocarditis", "text": "Medical condition\nEndocarditis is an inflammation of the inner layer of the heart, the endocardium. It usually involves the heart valves. Other structures that may be involved include the interventricular septum, the chordae tendineae, the mural endocardium, or the surfaces of intracardiac devices. Endocarditis is characterized by lesions, known as \"vegetations\", which is a mass of platelets, fibrin, microcolonies of microorganisms, and scant inflammatory cells. In the subacute form of infective endocarditis, the vegetation may also include a center of granulomatous tissue, which may fibrose or calcify.\nThere are several ways to classify endocarditis. The simplest classification is based on cause: either \"infective\" or \"non-infective\", depending on whether a microorganism is the source of the inflammation or not. Regardless, the diagnosis of endocarditis is based on clinical features, investigations such as an echocardiogram, and blood cultures demonstrating the presence of endocarditis-causing microorganisms.\nSigns and symptoms include fever, chills, sweating, malaise, weakness, anorexia, weight loss, splenomegaly, flu-like feeling, cardiac murmur, heart failure, petechia (red spots on the skin), Osler's nodes (subcutaneous nodules found on hands and feet), Janeway lesions (nodular lesions on palms and soles), and Roth's spots (retinal hemorrhages).\nInfective endocarditis.\nInfective endocarditis is an infection of the inner surface of the heart, usually the valves. Symptoms may include fever, small areas of bleeding into the skin, heart murmur, feeling tired, and low red blood cells. Complications may include valvular insufficiency, heart failure, stroke, and kidney failure.\nThe cause is typically a bacterial infection and less commonly a fungal infection. Risk factors include valvular heart disease including rheumatic disease, congenital heart disease, artificial valves, hemodialysis, intravenous drug use, and electronic pacemakers. The bacterial most commonly involved are streptococci or staphylococci.\nThe diagnosis of infective endocarditis relies on the Duke criteria, which were originally described in 1994 and modified in 2000. Clinical features and microbiological examinations are the first steps to diagnose an infective endocarditis. The imaging is also crucial. Echocardiography is the cornerstone of imaging modality in the diagnosis of infective endocarditis. Alternative imaging modalities as computer tomography, magnetic resonance imaging, and positron emission tomography/computer tomography (PET/CT) with 2-[18F]fluorodeoxyglucose (FDG) are playing an increasing role in the diagnosis and management of infective endocarditis.\nThe usefulness of antibiotics following dental procedures for prevention is unclear. Some recommend them in those at high risk. Treatment is generally with intravenous antibiotics. The choice of antibiotics is based on the blood cultures. Occasionally heart surgery is required.\nThe number of people affected is about 5 per 100,000 per year. Rates, however, vary between regions of the world. Males are affected more often than females. The risk of death among those infected is about 25%. Without treatment it is almost universally fatal.\nNon-infective endocarditis.\nNonbacterial thrombotic endocarditis (NBTE) is most commonly found on previously undamaged valves. As opposed to infective endocarditis, the vegetations in NBTE are small, sterile, and tend to aggregate along the edges of the valve or the cusps. Also unlike infective endocarditis, NBTE does not cause an inflammation response from the body. NBTE usually occurs during a hypercoagulable state such as system-wide bacterial infection, or pregnancy, though it is also sometimes seen in patients with venous catheters. NBTE may also occur in patients with cancers, particularly mucinous adenocarcinoma where Trousseau syndrome can be encountered. Typically NBTE does not cause many problems on its own, but parts of the vegetations may break off and embolize to the heart or brain, or they may serve as a focus where bacteria can lodge, thus causing infective endocarditis.\nAnother form of sterile endocarditis is termed Libman\u2013Sacks endocarditis; this form occurs more often in patients with lupus erythematosus and is thought to be due to the deposition of immune complexes. Like NBTE, Libman-Sacks endocarditis involves small vegetations, while infective endocarditis is composed of large vegetations. These immune complexes precipitate an inflammation reaction, which helps to differentiate it from NBTE. Also unlike NBTE, Libman-Sacks endocarditis does not seem to have a preferred location of deposition and may form on the undersurfaces of the valves or even on the endocardium.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9660", "revid": "41129657", "url": "https://en.wikipedia.org/wiki?curid=9660", "title": "Euler's sum of powers conjecture", "text": "Disproved conjecture in number theory \nEuler's conjecture is a disproved conjecture in mathematics related to Fermat's Last Theorem. It was proposed by Leonhard Euler in 1769. It states that for all integers \"n\" and \"k\" greater than 1, if the sum of \"n\" many \"k\"th powers of positive integers is itself a \"k\"th power, then \"n\" is greater than or equal to \"k\":\n \"bk\" \u21d2 \"n\" \u2265 \"k\"\nThe conjecture represents an attempt to generalize Fermat's Last Theorem, which is the special case \"n\" \n 2: if + \n \"bk\", then 2 \u2265 \"k\".\nAlthough the conjecture holds for the case \"k\" \n 3 (which follows from Fermat's Last Theorem for the third powers), it was disproved for \"k\" \n 4 and \"k\" \n 5. It is unknown whether the conjecture fails or holds for any value \"k\" \u2265 6.\nBackground.\nEuler was aware of the equality 594 + 1584 \n 1334 + 1344 involving sums of four fourth powers; this, however, is not a counterexample because no term is isolated on one side of the equation. He also provided a complete solution to the four cubes problem as in Plato's number 33 + 43 + 53 \n 63 or the taxicab number 1729. The general solution of the equation\nformula_1\nis\nformula_2\nformula_3\nwhere a and b are any integers.\nCounterexamples.\nEuler's conjecture was disproven by L. J. Lander and T. R. Parkin in 1966 when, through a direct computer search on a CDC 6600, they found a counterexample for \"k\" \n 5. This was published in a paper comprising just two sentences. A total of three primitive (that is, in which the summands do not all have a common factor) counterexamples are known:\n275 + 845 + 1105 + 1335 \n 1445 (Lander &amp; Parkin, 1966),\n(\u2212220)5 + 50275 + 62375 + 5 \n 5 (Scher &amp; Seidl, 1996), and\n555 + 31835 + 5 + 5 \n 5 (Frye, 2004).\nIn 1988, Noam Elkies published a method to construct an infinite sequence of counterexamples for the \"k\" \n 4 case. His smallest counterexample was\n4 + 4 + 4 \n 4.\nA particular case of Elkies' solutions can be reduced to the identity\n(85\"v\"2 + 484\"v\" \u2212 313)4 + (68\"v\"2 \u2212 586\"v\" + 10)4 + (2\"u\")4 \n (357\"v\"2 \u2212 204\"v\" + 363)4\nwhere\n\"u\"2 \n + \"v\" \u2212 \"v\"2 + \"v\"3 \u2212 \"v\"4.\nThis is an elliptic curve with a rational point at \"v\"1 \n \u2212. From this initial rational point, one can compute an infinite collection of others. Substituting \"v\"1 into the identity and removing common factors gives the numerical example cited above.\nIn 1988, Roger Frye found the smallest possible counterexample \n4 + 4 + 4 \n 4\nfor \"k\" \n 4 by a direct computer search using techniques suggested by Elkies. This solution is the only one with values of the variables below 1,000,000.\nGeneralizations.\nIn 1967, L. J. Lander, T. R. Parkin, and John Selfridge conjectured that if \nformula_4,\nwhere \"ai\" \u2260 \"bj\" are positive integers for all 1 \u2264 \"i\" \u2264 \"n\" and 1 \u2264 \"j\" \u2264 \"m\", then \"m\" + \"n\" \u2265 \"k\". In the special case \"m\" \n 1, the conjecture states that if\nformula_5\n(under the conditions given above) then \"n\" \u2265 \"k\" \u2212 1.\nThe special case may be described as the problem of giving a partition of a perfect power into few like powers. For \"k\" \n 4, 5, 7, 8 and \"n\" \n \"k\" or \"k\" \u2212 1, there are many known solutions. Some of these are listed below. \nSee OEIS:\u00a0 for more data.\n===\"k\" \n 3===\n33 + 43 + 53 \n 63 (Plato's number 216)\nThis is the case \"a\" = 1, \"b\" = 0 of Srinivasa Ramanujan's formula \nformula_6 \nA cube as the sum of three cubes can also be parameterized as\nformula_7\nor as\nformula_8\nThe number 2 100 0003 can be expressed as the sum of three cubes in nine different ways.\n===\"k\" \n 4===\n4 + 4 + 4 \n 4 (R. Frye, 1988)\n304 + 1204 + 2724 + 3154 \n 3534 (R. Norrie, 1911)\nThis is the smallest solution to the problem by R. Norrie.\n===\"k\" \n 5===\n275 + 845 + 1105 + 1335 \n 1445 (Lander &amp; Parkin, 1966)\n195 + 435 + 465 + 475 + 675 \n 725 (Lander, Parkin, Selfridge, smallest, 1967)\n215 + 235 + 375 + 795 + 845 \n 945 (Lander, Parkin, Selfridge, second smallest, 1967)\n75 + 435 + 575 + 805 + 1005 \n 1075 (Sastry, 1934, third smallest)\n===\"k\" \n 6===\nAs of 2002, there are no solutions for formula_9 whose final term is \u2264 730000. \n===\"k\" \n 7===\n1277 + 2587 + 2667 + 4137 + 4307 + 4397 + 5257 \n 5687 (M. Dodrill, 1999)\n===\"k\" \n 8===\n908 + 2238 + 4788 + 5248 + 7488 + 10888 + 11908 + 13248 \n 14098 (S. Chase, 2000)\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9662", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=9662", "title": "Book of Exodus", "text": "Second book of the Bible\nThe Book of Exodus (from ; \"\u0160\u0259m\u014d\u1e6f\", 'Names') is the second book of the Bible. It narrates the story of the Exodus, in which the Israelites leave slavery in Biblical Egypt through the strength of Yahweh, who has chosen them as his people. The Israelites then journey with the prophet Moses to Mount Sinai, where Yahweh gives the 10 commandments and they enter into a covenant with Yahweh, who promises to make them a \"holy nation, and a kingdom of priests\" on condition of their faithfulness. He gives them their laws and instructions to build the Tabernacle, the means by which he will come from heaven and dwell with them and lead them in a holy war to possess the land of Canaan (the \"Promised Land\"), which had earlier, according to the story of Genesis, been promised to the seed of Abraham.\nTraditionally ascribed to Moses himself, modern scholars see its initial composition as a product of the Babylonian exile (6th century BCE), based on earlier written sources and oral traditions, with final revisions in the Persian post-exilic period (5th century BCE). American biblical scholar Carol Meyers, in her commentary on Exodus, suggests that it is arguably the most important book in the Bible, as it presents the defining features of Israel's identity\u2014memories of a past marked by hardship and escape, a binding covenant with God, who chooses Israel, and the establishment of the life of the community and the guidelines for sustaining it. The consensus among modern scholars is that the story in the Book of Exodus is best understood as a myth.\nTitle.\nThe English name \"Exodus\" comes from the , from and . In Hebrew the book's title is \u05e9\u05b0\u05c1\u05de\u05d5\u05b9\u05ea, \"shem\u014dt\", \"Names\", from the beginning words of the text: \"These are the names of the sons of Israel\" ().\nHistoricity.\nMost mainstream scholars do not accept the biblical Exodus account as historical for a number of reasons. It is generally agreed that the Exodus stories were written centuries after the apparent setting of the stories. Archaeologists Israel Finkelstein and Neil Asher Silberman argue that archaeology has not found evidence for even a small band of wandering Israelites living in the Sinai: \"The conclusion \u2013 that Exodus did not happen at the time and in the manner described in the Bible \u2013 seems irrefutable [...] repeated excavations and surveys throughout the entire area have not provided even the slightest evidence\". Instead, they argue how modern archaeology suggests continuity between Canaanite and Israelite settlements, indicating a heavily Canaanite origin for Israel, with little suggestion that a group of foreigners from Egypt comprised early Israel.\nHowever, a majority of scholars believe that the story has some historical basis, though disagreeing widely about what that historical kernel might have been. Kenton Sparks refers to it as \"mythologized history\". Some scholars such as Benjamin J. Noonan have pointed out that the presence of Egyptian cognates in the Exodus and wilderness traditions \u201centered Hebrew during the Late Bronze Age, precisely when we would expect them to have been borrowed if the events of these narratives really occurred,\u201d challenging the assumption of a post-exilic tradition. Furthermore, in direct response to popular claims that the Exodus \u201cwandering period\u201d lacks evidence in the Sinai region, various anthropologists of Near Eastern history have noted that a lack of material culture from the Israelites in the Book of Exodus is actually expected given what is known about historical and present semi-nomadic peoples.\nStructure.\nThere is no unanimous agreement among scholars on the structure of Exodus. One strong possibility is that it is a diptych (i.e., divided into two parts), with the division between parts 1 and 2 at the crossing of the Red Sea or at the beginning of the theophany (appearance of God) in chapter 19. On this plan, the first part tells of God's rescue of his people from Egypt and their journey under his care to Sinai (chapters 1\u201319) and the second tells of the covenant between them (chapters 20\u201340).\nSummary.\nThe text of the Book of Exodus begins after the events at the end of the Book of Genesis where Jacob's sons and their families joined their brother Joseph in Egypt, which Joseph had saved from famine. It is four hundred years later and Egypt's new Pharaoh, who does not remember Joseph, is fearful that the enslaved and now numerous Israelites could become a fifth column. He hardens their labor and orders the killing of all newborn boys. A Levite woman named Jochebed saves her baby by setting him adrift on the Nile in an ark of bulrushes. Pharaoh's daughter finds the child, names him Moses, and brings him up as her own.\nLater, a grown Moses goes out to see his kinsmen and witnesses the abuse of a Hebrew slave by an Egyptian overseer. Angered, Moses kills him and flees into Midian to escape punishment. There, he marries Zipporah, daughter of Jethro, a Midianite priest. While tending Jethro's flock, Moses encounters God in a burning bush. Moses asks God for his name, to which God replies with three words, often translated as \"I Am that I Am.\" This is the book's explanation for the origin of the name Yahweh, as God is thereafter known. God tells Moses to return to Egypt, free the Hebrews from slavery and lead them into Canaan, the land promised to the seed of Abraham in Genesis. On the journey back to Egypt, God seeks to kill Moses. Zipporah circumcises their son and the attack stops. \"(See Zipporah at the inn.)\"\nMoses reunites with his brother Aaron and, returning to Egypt, convenes the Israelite elders, preparing them to go into the wilderness to worship God. Pharaoh refuses to release the Israelites from their work for the festival, and so God curses the Egyptians with ten terrible plagues, such as a , an outbreak of frogs, and the . Moses is commanded by God to fix the spring month of Aviv at the head of the Hebrew calendar. The Israelites are to take a lamb on the 10th day of the month, sacrifice the lamb on the 14th day, daub its blood on their mezuzot\u2014doorposts and lintels, and to observe the Passover meal that night, during the full moon. The 10th plague comes that night, causing the death of all Egyptian firstborn sons, prompting Pharaoh to expel the Israelites. Regretting his decision, Pharaoh commands his chariot army after the Israelites, who appear trapped at the Red Sea. God parts the sea, allowing the Israelites to pass through, before drowning Pharaoh's pursuing forces.\nAs desert life proves arduous, the Israelites complain and long for Egypt, but God miraculously provides manna for them to eat and water to drink. The Israelites arrive at the mountain of God, where Moses's father-in-law Jethro visits Moses; at his suggestion, Moses appoints judges over Israel. God asks whether they will agree to be his people \u2013 They accept. The people gather at the foot of the mountain, and with thunder and lightning, fire and clouds of smoke, the sound of trumpets, and the trembling of the mountain, God appears on the peak, and the people see the cloud and hear the voice (or possibly sound) of God. God tells Moses to ascend the mountain. God pronounces the Ten Commandments (the Ethical Decalogue) in the hearing of all Israel. Moses goes up the mountain into the presence of God, who pronounces the Covenant Code of ritual and civil law and promises Canaan to them if they obey. Moses comes down from the mountain and writes down God's words, and the people agree to keep them. God calls Moses up the mountain again, where he remains for forty days and forty nights, after which he returns, bearing the set of stone tablets.\nGod gives Moses instructions for the construction of the tabernacle so that God may dwell permanently among his chosen people, along with instructions for the priestly vestments, the altar and its appurtenances, procedures for the ordination of priests, and the daily sacrifice offerings. Aaron becomes the first hereditary high priest. God gives Moses the two tablets of stone containing the words of the ten commandments, written with the \"finger of God\".\nWhile Moses is with God, Aaron casts a golden calf, which the people worship. God informs Moses of their apostasy and threatens to kill them all, but relents when Moses pleads for them. Moses comes down from the mountain, smashes the stone tablets in anger, and commands the Levites to massacre the unfaithful Israelites. God commands Moses to construct two new tablets. Moses ascends the mountain again, where God dictates the Ten Commandments for Moses to write on the tablets.\nMoses descends from the mountain with a transformed face; from that time onwards he must hide his face with a veil. Moses assembles the Hebrews and repeats to them the commandments he has received from God, which are to keep the Sabbath and to construct the Tabernacle. The Israelites do as they are commanded. From that time God dwells in the Tabernacle and orders the travels of the Hebrews.\nComposition.\nAuthorship.\nJewish and Christian tradition viewed Moses as the author of Exodus and the entire Torah, but by the end of the 19th century the increasing awareness of discrepancies, inconsistencies, repetitions and other features of the Pentateuch had led scholars to abandon this idea. In approximate round dates, the process which produced Exodus and the Pentateuch probably began around 600 BCE when existing oral and written traditions were brought together to form books recognizable as those we know, reaching their final form as unchangeable sacred texts around 400 BCE.\nSources.\nAlthough patent mythical elements are not so prominent in Exodus as in Genesis, ancient legends may have an influence on the book's form or content: for example, the story of the infant Moses's salvation from the Nile is argued to be based on an earlier legend of king Sargon of Akkad, while the story of the parting of the Red Sea may trade on Mesopotamian creation mythology. Similarly, the Covenant Code (the law code in Exodus 20:22\u201323:33) has some similarities in both content and structure with the Laws of Hammurabi. These potential influences serve to reinforce the conclusion that the Book of Exodus originated in the exiled Jewish community of 6th-century BCE Babylon, but not all the potential sources are Mesopotamian: the story of Moses's flight to Midian following the murder of the Egyptian overseer may draw on the Egyptian \"Story of Sinuhe\".\nThemes.\nSalvation.\nBiblical scholars describe the Bible's theologically-motivated history writing as \"salvation history\", meaning a history of God's saving actions that give identity to Israel \u2013 the promise of offspring and land to the ancestors, the Exodus from Egypt (in which God saves Israel from slavery), the wilderness wandering, the revelation at Sinai, and the hope for the future life in the promised land.\nTheophany.\nA theophany is a manifestation (appearance) of a god \u2013 in the Bible, an appearance of the God of Israel, accompanied by storms \u2013 the earth trembles, the mountains quake, the heavens pour rain, thunder peals and lightning flashes. The theophany in Exodus begins \"the third day\" from their arrival at Sinai in chapter 19: Yahweh and the people meet at the mountain, God appears in the storm and converses with Moses, giving him the Ten Commandments while the people listen. The theophany is therefore a public experience of divine law.\nThe second half of Exodus marks the point at which, and describes the process through which, God's theophany becomes a permanent presence for Israel via the Tabernacle. That so much of the book (chapters 25\u201331, 35\u201340) describes the plans of the Tabernacle demonstrates the importance it played in the perception of Second Temple Judaism at the time of the text's redaction by the Priestly writers: the Tabernacle is the place where God is physically present, where, through the priesthood, Israel could be in direct, literal communion with him.\nCovenant.\nThe heart of Exodus is the Sinaitic covenant. A covenant is a legal document binding two parties to take on certain obligations towards each other. There are several covenants in the Bible, and in each case they exhibit at least some of the elements in real-life treaties of the ancient Middle East: a preamble, historical prologue, stipulations, deposition and reading, list of witnesses, blessings and curses, and ratification by animal sacrifice. Biblical covenants, in contrast to Eastern covenants in general, are between a god, Yahweh, and a people, Israel, instead of between a strong ruler and a weaker vassal.\nElection of Israel.\nGod elects Israel for salvation because the \"sons of Israel\" are \"the firstborn son\" of the God of Israel, descended through Shem and Abraham to the chosen line of Jacob whose name is changed to Israel. The goal of the divine plan in Exodus is a return to humanity's state in Eden, so that God can dwell with the Israelites as he had with Adam and Eve through the Ark and Tabernacle, which together form a model of the universe; in later Abrahamic religions Israel becomes the guardian of God's plan for humanity, to bring \"God's creation blessing to mankind\" begun in Adam.\nJudaism's weekly Torah portions in the Book of Exodus.\nList of Torah portions in the Book of Exodus:\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral bibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9663", "revid": "36794330", "url": "https://en.wikipedia.org/wiki?curid=9663", "title": "Electronics", "text": "Branch of physics and electrical engineering\nElectronics is a scientific and engineering discipline that studies and applies the principles of physics and mathematical concepts to design, create, and operate devices that manipulate electrons and other charged particles. Electronics is a subfield of electrical engineering, but it differs from it in that it focuses on using active devices such as transistors, diodes, and integrated circuits to control and amplify the flow of electric current and to convert it from one form to another, such as from alternating current (AC) to direct current (DC) or from analog to digital. Electronics also encompasses the fields of microelectronics, nanoelectronics, optoelectronics, and quantum electronics, which deal with the fabrication and application of electronic devices at microscopic, nanoscopic, optical, and quantum scales.\nElectronics has a profound impact on various aspects of modern society and culture, such as communication, entertainment, education, health care, industry, and security. The main driving force behind the advancement of electronics is the semiconductor industry, which produces the basic materials and components for electronic devices and circuits. The semiconductor industry is one of the largest and most profitable sectors in the global economy, with annual revenues exceeding $481 billion in 2018. The electronics industry also encompasses other sectors that rely on electronic devices and systems, such as e-commerce, which generated over $29 trillion in online sales in 2017.\nHistory and development.\nElectronics has hugely influenced the development of modern society. The identification of the electron in 1897, along with the subsequent invention of the vacuum tube which could amplify and rectify small electrical signals, inaugurated the field of electronics and the electron age. Practical applications started with the invention of the diode by Ambrose Fleming and the triode by Lee De Forest in the early 1900s, which made the detection of small electrical voltages such as radio signals from a radio antenna possible with a non-mechanical device.\nVacuum tubes (thermionic valves) were the first active electronic components which controlled current flow by influencing the flow of individual electrons, They were responsible for the electronics revolution of the first half of the twentieth century, They enabled the construction of equipment that used current amplification and rectification to give us radio, television, radar, long-distance telephony and much more. The early growth of electronics was rapid, and by the 1920s, commercial radio broadcasting and communications were becoming widespread and electronic amplifiers were being used in such diverse applications as long-distance telephony and the music recording industry.\nThe next big technological step took several decades to appear, when the first working point-contact transistor was invented by John Bardeen and Walter Houser Brattain at Bell Labs in 1947.\nHowever, vacuum tubes played a leading role in the field of microwave and high power transmission as well as television receivers until the middle of the 1980s.\nSince then, solid-state devices have all but completely taken over. Vacuum tubes are still used in some specialist applications such as high power RF amplifiers, cathode ray tubes, specialist audio equipment, guitar amplifiers and some microwave devices.\nIn April 1955, the IBM 608 was the first IBM product to use transistor circuits without any vacuum tubes and is believed to be the first all-transistorized calculator to be manufactured for the commercial market. The 608 contained more than 3,000 germanium transistors. Thomas J. Watson Jr. ordered all future IBM products to use transistors in their design. From that time on transistors were almost exclusively used for computer logic and peripherals. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.\nThe MOSFET (MOS transistor) was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959. The MOSFET was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. Its advantages include high scalability, affordability, low power consumption, and high density. It revolutionized the electronics industry, becoming the most widely used electronic device in the world. The MOSFET is the basic element in most modern electronic equipment.\nAs the complexity of circuits grew, problems arose. One problem was the size of the circuit. A complex circuit like a computer was dependent on speed. If the components were large, the wires interconnecting them must be long. The electric signals took time to go through the circuit, thus slowing the computer. The invention of the integrated circuit by Jack Kilby and Robert Noyce solved this problem by making all the components and the chip out of the same block (monolith) of semiconductor material. The circuits could be made smaller, and the manufacturing process could be automated. This led to the idea of integrating all components on a single-crystal silicon wafer, which led to small-scale integration (SSI) in the early 1960s, and then medium-scale integration (MSI) in the late 1960s, followed by VLSI. In 2008, billion-transistor processors became commercially available.\nSubfields.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDevices and components.\nAn electronic component is any component in an electronic system either active or passive. Components are connected together, usually by being soldered to a printed circuit board (PCB), to create an electronic circuit with a particular function. Components may be packaged singly, or in more complex groups as integrated circuits. Passive electronic components are capacitors, inductors, resistors, whilst active components are such as semiconductor devices; transistors and thyristors, which control current flow at electron level.\nTypes of circuits.\nElectronic circuit functions can be divided into two function groups: analog and digital. A particular device may consist of circuitry that has either or a mix of the two types. Analog circuits are becoming less common, as many of their functions are being digitized.\nAnalog circuits.\nMost analog electronic appliances, such as radio receivers, are constructed from combinations of a few types of basic circuits. Analog circuits use a continuous range of voltage or current as opposed to discrete levels as in digital circuits.\nThe number of different analog circuits so far devised is huge, especially because a 'circuit' can be defined as anything from a single component, to systems containing thousands of components.\nAnalog circuits are sometimes called linear circuits although many non-linear effects are used in analog circuits such as mixers, modulators, etc. Good examples of analog circuits include vacuum tube and transistor amplifiers, operational amplifiers and oscillators.\nOne rarely finds modern circuits that are entirely analog \u2013 these days analog circuitry may use digital or even microprocessor techniques to improve performance. This type of circuit is usually called \"mixed signal\" rather than analog or digital.\nSometimes it may be difficult to differentiate between analog and digital circuits as they have elements of both linear and non-linear operation. An example is the comparator which takes in a continuous range of voltage but only outputs one of two levels as in a digital circuit. Similarly, an overdriven transistor amplifier can take on the characteristics of a controlled switch having essentially two levels of output. In fact, many digital circuits are actually implemented as variations of analog circuits similar to this example\u00a0\u2013 after all, all aspects of the real physical world are essentially analog, so digital effects are only realized by constraining analog behaviour.\nDigital circuits.\nDigital circuits are electric circuits based on a number of discrete voltage levels. Digital circuits are the most common physical representation of Boolean algebra and are the basis of all digital computers. To most engineers, the terms \"digital circuit\", \"digital system\" and \"logic\" are interchangeable in the context of digital circuits.\nMost digital circuits use a binary system with two voltage levels labelled \"0\" and \"1\". Often logic \"0\" will be a lower voltage and referred to as \"Low\" while logic \"1\" is referred to as \"High\". However, some systems use the reverse definition (\"0\" is \"High\") or are current based. Quite often the logic designer may reverse these definitions from one circuit to the next as they see fit to facilitate their design. The definition of the levels as \"0\" or \"1\" is arbitrary.\nTernary (with three states) logic has been studied, and some prototype computers made. Mass-produced binary systems have caused lower significance for using ternary logic. Computers, electronic clocks, and programmable logic controllers (used to control industrial processes) are constructed of digital circuits. Digital signal processors, which measure, filter or compress continuous real-world analog signals, are another example. Transistors such as MOSFET are used to control binary states.\nHighly integrated devices:\nDesign.\nElectronic systems design deals with the multi-disciplinary design issues of complex electronic devices and systems, such as mobile phones and computers. The subject covers a broad spectrum, from the design and development of an electronic system (new product development) to assuring its proper function, service life and disposal. Electronic systems design is therefore the process of defining and developing complex electronic devices to satisfy specified requirements of the user.\nDue to the complex nature of electronics theory, laboratory experimentation is an important part of the development of electronic devices. These experiments are used to test or verify the engineer's design and detect errors. Historically, electronics labs have consisted of electronics devices and equipment located in a physical space, although in more recent years the trend has been towards electronics lab simulation software, such as CircuitLogix, Multisim, and PSpice.\nComputer-aided design.\nToday's electronics engineers have the ability to design circuits using premanufactured building blocks such as power supplies, semiconductors (i.e. semiconductor devices, such as transistors), and integrated circuits. Electronic design automation software programs include schematic capture programs and printed circuit board design programs. Popular names in the EDA software world are NI Multisim, Cadence (ORCAD), EAGLE PCB and Schematic, Mentor (PADS PCB and LOGIC Schematic), Altium (Protel), LabCentre Electronics (Proteus), gEDA, KiCad and many others.\nNegative qualities.\nThermal management.\nHeat generated by electronic circuitry must be dissipated to prevent immediate failure and improve long term reliability. Heat dissipation is mostly achieved by passive conduction/convection. Means to achieve greater dissipation include heat sinks and fans for air cooling, and other forms of computer cooling such as water cooling. These techniques use convection, conduction, and radiation of heat energy.\nNoise.\nElectronic noise is defined as unwanted disturbances superposed on a useful signal that tend to obscure its information content. Noise is not the same as signal distortion caused by a circuit. Noise is associated with all electronic circuits. Noise may be electromagnetically or thermally generated, which can be decreased by lowering the operating temperature of the circuit. Other types of noise, such as shot noise cannot be removed as they are due to limitations in physical properties.\nPackaging methods.\nMany different methods of connecting components have been used over the years. For instance, early electronics often used point to point wiring with components attached to wooden breadboards to construct circuits. Cordwood construction and wire wrap were other methods used. Most modern day electronics now use printed circuit boards made of materials such as FR4, or the cheaper (and less hard-wearing) Synthetic Resin Bonded Paper (SRBP, also known as Paxoline/Paxolin (trade marks) and FR2) \u2013 characterised by its brown colour. Health and environmental concerns associated with electronics assembly have gained increased attention in recent years, especially for products destined to go to European markets.\nElectrical components are generally mounted in the following ways:\nIndustry.\nThe electronics industry consists of various sectors. The central driving force behind the entire electronics industry is the semiconductor industry sector, which has annual sales of over $ as of 2018. The largest industry sector is e-commerce, which generated over $ in 2017. The most widely manufactured electronic device is the metal-oxide-semiconductor field-effect transistor (MOSFET), with an estimated 13sextillion MOSFETs having been manufactured between 1960 and 2018. In the 1960s, U.S. manufacturers were unable to compete with Japanese companies such as Sony and Hitachi who could produce high-quality goods at lower prices. By the 1980s, however, U.S. manufacturers became the world leaders in semiconductor development and assembly.\nHowever, during the 1990s and subsequently, the industry shifted overwhelmingly to East Asia (a process begun with the initial movement of microchip mass-production there in the 1970s), as plentiful, cheap labor, and increasing technological sophistication, became widely available there.\nOver three decades, the United States' global share of semiconductor manufacturing capacity fell, from 37% in 1990, to 12% in 2022. America's pre-eminent semiconductor manufacturer, Intel Corporation, fell far behind its subcontractor Taiwan Semiconductor Manufacturing Company (TSMC) in manufacturing technology.\nBy that time, Taiwan had become the world's leading source of advanced semiconductors\u2014followed by South Korea, the United States, Japan, Singapore, and China.\nImportant semiconductor industry facilities (which often are subsidiaries of a leading producer based elsewhere) also exist in Europe (notably the Netherlands), Southeast Asia, South America, and Israel.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9664", "revid": "1159835035", "url": "https://en.wikipedia.org/wiki?curid=9664", "title": "Erewhon", "text": "1872 novel by Samuel Butler\nErewhon: or, Over the Range () is a novel by English writer Samuel Butler, first published anonymously in 1872, set in a fictional country discovered and explored by the protagonist. The book is a satire on Victorian society.\nThe first few chapters of the novel dealing with the discovery of Erewhon are in fact based on Butler's own experiences in New Zealand, where, as a young man, he worked as a sheep farmer on Mesopotamia Station for about four years (1860\u201364), and explored parts of the interior of the South Island and wrote about in his \"A First Year in Canterbury Settlement\" (1863).\nThe novel is one of the first to explore ideas of artificial intelligence, as influenced by Darwin's recently published \"On the Origin of Species\" (1859) and the machines developed out of the Industrial Revolution (late 18th to early 19th centuries). Specifically, it concerns itself, in the three-chapter \"Book of the Machines\", with the potentially dangerous ideas of machine consciousness and self-replicating machines.\nContent.\nThe greater part of the book consists of a description of Erewhon. The nature of this nation is intended to be ambiguous. At first glance, Erewhon appears to be a Utopia, yet it soon becomes clear that this is far from the case. Yet for all the failings of Erewhon, it is also clearly not a dystopia, such as that depicted in 1949 in George Orwell's \"Nineteen Eighty-Four\".\nAs a satirical utopia, \"Erewhon\" has sometimes been compared to \"Gulliver's Travels\" (1726), a classic novel by Jonathan Swift; the image of Utopia in this latter case also bears strong parallels with the self-view of the British Empire at the time. It can also be compared to the William Morris novel, \"News from Nowhere\" (1890).\n\"Erewhon\" satirises various aspects of Victorian society, including criminal punishment, religion, and anthropocentrism. For example, according to Erewhonian law, offenders are treated as if they were ill, whereas ill people are looked upon as criminals. Another feature of Erewhon is the absence of machines; this is due to the widely shared perception by the Erewhonians that machines are potentially dangerous.\nThe Book of the Machines.\nButler developed the three chapters of \"Erewhon\" that make up \"The Book of the Machines\" from a number of articles he had contributed to \"The Press\", which had just begun publication in Christchurch, New Zealand, beginning with \"Darwin among the Machines\" (1863). Butler was the first to write about the possibility that machines might develop consciousness by natural selection.\nMany dismissed this as a joke, but, in his preface to the second edition, Butler wrote, \"I regret that reviewers have in some cases been inclined to treat the chapters on Machines as an attempt to reduce Mr Darwin's theory to an absurdity. Nothing could be further from my intention, and few things would be more distasteful to me than any attempt to laugh at Mr Darwin.\"\nReception.\nIn a 1945 broadcast, George Orwell praised the book and said that when Butler wrote \"Erewhon\" it needed \"imagination of a very high order to see that machinery could be dangerous as well as useful.\" He recommended the novel, though not its sequel, \"Erewhon Revisited\".\nInfluence and legacy.\nDeleuze and Guattari.\nThe French philosopher Gilles Deleuze used ideas from Butler's book at various points in the development of his philosophy of difference. In \"Difference and Repetition\" (1968), Deleuze refers to what he calls \"Ideas\" as \"Erewhon\". \"Ideas are not concepts\", he argues, but rather \"a form of eternally positive differential multiplicity, distinguished from the identity of concepts.\" \"Erewhon\" refers to the \"nomadic distributions\" that pertain to simulacra, which \"are not universals like the categories, nor are they the \"hic et nunc\" or \"nowhere\", the diversity to which categories apply in representation.\" \"Erewhon\", in this reading, is \"not only a disguised \"no-where\" but a rearranged \"now-here\".\"\nIn his collaboration with F\u00e9lix Guattari, \"Anti-Oedipus\" (1972), Deleuze draws on Butler's \"The Book of the Machines\" to \"go beyond\" the \"usual polemic between vitalism and mechanism\" as it relates to their concept of \"desiring-machines\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For one thing, Butler is not content to say that machines extend the organism, but asserts that they are really limbs and organs lying on the body without organs of a society, which men will appropriate according to their power and their wealth, and whose poverty deprives them as if they were mutilated organisms. For another, he is not content to say that organisms are machines, but asserts that they contain such an abundance of parts that they must be compared to very different parts of distinct machines, each relating to the others, engendered in combination with the others ... He shatters the vitalist argument by calling in question the specific or personal unity of the organism, and the mechanist argument even more decisively, by calling in question the structural unity of the machine.\nOther uses.\nC. S. Lewis alludes to the book in his essay, \"The Humanitarian Theory of Punishment\" in the posthumously published collection, \"God in the Dock\" (1970).\nAldous Huxley alludes to the book in his novel \"Island\" (1962), as does Agatha Christie in \"Death on the Nile\" (1937). A copy of the book figures in Elizabeth Bowen's short story 'The Cat Jumps' (1934).\nIn 1994, a group of ex-Yugoslavian writers in Amsterdam, who had established the PEN centre of Yugoslav Writers in Exile, published a single issue of a literary journal \"Erewhon\".\nThe boat is named Erewhon in the 1973 movie \"The Day of the Dolphin.\"\nNew Zealand sound art organisation, the Audio Foundation, published in 2012 an anthology edited by Bruce Russell named \"Erewhon Calling\" after Butler's book.\nIn 2014, New Zealand artist Gavin Hipkins released his first feature film, titled \"Erewhon\" and based on Butler's book. It premiered at the New Zealand International Film Festival and the Edinburgh Art Festival.\nIn \"Smile\", the second episode of the 2017 season of \"Doctor Who\", the Doctor and Bill explore a spaceship named \"Erehwon\". Despite the slightly different spelling, the episode writer Frank Cottrell-Boyce confirmed that this was a reference to Butler's novel.\nThe book \"The Open Society and Its Enemies\", by Karl Popper, reproduces on its first page the following citation of Butler: \"\"It will be seen ... that the Erewhonians are a meek and long-suffering people easily led by the nose, and quick to offer up common sense at the shrine of logic, when a philosopher arises among them who carries them away ... by convincing them that their existing institutions are not based on the strictest principles of morality\".\"\n\"Erewhon\" is the unofficial name US astronauts gave Regan Station, a military space station in David Brin's 1990 novel \"Earth\".\nThe 'Butlerian Jihad' is the name of the crusade to wipe out 'thinking machines' in the novel, \"Dune\", by Frank Herbert.\nErewhon is the name of Los Angeles-based natural foods grocery store originally founded in Boston in 1966.\nErewhon is also the name of an independent speculative fiction publishing company founded in 2018 by Liz Gorinsky.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9665", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=9665", "title": "Ectopia (medicine)", "text": "An ectopia () is a displacement or malposition of an organ or other body part, which is then referred to as ectopic (). Most ectopias are congenital, but some may happen later in life."}
{"id": "9667", "revid": "28683273", "url": "https://en.wikipedia.org/wiki?curid=9667", "title": "Entorhinal cortex", "text": "Area of the temporal lobe of the brain\nThe entorhinal cortex (EC) is an area of the brain's allocortex, located in the medial temporal lobe, whose functions include being a widespread network hub for memory, navigation, and the perception of time. The EC is the main interface between the hippocampus and neocortex. The EC-hippocampus system plays an important role in declarative (autobiographical/episodic/semantic) memories and in particular spatial memories including memory formation, memory consolidation, and memory optimization in sleep. The EC is also responsible for the pre-processing (familiarity) of the input signals in the reflex nictitating membrane response of classical trace conditioning; the association of impulses from the eye and the ear occurs in the entorhinal cortex.\nAnatomy.\nThe entorhinal cortex is a portion of the rostral parahippocampal gyrus.\nStructure.\nIt is usually divided into medial and lateral regions with three bands with distinct properties and connectivity running perpendicular across the whole area. A distinguishing characteristic of the EC is the lack of cell bodies where layer IV should be; this layer is called the \"Lamina dissecans\".\nConnections.\nThe superficial layers \u2013 layers II and III \u2013 of EC project to the dentate gyrus and hippocampus: Layer II projects primarily to dentate gyrus and hippocampal region CA3; layer III projects primarily to hippocampal region CA1 and the subiculum. These layers receive input from other cortical areas, especially associational, perirhinal, and parahippocampal cortices, as well as prefrontal cortex. EC as a whole, therefore, receives highly processed input from every sensory modality, as well as input relating to ongoing cognitive processes, though it should be stressed that, within EC, this information remains at least partially segregated.\nThe deep layers, especially layer V, receive one of the three main outputs of the hippocampus and, in turn, reciprocate connections from other cortical areas that project to superficial EC.\nFunction.\nNeuron information processing.\nIn 2005, it was discovered that entorhinal cortex contains a neural map of the spatial environment in rats. In 2014, John O'Keefe, May-Britt Moser and Edvard Moser received the Nobel Prize in Physiology or Medicine, partly because of this discovery.\nIn rodents, neurons in the lateral entorhinal cortex exhibit little spatial selectivity, whereas neurons of the medial entorhinal cortex (MEC), exhibit multiple \"place fields\" that are arranged in a hexagonal pattern, and are, therefore, called \"grid cells\". These fields and spacing between fields increase from the dorso-lateral MEA to the ventro-medial MEA.\nThe same group of researchers has found speed cells in the medial entorhinal cortex of rats. The speed of movement is translated from proprioceptive information and is represented as firing rates in these cells. The cells are known to fire in correlation to future speed of the rodent.\nRecently, a general theory has been proposed to elucidate the function of the reelin positive cells in the layer II of the entorhinal cortex. According to this concept, these cells would be generally organized into 1-dimensional ring attractors, and in the \"medial\" (in humans: \"posteromedial\") portion, would function as grid cells (anatomically: stellate cells) while in \"lateral\" (in humans: \"anterolateral\") portion, where they appear as fan cells, would enable the encoding of new episodic memories. This concept is underscored by the fact that fan cells of the entorhinal cortex are indispensable for the formation of episodic-like memories in rodents. \nSingle-unit recording of neurons in humans playing video games find path cells in the EC, the activity of which indicates whether a person is taking a clockwise or counterclockwise path. Such EC \"direction\" path cells show this directional activity irrespective of the location of where a person experiences themselves, which contrasts them to place cells in the hippocampus, which are activated by specific locations.\nEC neurons process general information such as directional activity in the environment, which contrasts to that of the hippocampal neurons, which usually encode information about specific places. This suggests that EC encodes general properties about current contexts that are then used by hippocampus to create unique representations from combinations of these properties.\nResearch generally highlights a useful distinction in which the medial entorhinal cortex (MEC) mainly supports processing of space, whereas the lateral entorhinal cortex (LEC) mainly supports the processing of time. \nThe MEC exhibits a strong ~8 Hz rhythmic neural activity known as theta. Alterations in the neural activity across the brain region results in an observed \"traveling wave\" phenomena across the MEC long-axis, similar to that of the hippocampus, due to asymmetric theta oscillations. The underlying cause of these phase shifts and their waveform changes is unknown. \nIndividual variation in the volume of EC is linked to taste perception. People with a larger EC in the left hemisphere found quinine, the source of bitterness in tonic water, less bitter. \nClinical significance.\nAlzheimer's disease.\nThe entorhinal cortex is the first area of the brain to be affected in Alzheimer's disease; a recent functional magnetic resonance imaging study has localised the area to the lateral entorhinal cortex. Lopez \"et al.\" have shown, in a multimodal study, that there are differences in the volume of the left entorhinal cortex between progressing (to Alzheimer's disease) and stable mild cognitive impairment patients. These authors also found that the volume of the left entorhinal cortex inversely correlates with the level of alpha band phase synchronization between the right anterior cingulate and temporo-occipital regions.\nIn 2012, neuroscientists at UCLA conducted an experiment using a virtual taxi video game connected to seven epilepsy patients with electrodes already implanted in their brains, allowing the researchers to monitor neuronal activity whenever memories were being formed. As the researchers stimulated the nerve fibers of each of the patients' entorhinal cortex as they were learning, they were then able to better navigate themselves through various routes and recognize landmarks more quickly. This signified an improvement in the patients' spatial memory.\nResearch.\nEffect of aerobic exercise\nA study on young subjects found aerobic fitness to be positively correlated with entorhinal cortex volume, indicating that aerobic exercise may have a positive effect on the medial temporal lobe memory system (which includes the entorhinal cortex).\nIn other animals.\nIn rodents, the EC is located at the caudal end of the temporal lobe. The rodent entorhinal cortex shows a modular organization, with different properties and connections in different areas.\nIn primates it is located at the rostral end of the temporal lobe and stretches dorsolaterally.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9668", "revid": "525927", "url": "https://en.wikipedia.org/wiki?curid=9668", "title": "Ernst Haeckel", "text": "German biologist, philosopher, physician, and artist (1834\u20131919)\nErnst Heinrich Philipp August Haeckel (]; 16 February 1834 \u2013 9 August 1919) was a German zoologist, naturalist, eugenicist, philosopher, physician, professor, marine biologist and artist. He discovered, described and named thousands of new species, mapped a genealogical tree relating all life forms and coined many terms in biology, including \"ecology\", \"phylum\", \"phylogeny\", and \"Protista.\" Haeckel promoted and popularised Charles Darwin's work in Germany and developed the influential but no longer widely held recapitulation theory (\"ontogeny recapitulates phylogeny\") claiming that an individual organism's biological development, or ontogeny, parallels and summarises its species' evolutionary development, or phylogeny.\nThe published artwork of Haeckel includes over 100 detailed, multi-colour illustrations of animals and sea creatures, collected in his \"Kunstformen der Natur\" (\"Art Forms of Nature\"), a book which would go on to influence the Art Nouveau artistic movement. As a philosopher, Ernst Haeckel wrote \"Die Weltr\u00e4thsel\" (1895\u20131899; in English: \"The Riddle of the Universe\", 1901), the genesis for the term \"world riddle\" (\"Weltr\u00e4tsel\"); and \"Freedom in Science and Teaching\" to support teaching evolution.\nHaeckel was also a promoter of scientific racism and embraced the idea of Social Darwinism. He was the first person to characterize the Great War the \"first\" World War which he did already in 1914.\nLife.\nErnst Haeckel was born on 16 February 1834, in Potsdam (then part of the Kingdom of Prussia).\nIn 1852 Haeckel completed studies at the \"Domgymnasium\", the cathedral high-school of Merseburg. He then studied medicine in Berlin and W\u00fcrzburg, particularly with Albert von K\u00f6lliker, Franz Leydig, Rudolf Virchow (with whom he later worked briefly as assistant), and with the anatomist-physiologist Johannes Peter M\u00fcller (1801\u20131858). Together with Hermann Steudner he attended botany lectures in W\u00fcrzburg. In 1857 Haeckel attained a doctorate in medicine, and afterwards he received the license to practice medicine. The occupation of physician appeared less worthwhile to Haeckel after contact with suffering patients.\nHe studied under Karl Gegenbaur at the University of Jena for three years, earning a habilitation in comparative anatomy in 1861, before becoming a professor of zoology at the University at Jena, where he remained for 47 years, from 1862 to 1909. Between 1859 and 1866 Haeckel worked on many phyla, such as radiolarians, poriferans (sponges) and annelids (segmented worms). During a trip to the Mediterranean, Haeckel named nearly 150 new species of radiolarians.\nIn 1864, his first wife, Anna Sethe, died. Haeckel dedicated some species of jellyfish that he found beautiful (such as \"Desmonema annasethe\") to her.\nFrom 1866 to 1867 Haeckel made an extended journey to the Canary Islands with Hermann Fol. On 17 October 1866 he arrived in London. Over the next few days he met Charles Lyell, and visited Thomas Huxley and family at their home. On 21 October he visited Charles Darwin at Down House in Kent. In 1867 he married Agnes Huschke. Their son Walter was born in 1868, their daughters Elizabeth in 1871 and Emma in 1873. In 1869 he traveled as a researcher to Norway, in 1871 to Croatia (where he lived on the island of Hvar in a monastery), and in 1873 to Egypt, Turkey, and Greece. In 1907 he had a museum built in Jena to teach the public about evolution. Haeckel retired from teaching in 1909, and in 1910 he withdrew from the Evangelical Church of Prussia.\nOn the occasion of his 80th birthday celebration he was presented with a two-volume work entitled \"Was wir Ernst Haeckel verdanken (What We Owe to Ernst Haeckel)\", edited at the request of the German Monistenbund by Heinrich Schmidt of Jena.\nHaeckel's wife, Agnes, died in 1915, and he became substantially frailer, breaking his leg and arm. He sold his \"Villa Medusa\" in Jena in 1918 to the Carl Zeiss foundation, which preserved his library. Haeckel died on 9 August 1919.\nHaeckel became the most famous proponent of Monism in Germany.\nPolitics.\nHaeckel's affinity for the German Romantic movement, coupled with his acceptance of a form of Lamarckism, influenced his political beliefs. Rather than being a strict Darwinian, Haeckel believed that the characteristics of an organism were acquired through interactions with the environment and that ontogeny reflected phylogeny. He saw the social sciences as instances of \"applied biology\", and that phrase was picked up and used for Nazi propaganda.\nIn 1906 Haeckel belonged to the founders of the Monist League (), which took a stance against philosophical materialism and promote a \"natural Weltanschauung\". This organization lasted until 1933 and included such notable members as Wilhelm Ostwald, Georg von Arco (1869\u20131940), Helene St\u00f6cker and Walter Arthur Berendsohn. He was the first person to use the term \"first world war\" about World War I.\nHowever, Haeckel's books were banned by the Nazi Party, which refused Monism and Haeckel's freedom of thought. Moreover, it is worth mentioning that Haeckel had often overtly recognized the great contribution of educated Jews to the German culture.\nResearch.\nHaeckel was a zoologist, an accomplished artist and illustrator, and later a professor of comparative anatomy. Although Haeckel's ideas are important to the history of evolutionary theory, and although he was a competent invertebrate anatomist most famous for his work on radiolaria, many speculative concepts that he championed are now considered incorrect. For example, Haeckel described and named hypothetical ancestral microorganisms that have never been found.\nHe was one of the first to consider psychology as a branch of physiology. He also proposed the kingdom \"Protista\" in 1866. His chief interests lay in evolution and life development processes in general, including development of nonrandom form, which culminated in the beautifully illustrated \"Kunstformen der Natur\" (\"Art forms of nature\"). Haeckel did not support natural selection, rather believing in Lamarckism.\nHaeckel advanced a version of the earlier recapitulation theory previously set out by \u00c9tienne Serres in the 1820s and supported by followers of \u00c9tienne Geoffroy Saint-Hilaire including Robert Edmond Grant. It proposed a link between ontogeny (development of form) and phylogeny (evolutionary descent), summed up by Haeckel in the phrase \"ontogeny recapitulates phylogeny\". His concept of recapitulation has been refuted in the form he gave it (now called \"strong recapitulation\"), in favour of the ideas first advanced by Karl Ernst von Baer. The strong recapitulation hypothesis views ontogeny as repeating forms of adult ancestors, while weak recapitulation means that what is repeated (and built upon) is the ancestral embryonic development process. Haeckel supported the theory with embryo drawings that have since been shown to be oversimplified and in part inaccurate, and the theory is now considered an oversimplification of quite complicated relationships, however comparison of embryos remains a powerful way to demonstrate that all animals are related. Haeckel introduced the concept of heterochrony, the change in timing of embryonic development over the course of evolution.\nHaeckel was a flamboyant figure, who sometimes took great, non-scientific leaps from available evidence. For example, at the time when Darwin published \"On the Origin of Species by Means of Natural Selection\" (1859), Haeckel postulated that evidence of human evolution would be found in the Dutch East Indies (now Indonesia). At that time, no remains of human ancestors had yet been identified. He described these theoretical remains in great detail and even named the as-yet unfound species, \"Pithecanthropus alalus\", and instructed his students such as Richard and Oskar Hertwig to go and find it.\nOne student did find some remains: a Dutchman named Eug\u00e8ne Dubois searched the East Indies from 1887 to 1895, discovering the remains of Java Man in 1891, consisting of a skullcap, thighbone, and a few teeth. These remains are among the oldest hominid remains ever found. Dubois classified Java Man with Haeckel's \"Pithecanthropus\" label, though they were later reclassified as \"Homo erectus\". Some scientists of the day suggested Dubois' Java Man as a potential intermediate form between modern humans and the common ancestor we share with the other great apes. The current consensus of anthropologists is that the direct ancestors of modern humans were African populations of \"Homo erectus\" (possibly \"Homo ergaster\"), rather than the Asian populations exemplified by Java Man and Peking Man. (Ironically, a new human species, Homo floresiensis, a dwarf human type, has recently been discovered in the island of Flores).\nPolygenism and racial theory.\nThe creationist polygenism of Samuel George Morton and Louis Agassiz, which presented human races as separately created species, was rejected by Charles Darwin, who argued for the monogenesis of the human species and the African origin of modern humans. In contrast to most of Darwin's supporters, Haeckel put forward a doctrine of evolutionary polygenism based on the ideas of the linguist August Schleicher, in which several different language groups had arisen separately from speechless prehuman \"Urmenschen\" (), which themselves had evolved from simian ancestors. These separate languages had completed the transition from animals to man, and under the influence of each main branch of languages, humans had evolved \u2013 in a kind of Lamarckian use-inheritance \u2013 as separate species, which could be subdivided into races. From this, Haeckel drew the implication that languages with the most potential yield the human races with the most potential, led by the Semitic and Indo-Germanic groups, with Berber, Jewish, Greco-Roman and Germanic varieties to the fore. As Haeckel stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We must mention here one of the most important results of the comparative study of languages, which for the Stammbaum of the species of men is of the highest significance, namely that human languages probably had a multiple or polyphyletic origin. Human language as such probably developed only after the species of speechless \"Urmenschen\" or \"Affenmenschen\" () had split into several species or kinds. With each of these human species, language developed on its own and independently of the others. At least this is the view of Schleicher, one of the foremost authorities on this subject.\u00a0... If one views the origin of the branches of language as the special and principal act of becoming human, and the species of humankind as distinguished according to their language stem, then one can say that the different species of men arose independently of one another.\nHaeckel's view can be seen as a forerunner of the views of Carleton Coon, who also believed that human races evolved independently and in parallel with each other. These ideas eventually fell from favour.\nHaeckel also applied the hypothesis of polygenism to the modern diversity of human groups. He became a key figure in social darwinism and leading proponent of scientific racism, stating for instance:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Caucasian, or Mediterranean man (\"Homo Mediterraneus\"), has from time immemorial been placed at the head of all the races of men, as the most highly developed and perfect. It is generally called the Caucasian race, but as, among all the varieties of the species, the Caucasian branch is the least important, we prefer the much more suitable appellation proposed by Friedrich M\u00fcller, namely, that of \"Mediterranese\". For the most important varieties of this species, which are moreover the most eminent actors in what is called \"Universal History\", first rose to a flourishing condition on the shores of the Mediterranean.\u00a0... This species alone (with the exception of the Mongolian) has had an actual history; it alone has attained to that degree of civilisation which seems to raise men above the rest of nature.\nHaeckel divided human beings into ten races, of which the Caucasian was the highest and the primitives were doomed to extinction. In his view, 'Negroes' were savages and Whites were the most civilised: for instance, he claimed that '[t]he Negro' had stronger and more freely movable toes than any other race, which, he argued, was evidence of their being less evolved, and which led him to compare them to '\"four-handed\" Apes'.\nIn his \"Ontogeny and Phylogeny\" Harvard paleontologist Stephen Jay Gould wrote: \"[Haeckel's] evolutionary racism; his call to the German people for racial purity and unflinching devotion to a 'just' state; his belief that harsh, inexorable laws of evolution ruled human civilization and nature alike, conferring upon favored races the right to dominate others\u00a0... all contributed to the rise of Nazism.\"\nIn his introduction to the Nazi party ideologue Alfred Rosenberg's 1930 book, \"[The Myth of the Twentieth Century]\", Peter Peel affirms that Rosenberg had indeed read Haeckel.\nIn the same line of thought, historian Daniel Gasman states that Haeckel's ideology stimulated the birth of Fascist ideology in Italy and France.\nHowever, Robert J. Richards notes: \"Haeckel, on his travels to Ceylon and Indonesia, often formed closer and more intimate relations with natives, even members of the untouchable classes, than with the European colonials.\" and says the Nazis rejected Haeckel, since he opposed antisemitism, while supporting ideas they disliked (for instance atheism, feminism, internationalism, pacifism etc.).\nAsia hypothesis.\nHaeckel claimed the origin of humanity was to be found in Asia: he believed that Hindustan (Indian subcontinent) was the actual location where the first humans had evolved. Haeckel argued that humans were closely related to the primates of Southeast Asia and rejected Darwin's hypothesis of Africa.\nHaeckel later claimed that the missing link was to be found on the lost continent of Lemuria located in the Indian Ocean. He believed that Lemuria was the home of the first humans and that Asia was the home of many of the earliest primates; he thus supported that Asia was the cradle of hominid evolution. Haeckel also claimed that Lemuria connected Asia and Africa, which allowed the migration of humans to the rest of the world.\nIn Haeckel's book \"The History of Creation\" (1884) he included migration routes which he thought the first humans had used outside of Lemuria.\nReligious views.\nIn \"Monism as Connecting Religion and Science\" (1892), he argued in favor of monism as the view most compatible with the current scientific understanding of the natural world. His perspective of monism was pantheistic and impersonal. The monistic idea of God, which alone is compatible with our present knowledge of nature, recognizes the divine spirit in all things. It can never recognise in God a \"personal being,\" or, in other words, an individual of limited extension in space, or even of human form. God is everywhere.\nEmbryology and recapitulation theory.\nWhen Haeckel was a student in the 1850s he showed great interest in embryology, attending the rather unpopular lectures twice and in his notes sketched the visual aids: textbooks had few illustrations, and large format plates were used to show students how to see the tiny forms under a reflecting microscope, with the translucent tissues seen against a black background. Developmental series were used to show stages within a species, but inconsistent views and stages made it even more difficult to compare different species. It was agreed by all European evolutionists that all vertebrates looked very similar at an early stage, in what was thought of as a common ideal type, but there was a continuing debate from the 1820s between the Romantic recapitulation theory that human embryos developed through stages of the forms of all the major groups of adult animals, literally manifesting a sequence of organisms on a linear chain of being, and Karl Ernst von Baer's opposing view, stated in von Baer's laws of embryology, that the early general forms diverged into four major groups of specialised forms without ever resembling the adult of another species, showing affinity to an archetype but no relation to other types or any transmutation of species. By the time Haeckel was teaching he was able to use a textbook with woodcut illustrations written by his own teacher Albert von K\u00f6lliker, which purported to explain human development while also using other mammalian embryos to claim a coherent sequence. Despite the significance to ideas of transformism, this was not really polite enough for the new popular science writing, and was a matter for medical institutions and for experts who could make their own comparisons.\nDarwin, Naturphilosophie and Lamarck.\nDarwin's \"On the Origin of Species\", which made a powerful impression on Haeckel when he read it in 1864, was very cautious about the possibility of ever reconstructing the history of life, but did include a section reinterpreting von Baer's embryology and revolutionising the field of study, concluding that \"Embryology rises greatly in interest, when we thus look at the embryo as a picture, more or less obscured, of the common parent-form of each great class of animals.\" It mentioned von Baer's 1828 anecdote (misattributing it to Louis Agassiz) that at an early stage embryos were so similar that it could be impossible to tell whether an unlabelled specimen was of a mammal, a bird, or of a reptile, and Darwin's own research using embryonic stages of barnacles to show that they are crustaceans, while cautioning against the idea that one organism or embryonic stage is \"higher\" or \"lower\", or more or less evolved. Haeckel disregarded such caution, and in a year wrote his massive and ambitious \"Generelle Morphologie\", published in 1866, presenting a revolutionary new synthesis of Darwin's ideas with the German tradition of \"Naturphilosophie\" going back to Goethe and with the progressive evolutionism of Lamarck in what he called \"Darwinismus\". He used morphology to reconstruct the evolutionary history of life, in the absence of fossil evidence using embryology as evidence of ancestral relationships. He invented new terms, including ontogeny and phylogeny, to present his evolutionised recapitulation theory that \"ontogeny recapitulated phylogeny\". The two massive volumes sold poorly, and were heavy going: with his limited understanding of German, Darwin found them impossible to read. Haeckel's publisher turned down a proposal for a \"strictly scholarly and objective\" second edition.\nEmbryological drawings.\nHaeckel's aim was a reformed morphology with evolution as the organising principle of a cosmic synthesis unifying science, religion, and art. He was giving successful \"popular lectures\" on his ideas to students and townspeople in Jena, in an approach pioneered by his teacher Rudolf Virchow. To meet his publisher's need for a popular work he used a student's transcript of his lectures as the basis of his \"Nat\u00fcrliche Sch\u00f6pfungsgeschichte\" of 1868, presenting a comprehensive presentation of evolution. In the Spring of that year he drew figures for the book, synthesising his views of specimens in Jena and published pictures to represent types. After publication he told a colleague that the images \"are completely exact, partly copied from nature, partly assembled from all illustrations of these early stages that have hitherto become known\". There were various styles of embryological drawings at that time, ranging from more schematic representations to \"naturalistic\" illustrations of specific specimens. Haeckel believed privately that his figures were both exact and synthetic, and in public asserted that they were schematic like most figures used in teaching. The images were reworked to match in size and orientation, and though displaying Haeckel's own views of essential features, they support von Baer's concept that vertebrate embryos begin similarly and then diverge. Relating different images on a grid conveyed a powerful evolutionary message. As a book for the general public, it followed the common practice of not citing sources.\nThe book sold very well, and while some anatomical experts hostile to Haeckel's evolutionary views expressed some private concerns that certain figures had been drawn rather freely, the figures showed what they already knew about similarities in embryos. The first published concerns came from Ludwig R\u00fctimeyer, a professor of zoology and comparative anatomy at the University of Basel who had placed fossil mammals in an evolutionary lineage early in the 1860s and had been sent a complimentary copy. At the end of 1868 his review in the \"Archiv f\u00fcr Anthropologie\" wondered about the claim that the work was \"popular and scholarly\", doubting whether the second was true, and expressed horror about such public discussion of man's place in nature with illustrations such as the evolutionary trees being shown to non-experts. Though he made no suggestion that embryo illustrations should be directly based on specimens, to him the subject demanded the utmost \"scrupulosity and conscientiousness\" and an artist must \"not arbitrarily model or generalise his originals for speculative purposes\" which he considered proved by comparison with works by other authors. In particular, \"one and the same, moreover incorrectly interpreted woodcut, is presented to the reader three times in a row and with three different captions as [the] embryo of the dog, the chick, [and] the turtle\". He accused Haeckel of \"playing fast and loose with the public and with science\", and failing to live up to the obligation to the truth of every serious researcher. Haeckel responded with angry accusations of bowing to religious prejudice, but in the second (1870) edition changed the duplicated embryo images to a single image captioned \"embryo of a mammal or bird\". Duplication using galvanoplastic stereotypes (clich\u00e9s) was a common technique in textbooks, but not on the same page to represent different eggs or embryos. In 1891 Haeckel made the excuse that this \"extremely rash foolishness\" had occurred in undue haste but was \"bona fide\", and since repetition of incidental details was obvious on close inspection, it is unlikely to have been intentional deception.\nThe revised 1870 second edition of 1,500 copies attracted more attention, being quickly followed by further revised editions with larger print runs as the book became a prominent part of the optimistic, nationalist, anticlerical \"culture of progress\" in Otto von Bismarck's new German Empire. The similarity of early vertebrate embryos became common knowledge, and the illustrations were praised by experts such as Michael Foster of the University of Cambridge. In the introduction to his 1871 \"The Descent of Man, and Selection in Relation to Sex\", Darwin gave particular praise to Haeckel, writing that if \"Nat\u00fcrliche Sch\u00f6pfungsgeschichte\" \"had appeared before my essay had been written, I should probably never have completed it\". The first chapter included an illustration: \"As some of my readers may never have seen a drawing of an embryo, I have given one of man and another of a dog, at about the same early stage of development, carefully copied from two works of undoubted accuracy\" with a footnote citing the sources and noting that \"H\u00e4ckel has also given analogous drawings in his \"Sch\u00f6pfungsgeschichte.\"\" The fifth edition of Haeckel's book appeared in 1874, with its frontispiece a heroic portrait of Haeckel himself, replacing the previous controversial image of the heads of apes and humans.\nControversy.\nLater in 1874, Haeckel's simplified embryology textbook \"Anthropogenie\" made the subject into a battleground over Darwinism aligned with Bismarck's \"Kulturkampf\" (\"culture struggle\") against the Catholic Church. Haeckel took particular care over the illustrations, changing to the leading zoological publisher Wilhelm Engelmann of Leipzig and obtaining from them use of illustrations from their other textbooks as well as preparing his own drawings including a dramatic double page illustration showing \"early\", \"somewhat later\" and \"still later\" stages of 8 different vertebrates. Though Haeckel's views had attracted continuing controversy, there had been little dispute about the embryos and he had many expert supporters, but Wilhelm His revived the earlier criticisms and introduced new attacks on the 1874 illustrations. Others joined in: both expert anatomists and Catholic priests and supporters were politically opposed to Haeckel's views.\nWhile it has been widely claimed that Haeckel was charged with fraud by five professors and convicted by a university court at Jena, there does not appear to be an independently verifiable source for this claim. Recent analyses (Richardson 1998, Richardson and Keuck 2002) have found that some of the criticisms of Haeckel's embryo drawings were legitimate, but others were unfounded. There were multiple versions of the embryo drawings, and Haeckel rejected the claims of fraud. It was later said that \"there is evidence of sleight of hand\" on both sides of the feud between Haeckel and Wilhelm His. Robert J. Richards, in a paper published in 2008, defends the case for Haeckel, shedding doubt against the fraud accusations based on the material used for comparison with what Haeckel could access at the time.\nAwards and honors.\nHaeckel was elected as a member to the American Philosophical Society in 1885. He was awarded the title of Excellency by Kaiser Wilhelm II in 1907 and the Linnean Society of London's prestigious Darwin-Wallace Medal in 1908. In the United States, \"Mount Haeckel\", a summit in the Eastern Sierra Nevada, overlooking the Evolution Basin, is named in his honour, as is another \"Mount Haeckel\", a summit in New Zealand; and the asteroid 12323 Haeckel.\nIn Jena he is remembered with a monument at Herrenberg (erected in 1969), an exhibition at Ernst-Haeckel-Haus, and at the Jena Phyletic Museum, which continues to teach about evolution and share his work to this day.\nThe ratfish, \"Harriotta haeckeli\" is named in his honor.\nThe research vessel \"Ernst Haeckel\" is named in his honor.\nIn 1981, a botanical journal called \"Ernstia\" was started being published in the city of Maracay, Venezuela.\nIn 2013, \"Ernstia\", a genus of calcareous sponges in the family Clathrinidae. The genus was erected to contain five species previously assigned to \"Clathrina\". The genus name honors Ernst Haeckel for his contributions towards sponge taxonomy and phylogeny.\nPublications.\nDarwin's 1859 book \"On the Origin of Species\" had immense popular influence, but although its sales exceeded its publisher's hopes it was a technical book rather than a work of popular science: long, difficult and with few illustrations. One of Haeckel's books did a great deal to explain his version of \"Darwinism\" to the world. It was a bestselling, provocatively illustrated book in German, titled \"Nat\u00fcrliche Sch\u00f6pfungsgeschichte\", published in Berlin in 1868, and translated into English as \"The History of Creation\" in 1876. Until 1909, eleven editions had appeared, as well as 25 translations into other languages. The \"Nat\u00fcrliche Sch\u00f6pfungsgeschichte\" cemented Haeckel's reputation as one of Germany's most forceful popularizers of science. His \"Weltr\u00e4thsel\" were reprinted ten times after the book's first publication in 1899; ultimately, over 400,000 copies were sold.\nHaeckel argued that human evolution consisted of precisely 22 phases, the 21st \u2013 the \"missing link\" \u2013 being a halfway step between apes and humans. He even formally named this missing link \"Pithecanthropus alalus\", translated as \"ape man without speech\".\nHaeckel's literary output was extensive, including many books, scientific papers, and illustrations.\nTravel books.\nFor a fuller list of works of and about Haeckel, see his entry in the .\nThe standard author abbreviation Haeckel is used to indicate this person as the author when citing a botanical name.\nAssessments of potential influence on Nazism.\nSome historians have seen Haeckel's social Darwinism as a forerunner to Nazi ideology. Others have denied the relationship altogether.\nThe evidence is in some respects ambiguous. On one hand, Haeckel was an advocate of scientific racism. He held that evolutionary biology had definitively proven that races were unequal in intelligence and ability, and that their lives were also of unequal value, e.g., \"These lower races (such as the Veddahs or Australian negroes) are psychologically nearer to the mammals (apes or dogs) than to civilised Europeans; we must therefore, assign a totally different value to their lives.\" As a result of the \"struggle for existence\", it followed that the \"lower\" races would eventually be exterminated. He was also a social Darwinist who believed that \"survival of the fittest\" was a natural law, and that struggle led to improvement of the race. As an advocate of eugenics, he also believed that about 200,000 mentally and congenitally ill should be killed by a medical control board. This idea was later put into practice by Nazi Germany, as part of the Aktion T4 program. Alfred Ploetz, founder of the German Society for Racial Hygiene, praised Haeckel repeatedly, and invited him to become an honorary member. Haeckel accepted the invitation. Haeckel also believed that Germany should be governed by an authoritarian political system, and that inequalities both within and between societies were an inevitable product of evolutionary law. Haeckel was also an extreme German nationalist who believed strongly in the superiority of German culture.\nOn the other hand, Haeckel was not an anti-Semite. In the racial hierarchies he constructed Jews tended to appear closer to the top, rather than closer to the bottom as in Nazi racial thought. He was also a pacifist until the First World War, when he wrote propaganda in favor of the war. The principal arguments of historians who deny a meaningful connection between Haeckel and Nazism are that Haeckel's ideas were very common at the time, that Nazis were much more strongly influenced by other thinkers, and that Haeckel is properly classified as a 19th-century German liberal, rather than a forerunner to Nazism. They also point to incompatibilities between evolutionary biology and Nazi ideology.\nNazis themselves divided on the question of whether Haeckel should be counted as a pioneer of their ideology. SS captain and biologist Heinz Br\u00fccher wrote a biography of Haeckel in 1936, in which he praised Haeckel as a \"pioneer in biological state thinking\". This opinion was also shared by the scholarly journal, \"Der Biologe\", which celebrated Haeckel's 100th birthday, in 1934, with several essays acclaiming him as a pioneering thinker of Nazism. Other Nazis kept their distance from Haeckel. Nazi propaganda guidelines issued in 1935 listed books which popularized Darwin and evolution on an \"expunged list\". Haeckel was included by name as a forbidden author. Gunther Hecht, a member of the Nazi Department of Race Politics, also issued a memorandum rejecting Haeckel as a forerunner of Nazism. Kurt Hildebrandt, a Nazi political philosopher, also rejected Haeckel. Eventually Haeckel was rejected by Nazi bureaucrats.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9670", "revid": "18916437", "url": "https://en.wikipedia.org/wiki?curid=9670", "title": "Evolutionism", "text": "Derogatory term for the theory of evolution\nEvolutionism is a term used (often derogatorily) to denote the theory of evolution. Its exact meaning has changed over time as the study of evolution has progressed. In the 19th century, it was used to describe the belief that organisms deliberately improved themselves through progressive inherited change (orthogenesis). The teleological belief went on to include cultural evolution and social evolution. In the 1970s, the term \"Neo-Evolutionism\" was used to describe the idea that \"human beings sought to preserve a familiar style of life unless change was forced on them by factors that were beyond their control.\"\nThe term is most often used by creationists to describe adherence to the scientific consensus on evolution as equivalent to a secular religion. The term is very seldom used within the scientific community, since the scientific position on evolution is accepted by the overwhelming majority of scientists. Because evolutionary biology is the default scientific position, it is assumed that \"scientists\" or \"biologists\" are \"evolutionists\" unless specifically noted otherwise. In the creation\u2013evolution controversy, creationists often call those who accept the validity of the modern evolutionary synthesis \"evolutionists\" and the theory itself \"evolutionism\".\n19th-century teleological use.\nBefore its use to describe biological evolution, the term \"evolution\" was originally used to refer to any orderly sequence of events with the outcome somehow contained at the start. The first five editions of Darwin's in \"Origin of Species\" used the word \"evolved\", but the word \"evolution\" was only used in its sixth edition in 1872. By then, Herbert Spencer had developed the concept theory that organisms strive to evolve due to an internal \"driving force\" (orthogenesis) in 1862. Edward B. Tylor and Lewis H Morgan brought the term \"evolution\" to anthropology though they tended toward the older pre-Spencerian definition helping to form the concept of unilineal (social) evolution used during the later part of what Trigger calls the Antiquarianism-Imperial Synthesis period (c1770-c1900). The term evolutionism subsequently came to be used for the now discredited theory that evolution contained a deliberate component, rather than the selection of beneficial traits from random variation by differential survival.\nModern use by creationists.\nThe term \"evolution\" is widely used, but the term \"evolutionism\" is not used in the scientific community to refer to evolutionary biology as it is redundant and anachronistic.\nHowever, the term has been used by creationists in discussing the creation\u2013evolution controversy. For example, the Institute for Creation Research, in order to imply placement of evolution in the category of 'religions', including atheism, fascism, humanism and occultism, commonly uses the words \"evolutionism\" and \"evolutionist\" to describe the consensus of mainstream science and the scientists subscribing to it, thus implying through language that the issue is a matter of religious belief. The BioLogos Foundation, an organization that promotes the idea of theistic evolution, uses the term \"evolutionism\" to describe \"the atheistic worldview that so often accompanies the acceptance of biological evolution in public discourse.\" It views this as a subset of scientism.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9672", "revid": "13816079", "url": "https://en.wikipedia.org/wiki?curid=9672", "title": "Entscheidungsproblem", "text": "Impossible task in computing\nIn mathematics and computer science, the ; ]) is a challenge posed by David Hilbert and Wilhelm Ackermann in 1928. The problem asks for an algorithm that considers, as input, a statement and answers \"yes\" or \"no\" according to whether the statement is \"universally valid\", i.e., valid in every structure satisfying the axioms.\nCompleteness theorem.\nBy the completeness theorem of first-order logic, a statement is universally valid if and only if it can be deduced from the axioms, so the \"\" can also be viewed as asking for an algorithm to decide whether a given statement is provable from the axioms using the rules of logic.\nIn 1936, Alonzo Church and Alan Turing published independent papers showing that a general solution to the \"\" is impossible, assuming that the intuitive notion of \"effectively calculable\" is captured by the functions computable by a Turing machine (or equivalently, by those expressible in the lambda calculus). This assumption is now known as the Church\u2013Turing thesis.\nHistory of the problem.\nThe origin of the goes back to Gottfried Leibniz, who in the seventeenth century, after having constructed a successful mechanical calculating machine, dreamt of building a machine that could manipulate symbols in order to determine the truth values of mathematical statements. He realized that the first step would have to be a clean formal language, and much of his subsequent work was directed toward that goal. In 1928, David Hilbert and Wilhelm Ackermann posed the question in the form outlined above.\nIn continuation of his \"program\", Hilbert posed three questions at an international conference in 1928, the third of which became known as \"Hilbert's \". In 1929, Moses Sch\u00f6nfinkel published one paper on special cases of the decision problem, that was prepared by Paul Bernays.\nAs late as 1930, Hilbert believed that there would be no such thing as an unsolvable problem.\nNegative answer.\nBefore the question could be answered, the notion of \"algorithm\" had to be formally defined. This was done by Alonzo Church in 1935 with the concept of \"effective calculability\" based on his \u03bb-calculus, and by Alan Turing the next year with his concept of Turing machines. Turing immediately recognized that these are equivalent models of computation.\nThe negative answer to the was then given by Alonzo Church in 1935\u201336 (Church's theorem) and independently shortly thereafter by Alan Turing in 1936 (Turing's proof). Church proved that there is no computable function which decides, for two given \u03bb-calculus expressions, whether they are equivalent or not. He relied heavily on earlier work by Stephen Kleene. Turing reduced the question of the existence of an 'algorithm' or 'general method' able to solve the to the question of the existence of a 'general method' which decides whether any given Turing machine halts or not (the halting problem). If 'algorithm' is understood as meaning a method that can be represented as a Turing machine, and with the answer to the latter question negative (in general), the question about the existence of an algorithm for the also must be negative (in general). In his 1936 paper, Turing says: \"Corresponding to each computing machine 'it' we construct a formula 'Un(it)' and we show that, if there is a general method for determining whether 'Un(it)' is provable, then there is a general method for determining whether 'it' ever prints 0\".\nThe work of both Church and Turing was heavily influenced by Kurt G\u00f6del's earlier work on his incompleteness theorem, especially by the method of assigning numbers (a G\u00f6del numbering) to logical formulas in order to reduce logic to arithmetic.\nThe \"\" is related to Hilbert's tenth problem, which asks for an algorithm to decide whether Diophantine equations have a solution. The non-existence of such an algorithm, established by the work of Yuri Matiyasevich, Julia Robinson, Martin Davis, and Hilary Putnam, with the final piece of the proof in 1970, also implies a negative answer to the \"Entscheidungsproblem\".\nSome first-order theories are algorithmically decidable; examples of this include Presburger arithmetic, real closed fields, and static type systems of many programming languages. The general first-order theory of the natural numbers expressed in Peano's axioms cannot be decided with an algorithm, however.\nPractical decision procedures.\nHaving practical decision procedures for classes of logical formulas is of considerable interest for program verification and circuit verification. Pure Boolean logical formulas are usually decided using SAT-solving techniques based on the DPLL algorithm. Conjunctive formulas over linear real or rational arithmetic can be decided using the simplex algorithm, formulas in linear integer arithmetic (Presburger arithmetic) can be decided using Cooper's algorithm or William Pugh's Omega test. Formulas with negations, conjunctions and disjunctions combine the difficulties of satisfiability testing with that of decision of conjunctions; they are generally decided nowadays using SMT-solving techniques, which combine SAT-solving with decision procedures for conjunctions and propagation techniques. Real polynomial arithmetic, also known as the theory of real closed fields, is decidable; this is the Tarski\u2013Seidenberg theorem, which has been implemented in computers by using the cylindrical algebraic decomposition.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9674", "revid": "494861", "url": "https://en.wikipedia.org/wiki?curid=9674", "title": "Einhard", "text": "Frankish scholar and courtier (c. 775 \u2013 840)\nEinhard (also Eginhard or Einhart; ; c. 775 \u2013 14 March 840) was a Frankish scholar and courtier. Einhard was a dedicated servant of Charlemagne and his son Louis the Pious; his main work is a biography of Charlemagne, the \"Vita Karoli Magni\", \"one of the most precious literary bequests of the early Middle Ages\".\nPublic life.\nEinhard was from the eastern German-speaking part of the Frankish Kingdom. Born into a family of landowners of some importance, his parents sent him to be educated by the monks of Fulda, one of the most impressive centers of learning in the Frank lands. Perhaps due to his small stature, which restricted his riding and sword-fighting ability, Einhard concentrated his energies on scholarship, especially the mastering of Latin. He was accepted into the hugely wealthy court of Charlemagne around 791 or 792. Charlemagne actively sought to amass scholarly men around him and established a royal school led by the Northumbrian scholar Alcuin. Einhard was evidently a talented builder and construction manager, because Charlemagne put him in charge of the completion of several palace complexes including Aachen and Ingelheim. Despite the fact that Einhard was on intimate terms with Charlemagne, he never achieved office in his reign. In 814, on Charlemagne's death, his son Louis the Pious made Einhard his private secretary. Einhard retired from court during the time of the disputes between Louis and his sons in the spring of 830.\nHe died at Seligenstadt in 840.\nPrivate life.\nEinhard was married to Emma, of whom little is known. There is a possibility that their marriage bore a son, Vussin. Their marriage also appears to have been exceptionally liberal for the period, with Emma being as active as Einhard, if not more so, in the handling of their property. It is said that in the later years of their marriage Emma and Einhard abstained from sexual relations, choosing instead to focus their attentions on their many religious commitments. Though he was undoubtedly devoted to her, Einhard wrote nothing of his wife until after her death on 13 December 835, when he wrote to a friend that he was reminded of her loss in \u2018every day, in every action, in every undertaking, in all the administration of the house and household, in everything needing to be decided upon and sorted out in my religious and earthly responsibilities\u2019.\nReligious beliefs.\nEinhard made numerous references to himself as a \"sinner\" according to his strong Christian faith. He erected churches at both of his estates in Michelstadt and Mulinheim. In Michelstadt, he also saw fit to build a basilica completed in 827 and then sent a servant, Ratleic, to Rome with an end to find relics for the new building. Once in Rome, Ratleic robbed a catacomb of the bones of the Martyrs Marcellinus and Peter and had them translated to Michelstadt. Once there, the relics made it known they were unhappy with their new tomb and thus had to be moved again to Mulinheim. Once established there, they proved to be miracle workers. Although unsure as to why these saints should choose such a \"sinner\" as their patron, Einhard nonetheless set about ensuring they continued to receive a resting place fitting of their honour. Between 831 and 834 he founded a Benedictine Monastery and, after the death of his wife, served as its Abbot until his own death in 840.\nLocal lore.\nLocal lore from Seligenstadt portrays Einhard as the lover of Emma, one of Charlemagne's daughters, and has the couple elope from court. Charlemagne found them at Seligenstadt (then called Oberm\u00fchlheim) and forgave them. This account is used to explain the name \"Seligenstadt\" by folk etymology. Einhard and his wife were originally buried in one sarcophagus in the choir of the church in Seligenstadt, but in 1810 the sarcophagus was presented by the Grand Duke of Hesse to the count of Erbach, who claims descent from Einhard as the husband of Imma, the reputed daughter of Charlemagne. The count put it in the famous chapel of his castle at Erbach in the Odenwald.\nWorks.\nThe most famous of Einhard's works is his biography of Charlemagne, the \"Vita Karoli Magni\", \"The Life of Charlemagne\" (c. 817\u2013836), which provides much direct information about Charlemagne's life and character, written sometime between 817 and 830. In composing this he relied heavily upon the Royal Frankish Annals. Einhard's literary model was the classical work of the Roman historian Suetonius, the \"Lives of the Caesars\", though it is important to stress that the work is very much Einhard's own, that is to say he adapts the models and sources for his own purposes. His work was written as a praise of Charlemagne, whom he regarded as a foster-father (\"nutritor\") and to whom he was a debtor \"in life and death\". The work thus contains an understandable degree of bias, Einhard taking care to exculpate Charlemagne in some matters, not mention others, and to gloss over certain issues which would be of embarrassment to Charlemagne, such as the morality of his daughters; by contrast, other issues are curiously not glossed over, like his concubines. \nEinhard is also responsible for three other extant works: a collection of letters, \"On the Translations and the Miracles of SS. Marcellinus and Petrus\", and \"On the Adoration of the Cross\". The latter dates from ca. 830 and was not rediscovered until 1885, when Ernst D\u00fcmmler identified a text in a manuscript in Vienna as the missing \"Libellus de adoranda cruce\", which Einhard had dedicated to his pupil Lupus Servatus.\nThe Arch of Einhard was a reliquary made by Einhard, which reproduced on a small scale a Roman triumphal arch that represented the victory of Christianity. It has not survived.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9675", "revid": "36087022", "url": "https://en.wikipedia.org/wiki?curid=9675", "title": "Ester", "text": "Compound derived from an acid\nIn chemistry, an ester is a compound derived from an acid (organic or inorganic) in which the hydrogen atom (H) of at least one acidic hydroxyl group () of that acid is replaced by an organyl group (). Analogues derived from oxygen replaced by other chalcogens belong to the ester category as well. According to some authors, organyl derivatives of acidic hydrogen of other acids are esters as well (e.g. amides), but not according to the IUPAC.\nGlycerides are fatty acid esters of glycerol; they are important in biology, being one of the main classes of lipids and comprising the bulk of animal fats and vegetable oils. Lactones are cyclic carboxylic esters; naturally occurring lactones are mainly 5- and 6-membered ring lactones. Lactones contribute to the aroma of fruits, butter, cheese, vegetables like celery and other foods.\nEsters can be formed from oxoacids (e.g. esters of acetic acid, carbonic acid, sulfuric acid, phosphoric acid, nitric acid, xanthic acid), but also from acids that do not contain oxygen (e.g. esters of thiocyanic acid and trithiocarbonic acid). An example of an ester formation is the substitution reaction between a carboxylic acid () and an alcohol (), forming an ester (), where R stands for any group (organic or inorganic, typically hydrogen or organyl) and R\u2032 stands for organyl group.\nOrganyl esters of carboxylic acids typically have a pleasant smell; those of low molecular weight are commonly used as fragrances and are found in essential oils and pheromones. They perform as high-grade solvents for a broad array of plastics, plasticizers, resins, and lacquers, and are one of the largest classes of synthetic lubricants on the commercial market. Polyesters are important plastics, with monomers linked by ester moieties. Esters of phosphoric acid form the backbone of DNA molecules. Esters of nitric acid, such as nitroglycerin, are known for their explosive properties.\nThere are compounds in which an acidic hydrogen of acids mentioned in this article are not replaced by an organyl, but by some other group. According to some authors, those compounds are esters as well (e.g. according to them, trimethylstannyl acetate (or trimethyltin acetate) is a trimethylstannyl ester of acetic acid, and dibutyltin dilaurate is a dibutylstannylene ester of lauric acid).\nNomenclature.\nEtymology.\nThe word \"ester\" was coined in 1848 by a German chemist Leopold Gmelin, probably as a contraction of the German , \"acetic ether\".\nIUPAC nomenclature.\nThe names of esters that are formed from an alcohol and an acid, are derived from the parent alcohol and the parent acid, where the latter may be organic or inorganic. Esters derived from the simplest carboxylic acids are commonly named according to the more traditional, so-called \"trivial names\" e.g. as formate, acetate, propionate, and butyrate, as opposed to the IUPAC nomenclature methanoate, ethanoate, propanoate, and butanoate. Esters derived from more complex carboxylic acids are, on the other hand, more frequently named using the systematic IUPAC name, based on the name for the acid followed by the suffix \"-oate\". For example, the ester hexyl octanoate, also known under the trivial name hexyl caprylate, has the formula .\nThe chemical formulas of organic esters formed from carboxylic acids and alcohols usually take the form or RCOOR', where R and R' are the organyl parts of the carboxylic acid and the alcohol, respectively, and R can be a hydrogen in the case of esters of formic acid. For example, butyl acetate (systematically butyl ethanoate), derived from butanol and acetic acid (systematically ethanoic acid) would be written . Alternative presentations are common including BuOAc and .\nCyclic esters are called lactones, regardless of whether they are derived from an organic or inorganic acid. One example of an organic lactone is \u03b3-valerolactone.\nOrthoesters.\nAn uncommon class of esters are the orthoesters. One of them are the esters of orthocarboxylic acids. Those esters have the formula , where R stands for any group (organic or inorganic) and R\u2032 stands for organyl group. For example, triethyl orthoformate () is derived, in terms of its name (but not its synthesis) from esterification of orthoformic acid () with ethanol.\nEsters of inorganic acids.\nEsters can also be derived from inorganic acids.\nInorganic acids that exist as tautomers form two or more kinds of esters.\nSome inorganic acids that are unstable or elusive form stable esters.\nIn principle, all metal and metalloid alkoxides, of which many hundreds are known, could be classified as esters of the hypothetical acids, e.g. aluminium triethoxide () could be classified as an ester of aluminic acid which is aluminium hydroxide, tetraethyl orthosilicate () could be classified as an ester of orthosilicic acid, and titanium ethoxide () could be classified as an ester of orthotitanic acid.\nStructure and bonding.\nEsters derived from carboxylic acids and alcohols contain a carbonyl group C=O, which is a divalent group at C atom, which gives rise to 120\u00b0 C\u2013C\u2013O and O\u2013C\u2013O angles. Unlike amides, carboxylic acid esters are structurally flexible functional groups because rotation about the C\u2013O\u2013C bonds has a low barrier. Their flexibility and low polarity is manifested in their physical properties; they tend to be less rigid (lower melting point) and more volatile (lower boiling point) than the corresponding amides. The p\"K\"a of the alpha-hydrogens on esters is around 25.\nMany carboxylic acid esters have the potential for conformational isomerism, but they tend to adopt an \"S\"-\"cis\" (or \"Z\") conformation rather than the \"S\"-\"trans\" (or \"E\") alternative, due to a combination of hyperconjugation and dipole minimization effects. The preference for the \"Z\" conformation is influenced by the nature of the substituents and solvent, if present. Lactones with small rings are restricted to the \"s\"-trans (i.e. E) conformation due to their cyclic structure.\nPhysical properties and characterization.\nEsters derived from carboxylic acids and alcohols are more polar than ethers but less polar than alcohols. They participate in hydrogen bonds as hydrogen-bond acceptors, but cannot act as hydrogen-bond donors, unlike their parent alcohols. This ability to participate in hydrogen bonding confers some water-solubility. Because of their lack of hydrogen-bond-donating ability, esters do not self-associate. Consequently, esters are more volatile than carboxylic acids of similar molecular weight.\nCharacterization and analysis.\nEsters are generally identified by gas chromatography, taking advantage of their volatility. IR spectra for esters feature an intense sharp band in the range 1730\u20131750\u00a0cm\u22121 assigned to \"\u03bd\"C=O. This peak changes depending on the functional groups attached to the carbonyl. For example, a benzene ring or double bond in conjugation with the carbonyl will bring the wavenumber down about 30\u00a0cm\u22121.\nApplications and occurrence.\nEsters are widespread in nature and are widely used in industry. In nature, fats are, in general, triesters derived from glycerol and fatty acids. Esters are responsible for the aroma of many fruits, including apples, durians, pears, bananas, pineapples, and strawberries. Several billion kilograms of polyesters are produced industrially annually, important products being polyethylene terephthalate, acrylate esters, and cellulose acetate.\nPreparation.\nEsterification is the general name for a chemical reaction in which two reactants (typically an alcohol and an acid) form an ester as the reaction product. Esters are common in organic chemistry and biological materials, and often have a pleasant characteristic, fruity odor. This leads to their extensive use in the fragrance and flavor industry. Ester bonds are also found in many polymers.\nEsterification of carboxylic acids with alcohols.\nThe classic synthesis is the Fischer esterification, which involves treating a carboxylic acid with an alcohol in the presence of a dehydrating agent:\nThe equilibrium constant for such reactions is about 5 for typical esters, e.g., ethyl acetate. The reaction is slow in the absence of a catalyst. Sulfuric acid is a typical catalyst for this reaction. Many other acids are also used such as polymeric sulfonic acids. Since esterification is highly reversible, the yield of the ester can be improved using Le Chatelier's principle:\nReagents are known that drive the dehydration of mixtures of alcohols and carboxylic acids. One example is the Steglich esterification, which is a method of forming esters under mild conditions. The method is popular in peptide synthesis, where the substrates are sensitive to harsh conditions like high heat. DCC (dicyclohexylcarbodiimide) is used to activate the carboxylic acid to further reaction. 4-Dimethylaminopyridine (DMAP) is used as an acyl-transfer catalyst.\nAnother method for the dehydration of mixtures of alcohols and carboxylic acids is the Mitsunobu reaction:\nCarboxylic acids can be esterified using diazomethane:\nUsing this diazomethane, mixtures of carboxylic acids can be converted to their methyl esters in near quantitative yields, e.g., for analysis by gas chromatography. The method is useful in specialized organic synthetic operations but is considered too hazardous and expensive for large-scale applications.\nEsterification of carboxylic acids with epoxides.\nCarboxylic acids are esterified by treatment with epoxides, giving \u03b2-hydroxyesters:\nThis reaction is employed in the production of vinyl ester resin from acrylic acid.\nAlcoholysis of acyl chlorides and acid anhydrides.\nAlcohols react with acyl chlorides and acid anhydrides to give esters:\n\nThe reactions are irreversible simplifying work-up. Since acyl chlorides and acid anhydrides also react with water, anhydrous conditions are preferred. The analogous acylations of amines to give amides are less sensitive because amines are stronger nucleophiles and react more rapidly than does water. This method is employed only for laboratory-scale procedures, as it is expensive.\nAlkylation of carboxylate salts.\nAlthough rarely employed for esterifications, carboxylate salts (often generated \"in situ\") react with electrophilic alkylating agents, such as alkyl halides, to give esters. Anion availability can inhibit this reaction, which correspondingly benefits from phase transfer catalysts or such highly polar aprotic solvents as DMF. An additional iodide salt may, via the Finkelstein reaction, catalyze the reaction of a recalcitrant alkyl halide. Alternatively, salts of a coordinating metal, such as silver, may improve the reaction rate by easing halide elimination.\nTransesterification.\nTransesterification, which involves changing one ester into another one, is widely practiced:\nLike the hydrolysation, transesterification is catalysed by acids and bases. The reaction is widely used for degrading triglycerides, e.g. in the production of fatty acid esters and alcohols. Poly(ethylene terephthalate) is produced by the transesterification of dimethyl terephthalate and ethylene glycol: \nA subset of transesterification is the alcoholysis of diketene. This reaction affords 2-ketoesters.\nCarbonylation.\nAlkenes undergo \"hydroesterification\" in the presence of metal carbonyl catalysts. Esters of propanoic acid are produced commercially by this method:\nA preparation of methyl propionate is one illustrative example. \nThe carbonylation of methanol yields methyl formate, which is the main commercial source of formic acid. The reaction is catalyzed by sodium methoxide:\nAddition of carboxylic acids to alkenes and alkynes.\nIn hydroesterification, alkenes and alkynes insert into the bond of carboxylic acids. Vinyl acetate is produced industrially by the addition of acetic acid to acetylene in the presence of zinc acetate catalysts: Presently, zinc acetate is used as the catalyst:\nVinyl acetate can also be produced by palladium-catalyzed reaction of ethylene, acetic acid, and oxygen:\nSilicotungstic acid is used to manufacture ethyl acetate by the alkylation of acetic acid by ethylene:\nFrom aldehydes.\nThe Tishchenko reaction involve disproportionation of an aldehyde in the presence of an anhydrous base to give an ester. Catalysts are aluminium alkoxides or sodium alkoxides. Benzaldehyde reacts with sodium benzyloxide (generated from sodium and benzyl alcohol) to generate benzyl benzoate. The method is used in the production of ethyl acetate from acetaldehyde.\nReactions.\nEsters react with nucleophiles at the carbonyl carbon. The carbonyl is weakly electrophilic but is attacked by strong nucleophiles (amines, alkoxides, hydride sources, organolithium compounds, etc.). The C\u2013H bonds adjacent to the carbonyl are weakly acidic but undergo deprotonation with strong bases. This process is the one that usually initiates condensation reactions. The carbonyl oxygen in esters is weakly basic, less so than the carbonyl oxygen in amides due to resonance donation of an electron pair from nitrogen in amides, but forms adducts.\nHydrolysis and saponification.\nEsterification is a reversible reaction. Esters undergo hydrolysis under acidic and basic conditions. Under acidic conditions, the reaction is the reverse reaction of the Fischer esterification. Under basic conditions, hydroxide acts as a nucleophile, while an alkoxide is the leaving group. This reaction, saponification, is the basis of soap making.\nThe alkoxide group may also be displaced by stronger nucleophiles such as ammonia or primary or secondary amines to give amides: (ammonolysis reaction)\nThis reaction is not usually reversible. Hydrazines and hydroxylamine can be used in place of amines. Esters can be converted to isocyanates through intermediate hydroxamic acids in the Lossen rearrangement.\nSources of carbon nucleophiles, e.g., Grignard reagents and organolithium compounds, add readily to the carbonyl.\nReduction.\nCompared to ketones and aldehydes, esters are relatively resistant to reduction. The introduction of catalytic hydrogenation in the early part of the 20th century was a breakthrough; esters of fatty acids are hydrogenated to fatty alcohols.\nA typical catalyst is copper chromite. Prior to the development of catalytic hydrogenation, esters were reduced on a large scale using the Bouveault\u2013Blanc reduction. This method, which is largely obsolete, uses sodium in the presence of proton sources.\nEspecially for fine chemical syntheses, lithium aluminium hydride is used to reduce esters to two primary alcohols. The related reagent sodium borohydride is slow in this reaction. DIBAH reduces esters to aldehydes.\nDirect reduction to give the corresponding ether is difficult as the intermediate hemiacetal tends to decompose to give an alcohol and an aldehyde (which is rapidly reduced to give a second alcohol). The reaction can be achieved using triethylsilane with a variety of Lewis acids.\nClaisen condensation and related reactions.\nAs for aldehydes, the hydrogen atoms on the carbon adjacent (\"\u03b1 to\") the carboxyl group in esters are sufficiently acidic to undergo deprotonation, which in turn leads to a variety of useful reactions. Deprotonation requires relatively strong bases, such as alkoxides. Deprotonation gives a nucleophilic enolate, which can further react, e.g., the Claisen condensation and its intramolecular equivalent, the Dieckmann condensation. This conversion is exploited in the malonic ester synthesis, wherein the diester of malonic acid reacts with an electrophile (e.g., alkyl halide), and is subsequently decarboxylated. Another variation is the Fr\u00e1ter\u2013Seebach alkylation.\nProtecting groups.\nAs a class, esters serve as protecting groups for carboxylic acids. Protecting a carboxylic acid is useful in peptide synthesis, to prevent self-reactions of the bifunctional amino acids. Methyl and ethyl esters are commonly available for many amino acids; the \"t\"-butyl ester tends to be more expensive. However, \"t\"-butyl esters are particularly useful because, under strongly acidic conditions, the \"t\"-butyl esters undergo elimination to give the carboxylic acid and isobutylene, simplifying work-up.\nHazards.\nEsters react with strong oxidizing acids, which may cause a violent reaction that is sufficiently exothermic to ignite the esters and the reaction products. Heat is also generated by the interaction of esters with alkali solutions. Very flammable hydrogen gas is generated by mixing esters with alkali metals and ionic hydrides.\nList of ester odorants.\nMany esters have distinctive fruit-like odors, and many occur naturally in the essential oils of plants. This has also led to their common use in artificial flavorings and fragrances which aim to mimic those odors.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9677", "revid": "1152308", "url": "https://en.wikipedia.org/wiki?curid=9677", "title": "Endosymbiont", "text": "Organism that lives within the body or cells of another organism\nAn endosymbiont or endobiont is any organism that lives within the body or cells of another organism most often, though not always, in a mutualistic relationship.\n(The term endosymbiosis is from the Greek: \u1f14\u03bd\u03b4\u03bf\u03bd \"endon\" \"within\", \u03c3\u03cd\u03bd \"syn\" \"together\" and \u03b2\u03af\u03c9\u03c3\u03b9\u03c2 \"biosis\" \"living\".) Examples are nitrogen-fixing bacteria (called rhizobia), which live in the root nodules of legumes, single-cell algae inside reef-building corals and bacterial endosymbionts that provide essential nutrients to insects.\nThe history behind the concept of endosymbiosis stems from the postulates of the endosymbiotic theory. The endosymbiotic theory (symbiogenesis) pushes the notion of bacteria exclusively living in eukaryotic organisms after being engulfed by them. This is popular with the concept of organelle development observed with eukaryotes. Two major types of organelle in eukaryotic cells, mitochondria and plastids such as chloroplasts, are considered to be obtained from bacterial endosymbionts.\nThere are two main types of symbiont transmissions. In horizontal transmission, each new generation acquires free living symbionts from the environment. An example is the nitrogen-fixing bacteria in certain plant roots. Vertical transmission takes place when the symbiont is transferred directly from parent to offspring. An example is pea aphid symbionts. Also, it is possible for both to be involved in a mixed-mode transmission, where symbionts are transferred vertically for some generation before a switch of host occurs and new symbionts are horizontally acquired from the environment. Other examples include \"Wigglesworthia\" nutritional symbionts of tse-tse flies, or in sponges. When a symbiont reaches this stage, it begins to resemble a cellular organelle, similar to mitochondria or chloroplasts.\nMany instances of endosymbiosis are obligate; that is, either the endosymbiont or the host cannot survive without the other, such as the gutless marine worms of the genus \"Riftia\", which obtain nutrition from their endosymbiotic bacteria. The most common examples of obligate endosymbioses are mitochondria and chloroplasts. Some human parasites, e.g. \"Wuchereria bancrofti\" and \"Mansonella perstans\", thrive in their intermediate insect hosts because of an obligate endosymbiosis with \"Wolbachia spp.\" They can both be eliminated from hosts by treatments that target this bacterium. However, not all endosymbioses are obligate and some endosymbioses can be harmful to either of the organisms involved.\nThe Origin: Symbiogenesis and Symbiont transmission.\nSymbiogenesis and organelles.\nSymbiogenesis explains the origins of eukaryotes, whose cells contain two major kinds of organelle: mitochondria and chloroplasts. The theory proposes that these organelles evolved from certain types of bacteria that eukaryotic cells engulfed through phagocytosis. These cells and the bacteria trapped inside them entered an endosymbiotic relationship, meaning that the bacteria took up residence and began living exclusively within the eukaryotic cells.\nNumerous insect species have endosymbionts at different stages of symbiogenesis. A common theme of symbiogenesis involves the reduction of the genome to only essential genes for the host and symbiont collective genome. A remarkable example of this is the fractionation of the \"Hodgkinia\" genome of \"Magicicada\" cicadas. Because the cicada life cycle takes years underground, natural selection on endosymbiont populations is relaxed for many bacterial generations. This allows the symbiont genomes to diversify within the host for years with only punctuated periods of selection when the cicadas reproduce. As a result, the ancestral \"Hodgkinia\" genome has split into three groups of primary endosymbiont, each encoding only a fraction of the essential genes for the symbiosis. The host now requires all three sub-groups of symbiont, each with degraded genomes lacking most essential genes for bacterial viability.\nSymbiont transmission.\nSymbiont transmission is the process where the host in a symbiotic relationship between two organisms acquires an organism (internally or externally) that serves as its symbiont. Most symbionts are either obligatory (require their host to survive) or facultative (do not necessarily need their host to survive). Many instances of endosymbiosis are obligate; that is, either the endosymbiont or the host cannot survive without the other, such as the gutless marine worms of the genus \"Riftia\", which get nutrition from their endosymbiotic bacteria. The most common examples of obligate endosymbiosis are mitochondria and chloroplasts. Some human parasites, e.g. \"Wuchereria bancrofti\" and \"Mansonella perstans\", thrive in their intermediate insect hosts because of an obligate endosymbiosis with \"Wolbachia spp.\" They can both be eliminated from hosts by treatments that target this bacterium.\nHorizontal (lateral), vertical, and mix-mode (hybrid of horizonal and vertical) transmission are the three paths for symbiont transfer. Horizontal symbiont transfer (horizontal transmission) is a process where a host acquires a facultative symbiont from the environment or from another host. The Rhizobia-Legume symbiosis (bacteria-plant endosymbiosis) is a prime example of horizontal symbiont transmission. The Rhizobia-legume symbiotic relationship is important for processes like the formation of root nodules. It starts with flavonoids released by the plant host (Legume), which causes the rhizobia species (endosymbiont) to activate its \"nod\" genes. These \"Nod\" genes generate lipooligosaccharide signals which the legume(host) detects, thus leading to root nodule formation. This process bleeds on to other unique processes like nitrogen fixation in plants. The evolutionary advantage of such an interaction allows genetic exchange between both organisms involved increasing the propensity for novel functions as seen in the plant-bacterium interaction (holobiont formation).\nIn vertical transmission, the symbionts often have a reduced genome and are no longer able to survive on their own. As a result, the symbiont depends on the host, resulting in a highly intimate co-dependent relationship. For instance, pea aphid symbionts have lost genes for essential molecules, now relying on the host to supply them with nutrients. In return, the symbionts synthesize essential amino acids for the aphid host. Other examples include \"Wigglesworthia\" nutritional symbionts of tsetse flies, or in sponges. When a symbiont reaches this stage, it begins to resemble a cellular organelle, similar to mitochondria or chloroplasts. The evolutionary consequences causes the host and the symbiont to be dependent and form a holobiont, and in the event of a bottleneck a decrease in symbiont diversity could affect the host-symbiont interactions adversely, when deleterious mutations build up over time.\nBacterial endosymbionts of invertebrates.\nThe best-studied examples of endosymbiosis are known from invertebrates. These symbioses affect organisms with global impact, including \"Symbiodinium\" of corals, or \"Wolbachia\" of insects. Many insect agricultural pests and human disease vectors have intimate relationships with primary endosymbionts.\nOf insects.\nScientists classify insect endosymbionts in two broad categories, 'Primary' and 'Secondary'. Primary endosymbionts (sometimes referred to as P-endosymbionts) have been associated with their insect hosts for many millions of years (from 10 to several hundred million years in some cases). They form obligate associations (see below), and display cospeciation with their insect hosts. Secondary endosymbionts exhibit a more recently developed association, are sometimes horizontally transferred between hosts, live in the hemolymph of the insects (not specialized bacteriocytes, see below), and are not obligate.\nPrimary.\nAmong primary endosymbionts of insects, the best-studied are the pea aphid (\"Acyrthosiphon pisum\") and its endosymbiont \"Buchnera sp.\" APS, the tsetse fly \"Glossina morsitans morsitans\" and its endosymbiont \"Wigglesworthia glossinidia brevipalpis\" and the endosymbiotic protists in lower termites. As with endosymbiosis in other insects, the symbiosis is obligate in that neither the bacteria nor the insect is viable without the other. Scientists have been unable to cultivate the bacteria in lab conditions outside of the insect. With special nutritionally-enhanced diets, the insects can survive, but are unhealthy, and at best survive only a few generations.\nIn some insect groups, these endosymbionts live in specialized insect cells called bacteriocytes (also called \"mycetocytes\"), and are maternally-transmitted, i.e. the mother transmits her endosymbionts to her offspring. In some cases, the bacteria are transmitted in the egg, as in \"Buchnera\"; in others like \"Wigglesworthia\", they are transmitted via milk to the developing insect embryo. In termites, the endosymbionts reside within the hindguts and are transmitted through trophallaxis among colony members.\nThe primary endosymbionts are thought to help the host either by providing nutrients that the host cannot obtain itself or by metabolizing insect waste products into safer forms. For example, the putative primary role of \"Buchnera\" is to synthesize essential amino acids that the aphid cannot acquire from its natural diet of plant sap. Likewise, the primary role of \"Wigglesworthia\", it is presumed, is to synthesize vitamins that the tsetse fly does not get from the blood that it eats. In lower termites, the endosymbiotic protists play a major role in the digestion of lignocellulosic materials that constitute a bulk of the termites' diet.\nBacteria benefit from the reduced exposure to predators and competition from other bacterial species, the ample supply of nutrients and relative environmental stability inside the host.\nGenome sequencing reveals that obligate bacterial endosymbionts of insects have among the smallest of known bacterial genomes and have lost many genes that are commonly found in closely related bacteria. Several theories have been put forth to explain the loss of genes. It is presumed that some of these genes are not needed in the environment of the host insect cell. A complementary theory suggests that the relatively small numbers of bacteria inside each insect decrease the efficiency of natural selection in 'purging' deleterious mutations and small mutations from the population, resulting in a loss of genes over many millions of years. Research in which a parallel phylogeny of bacteria and insects was inferred supports the belief that the primary endosymbionts are transferred only vertically (i.e., from the mother), and not horizontally (i.e., by escaping the host and entering a new host).\nAttacking obligate bacterial endosymbionts may present a way to control their insect hosts, many of which are pests or carriers of human disease. For example, aphids are crop pests and the tsetse fly carries the organism \"Trypanosoma brucei\" that causes African sleeping sickness. Other motivations for their study involve understanding the origins of symbioses in general, as a proxy for understanding e.g. how chloroplasts or mitochondria came to be obligate symbionts of eukaryotes or plants.\nSecondary.\nThe pea aphid (\"Acyrthosiphon pisum\") is known to contain at least three secondary endosymbionts, \"Hamiltonella defensa\", \"Regiella insecticola\", and \"Serratia symbiotica\". \"Hamiltonella defensa\" defends its aphid host from parasitoid wasps. This defensive symbiosis improves the survival of aphids, which have lost some elements of the insect immune response.\nOne of the best-understood defensive symbionts is the spiral bacteria \"Spiroplasma poulsonii\". \"Spiroplasma sp.\" can be reproductive manipulators, but also defensive symbionts of \"Drosophila\" flies. In \"Drosophila neotestacea\", \"S. poulsonii\" has spread across North America owing to its ability to defend its fly host against nematode parasites. This defence is mediated by toxins called \"ribosome-inactivating proteins\" that attack the molecular machinery of invading parasites. These \"Spiroplasma\" toxins represent one of the first examples of a defensive symbiosis with a mechanistic understanding for defensive symbiosis between an insect endosymbiont and its host.\n\"Sodalis glossinidius\" is a secondary endosymbiont of tsetse flies that lives inter- and intracellularly in various host tissues, including the midgut and hemolymph. Phylogenetic studies have not indicated a correlation between evolution of \"Sodalis\" and tsetse. Unlike tsetse's primary symbiont \"Wigglesworthia\", though, \"Sodalis\" has been cultured \"in vitro\".\nMany other insects have secondary endosymbionts not reviewed here.\nOf ants.\nThe best-studied endosymbiont of ants are bacteria of the genus Blochmannia, which are the primary endosymbiont of Camponotus ants. In 2018 a new ant-associated symbiont was discovered in Cardiocondyla ants. This symbiont was named Candidatus Westeberhardia Cardiocondylae and it is also believed to be a primary symbiont.\nOf marine invertebrates.\nExtracellular endosymbionts are also represented in all four extant classes of Echinodermata (Crinoidea, Ophiuroidea, Echinoidea, and Holothuroidea). Little is known of the nature of the association (mode of infection, transmission, metabolic requirements, etc.) but phylogenetic analysis indicates that these symbionts belong to the class Alphaproteobacteria, relating them to \"Rhizobium\" and \"Thiobacillus\". Other studies indicate that these subcuticular bacteria may be both abundant within their hosts and widely distributed among the Echinoderms in general.\nSome marine oligochaeta (e.g., \"Olavius algarvensis\" and \"Inanidrillus spp.\") have obligate extracellular endosymbionts that fill the entire body of their host. These marine worms are nutritionally dependent on their symbiotic chemoautotrophic bacteria lacking any digestive or excretory system (no gut, mouth, or nephridia).\nThe sea slug \"Elysia chlorotica\" lives in endosymbiotic relationship with the algae \"Vaucheria litorea\", and the jellyfish \"Mastigias\" have a similar relationship with an algae. \"Elysia chlorotica\" forms this relationship intracellularly with the chloroplasts from the algae. These chloroplast retain their photosynthetic capabilities and structures for several months after being taken into the cells of the slug.\nDinoflagellate endosymbionts.\nDinoflagellate endosymbionts of the genus \"Symbiodinium\", commonly known as zooxanthellae, are found in corals, mollusks (esp. giant clams, the \"Tridacna\"), sponges, and foraminifera. These endosymbionts drive the formation of coral reefs by capturing sunlight and providing their hosts with energy for carbonate deposition.\nPreviously thought to be a single species, molecular phylogenetic evidence over the past couple decades has shown there to be great diversity in \"Symbiodinium\". In some cases, there is specificity between host and \"Symbiodinium\" clade. More often, however, there is an ecological distribution of \"Symbiodinium\", the symbionts switching between hosts with apparent ease. When reefs become environmentally stressed, this distribution of symbionts is related to the observed pattern of coral bleaching and recovery. Thus, the distribution of \"Symbiodinium\" on coral reefs and its role in coral bleaching presents one of the most complex and interesting current problems in reef ecology.\nOf phytoplankton.\nIn marine environments, bacterial endosymbionts have more recently been discovered. These endosymbiotic relationships are especially prevalent in oligotrophic or nutrient-poor regions of the ocean like that of the North Atlantic. In these oligotrophic waters, cell growth of larger phytoplankton like that of diatoms is limited by low nitrate concentrations.\u00a0 Endosymbiotic bacteria fix nitrogen for their diatom hosts and in turn receive organic carbon from photosynthesis. These symbioses play an important role in global carbon cycling in oligotrophic regions.\nOne known symbiosis between the diatom \"Hemialus\" spp. and the cyanobacterium \"Richelia intracellularis\" has been found in the North Atlantic, Mediterranean, and Pacific Ocean. The \"Richelia\" endosymbiont is found within the diatom frustule of \"Hemiaulus\" spp., and has a reduced genome likely losing genes related to pathways the host now provides.\u00a0 Research by Foster et al. (2011) measured nitrogen fixation by the cyanobacterial host \"Richelia intracellularis\" well above intracellular requirements, and found the cyanobacterium was likely fixing excess nitrogen for Hemiaulus host cells.\u00a0Additionally, both host and symbiont cell growth were much greater than free-living \"Richelia intracellularis\" or symbiont-free \"Hemiaulus\" spp.\u00a0The \"Hemaiulus\"-\"Richelia\" symbiosis is not obligatory especially in areas with excess nitrogen (nitrogen replete).\n\"Richelia intracellularis\" is also found in \"Rhizosolenia\" spp., a diatom found in oligotrophic oceans. Compared to the \"Hemaiulus\" host, the endosymbiosis with \"Rhizosolenia\" is much more consistent, and \"Richelia intracellularis\" is generally found in \"Rhizosolenia\". There are some asymbiotic (occurs without an endosymbiont) Rhizosolenia, however there appears to be mechanisms limiting growth of these organisms in low nutrient conditions. Cell division for both the diatom host and cyanobacterial symbiont can be uncoupled and mechanisms for passing bacterial symbionts to daughter cells during cell division are still relatively unknown.\nOther endosymbiosis with nitrogen fixers in open oceans include Calothrix in Chaetocerous spp. and UNCY-A in prymnesiophyte microalga.\u00a0 The Chaetocerous-Calothrix endosymbiosis is hypothesized to be more recent, as the Calothrix genome is generally intact. While other species like that of the UNCY-A symbiont and Richelia have reduced genomes.\u00a0This reduction in genome size occurs within nitrogen metabolism pathways indicating endosymbiont species are generating nitrogen for their hosts and losing the ability to use this nitrogen independently.\u00a0This endosymbiont reduction in genome size, might be a step that occurred in the evolution of organelles (above).\nOf protists.\n\"Mixotricha paradoxa\" is a protozoan that lacks mitochondria. However, spherical bacteria live inside the cell and serve the function of the mitochondria. \"Mixotricha\" also has three other species of symbionts that live on the surface of the cell.\n\"Paramecium bursaria\", a species of ciliate, has a mutualistic symbiotic relationship with green alga called \"Zoochlorella\". The algae live inside the cell, in the cytoplasm.\n\"Paulinella chromatophora\" is a freshwater amoeboid which has recently (evolutionarily speaking) taken on a cyanobacterium as an endosymbiont.\nMany foraminifera are hosts to several types of algae, such as red algae, diatoms, dinoflagellates and chlorophyta. These endosymbionts can be transmitted vertically to the next generation via asexual reproduction of the host, but because the endosymbionts are larger than the foraminiferal gametes, they need to acquire new algae again after sexual reproduction.\nSeveral species of radiolaria have photosynthetic symbionts. In some species the host will sometimes digest algae to keep their population at a constant level.\n\"Hatena arenicola\" is a flagellate protist with a complicated feeding apparaturs that feed on other microbes. But when it engulfs a green alga from the genus \"Nephroselmis\", the feeding apparatus disappears and it becomes photosynthetic. During mitosis the algae is transferred to only one of the two cells, and the cell without the algae needs to start the cycle all over again.\nIn 1966, biologist Kwang W. Jeon found that a lab strain of \"Amoeba proteus\" had been infected by bacteria that lived inside the cytoplasmic vacuoles. This infection killed all the protists except for a few individuals. After the equivalent of 40 host generations, the two organisms gradually became mutually interdependent. Over many years of study, it has been confirmed that a genetic exchange between the prokaryotes and protists had occurred.\nOf vertebrates.\nThe spotted salamander (\"Ambystoma maculatum\") lives in a relationship with the algae \"Oophila amblystomatis\", which grows in the egg cases.\nOf plants.\nPlants are diverse photosynthetic eukaryotes having wide variety of cell morphologies and lifestyles. Plants are considered one of the primary producers. Plants with all photosynthetic eukaryotes are dependent on an intracellular organelle known as plastid or chloroplast (in case of plants and green algae). The chloroplast is derived from a cyanobacterial primary endosymbiosis over one billion years ago. The oxygenic photosynthetic free-living cyanobacterium was engulfed and kept by a heterotrophic protist and eventually evolved into the present intracellular organelle over the course of many years. \u00a0\nThe plant symbioses can be categorized into epiphytic, endophytic, and mycorrhizal. The mycorrhizal category is only used for fungi. The endosymbiosis relation of plants and endosymbionts can also be categorized into beneficial, mutualistic, neutral, and pathogenic. Typically, most of the studies related to plan symbioses or plant endosymbionts such as endophytic bacteria or fungi, are focused on a single category or specie to better understand the biological processes and functions one at a time. But this approach is not helping to understand the complex endosymbiotic interactions and biological functions in natural habitat. Microorganisms living in association as endosymbionts with plants can enhance the primary productivity of plants either by producing or capturing the limiting resources. These endosymbionts can also enhance the productivity of plants by the production of toxic metabolites helping plant defenses against herbivores . Although, the role and potential of microorganisms in community regulations has been neglected since long, may because of the microscopic size and unseen lifestyle. Theoretically, all the vascular plants harbor endosymbionts (e.g., fungi and bacteria). these endosymbionts colonize the plants cells and tissue predominantly but not exclusively. Plant endosymbionts can be categorized into different types based on the function, relation and location, some common plant endosymbionts are discussed as follow.\nPlant endosymbionts, also called endophytes, include bacteria, fungi, viruses, protozoa and even microalgae. Endophytes help plant in biological processes such as growth and development, nutrient uptake and defense against biotic and abiotic stresses like drought, salinity, heat, and herbivores.\nFungi as plant endosymbionts.\nAll vascular plants have fungal and bacterial endophytes or endosymbionts which colonize predominantly but not exclusively, roots. Fungal endosymbionts can be found all out the plant tissues and based on their location in the plant, fungal endosymbionts can be defined in multiple ways like fungi living in plant tissues above the ground are termed as endophytes, while fungi living below the ground (roots) are known as mycorrhizal, but the mycorrhizal fungi also have different names based on their location inside the root which are ecto, endo, arbuscular, ericoid, etc. Furthermore, the fungal endosymbionts living in the roots and extending their extraradical hyphae into the outer rhizosphere are known as ectendosymbionts.\nArbuscular Mycorrhizal Fungi (AMF).\nAmong the plant microbial endosymbionts arbuscular mycorrhizal fungi or AMF are the most diverse group. With some exceptions Ericaceae family, almost all vascular plants are harboring the AMF endosymbionts both as endo and ecto as well. The AMF plant endosymbionts systematically colonize the plant roots and helping plant host by soil nutrients and as a return it takes the plant organic carbon sources. Plant roots exudates contain a diversity of secondary metabolites especially flavonoids and strigolactones which acts as chemical signals and attracts the AMF. Arbuscular mycyrrizal fungus \"Gigaspora margarita\" not only lives as a plant endosymbiont but also harbor further endosymbiont intracytoplasmic bacterium-like organisms. By isolating the pure cultures of AMF endosymbionts, it has been reported that it has different effects to the different plant hosts. By introducing the AMF of one plant can reduce the net growth of the other plant host which might have to do something with already present AMF. Furthermore, the AMF are reported in numerous studies as plant health and growth promoting and as an alleviating agent for abiotic stresses like salinity, drought, heat, poor nutrition and metal toxicity.\nEndophytic fungi.\nIn addition to mycorrhizal endosymbionts, the endophytic fungi are also catching the interest of scientist by showing so much potential not only in its mutualistic relation where it is benefiting host plant and taking advantages as well but also showing promising results in other domains like helping plant to grow in polluted environment such as high polluted environment with toxic metals. Fungal endophytes are taxonomically diverse group of omnipresent fungi which is divided into different categories based on mode of transmission, biodiversity, in planta colonization and host plant type. These categories are clavicipitaceous and non-clavicipitaceous, the former one systematically colonizes the temperate season grasses while the later one colonizes higher plants and even roots and that\u2019s why can be divided into further categories. \"Bacillus amyloliquefaciens\" is a seed born endophytic fungi which produces gibberellins and promotes the physiology. \"Bacillus amyloliquefaciens\" has been evaluated in a study for its growth promoting potential where it promotes the longer height of transgenic dwarf rice plants. Similarly, \"Aureobasidium\u00a0\"and \"preussia\" species of endophytic fungi isolated from Boswellia sacra are producing indole acetic acid hormone to promote plant health and development.\nAphids are most common insects and can be found in most of the plants and carnivorous ladybirds are the specialized predators of the aphids. These ladybirds are used in different programs for the pest control. A study conducted on the effect of plant-endophyte symbiosis on the population and fitness of carnivorous ladybirds. The plant endophytic fungus \"Neotyphodium lolii\" is producing alkaloid mycotoxins in response to aphid invasions. The ladybirds picking on the aphids from the infected plants exhibited reduced rate of fertility and abnormal reproductive performance. Adult ladybirds were not significantly affected in terms of their body symmetries and size. But the consistently strong negative effects of endophytes overall fitness of ladybirds suggest that the mycotoxins are transmitted along the food chain and effecting the top predators.\nEndophytic bacteria.\nEndophytic bacteria belong to a diverse group of plant endosymbionts and characterized by systematically colonization of plant internal tissues. Endophytic bacteria most common genera include \"Pseudomonas\", \"Bacillus\", \"Acinetobacter\", \"Actinobacteria\", \"Sphingomonas.\" Some endophytic bacteria genera additionally belong to the Enterobacteriacae family (Pirttila and Frank, 2011). Endophytic bacteria mostly colonize the leaf tissues from plant roots, but can also enter the plant through the leaves through leaf stomata (Senthilkumar et al., 2011).Generally, the endophytic bacteria are isolated from the plant tissues by surface sterilization of the plant tissue in a sterile environment.\u00a0 Moreover, the isolation of endophytic bacteria according to their essential needs in niche occupations has been explored. That\u2019s why the endophytic bacterial community can be divided into \"passenger\" and \"true\" endophytes. The passenger endophytic bacteria are those who eventually colonize inner tissue of plant by stochastic events while the true endophytes possess adaptive traits because of which they live in association with plants strictly. the in vitro cultivated endophytic bacteria association with plant is considered a more intimate relationship where it helps plant acclimatize to the conditions and promotes health and growth. The endophytic bacteria are considered as plant's essential endosymbionts because virtually all plants harbor it, and these endosymbionts play essential roles in host plant survival. This plant-endosymbiont relation is important in terms of ecology, evolution and diversity. Moreover, the endophytic bacteria such as \"Sphingomonas\" sp. and \"Serratia\" sp. being isolated from arid land plants regulate endogenous hormone content and promote growth in crop plants.\nArchaea as plant endosymbionts.\nArchaea are members of most microbiomes. While archaea are highly abundant in extreme environments, they are less abundant and diverse in association with eukaryotic hosts. Nevertheless, archaea are a substantial constituent of plant-associated ecosystems in the aboveground and belowground phytobiome, and play a role in host plant\u2019s health, growth and survival in biotic and abiotic stresses. However, only a few studies have investigated the role of archaea in plant health and its potential symbiosis in ecosystems. Generally, most of the plant endosymbiont related studies focus on fungal or bacterial endosymbionts using metagenomic approaches.\nThe characterization of archaea is not only limited to crop plants like rice and maize but also identified in many aquatic plant species. The abundance of archaea is different in different tissues for example archaea are more abundant in the rhizosphere than the phyllosphere and endosphere. This archaeal abundance is highly associated with plant species type, environment and plant\u2019s developmental stage. In a study conducted on the detection of plant-genotype specific archaeal and bacterial endophytes, 35% of archaeal sequences were detected in overall sequences (achieved using amplicon sequencing and verified by real time-PCR). The archaeal sequences belong to the phyla \"Thaumarchaeota\", \"Crenarchaeota,\" and \"Euryarchaeota\".\nEndosymbionts of bacteria.\nSome Betaproteobacteria have Gammaproteobacteria endosymbionts.\nEndosymbionts of fungi.\nFungi harbor endohyphal bacteria; however, the effects of the bacteria on the fungi are not well studied. Many fungi that harbor these endohyphal bacteria in turn live within plants. These fungi are otherwise known as fungal endophytes. It is hypothesized that the fungi offers a safe haven for the bacteria, and diverse bacteria colonize these refugia creating a micro-ecosystem. These interactions are important because they may impact the way that fungi interact with the environment by modulating their phenotypes.\nThe way in which the bacteria do this is by altering the gene expression of the fungi. For example, \"Luteibacter\" sp. has been shown to naturally infect the ascomycetous endophyte \"Pestalotiopsis\" sp. isolated from \"Platycladus orientalis.\" The \"Luteibacter\" sp. influences the auxin and enzyme production within its host, which, in turn, may influence the effect the fungus has on its plant host\".\" Another interesting example of a bacteria living in symbiosis with a fungus is with the fungus \"Mortierella.\" This soil-dwelling fungus lives in close association with a toxin-producing bacteria, \"Mycoavidus\", which helps the fungus to defend against nematodes. This is a very new, but potentially very important, area of study within the study of symbiosis.\nVirus-host associations.\nThe human genome project found several thousand endogenous retroviruses, endogenous viral elements in the genome that closely resemble and can be derived from retroviruses, organized into 24 families.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9678", "revid": "1160113939", "url": "https://en.wikipedia.org/wiki?curid=9678", "title": "Exponential function", "text": "Mathematical function, denoted exp(x) or e^x\nThe exponential function is a mathematical function denoted by formula_1 or formula_2 (where the argument x is written as an exponent). Unless otherwise specified, the term generally refers to the positive-valued function of a real variable, although it can be extended to the complex numbers or generalized to other mathematical objects like matrices or Lie algebras. The exponential function originated from the notion of exponentiation (repeated multiplication), but modern definitions (there are several equivalent characterizations) allow it to be rigorously extended to all real arguments, including irrational numbers. Its ubiquitous occurrence in pure and applied mathematics led mathematician Walter Rudin to opine that the exponential function is \"the most important function in mathematics\". \nThe exponential function satisfies the exponentiation identity \nformula_3\nwhich, along with the definition formula_4, shows that formula_5 for positive integers n, and relates the exponential function to the elementary notion of exponentiation. The base of the exponential function, its value at 1, formula_4, is a ubiquitous mathematical constant called Euler's number. \nWhile other continuous nonzero functions formula_7 that satisfy the exponentiation identity are also known as \"exponential functions\", the exponential function exp is the unique real-valued function of a real variable whose derivative is itself and whose value at 0 is 1; that is, formula_8 for all real x, and formula_9 Thus, exp is sometimes called the natural exponential function to distinguish it from these other exponential functions, which are the functions of the form formula_10 where the base b is a positive real number. The relation formula_11 for positive b and real or complex x establishes a strong relationship between these functions, which explains this ambiguous terminology.\nThe real exponential function can also be defined as a power series. This power series definition is readily extended to complex arguments to allow the complex exponential function formula_12 to be defined. The complex exponential function takes on all complex values except for 0 and is closely related to the complex trigonometric functions, as shown by Euler's formula. \nMotivated by more abstract properties and characterizations of the exponential function, the exponential can be generalized to and defined for entirely different kinds of mathematical objects (for example, a square matrix or a Lie algebra).\nIn applied settings, exponential functions model a relationship in which a constant change in the independent variable gives the same proportional change (that is, percentage increase or decrease) in the dependent variable. This occurs widely in the natural and social sciences, as in a self-reproducing population, a fund accruing compound interest, or a growing body of manufacturing expertise. Thus, the exponential function also appears in a variety of contexts within physics, computer science, chemistry, engineering, mathematical biology, and economics. \nThe real exponential function is a bijection from formula_13 to formula_14. Its inverse function is the natural logarithm, denoted formula_15 formula_16 or formula_17 because of this, some old texts refer to the exponential function as the antilogarithm.\nGraph.\nThe graph of formula_18 is upward-sloping, and increases faster as x increases. The graph always lies above the x-axis, but becomes arbitrarily close to it for large negative x; thus, the x-axis is a horizontal asymptote. The equation formula_19 means that the slope of the tangent to the graph at each point is equal to its y-coordinate at that point.\nRelation to more general exponential functions.\nThe exponential function formula_20 is sometimes called the \"natural exponential function\" for distinguishing it from the other exponential functions. The study of any exponential function can easily be reduced to that of the natural exponential function, since per definition, for positive b,\nformula_21\nAs functions of a real variable, exponential functions are uniquely characterized by the fact that the derivative of such a function is directly proportional to the value of the function. The constant of proportionality of this relationship is the natural logarithm of the base b:\nformula_22\nFor \"b\" &gt; 1, the function formula_23 is increasing (as depicted for \"b\" = \"e\" and \"b\" = 2), because formula_24 makes the derivative always positive; while for \"b\" &lt; 1, the function is decreasing (as depicted for \"b\" =); and for \"b\" = 1 the function is constant.\nEuler's number \"e\" = 2.71828... is the unique base for which the constant of proportionality is 1, since formula_25, so that the function is its own derivative:\nformula_26\nThis function, also denoted as exp \"x\", is called the \"natural exponential function\", or simply \"the exponential function\". Since any exponential function can be written in terms of the natural exponential as formula_11, it is computationally and conceptually convenient to reduce the study of exponential functions to this particular one. The natural exponential is hence denoted by\nformula_28 or formula_29\nThe former notation is commonly used for simpler exponents, while the latter is preferred when the exponent is more complicated and harder to read in a small font.\nFor real numbers c and d, a function of the form formula_30 is also an exponential function, since it can be rewritten as \nformula_31\nFormal definition.\nThe real exponential function formula_32 can be characterized in a variety of equivalent ways. It is commonly defined by the following power series:\nformula_33\nSince the radius of convergence of this power series is infinite, this definition is, in fact, applicable to all complex numbers; see for the extension of formula_34 to the complex plane. Using the power series, the constant e can be defined as formula_35\nThe term-by-term differentiation of this power series reveals that formula_36 for all real x, leading to another common characterization of formula_34 as the unique solution of the differential equation\nformula_38\nthat satisfies the initial condition formula_39\nBased on this characterization, the chain rule shows that its inverse function, the natural logarithm, satisfies formula_40 for formula_41 or formula_42 This relationship leads to a less common definition of the real exponential function formula_34 as the solution formula_44 to the equation\nformula_45\nBy way of the binomial theorem and the power series definition, the exponential function can also be defined as the following limit:\nformula_46\nIt can be shown that every continuous, nonzero solution of the functional equation formula_47 for formula_48 is an exponential function, formula_49 with formula_50\nOverview.\nThe exponential function arises whenever a quantity grows or decays at a rate proportional to its current value. One such situation is continuously compounded interest, and in fact it was this observation that led Jacob Bernoulli in 1683 to the number\nformula_51\nnow known as \"e\". Later, in 1697, Johann Bernoulli studied the calculus of the exponential function.\nIf a principal amount of 1 earns interest at an annual rate of \"x\" compounded monthly, then the interest earned each month is times the current value, so each month the total value is multiplied by (1 + ), and the value at the end of the year is (1 + )12. If instead interest is compounded daily, this becomes (1 + )365. Letting the number of time intervals per year grow without bound leads to the limit definition of the exponential function,\nformula_52\nfirst given by Leonhard Euler.\nThis is one of a number of characterizations of the exponential function; others involve series or differential equations.\nFrom any of these definitions it can be shown that the exponential function obeys the basic exponentiation identity,\nformula_53\nwhich justifies the notation \"e\"\"x\" for exp \"x\".\nThe derivative (rate of change) of the exponential function is the exponential function itself. More generally, a function with a rate of change \"proportional\" to the function itself (rather than equal to it) is expressible in terms of the exponential function. This function property leads to exponential growth or exponential decay.\nThe exponential function extends to an entire function on the complex plane. Euler's formula relates its values at purely imaginary arguments to trigonometric functions. The exponential function also has analogues for which the argument is a matrix, or even an element of a Banach algebra or a Lie algebra.\nDerivatives and differential equations.\nThe importance of the exponential function in mathematics and the sciences stems mainly from its property as the unique function which is equal to its derivative and is equal to 1 when \"x\" = 0. That is,\nformula_54\nFunctions of the form \"ce\"\"x\" for constant \"c\" are the only functions that are equal to their derivative (by the Picard\u2013Lindel\u00f6f theorem). Other ways of saying the same thing include:\nIf a variable's growth or decay rate is proportional to its size\u2014as is the case in unlimited population growth (see Malthusian catastrophe), continuously compounded interest, or radioactive decay\u2014then the variable can be written as a constant times an exponential function of time. Explicitly for any real constant \"k\", a function \"f\": R \u2192 R satisfies \"f\"\u2032 = \"kf\" if and only if \"f\"(\"x\") = \"ce\"\"kx\" for some constant \"c\". The constant \"k\" is called the decay constant, disintegration constant, rate constant, or transformation constant.\nFurthermore, for any differentiable function \"f\", we find, by the chain rule:\nformula_55\nContinued fractions for.\nA continued fraction for \"e\"\"x\" can be obtained via an identity of Euler:\nformula_56\nThe following generalized continued fraction for \"e\"\"z\" converges more quickly:\nformula_57\nor, by applying the substitution \"z\" =:\nformula_58\nwith a special case for \"z\" = 2:\nformula_59\nThis formula also converges, though more slowly, for \"z\" &gt; 2. For example:\nformula_60\nComplex plane.\nAs in the real case, the exponential function can be defined on the complex plane in several equivalent forms. \nThe most common definition of the complex exponential function parallels the power series definition for real arguments, where the real variable is replaced by a complex one:\nformula_61\nAlternatively, the complex exponential function may be defined by modelling the limit definition for real arguments, but with the real variable replaced by a complex one:\nformula_62\nFor the power series definition, term-wise multiplication of two copies of this power series in the Cauchy sense, permitted by Mertens' theorem, shows that the defining multiplicative property of exponential functions continues to hold for all complex arguments:\nformula_63\nThe definition of the complex exponential function in turn leads to the appropriate definitions extending the trigonometric functions to complex arguments.\nIn particular, when \"z\" = \"it\" (t real), the series definition yields the expansion\nformula_64\nIn this expansion, the rearrangement of the terms into real and imaginary parts is justified by the absolute convergence of the series. The real and imaginary parts of the above expression in fact correspond to the series expansions of cos \"t\" and sin \"t\", respectively.\nThis correspondence provides motivation for defining cosine and sine for all complex arguments in terms of formula_65 and the equivalent power series:\nformula_66\nfor all formula_67\nThe functions exp, cos, and sin so defined have infinite radii of convergence by the ratio test and are therefore entire functions (that is, holomorphic on formula_68). The range of the exponential function is formula_69, while the ranges of the complex sine and cosine functions are both formula_68 in its entirety, in accord with Picard's theorem, which asserts that the range of a nonconstant entire function is either all of formula_68, or formula_68 excluding one lacunary value.\nThese definitions for the exponential and trigonometric functions lead trivially to Euler's formula:\nformula_73\nWe could alternatively define the complex exponential function based on this relationship. If \"z\" = \"x\" + \"iy\", where x and y are both real, then we could define its exponential as\nformula_74\nwhere exp, cos, and sin on the right-hand side of the definition sign are to be interpreted as functions of a real variable, previously defined by other means.\nFor formula_75, the relationship formula_76 holds, so that formula_77 for real formula_78 and formula_79 maps the real line (mod 2\"\u03c0\") to the unit circle in the complex plane. Moreover, going from formula_80 to formula_81, the curve defined by formula_82 traces a segment of the unit circle of length\nformula_83\nstarting from \"z\" = 1 in the complex plane and going counterclockwise. Based on these observations and the fact that the measure of an angle in radians is the arc length on the unit circle subtended by the angle, it is easy to see that, restricted to real arguments, the sine and cosine functions as defined above coincide with the sine and cosine functions as introduced in elementary mathematics via geometric notions.\nThe complex exponential function is periodic with period 2\"\u03c0i\" and formula_84 holds for all formula_85.\nWhen its domain is extended from the real line to the complex plane, the exponential function retains the following properties:\nformula_86\nfor all formula_87\nExtending the natural logarithm to complex arguments yields the complex logarithm log \"z\", which is a multivalued function.\nWe can then define a more general exponentiation:\nformula_88\nfor all complex numbers \"z\" and \"w\". This is also a multivalued function, even when \"z\" is real. This distinction is problematic, as the multivalued functions log \"z\" and \"z\"\"w\" are easily confused with their single-valued equivalents when substituting a real number for \"z\". The rule about multiplying exponents for the case of positive real numbers must be modified in a multivalued context:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;(\"ez\") \u2260 \"ezw\", but rather (\"ez\") = \"e\"(\"z\" + 2\"ni\u03c0\")\"w\" multivalued over integers \"n\"\nSee failure of power and logarithm identities for more about problems with combining powers.\nThe exponential function maps any line in the complex plane to a logarithmic spiral in the complex plane with the center at the origin. Two special cases exist: when the original line is parallel to the real axis, the resulting spiral never closes in on itself; when the original line is parallel to the imaginary axis, the resulting spiral is a circle of some radius.\nConsidering the complex exponential function as a function involving four real variables:\nformula_89\nthe graph of the exponential function is a two-dimensional surface curving through four dimensions.\nStarting with a color-coded portion of the formula_90 domain, the following are depictions of the graph as variously projected into two or three dimensions.\nThe second image shows how the domain complex plane is mapped into the range complex plane:\nThe third and fourth images show how the graph in the second image extends into one of the other two dimensions not shown in the second image.\nThe third image shows the graph extended along the real formula_91 axis. It shows the graph is a surface of revolution about the formula_91 axis of the graph of the real exponential function, producing a horn or funnel shape.\nThe fourth image shows the graph extended along the imaginary formula_44 axis. It shows that the graph's surface for positive and negative formula_44 values doesn't really meet along the negative real formula_92 axis, but instead forms a spiral surface about the formula_44 axis. Because its formula_44 values have been extended to \u00b12\"\u03c0\", this image also better depicts the 2\u03c0 periodicity in the imaginary formula_44 value.\nComputation of \"a\"\"b\" where both \"a\" and \"b\" are complex.\nComplex exponentiation \"a\"\"b\" can be defined by converting \"a\" to polar coordinates and using the identity (\"e\"ln \"a\") = \"a\"\"b\":\nformula_102\nHowever, when \"b\" is not an integer, this function is multivalued, because \"\u03b8\" is not unique (see failure of power and logarithm identities).\nMatrices and Banach algebras.\nThe power series definition of the exponential function makes sense for square matrices (for which the function is called the matrix exponential) and more generally in any unital Banach algebra \"B\". In this setting, \"e\"0 = 1, and \"e\"\"x\" is invertible with inverse \"e\"\u2212\"x\" for any \"x\" in \"B\". If \"xy\" = \"yx\", then \"e\"\"x\" + \"y\" = \"e\"\"x\"\"e\"\"y\", but this identity can fail for noncommuting \"x\" and \"y\".\nSome alternative definitions lead to the same function. For instance, \"e\"\"x\" can be defined as\nformula_103\nOr \"e\"\"x\" can be defined as \"f\"\"x\"(1), where \"f\"\"x\" : R \u2192 \"B\" is the solution to the differential equation (\"t\") = \"x\u200a\n f\"\"x\"(\"t\"), with initial condition \"f\"\"x\"(0) = 1; it follows that \"f\"\"x\"(\"t\") = \"e\"\"tx\" for every t in R.\nLie algebras.\nGiven a Lie group \"G\" and its associated Lie algebra formula_104, the exponential map is a map formula_104 \u21a6 \"G\" satisfying similar properties. In fact, since R is the Lie algebra of the Lie group of all positive real numbers under multiplication, the ordinary exponential function for real arguments is a special case of the Lie algebra situation. Similarly, since the Lie group GL(\"n\",R) of invertible \"n\" \u00d7 \"n\" matrices has as Lie algebra M(\"n\",R), the space of all \"n\" \u00d7 \"n\" matrices, the exponential function for square matrices is a special case of the Lie algebra exponential map.\nThe identity exp(\"x\" + \"y\") = exp \"x\" exp \"y\" can fail for Lie algebra elements \"x\" and \"y\" that do not commute; the Baker\u2013Campbell\u2013Hausdorff formula supplies the necessary correction terms.\nTranscendency.\nThe function \"e\"\"z\" is not in C(\"z\") (that is, is not the quotient of two polynomials with complex coefficients).\nIf \"a\"1, ..., \"a\"\"n\" are distinct complex numbers, then \"e\"\"a\"1\"z\", ..., \"e\"\"a\"\"n\"\"z\" are linearly independent over C(\"z\"). It follows that \"e\"\"z\" is transcendental over C(\"z\").\nComputation.\nWhen computing (an approximation of) the exponential function near the argument 0, the result will be close to 1, and computing the value of the difference formula_106 with floating-point arithmetic may lead to the loss of (possibly all) significant figures, producing a large calculation error, possibly even a meaningless result.\nFollowing a proposal by William Kahan, it may thus be useful to have a dedicated routine, often called codice_1, for computing \"ex\" \u2212 1 directly, bypassing computation of \"e\"\"x\". For example, if the exponential is computed by using its Taylor series\nformula_107\none may use the Taylor series of formula_106:\nformula_109\nThis was first implemented in 1979 in the Hewlett-Packard HP-41C calculator, and provided by several calculators, operating systems (for example Berkeley UNIX 4.3BSD), computer algebra systems, and programming languages (for example C99).\nIn addition to base \"e\", the IEEE 754-2008 standard defines similar exponential functions near 0 for base 2 and 10: formula_110 and formula_111.\nA similar approach has been used for the logarithm (see lnp1).\nAn identity in terms of the hyperbolic tangent,\nformula_112\ngives a high-precision value for small values of \"x\" on systems that do not implement expm1(\"x\").\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9679", "revid": "33501121", "url": "https://en.wikipedia.org/wiki?curid=9679", "title": "Prince Eugene of Savoy", "text": "Military commander in the service of Austria (1663\u20131736)\nPrince Eugene Francis of Savoy-Carignano, (18 October 1663 \u2013 21 April 1736) better known as Prince Eugene, was a field marshal in the army of the Holy Roman Empire and of the Austrian Habsburg dynasty during the 17th and 18th centuries. He was one of the most successful military commanders of his time, and rose to the highest offices of state at the Imperial court in Vienna.\nBorn in Paris, Eugene was brought up in the court of King Louis XIV of France. Based on the custom that the youngest sons of noble families were destined for the priesthood, the Prince was initially prepared for a clerical career, but by the age of 19, he had determined on a military career. Based on his poor physique and bearing, and perhaps due to a scandal involving his mother Olympe, he was rejected by Louis for service in the French army. Eugene moved to Austria and transferred his loyalty to the Holy Roman Empire.\nIn a career spanning six decades, Eugene served three Holy Roman Emperors: Leopold I, Joseph I, and Charles VI. His first battle experiences were fought against the Ottomans at the Siege of Vienna in 1683 and the subsequent War of the Holy League, before serving in the Nine Years' War, in which he fought alongside his cousin, the Duke of Savoy. The Prince's fame was secured with his decisive victory against the Ottomans at the Battle of Zenta in 1697, earning him Europe-wide fame. Eugene enhanced his standing during the War of the Spanish Succession, where his partnership with the Duke of Marlborough secured victories against the French on the fields of Blenheim (1704), Oudenarde (1708), and Malplaquet (1709); he gained further success in the war as Imperial commander in northern Italy, most notably at the Battle of Turin (1706). Renewed hostilities against the Ottomans in the Austro-Turkish War consolidated his reputation, with victories at the battles of Petrovaradin (1716), and the decisive encounter at the Siege of Belgrade in 1717.\nThroughout the late 1720s, Eugene's influence and skillful diplomacy managed to secure the Emperor powerful allies in his dynastic struggles with the Bourbon powers, but physically and mentally fragile in his later years, Eugene enjoyed less success as commander-in-chief of the army during his final conflict, the War of the Polish Succession. Nevertheless, in Austria, Eugene's reputation remains unrivalled. Although opinions differ as to his character, there is no dispute over his great achievements: he helped to save the Habsburg Empire from French conquest; he broke the westward thrust of the Ottomans, liberating parts of Europe after a century and a half of Turkish occupation; and he was one of the great patrons of the arts whose building legacy can still be seen in Vienna today. Eugene died in his sleep at his home on 21 April 1736, aged 72.\nEarly years (1663\u20131699).\nH\u00f4tel de Soissons.\nPrince Eugene was born at the H\u00f4tel de Soissons in Paris on 18 October 1663. His mother, Olympia Mancini, was one of Cardinal Mazarin's nieces whom the Cardinal had brought to Paris from Rome in 1647 to further his (and, to a lesser extent, their) ambitions. The Mancinis were raised at the Palais-Royal along with the young Louis XIV, with whom Olympia formed an intimate relationship. Yet to her great disappointment, her chance to become queen passed by, and in 1657, she married Eugene Maurice, Count of Soissons, Count of Dreux and Prince of Savoy.\nTogether they had had five sons (Eugene being the youngest) and three daughters, but neither parent spent much time with the children: the father, a French general officer, spent much of his time away campaigning, while Olympia's passion for court intrigue meant the children received little attention from her.\nThe King remained strongly attached to Olympia, so much so that many believed them to be lovers; but her scheming eventually led to her downfall. After falling out of favour at court, Olympia turned to Catherine Deshayes (known as \"La Voisin\"), and to the arts of black magic and astrology. It proved a fatal relationship. She became embroiled in the \"Affaire des poisons\"; suspicions abounded of her involvement in her husband's premature death in 1673, and even implicated her in a plot to kill the King himself. Whatever the truth, Olympia, rather than face trial, subsequently fled France for Brussels in January 1680, leaving Eugene in the care of his paternal grandmother, Marie de Bourbon, Countess of Soissons, and of his paternal aunt, Louise Christine of Savoy, Hereditary Princess of Baden, mother of Prince Louis of Baden.\nFrom the age of ten, Eugene had been brought up for a career in the church since he was the youngest of his family. Eugene's appearance was not impressive\u2014\"He was never good-looking \u2026\" wrote the Duchess of Orl\u00e9ans, \"It is true that his eyes are not ugly, but his nose ruins his face; he has two large teeth which are visible at all times\" According to the duchess, who was married to Louis XIV's bisexual brother, the Duke of Orl\u00e9ans, Eugene lived a life of \"debauchery\" and belonged to a small, effeminate set that included the famous cross-dresser abb\u00e9 Fran\u00e7ois-Timol\u00e9on de Choisy. In February 1683, to the surprise of his family, the 19-year-old Eugene declared his intention of joining the army. Eugene applied directly to Louis XIV for command of a company in French service, but the King\u2014who had shown no compassion for Olympia's children since her disgrace\u2014refused him out of hand. \"The request was modest, not so the petitioner\", he remarked. \"No one else ever presumed to stare me out so insolently.\" Whatever the case, Louis XIV's choice would cost him dearly twenty years later, for it would be precisely Eugene, in collaboration with the Duke of Marlborough, who would defeat the French army at Blenheim, a decisive battle which checked French military supremacy and political power.\nDenied a military career in France, Eugene decided to seek service abroad. One of Eugene's brothers, Louis Julius, had entered Imperial service the previous year, but he had been immediately killed fighting the Ottoman Empire in 1683. When news of his death reached Paris, Eugene decided to travel to Austria in the hope of taking over his brother's command. It was not an unnatural decision: his cousin, Louis of Baden, was already a leading general in the Imperial army, as was a more distant cousin, Maximilian II Emanuel, Elector of Bavaria. On the night of 26 July 1683, Eugene left Paris and headed east. Years later, in his memoirs, Eugene recalled his early years in France:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Some future historians, good or bad, will perhaps take the trouble to enter into the details of my youth, of which, I scarcely recollect anything. They will certainly speak of my mother; somewhat too intriguing, driven from the court, exiled from Paris, and suspected, I believe, of sorcery, by people who were not, themselves, very great wizards.\nThey will tell, how I was born in France then left it, my heart swelling with enmity against Louis XIV who refused me a cavalry company, because, said he, I was of too delicate a constitution; that he refused me an abbey, because (based on I don't know what ill talks about me or what invented anecdotes from the gallery of Versailles) that I was more shaped for pleasure than for piety.\nThere is not a Huguenot expelled by the revocation of the edict of Nantes who hated Louis XIV more than I did. Therefore when Louvois heard of my departure saying: \"So much the better; he will never return into this country again\" I swore never to enter it but with arms in my hands. I HAVE KEPT MY WORD.\nGreat Turkish War.\nBy May 1683, the Ottoman threat to Emperor Leopold I's capital, Vienna, was very evident. The Grand Vizier, Kara Mustafa Pasha\u2014encouraged by Imre Th\u00f6k\u00f6ly's Magyar rebellion\u2014had invaded Hungary with between 100,000 and 200,000 men; within two months approximately 90,000 were beneath Vienna's walls. With the 'Turks at the gates', the Emperor fled for the safe refuge of Passau up the Danube. It was at Leopold I's camp that Eugene arrived in mid-August.\nAlthough Eugene was not of Austrian extraction, he did have Habsburg antecedents. His grandfather, Thomas Francis, founder of the Carignano line of the House of Savoy, was the son of Catherine Michaela of Spain\u2014a daughter of Philip II of Spain\u2014and the great-grandson of the Emperor Charles V. But of more immediate consequence to Leopold I was the fact that Eugene was the second cousin of Victor Amadeus II, the Duke of Savoy, a connection that the Emperor hoped might prove useful in any future confrontation with France. These ties, together with his ascetic manner and appearance (a positive advantage to him at the sombre court of Leopold I), ensured the refugee from the hated French king a warm welcome at Passau, and a position in Imperial service. Though French was his favored language, he communicated with Leopold in Italian, as the Emperor (though he knew it perfectly) disliked French. But Eugene also had a reasonable command of German, which he understood very easily, something that helped him much in the military.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I will devote all my strength, all my courage, and if need be, my last drop of blood, to the service of your Imperial Majesty.\nEugene had no doubt as to where his new allegiance lay, and this loyalty was immediately put to the test. By September, the Imperial forces under the Duke of Lorraine, together with a powerful Polish army under King John III Sobieski, were poised to strike the Sultan's army. On the morning of 12 September, the Christian forces drew up in line of battle on the south-eastern slopes of the Vienna Woods, looking down on the massed enemy camp. The day-long Battle of Vienna resulted in the lifting of the 60-day siege, and the Sultan's forces were routed. Serving under Baden, as a twenty-year-old volunteer, Eugene distinguished himself in the battle, earning commendation from Lorraine and the Emperor; he later received the nomination for the colonelcy and was awarded the Kufstein regiment of dragoons by Leopold I.\nHoly League.\nIn March 1684, Leopold I formed the Holy League with Poland and Venice to counter the Ottoman threat. For the next two years, Eugene continued to perform with distinction on campaign and establish himself as a dedicated, professional soldier; by the end of 1685, still only 22 years old, he was made a Major-General. Little is known of Eugene's life during these early campaigns. Contemporary observers make only passing comments of his actions, and his own surviving correspondence, largely to his cousin Victor Amadeus, are typically reticent about his own feelings and experiences. Nevertheless, it is clear that Baden was impressed with Eugene's qualities\u2014\"This young man will, with time, occupy the place of those whom the world regards as great leaders of armies.\"\nIn June 1686, the Duke of Lorraine besieged Buda (Budapest), the centre of the Ottoman occupation in Hungary. After resisting for 78 days, the city fell on 2 September, and Turkish resistance collapsed throughout the region as far away as Transylvania and Serbia. Further success followed in 1687, where, commanding a cavalry brigade, Eugene made an important contribution to the victory at the Battle of Moh\u00e1cs on 12 August. Such was the scale of their defeat that the Ottoman army mutinied\u2014a revolt which spread to Constantinople. The Grand Vizier, Sar\u0131 S\u00fcleyman Pasha, was executed and Sultan Mehmed IV, deposed. Once again, Eugene's courage earned him recognition from his superiors, who granted him the honour of personally conveying the news of victory to the Emperor in Vienna. For his services, Eugene was promoted to Lieutenant-General in November 1687. He was also gaining wider recognition. King Charles II of Spain bestowed upon him the Order of the Golden Fleece, while his cousin, Victor Amadeus, provided him with money and two profitable abbeys in Piedmont. Eugene's military career suffered a temporary setback in 1688 when, on 6 September, the Prince suffered a severe wound to his knee by a musket ball during the Siege of Belgrade, and did not return to active service until January 1689.\nInterlude in the west: Nine Years' War.\nJust as Belgrade was falling to Imperial forces under Max Emmanuel in the east, French troops in the west were crossing the Rhine into the Holy Roman Empire. Louis XIV had hoped that a show of force would lead to a quick resolution to his dynastic and territorial disputes with the princes of the Empire along his eastern border, but his intimidatory moves only strengthened German resolve, and in May 1689, Leopold I and the Dutch signed an offensive compact aimed at repelling French aggression.\nThe Nine Years' War was professionally and personally frustrating for the prince. Initially fighting on the Rhine with Max Emmanuel\u2014receiving a slight head wound at the Siege of Mainz in 1689\u2014Eugene subsequently transferred himself to Piedmont after Victor Amadeus joined the Alliance against France in 1690. Promoted to general of cavalry, he arrived in Turin with his friend the Prince of Commercy; but it proved an inauspicious start. Against Eugene's advice, Amadeus insisted on engaging the French at Staffarda and suffered a serious defeat\u2014only Eugene's handling of the Savoyard cavalry in retreat saved his cousin from disaster. Eugene remained unimpressed with the men and their commanders throughout the war in Italy. \"The enemy would long ago have been beaten,\" he wrote to Vienna, \"if everyone had done their duty.\" So contemptuous was he of the Imperial commander, Count Caraffa, he threatened to leave Imperial service.\nIn Vienna, Eugene's attitude was dismissed as the arrogance of a young upstart, but so impressed was the Emperor by his passion for the Imperial cause, he promoted him to Field-Marshal in 1693. When Caraffa's replacement, Count Caprara, was himself transferred in 1694, it seemed that Eugene's chance for command and decisive action had finally arrived. But Amadeus, doubtful of victory and now more fearful of Habsburg influence in Italy than he was of French, had begun secret dealings with Louis XIV aimed at extricating himself from the war. By 1696, the deal was done, and Amadeus transferred his troops and his loyalty to the enemy. Eugene was never to fully trust his cousin again; although he continued to pay due reverence to the Duke as head of his family, their relationship would forever after remain strained.\nMilitary honours in Italy undoubtedly belonged to the French commander Marshal Catinat, but Eugene, the one Allied general determined on action and decisive results, did well to emerge from the Nine Years' War with an enhanced reputation. With the signing of the Treaty of Ryswick in September/October 1697, the desultory war in the west was finally brought to an inconclusive end, and Leopold I could once again devote all his martial energies into defeating the Ottoman Turks in the east.\nBattle of Zenta.\nThe distractions of the war against Louis XIV had enabled the Turks to recapture Belgrade in 1690. In August 1691, the Austrians, under Louis of Baden, regained the advantage by heavily defeating the Turks at the Battle of Slankamen on the Danube, securing Habsburg possession of Hungary and Transylvania. When Baden was transferred west to fight the French in 1692, his successors, first Caprara, then from 1696, Frederick Augustus, the Elector of Saxony, proved incapable of delivering the final blow. On the advice of the President of the Imperial War Council, Ernst R\u00fcdiger von Starhemberg, thirty-four-year old Eugene was offered supreme command of Imperial forces in April 1697. This was Eugene's first truly independent command\u2014no longer need he suffer under the excessively cautious generalship of Caprara and Caraffa, or be thwarted by the deviations of Victor Amadeus. But on joining his army, he found it in a state of 'indescribable misery'. Confident and self-assured, the Prince of Savoy (ably assisted by Commercy and Guido Starhemberg) set about restoring order and discipline.\nLeopold I had warned Eugene that \"he should act with extreme caution, forgo all risks and avoid engaging the enemy unless he has overwhelming strength and is practically certain of being completely victorious\", but when the Imperial commander learnt of Sultan Mustafa II's march on Transylvania, Eugene abandoned all ideas of a defensive campaign and moved to intercept the Turks as they crossed the River Tisza at Zenta on 11 September 1697.\nIt was late in the day before the Imperial army struck. The Ottoman cavalry had already crossed the river so Eugene decided to attack immediately, arranging his men in a half-moon formation. The vigour of the assault wrought terror and confusion amongst the Turks, and by nightfall, the battle was won. For the loss of some 2,000 dead and wounded, Eugene had inflicted an overwhelming defeat upon the enemy with approximately 25,000 Turks killed\u2014including the Grand Vizier, Elmas Mehmed Pasha, the pashas of Adana, Anatolia, and Bosnia, plus more than thirty aghas of the Janissaries, sipahis, and silihdars, as well as seven horsetails (symbols of high authority), 100 pieces of heavy artillery, 423 banners, and the revered seal which the sultan always entrusted to the Grand Vizier on an important campaign, Eugene had annihilated the Ottoman army and brought to an end the War of the Holy League. Although the Ottomans lacked western organisation and training, the Savoyard prince had revealed his tactical skill, his capacity for bold decision, and his ability to inspire his men to excel in battle against a dangerous foe.\nAfter a brief terror-raid into Ottoman Bosnia, culminating in the sack of Sarajevo, Eugene returned to Vienna in November to a triumphal reception. His victory at Zenta had turned him into a European hero, and with victory came reward. Land in Hungary, given him by the Emperor, yielded a good income, enabling the Prince to cultivate his newly acquired tastes in art and architecture (see below); but for all his new-found wealth and property, he was, nevertheless, without personal ties or family commitments. Of his four brothers, only one was still alive at this time. His fourth brother, Emmanuel, had died aged 14 in 1676; his third, Louis Julius (already mentioned) had died on active service in 1683, and his second brother, Philippe, died of smallpox in 1693. Eugene's remaining brother, Louis Thomas\u2014ostracised for incurring the displeasure of Louis XIV\u2014travelled Europe in search of a career, before arriving in Vienna in 1699. With Eugene's help, Louis found employment in the Imperial army, only to be killed in action against the French in 1702. Of Eugene's sisters, the youngest had died in childhood. The other two, Marie Jeanne-Baptiste and Louise Philiberte, led dissolute lives. Expelled from France, Marie joined her mother in Brussels, before eloping with a renegade priest to Geneva, living with him unhappily until her premature death in 1705. Of Louise, little is known after her early salacious life in Paris, but in due course, she lived for a time in a convent in Savoy before her death in 1726.\nThe Battle of Zenta proved to be the decisive victory in the long war against the Turks. With Leopold I's interests now focused on Spain and the imminent death of Charles II, the Emperor terminated the conflict with the Sultan; he signed the Treaty of Karlowitz on 26 January 1699.\nMiddle life (1700\u201320).\nWar of the Spanish Succession.\nWith the death of the infirm and childless Charles II of Spain on 1 November 1700, the succession of the Spanish throne and subsequent control over her empire once again embroiled Europe in war\u2014the War of the Spanish Succession. On his deathbed Charles II had bequeathed the entire Spanish inheritance to Louis XIV's grandson, Philip, Duke of Anjou. This threatened to unite the Spanish and French kingdoms under the House of Bourbon\u2014something unacceptable to England, the Dutch Republic, and Leopold I, who had himself a claim to the Spanish throne. From the beginning, the Emperor had refused to accept the will of Charles II, and he did not wait for England and the Dutch Republic to begin hostilities. Before a new Grand Alliance could be concluded Leopold I prepared to send an expedition to seize the Spanish lands in Italy.\nEugene crossed the Alps with some 30,000 men in May/June 1701. After a series of brilliant manoeuvres the Imperial commander defeated Catinat at the Battle of Carpi on 9 July. \"I have warned you that you are dealing with an enterprising young prince,\" wrote Louis XIV to his commander, \"he does not tie himself down to the rules of war.\" On 1 September Eugene defeated Catinat's successor, Marshal Villeroi, at the Battle of Chiari, in a clash as destructive as any in the Italian theatre. But as so often throughout his career the Prince faced war on two fronts\u2014the enemy in the field and the government in Vienna.\nStarved of supplies, money, and men, Eugene was forced into unconventional means against the vastly superior enemy. During a daring raid on Cremona on the night of 31 January/1 February 1702 Eugene captured the French commander-in-chief. Yet the coup was less successful than hoped: Cremona remained in French hands, and the Duke of Vend\u00f4me, whose talents far exceeded Villeroi's, became the theatre's new commander. Villeroi's capture caused a sensation in Europe and had a galvanising effect on English public opinion. \"The surprise at Cremona,\" wrote the diarist John Evelyn, \"\u2026 was the great discourse of this week\"; but appeals for succour from Vienna remained unheeded, forcing Eugene to seek battle and gain a 'lucky hit'. The resulting Battle of Luzzara on 15 August proved inconclusive. Although Eugene's forces inflicted double the number of casualties on the French the battle settled little except to deter Vend\u00f4me trying an all-out assault on Imperial forces that year, enabling Eugene to hold on south of the Alps. With his army rotting away, and personally grieving for his long-standing friend Prince Commercy who had died at Luzzara, Eugene returned to Vienna in January 1703.\nPresident of the Imperial War Council.\nEugene's European reputation was growing (Cremona and Luzzara had been celebrated as victories throughout the Allied capitals), yet because of the condition and morale of his troops the 1702 campaign had not been a success. Austria itself was now facing the direct threat of invasion from across the border in Bavaria where the state's Elector, Maximilian Emanuel, had declared for the Bourbons in August the previous year. Meanwhile, in Hungary a small-scale revolt had broken out in May and was fast gaining momentum. With the monarchy at the point of complete financial breakdown Leopold I was at last persuaded to change the government. At the end of June 1703 Gundaker Starhemberg replaced Gotthard Salaburg as President of the Treasury, and Prince Eugene succeeded Henry Mansfeld as the new President of the Imperial War Council (\"Hofkriegsratspr\u00e4sident\").\nAs head of the war council Eugene was now part of the Emperor's inner circle, and the first president since Raimondo Montecuccoli to remain an active commander. Immediate steps were taken to improve efficiency within the army: encouragement and, where possible, money, was sent to the commanders in the field; promotion and honours were distributed according to service rather than influence; and discipline improved. But the Austrian monarchy faced severe peril on several fronts in 1703: by June the Duke of Villars had reinforced the Elector of Bavaria on the Danube thus posing a direct threat to Vienna, while Vend\u00f4me remained at the head of a large army in northern Italy opposing Guido Starhemberg's weak Imperial force. Of equal alarm was Francis II R\u00e1k\u00f3czi's revolt which, by the end of the year, had reached as far as Moravia and Lower Austria.\nBlenheim.\nDissension between Villars and the Elector of Bavaria had prevented an assault on Vienna in 1703, but in the Courts of Versailles and Madrid, ministers confidently anticipated the city's fall. The Imperial ambassador in London, Count Wratislaw, had pressed for Anglo-Dutch assistance on the Danube as early as February 1703, but the crisis in southern Europe seemed remote from the Court of St. James's where colonial and commercial considerations were more to the fore of men's minds. Only a handful of statesmen in England or the Dutch Republic realised the true implications of Austria's peril; foremost amongst these was the English Captain-General, the Duke of Marlborough.\nBy early 1704 Marlborough had resolved to march south and rescue the situation in southern Germany and on the Danube, personally requesting the presence of Eugene on campaign so as to have \"a supporter of his zeal and experience\". The Allied commanders met for the first time at the small village of Mundelsheim on 10 June, and immediately formed a close rapport\u2014the two men becoming, in the words of Thomas Lediard, 'Twin constellations in glory'. This professional and personal bond ensured mutual support on the battlefield, enabling many successes during the Spanish Succession war. The first of these victories, and the most celebrated, came on 13 August 1704 at the Battle of Blenheim. Eugene commanded the right wing of the Allied army, holding the Elector of Bavaria's and Marshal Marsin's superior forces, while Marlborough broke through the Marshal Tallard's center, inflicting over 30,000 casualties. The battle proved decisive: Vienna was saved and Bavaria was knocked out of the war. Both Allied commanders were full of praise for each other's performance. Eugene's holding operation, and his pressure for action leading up to the battle, proved crucial for the Allied success.\nIn Europe Blenheim is regarded as much a victory for Eugene as it is for Marlborough, a sentiment echoed by Sir Winston Churchill (Marlborough's descendant and biographer), who pays tribute to \"the glory of Prince Eugene, whose fire and spirit had exhorted the wonderful exertions of his troops.\" France now faced the real danger of invasion, but Leopold I in Vienna was still under severe strain: R\u00e1k\u00f3czi's revolt was a major threat; and Guido Starhemberg and Victor Amadeus (who had once again switched loyalties and rejoined the Grand Alliance in 1703) had been unable to halt the French under Vend\u00f4me in northern Italy. Only Amadeus' capital, Turin, held on.\nTurin and Toulon.\nEugene returned to Italy in April 1705, but his attempts to move west towards Turin were thwarted by Vend\u00f4me's skillful manoeuvres. Lacking boats and bridging materials, and with desertion and sickness rife within his army, the outnumbered Imperial commander was helpless. Leopold I's assurances of money and men had proved illusory, but desperate appeals from Amadeus and criticism from Vienna goaded the Prince into action, resulting in the Imperialists' bloody defeat at the Battle of Cassano on 16 August. Following Leopold I's death and the accession of Joseph I to the Imperial throne in May 1705, Eugene began to receive the personal backing he desired. Joseph I proved to be a strong supporter of Eugene's supremacy in military affairs; he was the most effective emperor the Prince served and the one he was happiest under. Promising support, Joseph I persuaded Eugene to return to Italy and restore Habsburg honour.\nThe Imperial commander arrived in theatre in mid-April 1706, just in time to organise an orderly retreat of what was left of Count Reventlow's inferior army following his defeat by Vend\u00f4me at the Battle of Calcinato on 19 April. Vend\u00f4me now prepared to defend the lines along the River Adige, determined to keep Eugene cooped to the east while the Marquis of La Feuillade threatened Turin. Feigning attacks along the Adige, Eugene descended south across the river Po in mid-July, outmanoeuvring the French commander and gaining a favourable position from which he could at last move west towards Piedmont and relieve Savoy's capital.\nEvents elsewhere now had major consequences for the war in Italy. With Villeroi's crushing defeat by Marlborough at the Battle of Ramillies on 23 May, Louis XIV recalled Vend\u00f4me north to take command of French forces in Flanders. It was a transfer that Saint-Simon considered something of a deliverance for the French commander who was \"now beginning to feel the unlikelihood of success (in Italy) \u2026 for Prince Eugene, with the reinforcements that had joined him after the Battle of Calcinato, had entirely changed the outlook in that theatre of the war.\" The Duke of Orl\u00e9ans, under the direction of Marsin, replaced Vend\u00f4me, but indecision and disorder in the French camp led to their undoing. After uniting his forces with Victor Amadeus at Villastellone in early September, Eugene attacked, overwhelmed, and decisively defeated the French forces besieging Turin on 7 September. Eugene's success broke the French hold on northern Italy, and the whole Po valley fell under Allied control. Eugene had gained a victory as signal as his colleague had at Ramillies\u2014\"It is impossible for me to express the joy it has given me;\" wrote Marlborough, \"for I not only esteem but I really love the prince. This glorious action must bring France so low, that if our friends could but be persuaded to carry on the war with vigour one year longer, we cannot fail, with the blessing of God, to have such a peace as will give us quiet for all our days.\"\nThe Imperial victory in Italy marked the beginning of Austrian rule in Lombardy, and earned Eugene the Governorship of Milan. But the following year was to prove a disappointment for the Prince and the Grand Alliance as a whole. The Emperor and Eugene (whose main goal after Turin was to take Naples and Sicily from Philip duc d'Anjou's supporters), reluctantly agreed to Marlborough's plan for an attack on Toulon\u2014the seat of French naval power in the Mediterranean. Disunion between the Allied commanders\u2014Victor Amadeus, Eugene, and the English Admiral Cloudesley Shovell\u2014doomed the Toulon enterprise to failure. Although Eugene favoured some sort of attack on France's south-eastern border it was clear he felt the expedition impractical, and showed none of the \"alacrity which he had displayed on other occasions.\" Substantial French reinforcements finally brought an end to the venture, and on 22 August 1707, the Imperial army began its retirement. The subsequent capture of Susa could not compensate for the total collapse of the Toulon expedition and with it any hope of an Allied war-winning blow that year.\nOudenarde and Malplaquet.\nAt the beginning of 1708 Eugene successfully evaded calls for him to take charge in Spain (in the end Guido Starhemberg was sent), thus enabling him to take command of the Imperial army on the Moselle and once again unite with Marlborough in the Spanish Netherlands. Eugene (without his army) arrived at the Allied camp at Assche, west of Brussels, in early July, providing a welcome boost to morale after the early defection of Bruges and Ghent to the French. \" \u2026 our affairs improved through God's support and Eugene's aid,\" wrote the Prussian General Natzmer, \"whose timely arrival raised the spirits of the army again and consoled us.\" Heartened by the Prince's confidence the Allied commanders devised a bold plan to engage the French army under Vend\u00f4me and the Duke of Burgundy. On 10 July the Anglo-Dutch army made a forced march to surprise the French, reaching the River Scheldt just as the enemy was crossing to the north. The ensuing battle on 11 July\u2014more a contact action rather than a set-piece engagement\u2014ended in a resounding success for the Allies, aided by the dissension of the two French commanders. While Marlborough remained in overall command, Eugene had led the crucial right flank and centre. Once again the Allied commanders had co-operated remarkably well. \"Prince Eugene and I,\" wrote the Duke, \"shall never differ about our share of the laurels.\"\nMarlborough now favoured a bold advance along the coast to bypass the major French fortresses, followed by a march on Paris. But fearful of unprotected supply-lines, the Dutch and Eugene favoured a more cautious approach. Marlborough acquiesced and resolved upon the siege of Vauban's great fortress, Lille. While the Duke commanded the covering force, Eugene oversaw the siege of the town which surrendered on 22 October but Marshal Boufflers did not yield the citadel until 10 December. Yet for all the difficulties of the siege (Eugene was badly wounded above his left eye by a musket ball, and even survived an attempt to poison him), the campaign of 1708 had been a remarkable success. The French were driven out of almost all the Spanish Netherlands. \"He who has not seen this,\" wrote Eugene, \"has seen nothing.\"\nThe recent defeats, together with the severe winter of 1708\u201309, had caused extreme famine and privation in France. Louis XIV was close to accepting Allied terms, but the conditions demanded by the leading Allied negotiators, Anthonie Heinsius, Charles Townshend, Marlborough, and Eugene\u2014principally that Louis XIV should use his own troops to force Philip V off the Spanish throne\u2014proved unacceptable to the French. Neither Eugene nor Marlborough had objected to the Allied demands at the time, but neither wanted the war with France to continue, and would have preferred further talks to deal with the Spanish issue. But the French King offered no further proposals. Lamenting the collapse of the negotiations, and aware of the vagaries of war, Eugene wrote to the Emperor in mid-June 1709. \"There can be no doubt that the next battle will be the biggest and bloodiest that has yet been fought.\"\nAfter the fall of Tournai on 3 September (itself a major undertaking), the Allied generals turned their attention towards Mons. Marshal Villars, recently joined by Boufflers, moved his army south-west of the town and began to fortify his position. Marlborough and Eugene favoured an engagement before Villars could render his position impregnable; but they also agreed to wait for reinforcements from Tournai which did not arrive until the following night, thus giving the French further opportunity to prepare their defences. Notwithstanding the difficulties of the attack, the Allied generals did not shrink from their original determination. The subsequent Battle of Malplaquet, fought on 11 September 1709, was the bloodiest engagement of the war. On the left flank, the Prince of Orange led his Dutch infantry in desperate charges only to have it cut to pieces; on the other flank, Eugene attacked and suffered almost as severely. But sustained pressure on his extremities forced Villars to weaken his centre, thus enabling Marlborough to breakthrough and claim victory. Villars was unable to save Mons, which subsequently capitulated on 21 October, but his resolute defence at Malplaquet\u2014inflicting up to 25% casualties on the Allies\u2014may have saved France from destruction.\nFinal campaigning: Eugene alone.\nIn August 1709 Eugene's chief political opponent and critic in Vienna, Prince Salm, retired as court chamberlain. Eugene and Wratislaw were now the undisputed leaders of the Austrian government: all major departments of state were in their hands or those of their political allies. Another attempt at a negotiated settlement at Geertruidenberg in April 1710 failed, largely because the English Whigs still felt strong enough to refuse concessions, while Louis XIV saw little reason to accept what he had refused the previous year. Eugene and Marlborough could not be accused of wrecking the negotiations, but neither showed regret at the breakdown of the talks. There was no alternative but to continue the war, and in June the Allied commanders captured Douai. This success was followed by a series of minor sieges, and by the close of 1710 the Allies had cleared much of France's protective ring of fortresses. Yet there had been no final, decisive breakthrough, and this was to be the last year that Eugene and Marlborough would work together.\nFollowing the death of Joseph I on 17 April 1711 his brother, Charles, the pretender to the Spanish throne, became emperor. In England the new Tory government (the 'peace party' who had deposed the Whigs in October 1710) declared their unwillingness to see Charles VI become Emperor as well as King of Spain, and had already begun secret negotiations with the French. In January 1712 Eugene arrived in England hoping to divert the government away from its peace policy, but despite the social success the visit was a political failure: Queen Anne and her ministers remained determined to end the war regardless of the Allies. Eugene had also arrived too late to save Marlborough who, seen by the Tories as the main obstacle to peace, had already been dismissed on charges of embezzlement. Elsewhere the Austrians had made some progress\u2014the Hungarian revolt had finally came to end. Although Eugene would have preferred to crush the rebels the Emperor had offered lenient conditions, leading to the signing of the Treaty of Szatm\u00e1r on 30 April 1711.\nHoping to influence public opinion in England and force the French into making substantial concessions, Eugene prepared for a major campaign. But on 21 May 1712\u2014when the Tories felt they had secured favourable terms with their unilateral talks with the French\u2014the Duke of Ormonde (Marlborough's successor) received the so-called 'restraining orders', forbidding him to take part in any military action. Eugene took the fortress of Le Quesnoy in early July, before besieging Landrecies, but Villars, taking advantage of Allied disunity, outmanoeuvred Eugene and defeated the Earl of Albermarle's Dutch garrison at the Battle of Denain on 24 July. The French followed the victory by seizing the Allies' main supply magazine at Marchiennes, before reversing their earlier losses at Douai, Le Quesnoy and Bouchain. In one summer the whole forward Allied position laboriously built up over the years to act as the springboard into France had been precipitously abandoned.\nWith the death in December of his friend and close political ally, Count Wratislaw, Eugene became undisputed 'first minister' in Vienna. His position was built on his military successes, but his actual power was expressed through his role as president of the war council, and as \"de facto\" president of the conference which dealt with foreign policy. In this position of influence Eugene took the lead in pressing Charles VI towards peace. The government had come to accept that further war in the Netherlands or Spain was impossible without the aid of the Maritime Powers; yet the Emperor, still hoping that somehow he could place himself on the throne in Spain, refused to make peace at the Utrecht conference along with the other Allies. Reluctantly, Eugene prepared for another campaign, but lacking troops, finance, and supplies his prospects in 1713 were poor. Villars, with superior numbers, was able to keep Eugene guessing as to his true intent. Through successful feints and stratagems Landau fell to the French commander in August, followed in November by Freiburg. Eugene was reluctant to carry on the war, and wrote to the Emperor in June that a bad peace would be better than being 'ruined equally by friend and foe'. With Austrian finances exhausted and the German states reluctant to continue the war, Charles VI was compelled to enter into negotiations. Eugene and Villars (who had been old friends since the Turkish campaigns of the 1680s) initiated talks on 26 November. Eugene proved an astute and determined negotiator, and gained favourable terms by the Treaty of Rastatt signed on 7 March 1714 and the Treaty of Baden signed on 7 September 1714. Despite the failed campaign in 1713 the Prince was able to declare that, \"in spite of the military superiority of our enemies and the defection of our Allies, the conditions of peace will be more advantageous and more glorious than those we would have obtained at Utrecht.\"\nAustro-Turkish War.\nEugene's main reason for desiring peace in the west was the growing danger posed by the Turks in the east. Turkish military ambitions had revived after 1711 when they had mauled Peter the Great's army on the River Pruth (Pruth River Campaign): in December 1714 Sultan Ahmed III's forces attacked the Venetians in the Morea. To Vienna it was clear that the Turks intended to attack Hungary and undo the whole Karlowitz settlement of 1699. After the Sublime Porte rejected an offer of mediation in April 1716, Charles VI despatched Eugene to Hungary to lead his relatively small but professional army. Of all Eugene's wars this was the one in which he exercised most direct control; it was also a war which, for the most part, Austria fought and won on her own.Eugene left Vienna in early June 1716 with a field army of between 80,000 and 90,000 men. By early August 1716 the Ottoman Turks, some 200,000 men under the sultan's son-in-law, the Grand Vizier Damat Ali Pasha, were marching from Belgrade towards Eugene's position on the north bank of the Danube west of the fortress of Petrovaradin. The Grand Vizier had intended to seize the fortress; but Eugene gave him no chance to do so. After resisting calls for caution and forgoing a council of war, the Prince decided to attack immediately on the morning of 5 August with approximately 70,000 men. The Turkish janissaries had some initial success, but after an Imperial cavalry attack on their flank, Ali Pasha's forces fell into confusion. Although the Imperials lost almost 5,000 dead or wounded, the Turks, who retreated in disorder to Belgrade, seem to have lost double that amount, including the Grand Vizier himself who had entered the m\u00eal\u00e9e and subsequently died of his wounds.\nEugene proceeded to take the Banat fortress of Timi\u0219oara (Temeswar in German, from its original name in Hungarian, Temesv\u00e1r) in mid-October 1716 (thus ending 164 years of Turkish rule), before turning his attention to the next campaign and to what he considered the main goal of the war, Belgrade. Situated at the confluence of the Rivers Danube and Sava, Belgrade held a garrison of 30,000 men under Serasker Mustapha Pasha.\nImperial troops besieged the place in mid-June 1717, and by the end of July large parts of the city had been destroyed by artillery fire. By the first days of August, however, a huge Turkish field army (150,000\u2013200,000 strong), under the new Grand Vizier Hac\u0131 Halil Pasha had arrived on the plateau east of the city to relieve the garrison. News spread through Europe of Eugene's imminent destruction; but he had no intention of lifting the siege. With his men suffering from dysentery, and continuous bombardment from the plateau, Eugene, aware that a decisive victory alone could extricate his army, decided to attack the relief force. On the morning of 16 August, 40,000 Imperial troops marched through the fog, caught the Turks unaware, and routed Halil Pasha's army; a week later Belgrade surrendered, effectively bringing an end to the war. The victory was the crowning point of Eugene's military career and had confirmed him as the leading European general. His ability to snatch victory at the moment of defeat had shown the prince at his best.\nThe principal objectives of the war had been achieved: the task Eugene had begun at Zenta was complete, and the Karlowitz settlement secured. By the terms of the Treaty of Passarowitz, signed on 21 July 1718, the Turks surrendered the Banat of Temeswar, along with Belgrade and most of Serbia, although they regained the Morea from the Venetians. The war had dispelled the immediate Turkish threat to Hungary and was a triumph for the Empire and for Eugene personally.\nQuadruple Alliance.\nWhile Eugene fought the Turks in the east, unresolved issues following the Utrecht/Rastatt settlements led to hostilities between the Emperor and Philip V of Spain in the west. Charles VI had refused to recognise Philip V as King of Spain, a title which he himself claimed; in return, Philip V had refused to renounce his claims to Naples, Milan, and the Netherlands, all of which had transferred to the House of Austria following the Spanish Succession war. Philip V was roused by his influential wife, Elisabeth Farnese, daughter of the Hereditary Prince of Parma, who personally held dynastic claims in the name of her son, Charles, to the duchies of Tuscany, Parma and Piacenza. Representatives from a newly formed Anglo-French alliance\u2014who were desirous of European peace for their own dynastic securities and trade opportunities\u2014called on both parties to recognise each other's sovereignty. Yet Philip V remained intractable, and on 22 August 1717 his chief minister, Alberoni, effected the invasion of Austrian Sardinia in what seemed like the beginning of the reconquest of Spain's former Italian empire.\nEugene returned to Vienna from his recent victory at Belgrade (before the conclusion of the Turkish war) determined to prevent an escalation of the conflict, complaining that, \"two wars cannot be waged with one army\"; only reluctantly did the Prince release some troops from the Balkans for the Italian campaign. Rejecting all diplomatic overtures Philip V unleashed another assault in June 1718, this time against Savoyard Sicily as a preliminary to attacking the Italian mainland. Realising that only the British fleet could prevent further Spanish landings, and that pro-Spanish groups in France might push the regent, Duke of Orl\u00e9ans, into war against Austria, Charles VI had no option but to sign the Quadruple Alliance on 2 August 1718, and formally renounce his claim to Spain. Despite the Spanish fleet's destruction off Cape Passaro, Philip V and Elisabeth remained resolute, and rejected the treaty.\nAlthough Eugene could have gone south after the conclusion of the Turkish war, he chose instead to conduct operations from Vienna; but Austria's military effort in Sicily proved derisory, and Eugene's chosen commanders, Zum Jungen, and later Count Mercy, performed poorly. It was only from pressure exerted by the French army advancing into the Basque provinces of northern Spain in April 1719, and the British Navy's attacks on the Spanish fleet and shipping, that compelled Philip V and Elisabeth to dismiss Alberoni and join the Quadruple Alliance on 25 January 1720. Nevertheless, the Spanish attacks had strained Charles VI's government, causing tension between the Emperor and his Spanish Council on the one hand, and the conference, headed by Eugene, on the other. Despite Charles VI's own personal ambitions in the Mediterranean it was clear to the Emperor that Eugene had put the safeguarding of his conquests in Hungary before everything else, and that military failure in Sicily also had to rest on Eugene. Consequently, the Prince's influence over the Emperor declined considerably.\nLater life (1721\u201336).\nGovernor-General of the Austrian Netherlands.\nEugene had become governor of the Austrian Netherlands\u2014in June 1716, but he was an absent ruler, directing policy from Vienna through his chosen representative the Marquis of Pri\u00e9. Pri\u00e9 proved unpopular with the local population and the guilds who, following the Barrier Treaty of 1715, were obliged to meet the financial demands of the administration and the Dutch barrier garrisons; with Eugene's backing and encouragement, civil disturbances in Antwerp and Brussels were forcibly suppressed. After displeasing the Emperor over his initial opposition to the formation of the Ostend Company, Pri\u00e9 also lost the support of the native nobility from within his own council of state in Brussels, particularly from the Marquis de M\u00e9rode-Westerloo. One of Eugene's former favourites, General Bonneval, also joined the noblemen in opposition to Pri\u00e9, further undermining the Prince. When Pri\u00e9's position became untenable, Eugene felt compelled to resign his post as governor of the Austrian Netherlands on 16 November 1724. As compensation, Charles VI conferred on him the honorary position as vicar-general of Italy, worth 140,000 gulden a year, and an estate at Siebenbrunn in Lower Austria said to be worth double that amount. But his resignation distressed him, and to compound his concerns Eugene caught a severe bout of influenza that Christmas, marking the beginning of permanent bronchitis and acute infections every winter for the remaining twelve years of his life.\n'Cold war'.\nThe 1720s saw rapidly changing alliances between the European powers and almost constant diplomatic confrontation, largely over unsolved issues regarding the Quadruple Alliance. The Emperor and the Spanish King continued to use each other's titles, and Charles VI still refused to remove the remaining legal obstacles to Don Charles' eventual succession to the duchies of Parma and Tuscany. Yet in a surprise move Spain and Austria moved closer with the signing of the Treaty of Vienna in April/May 1725. In response Britain, France, and Prussia joined together in the Alliance of Hanover to counter the danger to Europe of an Austro-Spanish hegemony. For the next three years there was the continual threat of war between the Hanover Treaty powers and the Austro-Spanish bloc.\nFrom 1726 Eugene gradually began to regain his political influence. With his many contacts throughout Europe Eugene, backed by Gundaker Starhemberg and Count Sch\u00f6nborn, the Imperial vice-chancellor, managed to secure powerful allies and strengthen the Emperor's position\u2014his skill in managing the vast secret diplomatic network over the coming years was the main reason why Charles VI once again came to depend upon him. In August 1726 Russia acceded to the Austro-Spanish alliance, and in October Frederick William of Prussia followed suit by defecting from the Allies with the signing of a mutual defensive treaty with the Emperor.\nDespite the conclusion of the brief Anglo-Spanish conflict, manoeuvring between the European powers persisted throughout 1727\u201328. In 1729 Elisabeth Farnese abandoned the Austro-Spanish alliance. Realizing that Charles VI could not be drawn into the marriage pact she wanted, Elisabeth concluded that the best way to secure her son's succession to Parma and Tuscany now lay with Britain and France. To Eugene it was 'an event that which is seldom to be found in history'. Following the Prince's determined lead to resist all pressure, Charles VI sent troops into Italy to prevent the entry of Spanish garrisons into the contested duchies. By the beginning of 1730 Eugene, who had remained bellicose throughout the whole period, was again in control of Austrian policy.\nIn Britain there now emerged a new political re-alignment as the Anglo-French \"entente\" became increasingly defunct. Believing that a resurgent France now posed the greatest danger to their security British ministers, headed by Robert Walpole, moved to reform the Anglo-Austrian alliance, leading to the signing of the Second Treaty of Vienna on 16 March 1731. Eugene had been the Austrian minister most responsible for the alliance, believing once again it would provide security against France and Spain. The treaty compelled Charles VI to sacrifice the Ostend Company and accept, unequivocally, the accession of Don Charles to Parma and Tuscany. In return King George II as King of Great Britain and Elector of Hanover guaranteed the Pragmatic Sanction, the device to secure the rights of the Emperor's daughter, Maria Theresa, to the entire Habsburg inheritance. It was largely through Eugene's diplomacy that in January 1732 the Imperial diet also guaranteed the Pragmatic Sanction which, together with the Treaties with Britain, Russia, and Prussia, marked the culmination of the Prince's diplomacy. But the Treaty of Vienna had infuriated the court of King Louis XV: the French had been ignored and the Pragmatic Sanction guaranteed, thus increasing Habsburg influence and confirming Austria's vast territorial size. The Emperor also intended Maria Theresa to marry Francis Stephen of Lorraine which would present an unacceptable threat on France's border. By the beginning of 1733 the French army was ready for war: all that was needed was the excuse.\nWar of the Polish Succession.\nIn 1733 the Polish King and Elector of Saxony, Augustus the Strong, died. There were two candidates for his successor: first, Stanis\u0142aw Leszczy\u0144ski, the father-in-law of Louis XV; second, the Elector of Saxony's son, Augustus, supported by Russia, Austria, and Prussia. The Polish succession had afforded Louis XV's chief minister, Fleury, the opportunity to attack Austria and take Lorraine from Francis Stephen. In order to gain Spanish support France backed the succession of Elisabeth Farnese's sons to further Italian lands.\nEugene entered the War of the Polish Succession as President of the Imperial War Council and commander-in-chief of the army, but he was severely handicapped by the quality of his troops and the shortage of funds; now in his seventies, the Prince was also burdened by rapidly declining physical and mental powers. France declared war on Austria on 10 October 1733, but without the funds from the Maritime Powers\u2014who, despite the Vienna treaty, remained neutral throughout the war\u2014Austria could not hire the necessary troops to wage an offensive campaign. \"The danger to the monarchy,\" wrote Eugene to the Emperor in October, \"cannot be exaggerated\". By the end of the year Franco-Spanish forces had seized Lorraine and Milan; by early 1734 Spanish troops had taken Sicily.\nEugene took command on the Rhine in April 1734, but vastly outnumbered he was forced onto the defensive. In June Eugene set out to relieve Philippsburg, yet his former drive and energy was now gone. Accompanying Eugene was a young Frederick the Great, sent by his father to learn the art of war. Frederick gained considerable knowledge from Eugene, recalling in later life his great debt to his Austrian mentor, but the Prussian prince was aghast at Eugene's condition, writing later, \"his body was still there but his soul had gone.\" Eugene conducted another cautious campaign in 1735, once again pursuing a sensible defensive strategy on limited resources; but his short-term memory was by now practically non-existent, and his political influence disappeared completely\u2014Gundaker Starhemberg and Johann Christoph von Bartenstein now dominated the conference in his place. Fortunately for Charles VI, Fleury was determined to limit the scope of the war, and in October 1735 he granted generous peace preliminaries to the Emperor.\nLater years and death.\nEugene returned to Vienna from the War of the Polish Succession in October 1735, weak and feeble; when Maria Theresa and Francis Stephen married in February 1736 Eugene was too ill to attend. After playing cards at Countess Batthy\u00e1ny's on the evening of 20 April until nine in the evening, he returned home to the Stadtpalais, his attendant offered him to take his prescribed medicine which Eugene declined.\nWhen his servants arrived to wake him the next morning on 21 April 1736, they found Prince Eugene dead after passing away quietly during the night. It has been said that on the same morning he was discovered dead, the great lion in his menagerie was also found dead.\nEugene's heart was buried with the ashes of his ancestors in Turin, in the Basilica of Superga. His remains were carried in a long procession to St. Stephen's Cathedral, where his embalmed body was buried in the \"Kreuzkapelle\". It is said that the emperor himself attended as a mourner without anybody's knowledge.\nThe Prince's niece Maria Anna Victoria, whom he had never met, inherited Eugene's immense possessions. Within a few years she sold off the palaces, the country estates and the art collection of a man who had become one of the wealthiest in Europe, after arriving in Vienna as a refugee with empty pockets.\nPersonal life.\nIn what has been interpreted as a sign that he considered himself French by birth, Italian by dynastic extraction, and German-Austrian by allegiance, Eugene of Savoy signed himself using trilingual forms such as \"Eugenio\" (in Italian) \"Von\" (in German) \"Savoye\" (in French) or \"Eug\u00e8ne\" (in French) \"Von\" (in German) \"Savoia\" (in Italian). EVS was sometimes used as an abbreviation.\nEugene never married and was reported to have said that a woman was a hindrance in a war, and that a soldier should never marry, because of this he was called \"Mars without Venus\". Winston Churchill in his of the 1st Duke of Marlborough described Eugene as \"a bachelor, almost a misogynist, disdainful of money, content with his bright sword and his lifelong animosity against Louis XIV\" \nDuring the last 20 years of his life Eug\u00e8ne had a relationship with one woman, Hungarian Countess Eleonore Batthy\u00e1ny-Strattmann the widowed daughter of the former Theodor von Strattman. Much of their acquaintance remains speculative since Eugene left no personal papers: only letters of war, diplomacy and politics. Eug\u00e8ne and Eleonore were constant companions, meeting for dinner, receptions and card games almost every day till his death; although they lived apart most foreign diplomats assumed that Eleonore was his long time mistress. It is not known precisely when their relationship began, but his acquisition of a property in Hungary after the Battle of Zenta, near Rechnitz Castle, made them neighbours. In the years immediately following the War of the Spanish Succession she began to be mentioned regularly in diplomatic correspondence as \"Eugen's Egeria\" and within a few years she was referred to as his constant companion and his mistress. When asked if she and the Prince would marry, Countess Batthy\u00e1ny replied: \"I love him too well for that, I would rather have a bad reputation than deprive him of his\".\nIn spite of the lack of clear evidence, rumours that he was homosexual dated back to his teenage years. The origin of those rumours was Elizabeth Charlotte, Duchess of Orl\u00e9ans, the famous Versailles gossip-monger known as \"Madame,\" whose husband was the brother of Eugene's lifelong adversary, Louis XIV. The Duchess wrote about young Eugene's alleged antics with lackeys and pages and that he was refused an ecclesiastical benefice due to his \"depravity\". Eugene's biographer, historian Helmut Oehler, reported the Duchess's remarks but credited them to Elizabeth's personal resentment against the Prince. Aware of the malicious rumours, Eugene mocked them in his memoirs, calling them \"the invented anecdotes from the gallery of Versailles\". Whether or not Eugene had homosexual relationships in his youth, the Duchess's remarks about him were made years later, and only after Eugene had severely humiliated the armies of her brother-in-law, the King of France. After Eugene had left France at the age of nineteen, until his death at the age of seventy two, there were no further insinuations of homosexuality.\nBeing one of the richest and most celebrated men of his age certainly created enmity: jealousy and spite pursued Eugene from the battlefields to Vienna. His old subordinate Guido Starhemberg in particular was an incessant and rancorous detractor of Eugene's fame, and became known at the court of Vienna, according to Montesquieu, as Eugene\u2019s main rival. In a letter to a friend, Johann Matthias von der Schulenburg, another bitter rival, who had previously served under him during the wars of Spanish Succession, but whose ambition to obtain command in the Austrian army had been foiled by Eugene, wrote that the prince \"has no idea but to fight whenever the opportunity offers; he thinks that nothing equals the name of Imperialists, before whom all should bend the knee. He loves \"\"la petite d\u00e9bauche et la p----\" above all things\" That last sentence in French with a word intentionally censored, started speculations by some. For writer Curt Riess, it was \"a testament to sodomy\"; according to Eugene's foremost biographer, German historian Max Braubach, \"la p...\" meant (fornication), or , ie., Whoring. While Governor-General of the Southern Netherland, Eugene was known to be a regular at an exclusive brothel on Amsterdam's Prinsengracht, the keeper of the place was known as Madame Therese. Eugene once famously brought the English consul in Amsterdam with him. A drawing by Cornelis Troost, kept at the Rijksmuseum, the national museum of the Netherlands, depicts a scene in which Prince Eugene had \"the 'available' women parade in review, just as he did his own troops\" according to the museum, Troost based his drawing on an anecdote circulating at the time.\nEugene's other friends such as the papal nuncio, Passionei, who delivered the funeral oration of Prince Eugene, made up for the family he lacked. For his only surviving nephew, Emmanuel, the son of his brother Louis Thomas, Eugene arranged marriage with one of the daughters of Prince Liechtenstein, but Emmanuel died of smallpox in 1729. With the death of Emmanuel's son in 1734, no close male relatives remained to succeed the Prince. His closest relative, therefore, was Louis Thomas's unmarried daughter, Princess Maria Anna Victoria of Savoy, daughter of his eldest brother, the count of Soissons, whom Eugene had never met and had made no effort to do so.\nPatron of the arts.\nEugene's rewards for his victories, his share of booty, his revenues from his abbeys in Savoy, and a steady income from his Imperial offices and governorships, enabled him to contribute to the landscape of Baroque architecture Eugene spent most of his life in Vienna at his Winter Palace, the Stadtpalais, built by Fischer von Erlach. The palace acted as his official residence and home, but for reasons that remain speculative the Prince's association with Fischer ended before the building was complete, favouring instead Johann Lukas von Hildebrandt as his chief architect. Eugene first employed Hildebrandt to finish the Stadtpalais before commissioning him to prepare plans for a palace (Savoy Castle) on his Danubian island at R\u00e1ckeve. Begun in 1701 the single-story building took twenty years to complete; yet, probably because of the R\u00e1k\u00f3czi revolt, the Prince seems to have visited it only once\u2014after the siege of Belgrade in 1717.\nOf more importance was the grandiose complex of the two Belvedere palaces in Vienna. The single-storey Lower Belvedere, with its exotic gardens and zoo, was completed in 1716. The Upper Belvedere, completed between 1720 and 1722, is a more substantial building; with sparkling white stucco walls and copper roof, it became a wonder of Europe. Eugene and Hildebrandt also converted an existing structure on his Marchfeld estate into a country seat, the Schloss Hof, situated between the Rivers Danube and Morava. The building, completed in 1729, was far less elaborate than his other projects but it was strong enough to serve as a fortress in case of need. Eugene spent much of his spare time there in his last years accommodating large hunting parties.\nIn the years following the Peace of Rastatt Eugene became acquainted with a large number of scholarly men. Given his position and responsiveness, they were keen to meet him: few could exist without patronage and this was probably the main reason for Gottfried Leibniz's association with him in 1714. Eugene also befriended the French writer Jean-Baptiste Rousseau who, by 1716, was receiving financial support from Eugene. Rousseau stayed on attached to the Prince's household, probably helping in the library, until he left for the Netherlands in 1722. Another acquaintance, Montesquieu, already famous for his \"Persian Letters\" when he arrived in Vienna in 1728, favourably recalled his time spent at the Prince's table. Nevertheless, Eugene had no literary pretensions of his own, and was not tempted like Maurice de Saxe or Marshal Villars to write his memoirs or books on the art of war. He did, however, become a collector on the grandest scale: his picture galleries were filled with 16th- and 17th-century Italian, Dutch and Flemish art; his library at the Stadtpalais crammed with over 15,000 books, 237 manuscripts as well as a huge collection of prints (of particular interest were books on natural history and geography). \"It is hardly believable,\" wrote Rousseau, \"that a man who carries on his shoulders the burden of almost all the affairs of Europe \u2026 should find as much time to read as though he had nothing else to do.\"\nAt Eugene's death his possessions and estates, except those in Hungary which the crown reclaimed, went to his niece, Princess Maria Anna Victoria, who at once decided to sell everything. The artwork was bought by Charles Emmanuel III of Sardinia. Eugene's library, prints and drawings were purchased by the Emperor in 1737 and have since passed into Austrian national collections.\nHistorical reputation and legacy.\nNapoleon considered Eugene one of the seven greatest commanders of history. Although later military critics have disagreed with that assessment, Eugene was undoubtedly the greatest Austrian general. He was no military innovator, but he had the ability to make an inadequate system work. He was equally adept as an organizer, strategist, and tactician, believing in the primacy of battle and his ability to seize the opportune moment to launch a successful attack. \"The important thing,\" wrote Maurice de Saxe in his \"Reveries\", \"is to see the opportunity and to know how to use it. Prince Eugene possessed this quality which is the greatest in the art of war and which is the test of the most elevated genius.\" This fluidity was key to his battlefield successes in Italy and in his wars against the Turks. Nevertheless, in the Low Countries, particularly after the battle of Oudenarde in 1708, Eugene, like his cousin Louis of Baden, tended to play safe and become bogged down in a conservative strategy of sieges and defending supply lines. After the attempt on Toulon in 1707, he also became very wary of combined land/sea operations. To historian Derek McKay the main criticism of him as a general is his legacy\u2014he left no school of officers nor an army able to function without him.\nEugene was a disciplinarian\u2014when ordinary soldiers disobeyed orders he was prepared to shoot them himself\u2014but he rejected blind brutality, writing \"you should only be harsh when, as often happens, kindness proves useless\".\nOn the battlefield Eugene demanded courage in his subordinates, and expected his men to fight where and when he wanted; his criteria for promotion were based primarily on obedience to orders and courage on the battlefield rather than social position. On the whole, his men responded because he was willing to push himself as hard as them. His position as President of the Imperial War Council proved less successful. Following the long period of peace after the Austro-Turkish War, the idea of creating a separate field army or providing garrison troops with effective training for them to be turned into such an army quickly was never considered by Eugene. By the time of the War of the Polish Succession, therefore, the Austrians were outclassed by a better prepared French force. For this Eugene was largely to blame\u2014in his view (unlike the drilling and manoeuvres carried out by the Prussians which to Eugene seemed irrelevant to real warfare) the time to create actual fighting men was when war came.\nAlthough Frederick the Great had been struck by the muddle of the Austrian army and its poor organisation during the Polish Succession war, he later amended his initial harsh judgements. \"If I understand anything of my trade,\" commented Frederick in 1758, \"especially in the more difficult aspects, I owe that advantage to Prince Eugene. From him I learnt to hold grand objectives constantly in view, and direct all my resources to those ends.\" To historian Christopher Duffy it was this awareness of the 'grand strategy' that was Eugene's legacy to Frederick.\nTo his responsibilities, Eugene attached his own personal values\u2014physical courage, loyalty to his sovereign, honesty, self-control in all things\u2014and he expected these qualities from his commanders. Eugene's approach was dictatorial, but he was willing to co-operate with someone he regarded as his equal, such as Baden or Marlborough. Yet the contrast with his co-commander of the Spanish Succession war was stark. \"Marlborough,\" wrote Churchill, \"was the model husband and father, concerned with building up a home, founding a family, and gathering a fortune to sustain it\"; whereas Eugene, the bachelor, was \"disdainful of money, content with his bright sword and his lifelong animosities against Louis XIV\".\nThe result was an austere figure, inspiring respect and admiration rather than affection.\nSicco van Goslinga, one of the Dutch field deputies who worked very close with Eugene during his campaigns with Marlborough, described him in his memoires as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;He had untameable courage and outdid himself during battle and in all undertakings where vigorous action was required. But he was less skilled in matters requiring brainwork, perseverance, prudence and constant attention, like when it was necessary to take up a defensive position, carefully supply it with everything necessary for its preservation and watch over its security. He was unable to concern himself with [logistical] ancillary matters, which are so necessary for the security of an army. It was said that he needed a new army every year, implying that he had little concern for the lives of soldiers.\nMemorials.\nWarships.\nSeveral ships have been named in Eugene's honour:\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9682", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=9682", "title": "Echo and the Bunnymen", "text": ""}
{"id": "9683", "revid": "1157609314", "url": "https://en.wikipedia.org/wiki?curid=9683", "title": "Emanuel Leutze", "text": "German-American painter\nEmanuel Gottlieb Leutze (May 24, 1816\u00a0\u2013 July 18, 1868) was a German-American history painter best known for his 1851 painting \"Washington Crossing the Delaware\". He is associated with the D\u00fcsseldorf school of painting.\nBiography.\nLeutze was born in Schw\u00e4bisch Gm\u00fcnd, W\u00fcrttemberg, Germany. Later he was brought to the United States as a child in 1825. His parents settled first in Fredericksburg, Virginia, and then at Philadelphia. The first development of his artistic talent occurred while he was attending the sickbed of his father, when he attempted drawing to occupy the long hours of waiting. His father died in 1831. At 14, he was painting portraits for $5 apiece. Through such work, he supported himself after the death of his father. In 1834, he received his first instruction in art at the classes of John Rubens Smith, a portrait painter in Philadelphia. He soon became skilled, and promoted a plan for publishing, in Washington, portraits of eminent American statesmen; however, he was met with slight encouragement.\nEurope.\nIn 1840, one of his paintings attracted attention and gave him several orders, which enabled him to attend the Kunstakademie D\u00fcsseldorf in his native Germany. Due to his anti-academic attitude, he studied only one year at the academy, in the class of Director Schadow. Leutze was mostly influenced by the painter Karl Friedrich Lessing. In 1842 he went to Munich, studying the works of Cornelius and Kaulbach, and, while there, finished his \"Columbus before the Queen\". The following year he visited Venice and Rome, making studies from Titian and Michelangelo. His first work, \"Columbus before the Council of Salamanca\" (1841) was purchased by the D\u00fcsseldorf Art Union. A companion picture, \"Columbus in Chains\", procured him the gold medal of the Brussels Art Exhibition, and was subsequently purchased by the Art Union in New York; it was the basis of the 1893 $2 Columbian Issue stamp. In 1845, after a tour in Italy, he returned to D\u00fcsseldorf, marrying Juliane Lottner and making his home there for 14 years.\nDuring his years in D\u00fcsseldorf, he was a resource for visiting Americans: he found them places to live and work, provided introductions, and gave them emotional and even financial support. For many years, he was the president of the D\u00fcsseldorf Artists' Association; in 1848, he was an early promoter of the \"Malkasten\" art association; and in 1857, he led the call for a gathering of artists which originated the founding of the Allgemeine deutsche Kunstgenossenschaft.\nA strong supporter of Europe's Revolutions of 1848, Leutze decided to paint an image that would encourage Europe's liberal reformers with the example of the American Revolution. Using American tourists and art students as models and assistants, Leutze finished a first version of \"Washington Crossing the Delaware\" in 1850. Just after it was completed, the first version was damaged by fire in his studio, subsequently restored, and acquired by the Kunsthalle Bremen. On September 5, 1942, during World War II, it was destroyed in a bombing raid by the Allied forces. The second painting, a replica of the first, only larger, was ordered in 1850 by the Parisian art trader Adolphe Goupil for his New York branch and placed on exhibition on Broadway in October 1851. It is now owned by the Metropolitan Museum of Art in New York. In 1854, Leutze finished his depiction of the Battle of Monmouth, \"Washington rallying the troops at Monmouth,\" commissioned by an important patron, the banker David Leavitt of New York City and Great Barrington, Massachusetts.\nNew York City and Washington, D.C..\nIn 1859, Leutze returned to the United States and opened a studio in New York City. He divided his time between New York City and Washington, D.C. In 1859, he painted a portrait of Chief Justice Roger Brooke Taney, which hangs in the Harvard Law School. In a 1992 opinion, Justice Antonin Scalia described the portrait of Taney, made two years after Taney's infamous decision in \"Dred Scott v. Sandford\", as showing Taney \"in black, sitting in a shadowed red armchair, left hand resting upon a pad of paper in his lap, right hand hanging limply, almost lifelessly, beside the inner arm of the chair. He sits facing the viewer and staring straight out. There seems to be on his face, and in his deep-set eyes, an expression of profound sadness and disillusionment.\"\nLeutze also executed other portraits, including one of fellow painter William Morris Hunt. That portrait was owned by Hunt's brother Leavitt Hunt, a New York attorney and sometime Vermont resident, and was shown at an exhibition devoted to William Morris Hunt's work at the Museum of Fine Arts, Boston in 1878.\nIn 1860 Leutze was commissioned by the U.S. Congress to decorate a stairway in the Capitol Building in Washington, DC, for which he painted a large composition, \"Westward the Course of Empire Takes Its Way\", which is also commonly known as \"Westward Ho!\".\nLate in life, he became a member of the National Academy of Design. He was also a member of the Union League Club of New York, which has a number of his paintings. At age 52, he died in Washington, D.C. of heat stroke. He was interred at Glenwood Cemetery. At the time of his death, a painting, \"The Emancipation of the Slaves\", was in preparation.Leutze's portraits are known for their artistic quality and their patriotic romanticism. \"Washington Crossing the Delaware\" firmly ranks among the American national iconography.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nAdditional References:"}
{"id": "9684", "revid": "5662528", "url": "https://en.wikipedia.org/wiki?curid=9684", "title": "Erasmus Alberus", "text": "German humanist, reformer and poet\nErasmus Alberus (c. 1500\u00a0\u2013 5 May 1553) was a German humanist, Lutheran reformer, and poet.\nLife.\nHe was born in the village of Bruchenbr\u00fccken (now part of Friedberg, Hesse) about the year 1500. Although his father Tilemann Alber was a schoolmaster, his early education was neglected.\nUltimately in 1518, he found his way to the University of Wittenberg, where he studied theology. He had the good fortune to attract the attention of Martin Luther and Philipp Melanchthon, and subsequently became one of Luther's most active helpers in the Protestant Reformation.\nNot only did he fight for the Protestant cause as a preacher and theologian, but he was almost the only member of Luther's party who was able to confront the Roman Catholics with the weapon of literary satire. In 1542 he published a prose satire to which Luther wrote the preface, \"Der Barfusser Monche Eulenspiegel und Alkoran,\" a parodic adaptation of the \"Liber conformitatum\" of the Franciscan Bartolommeo Rinonico of Pisa, in which the Franciscan order is held up to ridicule. This drew reactions from Catholic scholars such as Henricus Sedulius, who published the \"Apologeticus aduersus Alcoranum Franciscanorum, pro Libro Conformitatum,\" which criticized Alberus' arguments in this satire. \nOf higher literary value is the didactic and satirical \"Buch von der Tugend und Weisheit\" (1550), a collection of forty-nine fables in which Alberus embodies his views on the relations of Church and State. His satire is incisive, but in a scholarly and humanistic way; it does not appeal to popular passions with the fierce directness which enabled the master of Catholic satire, Thomas Murner, to inflict such telling blows.\nSeveral of Alberus's hymns, all of which show the influence of his master Luther, have been retained in the German Protestant hymnal.\nAfter Luther's death, Alberus was for a time a deacon in Wittenberg; he became involved, however, in the political conflicts of the time, and was in Magdeburg in 1550\u20131551, while that town was besieged by Maurice, Elector of Saxony. In 1552 he was appointed General Superintendent at Neubrandenburg in Mecklenburg, where he died on 5 May 1553.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nAttribution:"}
{"id": "9685", "revid": "45942553", "url": "https://en.wikipedia.org/wiki?curid=9685", "title": "Earley parser", "text": "Algorithm for parsing context-free languages\nIn computer science, the Earley parser is an algorithm for parsing strings that belong to a given context-free language, though (depending on the variant) it may suffer problems with certain nullable grammars. The algorithm, named after its inventor, Jay Earley, is a chart parser that uses dynamic programming; it is mainly used for parsing in computational linguistics. It was first introduced in his dissertation in 1968 (and later appeared in an abbreviated, more legible, form in a journal).\nEarley parsers are appealing because they can parse all context-free languages, unlike LR parsers and LL parsers, which are more typically used in compilers but which can only handle restricted classes of languages. The Earley parser executes in cubic time in the general case formula_1, where \"n\" is the length of the parsed string, quadratic time for unambiguous grammars formula_2, and linear time for all deterministic context-free grammars. It performs particularly well when the rules are written left-recursively.\nEarley recogniser.\nThe following algorithm describes the Earley recogniser. The recogniser can be modified to create a parse tree as it recognises, and in that way can be turned into a parser.\nThe algorithm.\nIn the following descriptions, \u03b1, \u03b2, and \u03b3 represent any string of terminals/nonterminals (including the empty string), X and Y represent single nonterminals, and \"a\" represents a terminal symbol.\nEarley's algorithm is a top-down dynamic programming algorithm. In the following, we use Earley's dot notation: given a production X \u2192 \u03b1\u03b2, the notation X \u2192 \u03b1 \u2022 \u03b2 represents a condition in which \u03b1 has already been parsed and \u03b2 is expected.\nInput position 0 is the position prior to input. Input position \"n\" is the position after accepting the \"n\"th token. (Informally, input positions can be thought of as locations at token boundaries.) For every input position, the parser generates a \"state set\". Each state is a tuple (X \u2192 \u03b1 \u2022 \u03b2, \"i\"), consisting of\nA state is finished when its current position is the last position of the right side of the production, that is, when there is no symbol to the right of the dot \u2022 in the visual representation of the state.\nThe state set at input position \"k\" is called S(\"k\"). The parser is seeded with S(0) consisting of only the top-level rule. The parser then repeatedly executes three operations: \"prediction\", \"scanning\", and \"completion\".\nDuplicate states are not added to the state set, only new ones. These three operations are repeated until no new states can be added to the set. The set is generally implemented as a queue of states to process, with the operation to be performed depending on what kind of state it is.\nThe algorithm accepts if (X \u2192 \u03b3 \u2022, 0) ends up in S(\"n\"), where (X \u2192 \u03b3) is the top level-rule and \"n\" the input length, otherwise it rejects.\nPseudocode.\nAdapted from Speech and Language Processing by Daniel Jurafsky and James H. Martin, \nDECLARE ARRAY S;\nfunction INIT(words)\n S \u2190 CREATE_ARRAY(LENGTH(words) + 1)\n for k \u2190 from 0 to LENGTH(words) do\n S[k] \u2190 EMPTY_ORDERED_SET\nfunction EARLEY_PARSE(words, grammar)\n INIT(words)\n ADD_TO_SET((\u03b3 \u2192 \u2022S, 0), S[0])\n for k \u2190 from 0 to LENGTH(words) do\n for each state in S[k] do // S[k] can expand during this loop\n if not FINISHED(state) then\n if NEXT_ELEMENT_OF(state) is a nonterminal then\n PREDICTOR(state, k, grammar) // non_terminal\n else do\n SCANNER(state, k, words) // terminal\n else do\n COMPLETER(state, k)\n end\n end\n return chart\nprocedure PREDICTOR((A \u2192 \u03b1\u2022B\u03b2, j), k, grammar)\n for each (B \u2192 \u03b3) in GRAMMAR_RULES_FOR(B, grammar) do\n ADD_TO_SET((B \u2192 \u2022\u03b3, k), S[k])\n end\nprocedure SCANNER((A \u2192 \u03b1\u2022a\u03b2, j), k, words)\n if j &lt; LENGTH(words) and a \u2282 PARTS_OF_SPEECH(words[k]) then\n ADD_TO_SET((A \u2192 \u03b1a\u2022\u03b2, j), S[k+1])\n end\nprocedure COMPLETER((B \u2192 \u03b3\u2022, x), k)\n for each (A \u2192 \u03b1\u2022B\u03b2, j) in S[x] do\n ADD_TO_SET((A \u2192 \u03b1B\u2022\u03b2, j), S[k])\n end\nExample.\nConsider the following simple grammar for arithmetic expressions:\n&lt;P&gt; ::= &lt;S&gt; # the start rule\n&lt;S&gt; ::= &lt;S&gt; \"+\" &lt;M&gt; | &lt;M&gt;\n&lt;M&gt; ::= &lt;M&gt; \"*\" &lt;T&gt; | &lt;T&gt;\n&lt;T&gt; ::= \"1\" | \"2\" | \"3\" | \"4\"\nWith the input:\n 2 + 3 * 4\nThis is the sequence of state sets:\nThe state (P \u2192 S \u2022, 0) represents a completed parse. This state also appears in S(3) and S(1), which are complete sentences.\nConstructing the parse forest.\nEarley's dissertation briefly describes an algorithm for constructing parse trees by adding a set of pointers from each non-terminal in an Earley item back to the items that caused it to be recognized. But Tomita noticed that this does not take into account the relations between symbols, so if we consider the grammar S \u2192 SS | b and the string bbb, it only notes that each S can match one or two b's, and thus produces spurious derivations for bb and bbbb as well as the two correct derivations for bbb.\nAnother method is to build the parse forest as you go, augmenting each Earley item with a pointer to a shared packed parse forest (SPPF) node labelled with a triple (s, i, j) where s is a symbol or an LR(0) item (production rule with dot), and i and j give the section of the input string derived by this node. A node's contents are either a pair of child pointers giving a single derivation, or a list of \"packed\" nodes each containing a pair of pointers and representing one derivation. SPPF nodes are unique (there is only one with a given label), but may contain more than one derivation for ambiguous parses. So even if an operation does not add an Earley item (because it already exists), it may still add a derivation to the item's parse forest.\nSPPF nodes are never labeled with a completed LR(0) item: instead they are labelled with the symbol that is produced so that all derivations are combined under one node regardless of which alternative production they come from.\nOptimizations.\nPhilippe McLean and R. Nigel Horspool in their paper \"A Faster Earley Parser\" combine Earley parsing with LR parsing and achieve an improvement in an order of magnitude.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9686", "revid": "146242", "url": "https://en.wikipedia.org/wiki?curid=9686", "title": "Ethiopian cuisine", "text": "Culinary traditions of Ethiopia\nEthiopian cuisine ( \"Ye-\u012aty\u014d\u1e57\u1e57y\u0101 m\u0259g\u0259b\") characteristically consists of vegetable and often very spicy meat dishes. This is usually in the form of \"wat,\" a thick stew, served on top of \"injera\" (), a large sourdough flatbread, which is about in diameter and made out of fermented teff flour. Ethiopians eat most of the time with their right hands, using pieces of to pick up bites of entr\u00e9es and side dishes.\nThe Ethiopian Orthodox Tewahedo Church prescribes a number of fasting periods known as \"tsom\" ( \"\u1e63\u014dm\"), including all Wednesdays and Fridays and the whole Lenten season (including fifteen days outside Lent proper). Per Oriental Orthodox tradition, the faithful may not consume any kind of animal products (including dairy products and eggs) during fasts; Ethiopian cuisine therefore contains many dishes that are vegan.\nOverview.\nA typical dish consists of accompanied by a spicy stew, which frequently includes beef, lamb, vegetables and various types of legumes, such as lentils. The cuisines of the Southern Nations, Nationalities and People's Region and the Sidama region also make use of the false banana plant (, Ge'ez: \u12a5\u1295\u1230\u1275 \"\u00efnset\"), a type of ensete. The plant is pulverized and fermented to make various foods, including a bread-like food called \"kocho\" (Ge'ez: \u1246\u132e \"\u1e33\u014d\u010d\u0323\u014d\"), which is eaten with kitfo. The root of this plant may be powdered and prepared as a hot drink called \"bulla\" (Ge'ez: \u1261\u120b \"b\u016bl\u0101\"), which is often given to those who are tired or ill. Another typical Gurage preparation is coffee with butter (\"kebbeh\"). \"Kita\" herb bread is also baked.\nDue in part to the brief Italian occupation, pasta is popular and frequently available throughout Ethiopia, including rural areas. Coffee is also a large part of Ethiopian culture and cuisine. After every meal, a coffee ceremony is enacted and coffee is served.\nRestrictions of certain meats.\nEthiopian Orthodox Christians, Ethiopian Jews and Ethiopian Muslims avoid eating pork or shellfish, for religious reasons. Pork is considered unclean in Ethiopian Orthodox Christianity, Judaism and Islam. Most Ethiopian Protestants or P'ent'ay also abstain from eating food already prohibited from the Orthdox church. Many Ethiopians abstain from eating certain meats, eating mostly vegetarian foods, partially from the high cost of meat, eggs, dairy products.\nTraditional ingredients.\n\"Berbere\", a combination of powdered chili pepper and other spices (cardamom, fenugreek, coriander, cloves, ginger, nutmeg, cumin and allspice) is an important ingredient used to add flavor to many varied dishes like chicken stews and baked fish dishes. Also essential is \"niter kibbeh\", a clarified butter infused with ginger, garlic, and several spices.\n\"Mitmita\" (, ]) is a powdered seasoning mix used in Ethiopian cuisine. It is orange-red in color and contains ground birdseye chili peppers (piri piri), cardamom seed, cloves and salt. It occasionally has other spices including cinnamon, cumin and ginger.\nIn their adherence to strict fasting, Ethiopian cooks have developed a rich array of cooking oil sources\u2014besides sesame and safflower\u2014for use as a substitute for animal fats which are forbidden during fasting periods. Ethiopian cuisine also uses \"nug\" (also spelled \"noog\", also known as \"niger seed\").\nDishes.\nWat.\n\"Wat\" begins with a large amount of chopped red onion, which is simmered or sauteed in a pot. Once the onions have softened, \"niter kebbeh\" (or, in the case of vegan dishes, vegetable oil) is added. Following this, \"berbere\" is added to make a spicy \"keiy wat\" or \"keyyih tsebhi\". Turmeric is used instead of \"berbere\" for a milder \"alicha wat\" or both spices are omitted when making vegetable stews, such as \"atkilt wat\". Meat such as beef (\"\u1225\u130b\", \"s\u0259ga\"), chicken (\"\u12f6\u122e\", \"doro\" or \"derho\"), fish (\"\u12d3\u1223\", \"asa\"), goat or lamb (\"\u1260\u130d\", \"beg\" or \"beggi\") is also added. Legumes such as split peas (\"\u12ad\u12ad\", \"k\u0259k\" or \"kikki\") and lentils (\"\u121d\u1235\u122d\", \"m\u0259s\u0259r\" or \"birsin\"); or vegetables such as potatoes (\"\u12f5\u1295\u127d\", \"D\u0259n\u0259ch\"), carrots and chard (\u1246\u1235\u1323) are also used instead in vegan dishes.\nEach variation is named by appending the main ingredient to the type of \"wat\" (e.g. ). However, the word \"keiy\" is usually not necessary, as the spicy variety is assumed when it is omitted (e.g. \"doro wat\"). The term is sometimes used to refer to all vegetable dishes, but a more specific name can also be used (as in , which translates to \"potatoes and carrots stew\"; but the word \"atkilt\" is usually omitted when using the more specific term).\nTibs.\nMeat along with vegetables are saut\u00e9ed to make \"tibs\" (also \"tebs\", \"t'ibs\", \"tibbs\", etc., Ge'ez: \u1325\u1265\u1235 \"\u1e6d\u00efbs\"). \"Tibs\" is served in a variety of manners, and can range from hot to mild or contain little to no vegetables. There are many variations of the delicacy, depending on type, size or shape of the cuts of meat used. Beef, mutton, and goat are the most common meats used in the preparation of \"tibs\".\nThe mid-18th-century European visitor to Ethiopia Remedius Prutky describes \"tibs\" as a portion of grilled meat served \"to pay a particular compliment or show especial respect to someone.\" It may still be seen this way; today the dish is prepared to commemorate special events and holidays.\nKinche (Qinch'e).\n\"Kinche\" (\"Qinch\u2019e\"), a porridge, is a very common Ethiopian breakfast or supper. It is incredibly simple, inexpensive, and nutritious. It is made from cracked wheat, Ethiopian oats, barley or a mixture of those. It can be boiled in either milk or water with a little salt. The flavor of \"kinche\" comes from the \"nit'ir qibe\", which is a spiced butter.\nSalads.\nAzifa is an Ethiopian lentil salad made with mustard seed, jalape\u00f1os, and onions, and it is a dish often served cold. Buticha is an Ethiopian chickpea salad which is often served cold, and is sometimes compared to hummus.\nEthnic dishes.\nOromo dishes.\nThe Oromos' cuisine consists of various vegetable or meat side dishes and entr\u00e9es. As part of a long-established custom, practice, or belief, people do not eat pork in Oromia.\nGurage dishes.\nKitfo.\nAnother distinctively Ethiopian dish is \"kitfo\" (frequently spelled \"ketfo\"). It consists of raw (or rare) beef mince marinated in \"mitmita\" (Ge'ez: \u121a\u1325\u121a\u1323 \"m\u012b\u1e6dm\u012b\u1e6d\u0101\" a very spicy chili powder similar to ) and . \"Gored gored\" is very similar to , but uses cubed rather than ground beef.\nAyibe.\n (or \"Ayeb\") is a local cheese made from the curds of buttermilk that is mild and crumbly, close in texture to crumbled feta. Although not quite pressed, the whey has been drained and squeezed out. It is often served as a side dish to soften the effect of very spicy food. It has little to no distinct taste of its own. However, when served separately, is often mixed with a variety of mild or hot spices typical of Gurage cuisine.\nGomen kitfo.\n\"Gomen kitfo\" is another typical Gurage dish. Collard greens (\u130e\u1218\u1295 \"g\u014dmen\") are boiled, dried and then finely chopped and served with butter, chili and spices. It is a dish specially prepared for the occasion of Meskel, a very popular holiday marking the discovery of the True Cross. It is served along with or sometimes even \"kitfo\" in this tradition called .\nSidama dishes.\nWassa.\nThe enset plant (called \"wesse\" in the Sidamo language) is central to Sidama cuisine and after grinding and fermenting the root to produce \"wassa\", it is used in the preparation of several foods.\nBorasaame.\n\"Borasaame\" is a cooked mixture of \"wassa\" and butter sometimes eaten with Ethiopian mustard greens and/or beans. It is traditionally eaten by hand using a false banana leaf and is served in a ', a vase-like ceramic vessel. A common variant of \"borasaame\" uses maize flour instead of \"wassa\" and is called \"badela borasaame\". \"Borasaame\" is typically paired with a seasoned yogurt drink called \"w\u00e4t\u00e4t\". Both are common foods for funerals and the celebration of \"Fichee Chambalaalla\", the Sidama new year.\nAmulcho.\n is an enset flatbread used similarly to to eat wats made from beef, mushrooms, beans, gomen, or pumpkin.\nGomen ba siga.\nGomen ba siga (\u130e\u1218\u1295 \u1260\u1235\u130b, Amharic: \"cabbage with meat\") is a stewed mixture of beef and Ethiopian mustard served under a layer of bread.\nMaize.\nA commonly grown crop in Sidama, maize (\"badela\" in Sidaamu; also known as \"corn\" in North America) is often eaten as a snack with coffee. It can be ground into flour to make bread, roasted on the cob, or the kernels can be picked off to make \"bokolo\", which is served either boiled or roasted.\nBreakfast.\n\"Fit-fit\" or \"fir-fir\" is a common breakfast dish. It is made from shredded \"\" or \"kitcha\" stir-fried with spices or \"wat\". Another popular breakfast food is . The delicacy consists of a large fried pancake made with flour, often with a layer of egg. It is eaten with honey.\n\"Chechebsa\" (or \"kita firfir\") resembles a pancake covered with \"berbere\" and \"niter kibbeh\", or other spices, and may be eaten with a spoon. \"Genfo\" is a kind of porridge, which is another common breakfast dish. It is usually served in a large bowl with a dug-out made in the middle of the genfo and filled with spiced \"niter kibbeh\".\nA variation of \"ful\", a fava bean stew with condiments, served with baked rolls instead of , is also common for breakfast.\nSnacks.\nTypical Ethiopian snacks are \"dabo kolo\" (small pieces of baked bread that are similar to pretzels), or \"kolo\" (roasted barley sometimes mixed with other local grains). \"Kolo\" made from roasted and spiced barley, safflower kernels, chickpeas and/or peanuts are often sold by kiosks and street vendors, wrapped in a paper cone. Snacking on popcorn and traditional lentil samosa is also common.\nBeverages.\nTraditional alcoholic beverages.\nThere are many different traditional alcoholic drinks which are home made and of natural ingredients.\nTella.\n\"Tella\" is a home-brewed beer served in \"tella bet\" (\"tella houses\") which specialize in serving only \"tella\". \"Tella\" is the most common beverage made and served in households during holidays.\nIt is an alcoholic drink which is prepared from \"bikil\" (barley) as main ingredient and \"gesho\" (\"Rhamnus prinoides\") for fermentation purpose.\nIn Oromiffaa the drink is called \"farso\" and in Tigrinya \"siwa\".\nTej (honey wine).\n\"Tej\" is a potent honey wine. It is similar to mead, and is frequently served in bars, particularly in a \"tej bet\" or \"\"tej\" house\".\nIt is prepared from honey and gesho. It has a sweet taste and the alcoholic content is relatively higher than \"tella\". This drink can be stored for a long time; the longer it is stored, the higher the alcohol content, and the stronger the taste.\nAreki (katikala).\n\"Areki\", also known as \"katikala\", is probably the strongest alcoholic drink of Ethiopia. It is a home distilled spirit that is often filtered through charcoal to remove off tastes or flavored by smoking or infusion with garlic.\nNon-alcoholic beverages.\nEthiopians have diverse traditional non-alcoholic drinks which include natural and healthy ingredients.\nKenetto (keribo).\n\"Kenetto\", also known as \"keribo\", is a non-alcoholic traditional drink. It is mostly used as substitute for \"tella\" for those who don't drink alcohol.\nBorde.\n\"Borde\" is a cereal-based traditional fermented beverage famous in southern Ethiopia.\nManufactured drinks.\nJust like the rest of the world, Ethiopians also enjoy several locally manufactured beers, wine and non-alcoholic products like Coca-Cola and other similar products.\nAmbo Mineral Water or \"Ambo wuha\" is a bottled carbonated mineral water, sourced from the springs in Ambo Senkele near the town of Ambo.\nNon-alcoholic brews (hot drinks).\nAtmet.\n\"Atmet\" is a barley- and oat-flour based drink that is cooked with water, sugar and \"kibe\" (Ethiopian clarified butter) until the ingredients have combined to create a consistency slightly thicker than egg-nog. Though this drink is often given to women who are nursing, the sweetness and smooth texture make it a comfort drink for anyone who enjoys its flavor.\nCoffee.\nAccording to some sources, drinking of coffee (\"buna\") is likely to have originated in Ethiopia. A key national beverage, it is an important part of local commerce.\nThe coffee ceremony is the traditional serving of coffee, usually after a big meal. It often involves the use of a \"jebena\" (\u1300\u1260\u1293), a clay coffee pot in which the coffee is boiled. The preparer roasts the coffee beans in front of guests, then walks around wafting the smoke throughout the room so participants may sample the scent of coffee. Then the preparer grinds the coffee beans in a traditional tool called a . The coffee is put into the \"jebena\", boiled with water, and then served in small cups called \"si'ni\". Coffee is usually served with sugar, but is also served with salt in many parts of Ethiopia. In some parts of the country, \"niter kibbeh\" is added instead of sugar or salt.\nSnacks, such as popcorn or toasted barley (or \"kolo\"), are often served with the coffee. In most homes, a dedicated coffee area is surrounded by fresh grass, with special furniture for the coffee maker. A complete ceremony has three rounds of coffee (\"abol\", \"tona\" and \"bereka\") and is accompanied by the burning of frankincense.\nTea (shai).\nTea will most likely be served if coffee is declined. Tea is grown in Ethiopia at Gumaro and Wushwush.\nBoiled coffee leaves.\nAcross southern Ethiopia, many groups drink boiled coffee leaves, called \"kuti\" among the Harari in the east and \"kaari\" among the Majang in the west. This is often made with widely varying seasonings and spices, such as sugar, salt, rue, hot peppers, ginger. The Ethiopian Food Safety Authority has registered the safety of coffee leaf infusions with the European Union.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9688", "revid": "5635510", "url": "https://en.wikipedia.org/wiki?curid=9688", "title": "Epistle of James", "text": "Book of the New Testament\nThe Epistle of James is a general epistle and one of the 21 epistles (didactic letters) in the New Testament.\nJames 1:1 identifies the author as \"James, a servant of God and of the Lord Jesus Christ\" who is writing to \"the twelve tribes scattered abroad\". The epistle is traditionally attributed to James the brother of Jesus (James the Just), and the audience is generally considered to be Jewish Christians, who were dispersed outside Israel.\nFraming his letter within an overall theme of patient perseverance during trials and temptations, James writes in order to encourage his readers to live consistently with what they have learned in Christ. He condemns various sins, including pride, hypocrisy, favouritism, and slander. He encourages and implores believers to humbly live by godly, rather than worldly, wisdom and to pray in all situations. \nFor the most part, until the late 20th century, the epistle of James was relegated to benign disregard \u2013 though it was shunned by many early theologians and scholars due to its advocacy of Torah observance and good works. Famously, Luther at one time considered the epistle to be among the disputed books, and sidelined it to an appendix, although in his Large Catechism he treated it as the authoritative word of God.\nThe epistle aims to reach a wide Jewish audience. During the last decades, the epistle of James has attracted increasing scholarly interest due to a surge in the quest for the historical James, his role within the Jesus movement, his beliefs, and his relationships and views. This James revival is also associated with an increasing level of awareness of the Jewish grounding of both the epistle and the early Jesus movement.\nAuthorship.\nThe author is identified as \u201cJames, a servant of God and of the Lord Jesus Christ\u201d (Jas 1:1). James was an extremely common name in antiquity, and a number of early Christian figures are named James, including: James the son of Zebedee, James the son of Alphaeus, and James the brother of Jesus. Of these, James the brother of Jesus has the most prominent role in the early church, and is often understood as either the author of the epistle, or the implied author.\nThe earliest recorded references to the Epistle of James highlight the contentious nature of the epistle\u2019s authorship. Origen may be the first person to link the epistle to \"James the brother of Lord\" (\"Comm. on Romans\" 4.8.2), though this is only preserved in Rufinus\u2019s Latin translation of Origen. Eusebius writes that \"James, who is said to be the author of the first of the so-called catholic epistles. But it is to be observed that it is disputed\" (\"Historia ecclesiae\" 2.23.25). Jerome reported that the Epistle of James \"is claimed by some to have been published by some one else under his name, and gradually, as time went on, to have gained authority\" (\"De viris illustribus\" 2).\nTraditional authorship.\nThe link between James the brother of Jesus and the epistle continued to strengthen, and is now considered the traditional view on the authorship of the work. The traditional view can be divided into at least three further positions that relate also to the date of the epistle:\nMany who affirm traditional authorship think James had a sufficient proficiency in Greek education to write the letter himself. Some argue that James the brother of Jesus made use of an amanuensis, which explains the quality of Greek in the letter. Dan McCartney notes this position has garnered little support. Others have advocated for a two-stage composition theory, in which many of the sayings of epistle originate with James the brother of Jesus. They were collected by James\u2019 disciples and redacted into the current form of the letter.\nJohn Calvin and others suggested that the author was the James, son of Alphaeus, who is referred to as James the Less. The Protestant reformer Martin Luther denied it was the work of an apostle and termed it an \"epistle of straw\".\nThe Holy Tradition of the Eastern Orthodox Church teaches that the Book of James was \"written not by either of the apostles, but by the 'brother of the Lord' who was the first bishop of the Church in Jerusalem.\"\nPseudonymous authorship.\nA prevalent view within scholarship considers the Epistle of James to be pseudonymous. The real author chose to write under the name James, intending that the audience perceive James the brother of Jesus as the author. Scholars who maintain pseudonymous authorship differ on whether this was a deceitful or pious practice.\nThe following arguments are often cited in support of pseudepigraphy: \nDating.\nAccording to Josephus (\"Jewish Antiquities\" 20.197\u2013203), James the brother of Jesus was killed in 62 CE, during the high priesthood of Ananus. Those who hold to traditional authorship date the epistle to sometime before 62 CE, in the forties or fifties, making it one of the earliest writings of the New Testament.\nThose who maintain that the epistle is pseudonymous generally date the epistle later, from the late first to mid-second century. This is based on a number of considerations, including the epistle's potential dependence on 1 Peter, potential response to Paul's writings or Paul's later followers, late attestation in the historical record, and the 3rd and 4th century disputes concerning the epistle's authorship.\nThe earliest extant manuscripts of James usually date to the mid-to-late 3rd century.\nThe historiographic debate currently seems to be leaning to the side of those in favor of early dating, although not through irrefutable evidence but through indications and probabilities.\nGenre.\nThe Epistle of James is a letter, and includes the an epistolary prescript that identifies the sender (\u201cJames\u201d) and the recipients (\u201cto the twelve tribes in the diaspora\u201d) and provides a greeting (Jas 1:1). The epistle resembles the form of a Diaspora letter, written to encourage Jewish-Christian communities living outside of Israel amid the hardships of diaspora life. James stands in the tradition of the Jewish genre of \"Letters to the Diaspora\", including the letters of the members of the family of Gamaliel, the one preserved in 2 Maccabees 1:1-9, or some copied by Josephus, all of which are characterised by a double opening and an abrupt ending.\nMany consider James to have affinities to Jewish wisdom literature: \"like Proverbs and Sirach, it consists largely of moral exhortations and precepts of a traditional and eclectic nature.\" The epistle also has affinities with many of the sayings of Jesus which are found in the gospels of Luke and Matthew (i.e., those attributed to the hypothetical Q source, in the two-source hypothesis). Some scholars have argued that the author of James is familiar with a version of Q rather than Luke or Matthew. \nOther scholars have noted the epistle's affinities with Greco-Roman philosophical literature. The author's use and transformation of Q materials resembles the Hellenistic practice of \"aemulatio\", in which the author must \"rival and vie [\"aemulatio\"] with the original in the expression of the same thoughts\u201d (Quintilian, \"Inst\". 10.5.5). Other studies have analysed sections of James in light of Greco-Roman rhetorical conventions.\nStructure.\nSome view the epistle as having no overarching outline: \"James may have simply grouped together small 'thematic essays' without having more linear, Greco-Roman structures in mind.\" That view is generally supported by those who believe that the epistle may not be a true piece of correspondence between specific parties but an example of wisdom literature, formulated as a letter for circulation. The \"Catholic Encyclopedia\" says, \"the subjects treated of in the Epistle are many and various; moreover, St. James not infrequently, whilst elucidating a certain point, passes abruptly to another, and presently resumes once more his former argument.\"\nOthers view the letter as having only broad topical or thematic structure. They generally organize James under three (in the views of Ralph Martin) to seven (in the views of Luke Johnson) general key themes or segments.\nA third group believes that James was more purposeful in structuring his letter, linking each paragraph theologically and thematically:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;James, like the gospel writers, can be seen as a purposeful theologian, carefully weaving his smaller units together into larger fabrics of thought and using his overall structure to prioritize his key themes.\nThe third view of the structuring of James is a historical approach that is supported by scholars who are not content with leaving the book as \"New Testament wisdom literature, like a small book of proverbs\" or \"like a loose collection of random pearls dropped in no particular order onto a piece of string.\"\nA fourth group uses modern discourse analysis or Greco-Roman rhetorical structures to describe the structure of James.\nThe United Bible Societies' \"Greek New Testament\" divides the letter into the following sections:\nHistorical context.\nThe exact historical circumstances that occasioned the epistle are unknown. Those who understand James 2 as a polemic against Paul or Paul\u2019s followers suggest an occasion for the letter aimed at opposing Pauline justification. Others have argued that James' discussion on faith and works does not have Pauline categories in view.\nSome scholars have suggested that the epistle was written to both Christian and non-Christian Jews, who continued to worship together before the parting of the ways between Christianity and Judaism. The warning against cursing people (Jas 3:9\u201310) has been read in light of this historical reconstruction, and Dale Allison has argued that \u201cJames reflects an environment in which some Jews, unhappy with Jewish Christians, were beginning to use the \"Birkat ha-minim\" or something very much like it\u201d to curse Christians.\nPoverty and wealth are key concerns throughout the epistle, and these issues are likely to reflect the epistle's historical context. The author shows concern for vulnerable and marginalised groups, such as \"orphans and widows\" (Jas 1:27), believers who are \"poorly clothed and lacking in daily food\" (Jas 2:15), and the oppressed waged-worker (Jas 5:4). He writes strongly against the rich (Jas 1:10; 5:1\u20136) and those who show partiality towards them (Jas 2:1\u20137).\nDoctrine.\nJustification.\nThe epistle contains the following famous passage concerning salvation and justification:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;14 What good is it, my brothers, if someone says he has faith but does not have works? Can that faith save him? 15 If a brother or sister is poorly clothed and lacking in daily food, 16 and one of you says to them, \u201cGo in peace, be warmed and filled,\u201d without giving them the things needed for the body, what good is that? 17 So also faith by itself, if it does not have works, is dead.\n18 But someone will say, \u201cYou have faith and I have works.\u201d Show me your faith apart from your works, and I will show you my faith by my works. 19 You believe that God is one; you do well. Even the demons believe\u2014and shudder! 20 Do you want to be shown, you foolish person, that faith apart from works is useless? 21 Was not Abraham our father justified by works when he offered up his son Isaac on the altar? 22 You see that faith was active along with his works, and faith was completed by his works; 23 and the Scripture was fulfilled that says, \u201cAbraham believed God, and it was counted to him as righteousness\u201d\u2014and he was called a friend of God. 24 You see that a person is justified by works and not by faith alone. 25 And in the same way was not also Rahab the prostitute justified by works when she received the messengers and sent them out by another way? 26 For as the body apart from the spirit is dead, so also faith apart from works is dead.\nThis passage has been contrasted with the teachings of Paul the Apostle on justification. Some scholars even believe that the passage is a response to Paul. One issue in the debate is the meaning of the Greek word (, 'render righteous or such as he ought to be'), with some among the participants taking the view that James is responding to a misunderstanding of Paul.\nRoman Catholicism and Eastern Orthodoxy have historically argued that the passage disproves the doctrine of justification by faith alone (\"sola fide\"). The early (and many modern) Protestants resolve the apparent conflict between James and Paul regarding faith and works in alternate ways from the Catholics and Orthodox:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Paul was dealing with one kind of error while James was dealing with a different error. The errorists Paul was dealing with were people who said that works of the law were needed to be added to faith in order to help earn God's favor. Paul countered this error by pointing out that salvation was by faith alone apart from deeds of the law (Galatians 2:16; Romans 3:21\u201322). Paul also taught that saving faith is not dead but alive, showing thanks to God in deeds of love (Galatians 5:6 ['...since in Christ Jesus it is not being circumcised or being uncircumcised that can effect anything \u2013 only faith working through love.']). James was dealing with errorists who said that if they had faith they didn't need to show love by a life of faith (James 2:14\u201317). James countered this error by teaching that faith is alive, showing itself to be so by deeds of love (James 2:18,26). James and Paul both teach that salvation is by faith alone and also that faith is never alone but shows itself to be alive by deeds of love that express a believer's thanks to God for the free gift of salvation by faith in Jesus.\nAccording to Ben Witherington III, differences exist between the Apostle Paul and James, but both used the law of Moses, the teachings of Jesus and other Jewish and non-Jewish sources, and \"Paul was not anti-law any more than James was a legalist\". A more recent article suggests that the current confusion regarding the Epistle of James about faith and works resulted from Augustine of Hippo's anti-Donatist polemic in the early fifth century. This approach reconciles the views of Paul and James on faith and works. \nAnointing of the sick.\nThe epistle is also the chief biblical text for the anointing of the sick. James wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Is anyone among you sick? Let him call for the elders of the church, and let them pray over him, anointing him with oil in the name of the Lord. And the prayer of faith will save the one who is sick, and the Lord will raise him up. And if he has committed sins, he will be forgiven.\nG. A. Wells suggested that the passage was evidence of late authorship of the epistle, on the grounds that the healing of the sick being done through an official body of presbyters (elders) indicated a considerable development of ecclesiastical organisation \"whereas in Paul's day to heal and work miracles pertained to believers indiscriminately (I Corinthians, XII:9).\"\nWorks, deeds and care for the poor.\nJames and the M Source material in Matthew are unique in the canon in their stand against the rejection of works and deeds. According to Sanders, traditional Christian theology wrongly divested the term \"works\" of its ethical grounding, part of the effort to characterize Judaism as legalistic. However, for James and for all Jews, faith is alive only through Torah observance. In other words, belief demonstrates itself through practice and manifestation. For James, claims about belief are empty, unless they are alive in action, works and deeds.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Do not merely listen to the word, and so deceive yourselves. Do what it says. Anyone who listens to the word but does not do what it says is like someone who looks at his face in a mirror and, after looking at himself, goes away and immediately forgets what he looks like. But whoever looks intently into the perfect law that gives freedom, and continues in it-not forgetting what they have heard, but doing it-they will be blessed in what they do.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Religion that God our Father accepts as pure and faultless is this: to look after orphans and widows in their distress and to keep oneself from being polluted by the world.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Speak and act as those who are going to be judged by the law that gives freedom, because judgment without mercy will be shown to anyone who has not been merciful. Mercy triumphs over judgment.\n\u2014\u2009The epistle emphasizes the importance of acts of charity or works to go along with having the Christian faith by means the following three verses in Chapter 2 of his Epistle:\n-2:14. What shall it profit, my brethren, if a man say he hath faith, but hath not works? Shall faith be able to save him?\n-2:18. But some man will say: Thou hast faith, and I have works. Shew me thy faith without works; and I will shew thee, by works, my faith.\n-2:20. But wilt thou know, O vain man, that faith without works is dead?\nTorah observance.\nJames is unique in the canon by its explicit and wholehearted support of Torah observance (the Law). According to Bibliowicz, not only is this text a unique view into the milieu of the Jewish founders \u2013 its inclusion in the canon signals that as canonization began (fourth century onward) Torah observance among believers in Jesus was still authoritative. According to modern scholarship James, Q, Matthew, the Didache, and the pseudo-Clementine literature reflect a similar ethos, ethical perspective, and stand on, or assume, Torah observance. James call to Torah observance (James 1:22-27) insures salvation (James 2:12\u201313, 14\u201326). Hartin is supportive of the focus on Torah observance and concludes that these texts support faith through action and sees them as reflecting the milieu of the Jewish followers of Jesus. Hub van de Sandt sees Matthew's and James' Torah observance reflected in a similar use of the Jewish Two Ways theme which is detectable in the Didache too (Didache 3:1\u20136). McKnight thinks that Torah observance is at the heart of James's ethics. A strong message against those advocating the rejection of Torah observance characterizes, and emanates from, this tradition: \"Some have attempted while I am still alive, to transform my words by certain various interpretations, in order to teach the dissolution of the law; as though I myself were of such a mind, but did not freely proclaim it, which God forbid! For such a thing were to act in opposition to the law of God which was spoken by Moses, and was borne witness to by our Lord in respect of its eternal continuance; for thus he spoke: 'The heavens and the earth shall pass away, but one jot or one tittle shall in no wise pass away from the law.'\"\nJames seem to propose a more radical and demanding interpretation of the law than mainstream Judaism. According to Painter, there is nothing in James to suggest any relaxation of the demands of the law. \"No doubt James takes for granted his readers' observance of the whole law, while focusing his attention on its moral demands.\"\nCanonicity.\nThe first explicit references to the Epistle of James are found in the writings of Origen of Alexandria (e.g. \"Comm. on John.,\" 19.23) in the third century. Scholars have generally rejected the possible second century allusions to James in the Apostolic Fathers and Irenaeus of Lyons \"Against Heresies\". Neither is James mentioned by Tertullian (c. 155\u2013220 CE) or Cyprian (c. 210\u2013258 CE), and its authenticity of the epistle doubted by Theodore of Mopsuestia (c. 350\u2013428 CE). In \"Historia ecclesiae\" 2.23.25, Eusebius classes James among the Antilegomena or disputed works, stating \"it is to be observed that it is disputed; at least, not many of the ancients have mentioned it, as is the case likewise with the epistle that bears the name of Jude, which is also one of the seven so-called catholic epistles. Nevertheless we know that these also, with the rest, have been read publicly in very many churches.\" \nIts late recognition in the Church, especially in the West, was a consequence primarily of its sparse attestation by earlier Christian authors and its disputed authorship. Jerome reported that the Epistle of James \"is claimed by some to have been published by some one else under his name, and gradually, as time went on, to have gained authority\" (\"De viris illustribus\" 2). \nThe Epistle of James is missing from the Muratorian fragment (poss. 2nd to 4th century), the Cheltenham list (c. 360 CE), but was listed with the twenty-seven New Testament books by Athanasius of Alexandria in his \"Thirty-Ninth Festal Epistle\" (367 CE), and subsequently affirmed by the Councils of Laodicea (c. 363 CE), of Rome (382 CE) and of Carthage (397 and 419).\nDuring the Reformation era, Martin Luther took issue with the epistle on theological grounds, finding James' description of faith and works incompatible with his understanding of justification. Luther did not remove James from his German translation of the Bible, but he did move it (along with Hebrews, Jude, and Revelation) to the end of the Bible.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9689", "revid": "1158347293", "url": "https://en.wikipedia.org/wiki?curid=9689", "title": "Epistle of Jude", "text": "Book of the New Testament\nThe Epistle of Jude is the penultimate book of the New Testament as well as the Christian Bible. It is traditionally attributed to Jude, brother of James the Just, and thus relative of Jesus as well.\nJude is a short epistle written in Koine Greek. It condemns in fierce terms certain people the author sees as a threat to the early Christian community, but describes these opponents only vaguely. According to Jude, these opponents are within the Christian community, but are not true Christians: they are scoffers, false teachers, malcontents, given to their lusts, and so on. The epistle reassures its readers that these people will soon be judged by God. It is possible that the group being referred to would have been obvious to the original recipients of the letter, but if a specific group was being referred to, knowledge of the details has since been lost. The one bit of their potential ideology discussed in the letter is that these opponents denigrate angels and their role. If this was indeed a part of the ideology of this group the author opposed, then the epistle is possibly a counterpoint to the Epistle to the Colossians. Colossians condemns those who give angels undue prominence and worship them; this implies the two letters might be part of an early Christian debate on Christian angelology.\nAuthorship.\nThe epistle introduces itself with a simple claim of authorship: \"Jude, a servant of Jesus Christ and brother of James\" (NRSV). \"James\" is generally taken to mean James, brother of Jesus, a prominent leader in the early church. Introductions would typically refer to a father in the era, so the use of a brother suggests that this would only be done if the brother was famous within the community. Little is known about Jude himself. As the brother of James, it has traditionally meant Jude was also a brother of Jesus, since James is described as being the brother of Jesus. This is why Clement of Alexandria (c.\u00a0150\u2013215 AD) wrote in his work \"Comments on the Epistle of Jude\" that Jude, the author, was a son of Joseph and a brother of Jesus. However, there is a dispute as to whether \"brother\" means someone who has the same father and mother, or a half-brother, cousin, or more distant familial relationship. This dispute over the true meaning of \"brother\" grew as the doctrine of the Virgin Birth evolved. For example, Saint Jerome believed that not only Mary but also Joseph were virgins their entire lives, and thus James and by extension Jude were cousins.\nOutside the book of Jude, a \"Jude\" is mentioned five times in the New Testament: three times as Jude the Apostle, and twice as Jude the brother of Jesus (aside from references to Judas Iscariot and Judah (son of Jacob)). Debate continues as to whether the author of the epistle is the apostle, the brother of Jesus, both, or neither. Scholars have argued that since the author of the letter has not identified himself as an apostle and also refers to the apostles as a third party, he cannot be identified with Jude the Apostle. Other scholars have drawn the opposite conclusion, which is that, as an apostle, he would not have made a claim of apostleship on his own behalf.\nA reason to doubt that a relative of Jesus wrote the book is that they are unlikely to have been literate. Jesus's family were common laborers from Aramaic-speaking Galilee, and literary composition skills were overwhelmingly concentrated in the elite in antiquity. Few knew how to read, fewer how to write, and fewer still how to write complicated literary treatises. Jesus himself may have been able to read, presumably in Hebrew, but he was also exceptional and the star of the family. Even if somehow Jude had learned a little of how to read Hebrew, the epistle is written in excellent, complicated Koine Greek, with knowledge of common forms of rhetoric and argument of the era, as well as seeming knowledge of the scriptures in Hebrew. All this would be exceptional for a countryside Galilean. Scholars who support the authorship of Jude generally assume that he must have embarked upon extensive travel and missionary work among Hellenized Jews to master Greek as the author did. Ultimately, it is impossible to know more details of Jude's life for sure. One early Christian tradition states that Jude's grandchildren were brought before Emperor Domitian and interrogated; in the story, they defended themselves as not rebels and mere poor laborers eking out what they could from a single patch of land. While the story is clearly apocryphal \u2013 Roman emperors did not generally interrogate Galilean peasants \u2013 it does suggest that early Christians remembered Jude's family as lower-class laborers, not literate elites.\nIf the \"Jude\" writing the letter was not the actual Apostle Jude mentioned in the gospels, then he was possibly an unknown Christian who happened to share the name and coincidentally also had a brother named James. A final possibility is that the epistle is pseudepigrapha \u2013 that the author intentionally hinted to readers that it was from the more famous Jude, but only as a false attribution to give the letter more authority.\nDate.\nThe date of composition is not known, but is loosely speculated to be between the years 50 and 110. Among those who favor the authorship of the Jude mentioned in the gospels, the letter is generally placed before the destruction of the Temple in Jerusalem in 70 AD. Among those who favor the authorship of an unknown Christian, it is assumed to be a work of the early second century. Scholars who consider the letter a pseudonymous work generally favor the later dates due to the letter's references to the apostles (as if they lived in the past) and to tradition and because of its competent Greek style. Bo Reicke suggests around 90 AD; Heikki R\u00e4is\u00e4nen concurs and believes that it may have been written at the end of the first century. Bart Ehrman suggests an even later date, in the second half of the second century, due to use of certain terminology in ways similar to the pastoral epistles that was uncommon in the first century.\nContent.\nJude urges his readers to \"contend for the faith\" against \"certain intruders [who] have stolen in among you.\" He warns about false teachers who twist the grace of Christ as a pretext for wantonness. Jude asks the reader to recall how even after the Lord saved his own people out of the land of Egypt, he did not hesitate to destroy those who fell into unbelief, much as he punished the angels who fell from their original exalted status and the inhabitants of Sodom and Gomorrah. He also paraphrases (verse 9) an incident apparently from the Testament of Moses that has since been lost about Satan and Michael the Archangel quarreling over the body of Moses.\nContinuing the analogy from Israel's history, he says that the false teachers have followed in the way of Cain, have rushed after reward into the error of Balaam, and have perished in the rebellion of Korach. He describes in vivid terms the opponents he warns of, calling them \"clouds without rain\", \"trees without fruit\", \"foaming waves of the sea\", and \"wandering stars\". He exhorts believers to remember the words spoken by the Apostles, using language similar to the second epistle of Peter to answer concerns that the Lord seemed to tarry: \"In the last time there will be scoffers, indulging their own ungodly lusts,\" and to keep themselves in God's love, before delivering a doxology to God.\nJude quotes directly from 1 Enoch, a widely distributed work among the Old Testament Pseudepigrapha, citing a section of 1 Enoch 1:8 that is based on Deuteronomy 33:2.\nStyle and audience.\nThe Epistle of Jude is one of the shortest books of the New Testament, consisting of just 1 chapter with 25 verses, and almost the shortest book in the Bible. It may have been composed as an encyclical letter\u2014that is, one not directed to the members of one church in particular, but intended rather to be circulated and read in all churches. While addressed to the Christian Church as a whole, the reference to the Old Testament figures such as Michael, Cain, and Korah's sons; the Book of Enoch quotation; and the invocation of James, the head of the church of Jerusalem, suggests a Jewish Christian main audience that would be familiar with Enochian literature and revere James.\nThe wording and syntax of this epistle in its original Greek demonstrates that the author was capable and fluent. The epistle's style is combative, impassioned, and rushed. Many examples of evildoers and warnings about their fates are given in rapid succession.\nThe epistle concludes with a doxology, which is considered by Peter H. Davids to be one of the highest in quality contained in the Bible.\nCanonical status.\nThe letter of Jude was one of the disputed books of the biblical canon of the New Testament. Despite some opposition, it seems to have been accepted by most churches around the end of the second century. Clement of Alexandria, Tertullian, and the Muratorian canon considered the letter canonical. The letter was eventually accepted as part of the canon by later Church Fathers such as Athanasius of Alexandria. The canon list at the Council of Carthage (c. 397) included the epistle of Jude. \nThe first historical record of doubts as to authorship are found in the writings of Origen of Alexandria, who spoke of the doubts held by some in the early third century. Eusebius classified it with the \"disputed writings, the \"antilegomena\"\" in the early fourth century. Eusebius doubted its authenticity partially because it was rarely quoted among ancient sources, although he acknowledges it was read in many churches. The links between the Epistle and 2 Peter and its use of the biblical apocrypha raised concern: Saint Jerome wrote in 392 AD that the book was \"rejected by many\" since it quotes the Book of Enoch.\nSurviving early manuscripts.\nEarly manuscripts containing the text of the epistle of Jude include:\nIdentity of the opponents.\nThe epistle fiercely condemns the opponents it warns of and declares that God will judge and punish them, despite them being a part of the Christian community. However, the exact nature of these opponents has been a continuing interest for both theologians and historians, as the epistle does not describe them in any more detail than calling them corrupt and ungodly. Several theories have been proposed. The most specific verse describing the opponents is verse 8:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In the very same way, on the strength of their dreams these ungodly people pollute their own bodies, reject authority and heap abuse on celestial beings.\nReject \"authority\" (\u03ba\u03c5\u03c1\u03b9\u03bf\u03c4\u03b7\u03c4\u03b1, \"kyriot\u0113ta\"; alternate translations include \"dominion\" or \"lordship\") could mean several things. The most direct would be rejection of civil or ecclesiastical authority: the opponents were ignoring guidance from leaders. Martin Luther and Jean Calvin agreed with this interpretation, and it is the most common one. Another possibility is that this specifically referred to rejecting the authority of Jesus or God, which would agree with verse 4 and be reinforcing the claim that these opponents are not true Christians. A third possibility is that this is the singular of \"kyriot\u0113tes\" (Dominions), a class of angels. This would fit with the final part of the sentence of \"heap abuse on celestial beings\", but it is unusual that the singular is used. Versions of Jude vary, and some manuscripts such as the Codex Sinaiticus indeed use the plural form, though.\n\"Heap abuse on celestial beings\" is also a relevant statement, as it stands in some tension with the works of Paul the Apostle as well as the Epistle to the Hebrews. Paul's undisputed works indicate that believers are already on the same level as angels, that all existing powers are subject to Christ, and believers are the future judges of angels. Later writings attributed to Paul such as Colossians and Ephesians go even further, with Colossians decrying the alleged worship of angels. A hypothesis is thus that the author may have been attacking forms of Pauline Christianity that were not suitably deferential to angels in their opinion. \"Rejecting authority\" may be a reference to Paul's preaching that gentiles did not need to comply with Jewish Law. As James was known to be a major figure among Jewish Christians, this might indicate tension between the more Jewish strands of early Christianity represented by James and Jude set against Paul's message to the gentiles. However, the line about \"heap abuse on celestial beings\" might have essentially been just another insult, in which case this entire line of thought is rendered moot. \nThe inherent vagueness of the epistle means that the identities of these opponents may well never be known.\nSimilarity to 2 Peter.\nPart of Jude is very similar to 2 Peter (mainly 2 Peter chapter 2); so much so that most scholars agree that either one letter used the other directly, or they both drew on a common source. Comparing the Greek text portions of 2 Peter 2:1\u20133:3 (426 words) to Jude 4\u201318 (311 words) results in 80 words in common and 7 words of substituted synonyms.\nBecause this epistle is much shorter than 2 Peter, and due to various stylistic details, some scholars consider Jude the source for the similar passages of 2 Peter. However, other writers, arguing that Jude 18 quotes as past tense, consider Jude to have come after 2 Peter.\nSome scholars who consider Jude to predate 2 Peter note that the latter appears to quote the former but omits the reference to the non-canonical book of Enoch.\nReferences to other books.\nThe Epistle of Jude references at least three other books, with two (Book of Zechariah &amp; 2 Peter) being canonical in all churches and the other (Book of Enoch) non-canonical in most churches.\nVerse 9 refers to a dispute between Michael the Archangel and the devil about the body of Moses. Some interpreters understand this reference to be an allusion to the events described in Zechariah 3:1\u20132. The classical theologian Origen, as well as Clement of Alexandria, Didymus the Blind, and others, attributes this reference to the non-canonical Assumption of Moses. However, no extant copies of the Assumption of Moses contain this story, leading most scholars to conclude the section covering this dispute has been lost \u2013 perhaps a lost ending, since a story involving Moses's body would logically occur at the end. Some scholars disagree; James Charlesworth argues that the Assumption of Moses never contained any such content, and other ancient Church writers supported a different origin.\nVerses 14\u201315 contain a direct quotation of a prophecy from 1 Enoch 1:9. The title \"Enoch, the seventh from Adam\" is also sourced from 1 En. 60:1. Most commentators assume that this indicates that Jude accepts the antediluvian patriarch Enoch as the author of the Book of Enoch which contains the same quotation. An alternative explanation is that Jude quotes the Book of Enoch aware that verses 14\u201315 are an expansion of the words of Moses from Deuteronomy 33:2.\nThe Book of Enoch is not considered canonical by most churches, although it is by the Ethiopian Orthodox church. According to Western scholars, the older sections of the Book of Enoch (mainly in the \"Book of the Watchers\") date from about 300 BC and the latest part (\"Book of Parables\") probably was composed at the end of the 1st century BC. 1 Enoch 1:9, mentioned above, is part of the pseudepigrapha and is among the Dead Sea Scrolls [4Q Enoch (4Q204[4QENAR]) COL I 16\u201318]. It is largely accepted by scholars that the author of the Epistle of Jude was familiar with the Book of Enoch and was influenced by it in thought and diction.\nThe epistle also closely mirrors the Epistle of James, with many similar sentences and borrowed phrases.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nOnline translations of the Epistle of Jude:\nAudiobook Version:\nAdditional information:"}
{"id": "9692", "revid": "41840956", "url": "https://en.wikipedia.org/wiki?curid=9692", "title": "Eusebius Amort", "text": "German Roman Catholic theologian\nEusebius Amort (November 15, 1692\u00a0\u2013 February 5, 1775) was a German Roman Catholic theologian.\nLife.\nAmort was born at Bibermuhle, near Tolz, in Upper Bavaria. He studied at Munich, and at an early age joined the Canons Regular at Polling, where, shortly after his ordination in 1717, he taught theology and philosophy.\nThe Parnassus Boicus learned society was based on a plan started in 1720 by three Augustinian fathers: Eusebius Amort, Gelasius Hieber (1671\u20131731), a famous preacher in the German language and Agnellus Kandler (1692\u20131745), a genealogist and librarian. The initial plans fell through, but in 1722 they issued the first volume of the \"Parnassus Boicus\" journal, communicating interesting information from the arts and sciences.\nIn 1733 Amort went to Rome as theologian to Cardinal Niccolo Maria Lercari (died 1757).\nHe returned to Polling in 1735 and devoted the rest of his life to the revival of learning in Bavaria. He died at Polling in 1775.\nWorks.\nAmort, who had the reputation of being the most learned man of his age, was a voluminous writer on every conceivable subject, from poetry to astronomy, from dogmatic theology to mysticism. His best known works are:\nThe list of his other works, including his three erudite contributions to the question of authorship of the \"Imitatio Christi\", will be found in C. Toussaint's scholarly article in Alfred Vacant's \"Dictionnaire de theologie\" (1900, cols 1115-1117).\nReferences.\nCitations\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "9693", "revid": "45382375", "url": "https://en.wikipedia.org/wiki?curid=9693", "title": "Episcopus vagans", "text": "In Christianity, an episcopus vagans (plural episcopi vagantes; Latin for 'wandering bishops' or 'stray bishops') is a person consecrated, in a \"clandestine or irregular way\", as a bishop outside the structures and canon law of the established churches; a person regularly consecrated but later excommunicated, and not in communion with any generally recognized diocese; or a person who has in communion with them small groups that appear to exist solely for the bishop's sake.\nDavid V. Barrett, in the \"Encyclopedia of New Religious Movements\", specifies that now \"\" are \"those independent bishops who collect several different lines of transmission of apostolic succession, and who will happily (and sometimes for a fee) consecrate anyone who requests it\". Those described as wandering bishops often see the term as pejorative. The general term for \"wandering\" clerics, as were common in the Middle Ages, is \"clerici vagantes\"; the general term for those recognising no leader is \"acephali\".\nThe \"Oxford Dictionary of the Christian Church\" mentions as the main lines of succession deriving from \"episcopi vagantes\" in the 20th century those founded by Arnold Mathew, Joseph Ren\u00e9 Vilatte and Leon Chechemian. Others that could be added are those derived from Aftimios Ofiesh, Carlos Duarte Costa, Paolo Miraglia-Gulotti, Emmanuel Milingo, Pierre Martin Ng\u00f4 \u0110\u00ecnh Th\u1ee5c and Richard Williamson.\nHistory.\nAccording to Buchanan, \"the real rise of the problem\" happened in the 19th century, in the \"wake of the Anglo-Catholic movement\", \"through mischievous activities of a tiny number of independently acting bishops\". They exist worldwide, he writes, \"mostly without congregations\", and \"many in different stages of delusion and fantasy, not least in the Episcopal titles they confer on themselves\"; \"the distinguishing mark\" to \"specifically identif[y]\" an \"episcopus vagans\" is \"the lack of a true see or the lack of a real church life to oversee\".\nPaul Halsall, on the Internet History Sourcebooks Project, did not list a single church edifice of independent bishops, in a 1996\u20131998 New York City building architecture survey of religious communities, which maintain bishops claiming apostolic succession and claim cathedral status but noted there \"are now literally hundreds of these \", of lesser or greater spiritual probity. They seem to have a tendency to call living room sanctuaries 'cathedrals';\" those buildings were not perceived as cultural symbols and did not meet the survey criteria. David V. Barrett wrote, in \"A Brief Guide to Secret Religions\", that \"one hallmark of such bishops is that they often collect as many lineages as they can to strengthen their Episcopal legitimacy\u2014at least in their own eyes\" and their groups have more clergy than members.\nBarrett wrote that leaders \"of some esoteric movements, are also priests or bishops in small non-mainstream Christian Churches\"; he explains, this type of \"independent or autocephalous\" group has \"little in common with the Church it developed from, the Old Catholic Church, and even less in common with the Roman Catholic Church\" but still claims its authority from apostolic succession.56\nBuchanan writes that based the criteria of having \"a true see\" or having \"a real church life to oversee\", the bishops of most forms of the Continuing Anglican movement are not necessarily classified as vagantes, but \"are always in danger of becoming such\".\nTheological issues.\nA Roman or Eastern Catholic ordained to the episcopacy without a mandate from the Pope is automatically excommunicated and is thereby forbidden to celebrate the sacraments, according to canon law. Through the concept of \"valid but illicit\" ordinations however, and the dogma of sacramental character, though excommunicated and forbidden to celebrate sacraments within any church in communion with the Holy See, the person still holds a valid episcopacy though unrecognized at large.\nAccording to a theological view affirmed, for instance, by the International Bishops' Conference of the Old Catholic Church with regard to ordinations by Arnold Mathew, an episcopal ordination is for service within a specific Christian church, and an ordination ceremony that concerns only the individual himself does not make him truly a bishop. The Holy See has not commented on the validity of this theory, but has declared with regard to ordinations of this kind carried out, for example, by Emmanuel Milingo toward Peter Paul Brennan and others, that the Roman Church \"does not recognize and does not intend to recognize in the future those ordinations or any of the ordinations derived from them and therefore the canonical state of the alleged bishops remains that in which they were before the ordination conferred by Mr Milingo\", thereby recognizing their previous stance as \"illicit but valid\" clergy prior to Milingo.\nEastern Orthodox.\nVlassios Pheidas, on an official Church of Greece site, uses the canonical language of the Eastern Orthodox tradition, to describe the conditions in ecclesial praxis when sacraments, including Holy Orders, are real, valid, and efficacious. He notes language is itself part of the ecclesiological problem.ch. 1\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThis applies to the validity and efficacy of the ordination of bishops and the other sacraments, not only of the Independent Catholic churches, but also of all other Christian churches, including the Roman Catholic Church, Oriental Orthodoxy and the Assyrian Church of the East.\nAnglican.\nAnglican bishop Colin Buchanan, in the \"Historical Dictionary of Anglicanism\", says that the Anglican Communion has held an Augustinian view of orders, by which \"the validity of Episcopal ordinations (to whichever order) is based solely upon the historic succession in which the ordaining bishop stands, irrespective of their contemporary ecclesial context\".\nHe describes the circumstances of Archbishop Matthew Parker's consecration as one of the reasons why this theory is \"generally held\". Parker was chosen by Queen Elizabeth I of England to be the first Church of England Archbishop of Canterbury after the death of the previous office holder, Cardinal Reginald Pole, the last Roman Catholic Archbishop of Canterbury. Buchanan notes the Roman Catholic Church also focuses on issues of intention and not just breaks in historical succession. He does not explain whether intention has an ecclesiological role, for Anglicans, in conferring or receiving sacraments.\nParticular consecrations.\nArnold Mathew, according to Buchanan, \"lapsed into the vagaries of an \"\"\".335 Stephen Edmonds, in the \"Oxford Dictionary of National Biography\", wrote that in 1910 Mathew's wife separated from him; that same year, he declared himself and his church seceded from the Union of Utrecht. Within a few months, on 2 November 1911, he was excommunicated by the Roman Catholic Church. He later sued \"The Times\" for libel based on the words \"pseudo-bishop\" used to describe him in the newspaper's translation from the Latin text \"\", and, lost his case in 1913.\nHenry R.T. Brandreth wrote, in \"Episcopi Vagantes and the Anglican Church\", \"[o]ne of the most regrettable features of Mathew's episcopate was the founding of the Order of Corporate Reunion (OCR) in 1908. This claimed to be a revival of Frederick George Lee's movement, but was in fact unconnected with it\". Brandreth thought it \"seems still to exist in a shadowy underground way\" in 1947, but disconnected.18 Colin Holden, in \"Ritualist on a Tricycle\", places Mathew and his OCR into perspective, he wrote Mathew was an \", lived in a cottage provided for him, and performed his conditional OCR acts, sometimes called according to Holden \"bedroom ordinations\", in his cottage. Mathew questioned the validity of Anglican ordinations and became involved with the OCR, in 1911 according to Edmonds, and he openly advertised his offer to reordain Anglican clergy who requested it. This angered the Church of England.\nIn 1912, D. J. Scannell O'Neill wrote in \"The Fortnightly Review\" that London \"seems to have more than her due share of bishops\" and enumerates what he refers to as \"these hireling shepherds\". He also announces that one of them, Mathew, revived the OCR and published \"The Torch\", a monthly review, advocating the reconstruction of Western Christianity and reunion with Eastern Christianity. \"The Torch\" stated \"that the ordinations of the Church of England are not recognized by any church claiming to be Catholic\" so the promoters involved Mathew to conditionally ordain group members who are \"clergy of the Established Church\" and \"sign a profession of the Catholic Faith\". It stipulated Mathew's services were not a system of simony and given without simoniac expectations. The group sought to enroll \"earnest-minded Catholics who sincerely desire to help forward the work of [c]orporate [r]eunion with the Holy See\". Nigel Yates, in \"Anglican Ritualism in Victorian Britain, 1830-1910\", described it as \"an even more bizarre scheme to promote a Catholic Uniate Church in Britain\" than Lee and Ambrose Lisle March Phillipps de Lisle's Association for the Promotion of the Unity of Christendom. It was editorialized by O'Neill that the \"most charitable construction to be placed on this latest move of Mathew is that he is not mentally sound. Being an Irishman, it is strange that he has not sufficient humor to see the absurdity of falling away from the Catholic Church in order to assist others to unite with the Holy See\". Edmonds reports that \"anything between 4 and 265 was suggested\" as to how many took up his offer of reordination.\nWhen it declared devoid of canonical effect the consecration ceremony conducted by Archbishop Pierre Martin Ng\u00f4 \u0110\u00ecnh Th\u1ee5c for the Carmelite Order of the Holy Face group at midnight of 31 December 1975, the Holy See refrained from pronouncing on its validity. It also made the same statement with regard to later ordinations by those bishops, saying that, \"as for those who have already thus unlawfully received ordination or any who may yet accept ordination from these, whatever may be the validity of the orders (), the Church does not and will not recognise their ordination (), and will consider them, for all legal effects, as still in the state in which they were before, except that the ... penalties remain until they repent\".\nA similar declaration was issued with regard to Archbishop Emmanuel Milingo's conferring of episcopal ordination on four men - all of whom, by virtue of previous Independent Catholic consecrations, claimed already to be bishops - on 24 September 2006: the Holy See, as well as stating that, in accordance with Canon 1382 of the Code of Canon Law, all five men involved incurred automatic () excommunication through their actions, declared that \"the Church does not recognise and does not intend in the future to recognise these ordinations or any ordinations derived from them, and she holds that the canonical state of the four alleged bishops is the same as it was prior to the ordination\". \nConsecrations that the late Archbishop Marcel Lefebvre performed in 1988 for the service of the relatively numerous followers of the Traditionalist Catholic Society of St. Pius X that he had founded, and of the bishops who, under pressure from the Catholic Patriotic Association, \"have been ordained without the Pontifical mandate and who have not asked for, or have not yet obtained, the necessary legitimation\", and who consequently, Pope Benedict XVI declared, \"are to be considered illegitimate, but validly ordained\".\nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9695", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=9695", "title": "Elizabeth Garrett Anderson", "text": "English physician, doctor and feminist\nDr. Elizabeth Garrett Anderson (9 June 1836\u00a0\u2013 17 December 1917) was an English physician and suffragist. She was the first woman to qualify in Britain as a physician and surgeon. She was the co-founder of the first hospital staffed by women, the first dean of a British medical school, the first woman in Britain to be elected to a school board and, as mayor of Aldeburgh, the first female mayor in Britain.\nEarly life.\nElizabeth was born in Whitechapel, London, and the second of eleven children of Newson Garrett (1812\u20131893), from Leiston, Suffolk, and his wife, Louisa (born Dunnell; c. 1813\u20131903), from London.\nThe Garrett ancestors had been ironworkers in East Suffolk since the early seventeenth century. Newson was the youngest of three sons and not academically inclined, although he possessed the family's entrepreneurial spirit. When he finished school, the town of Leiston offered little to Newson, so he left for London to make his fortune. There, he fell in love with his brother's sister-in-law, Louisa Dunnell, the daughter of an innkeeper of Suffolk origin. After their wedding, the couple went to live in a pawnbroker's shop at 1 Commercial Road, Whitechapel. The Garretts had their first three children in quick succession: Louie, Elizabeth and their brother (Dunnell Newson) who died at the age of six months. While Louisa mourned the loss of her third child, it was not easy to raise their two daughters in the city of London at that time. When Garrett was three years old, the family moved to 142 Long Acre, where they lived for two years, while one more child was born and her father moved up in the world, becoming not only the manager of a larger pawnbroker's shop, but also a silversmith. Garrett's grandfather, owner of the family engineering works, Richard Garrett &amp; Sons, had died in 1837, leaving the business to his eldest son, Garrett's uncle. Despite his lack of capital, Newson was determined to be successful and in 1841, at the age of 29, he moved his family to Suffolk, where he bought a barley and coal merchants business in Snape, constructing Snape Maltings, a fine range of buildings for malting barley. \nThe Garretts lived in a square Georgian house opposite the church in Aldeburgh until 1852. Newson's malting business expanded and more children were born, Edmund (1840), Alice (1842), Agnes (1845), Millicent (1847), who was to become a leader in the constitutional campaign for women's suffrage, Sam (1850), Josephine (1853) and George (1854). By 1850, Newson was a prosperous businessman and was able to build Alde House, a mansion on a hill behind Aldeburgh. A \"by-product of the industrial revolution\", Garrett grew up in an atmosphere of \"triumphant economic pioneering\" and the Garrett children were to grow up to become achievers in the professional classes of late-Victorian England. Elizabeth was encouraged to take an interest in local politics and, contrary to practices at the time, was allowed the freedom to explore the town with its nearby salt-marshes, beach and the small port of Slaughden with its boatbuilders' yards and sailmakers' lofts.\nEarly education.\nThere was no school in Aldeburgh so Garrett learned the three Rs from her mother. When she was 10 years old, a governess, Miss Edgeworth, a poor gentlewoman, was employed to educate Garrett and her sister. Mornings were spent in the schoolroom; there were regimented afternoon walks; educating the young ladies continued at mealtimes when Edgeworth ate with the family; at night, the governess slept in a curtained off area in the girls' bedroom. Garrett despised her governess and sought to outwit the teacher in the classroom. When Garrett was 13 and her sister 15, they were sent to a private school, the Boarding School for Ladies in Blackheath, London, which was run by the step aunts of the poet Robert Browning. There, English literature, French, Italian and German as well as deportment, were taught.\nLater in life, Garrett recalled the stupidity of her teachers there, though her schooling there did help establish a love of reading. Her main complaint about the school was the lack of science and mathematics instruction. Her reading matter included Tennyson, Wordsworth, Milton, Coleridge, Trollope, Thackeray and George Eliot. Elizabeth and Louie were known as \"the bathing Garretts\", as their father had insisted they be allowed a hot bath once a week. However, they made what were to be lifelong friends there. When they finished in 1851, they were sent on a short tour abroad, ending with a memorable visit to the Great Exhibition in Hyde Park, London.\nAfter this formal education, Garrett spent the next nine years tending to domestic duties, but she continued to study Latin and arithmetic in the mornings and also read widely. Her sister Millicent recalled Garrett's weekly lectures, \"Talks on Things in General\", when her younger siblings would gather while she discussed politics and current affairs from Garibaldi to Macaulay's \"History of England\". In 1854, when she was eighteen, Garrett and her sister went on a long visit to their school friends, Jane and Anne Crow, in Gateshead where she met Emily Davies, the early feminist and future co-founder of Girton College, Cambridge. Davies was to be a lifelong friend and confidante, always ready to give sound advice during the important decisions of Garrett's career. It may have been in the \"English Woman's Journal\", first issued in 1858, that Garrett first read of Elizabeth Blackwell, who had become the first female doctor in the United States in 1849. When Blackwell visited London in 1859, Garrett travelled to the capital. By then, her sister Louie was married and living in London. Garrett joined the Society for Promoting the Employment of Women, which organised Blackwell's lectures on \"Medicine as a Profession for Ladies\" and set up a private meeting between Garrett and the doctor. It is said that during a visit to Alde House around 1860, one evening while sitting by the fireside, Garrett and Davies selected careers for advancing the frontiers of women's rights; Garrett was to open the medical profession to women, Davies the doors to a university education for women, while 13-year-old Millicent was allocated politics and votes for women. At first Newson was opposed to the radical idea of his daughter becoming a physician but came round and agreed to do all in his power, both financially and otherwise, to support Garrett.\nMedical education.\nAfter an initial unsuccessful visit to leading doctors in Harley Street, Garrett decided to first spend six months as a surgery nurse at Middlesex Hospital, London in August 1860. On proving to be a good nurse, she was allowed to attend an outpatients' clinic, then her first operation. She unsuccessfully attempted to enroll in the hospital's Medical School but was allowed to attend private tuition in Latin, Greek and \"materia medica\" with the hospital's apothecary, while continuing her work as a nurse. She also employed a tutor to study anatomy and physiology three evenings a week. Eventually she was allowed into the dissecting room and the chemistry lectures. Gradually, Garrett became an unwelcome presence among the male students, who in 1861 presented a memorial to the school against her admittance as a fellow student, despite the support she enjoyed from the administration. She was obliged to leave the Middlesex Hospital but she did so with an honours certificate in chemistry and \"materia medica\". Garrett then applied to several medical schools, including Oxford, Cambridge, Glasgow, Edinburgh, St Andrews and the Royal College of Surgeons, all of which refused her admittance.\nA companion to her in this struggle was the lesser known Dr. Sophia Jex-Blake. While both are considered \"outstanding\" medical figures of the late 19th century, Garrett was able to obtain her credentials by way of a \"side door\" through a loophole in admissions at the Worshipful Society of Apothecaries. Having privately obtained a certificate in anatomy and physiology, she was admitted in 1862 by the Society of Apothecaries who, as a condition of their charter, could not legally exclude her on account of her sex. She was the only woman in the Apothecaries Hall who sat the exam that year and among the 51 gentlemen candidates was William Heath Strange, who went on to found the Hampstead General Hospital, which was on the site now occupied by the Royal Free Hospital. She continued her battle to qualify by studying privately with various professors, including some at the University of St Andrews, the Edinburgh Royal Maternity and the London Hospital Medical School.\nIn 1865, she finally took her exam and obtained a licence (LSA) from the Society of Apothecaries to practise medicine, the first woman qualified in Britain to do so openly (previously there was Dr James Barry who was born and raised female but presented as male from the age of 20, and lived his adult life as a man). On the day, three out of seven candidates passed the exam, Garrett with the highest marks. The Society of Apothecaries immediately amended its regulations to prevent other women obtaining a licence meaning that Jex-Blake could not follow this same path; the new rule disallowed privately educated women to be eligible for examination. It was not until 1876 that the new Medical Act (39 and 40 Vict, Ch. 41) passed, which allowed British medical authorities to license all qualified applicants whatever their gender.\nCareer.\nThough she was now a licentiate of the Society of Apothecaries, as a woman, Garrett could not take up a medical post in any hospital. So in late 1865, Garrett opened her own practice at 20 Upper Berkeley Street, London. At first patients were scarce, but the practice gradually grew. After six months in practice, she wished to open an outpatients dispensary, to enable poor women to obtain medical help from a qualified practitioner of their own gender. In 1865, there was an outbreak of cholera in Britain, affecting both rich and poor, and in their panic, some people forgot any prejudices they had in relation to a female physician. The first death due to cholera occurred in 1866, but by then Garrett had already opened St Mary's Dispensary for Women and Children, at 69 Seymour Place. In the first year, she tended to 3,000 new patients, who made 9,300 outpatient visits to the dispensary. On hearing that the Dean of the faculty of medicine at the University of Sorbonne, Paris was in favour of admitting women as medical students, Garrett studied French so that she could apply for a medical degree, which she obtained in 1870 after some difficulty.\nThe same year she was elected to the first London School Board, an office newly opened to women; Garrett's was the highest vote among all the candidates. Also in that year, she was made one of the visiting physicians of the East London Hospital for Children (later the Queen Elizabeth Hospital for Children), becoming the first woman in Britain to be appointed to a medical post, but she found the duties of these two positions to be incompatible with her principal work in her private practice and the dispensary, as well as her role as a new mother, so she resigned from these posts by 1873. In 1872, the dispensary became the New Hospital for Women and Children, treating women from all over London for gynaecological conditions; the hospital moved to new premises in Marylebone Street in 1874. Around this time, Garrett also entered into discussion with male medical views regarding women. In 1874, Henry Maudsley's article on Sex and Mind in Education appeared, which argued that education for women caused over-exertion and thus reduced their reproductive capacity, sometimes causing \"nervous and even mental disorders\". Garrett's counter-argument was that the real danger for women was not education but boredom and that fresh air and exercise were preferable to sitting by the fire with a novel. In the same year, she co-founded London School of Medicine for Women with Sophia Jex-Blake and became a lecturer in what was the only teaching hospital in Britain to offer courses for women. She continued to work there for the rest of her career and was dean of the school from 1883 to 1902. This school was later called the Royal Free Hospital of Medicine, which later became part of what is now the medical school of University College London.\nBMA membership.\nIn 1873 she gained membership of the British Medical Association (BMA). In 1878 a motion was proposed to exclude women following the election of Garrett Anderson and Frances Hoggan. The motion was opposed by Dr Norman Kerr who maintained the equal rights of members. This was \"one of several instances where Garrett, uniquely, was able to enter a hitherto all male medical institution which subsequently moved formally to exclude any women who might seek to follow her.\" In 1892, women were again admitted to the British Medical Association. In 1897, Garrett Anderson was elected president of the East Anglian branch of the BMA.\nGarrett Anderson worked steadily at the development of the New Hospital for Women, and (from 1874) at the creation of the London School of Medicine for Women, where she served as its dean. Both institutions were handsomely and suitably housed and equipped. The New Hospital for Women was able to commission a building in the Euston Road; the architect was J. M. Brydon, who took into his employment at this time Anderson's sister Agnes Garrett and her cousin Rhoda Garrett, who contributed to its design. The hospital was for many years worked entirely by medical women. The schools (in Hunter Street, WC1) had over 200 students, most of them preparing for the medical degree of London University (the present-day University College London), which was opened to women in 1877.\nWomen\u2019s suffrage movement.\nGarrett Anderson was also active in the women's suffrage movement. In 1866, Garrett Anderson and Davies presented petitions signed by more than 1,500 asking that female heads of household be given the vote. That year, Garrett Anderson joined the first British Women's Suffrage Committee. She was not as active as her sister, Millicent Garrett Fawcett, though Garrett Anderson became a member of the Central Committee of the National Society for Women's Suffrage in 1889. After her husband's death in 1907, she became more active. As mayor of Aldeburgh, she gave speeches for suffrage, before the increasing militant activity in the movement led to her withdrawal in 1911. Her daughter Louisa, also a physician, was more active and more militant, spending time in prison in 1912 for her suffrage activities.\nPersonal life.\nElizabeth Garrett Anderson once remarked that \"a doctor leads two lives, the professional and the private, and the boundaries between the two are never traversed\". In 1871, she married James George Skelton Anderson (died 1907) of the Orient Steamship Company, but she did not give up her medical practice. She had three children, Louisa (1873\u20131943), Margaret (1874\u20131875), who died of meningitis, and Alan (1877\u20131952). Louisa also became a pioneering doctor of medicine and feminist activist.\nThey retired to Aldeburgh in 1902, moving to Alde House in 1903, after the death of Elizabeth's mother. Skelton died of a stroke in 1907. She enjoyed a happy marriage and in later life, devoted time to Alde House, gardening, and travelling with younger members of the extended family.\nOn 9 November 1908, she was elected mayor of Aldeburgh, the first female mayor in England. Her father had been mayor in 1889.\nShe died in 1917 and is buried in the churchyard of St Peter and St Paul's Church, Aldeburgh.\nLegacy.\nThe New Hospital for Women was renamed the Elizabeth Garrett Anderson Hospital in 1918 and amalgamated with the Obstetric Hospital in 2001 to form the Elizabeth Garrett Anderson and Obstetric Hospital before relocating to become the University College Hospital Elizabeth Garrett Anderson Wing at UCH.\nThe former Elizabeth Garrett Anderson Hospital buildings are incorporated into the new National Headquarters for the public service trade union UNISON. The Elizabeth Garrett Anderson Gallery, a permanent installation set within the restored hospital building, uses a variety of media to set the story of Garrett Anderson, her hospital, and women's struggle to achieve equality in the field of medicine within the wider framework of 19th and 20th century social history.\nThe critical care centre at Ipswich Hospital was named the Garrett Anderson Centre in her honour, in recognition of her connection to the county of Suffolk.\nThe new medical school at the University of Worcester, due to accept its first students in 2023, is to be called the Elizabeth Garrett Anderson Building.\nElizabeth Garrett Anderson School, a secondary school for girls in Islington, London, is named after her.\nThe archives of Elizabeth Garrett Anderson are held at the Women's Library at the London School of Economics. The archives of the Elizabeth Garrett Anderson Hospital (formerly the New Hospital for Women) are held at the London Metropolitan Archives.\nOn 9 June 2016, Google Doodle commemorated her 180th birthday.\nThe Elizabeth Garrett Anderson programme of the NHS Leadership Academy is a master's degree in leadership and management.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "9696", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=9696", "title": "Erosion", "text": "Natural processes that remove soil and rock\nErosion is the action of surface processes (such as water flow or wind) that removes soil, rock, or dissolved material from one location on the Earth's crust and then transports it to another location where it is deposited. Erosion is distinct from weathering which involves no movement. Removal of rock or soil as clastic sediment is referred to as \"physical\" or \"mechanical\" erosion; this contrasts with \"chemical\" erosion, where soil or rock material is removed from an area by dissolution. Eroded sediment or solutes may be transported just a few millimetres, or for thousands of kilometres.\nAgents of erosion include rainfall; bedrock wear in rivers; coastal erosion by the sea and waves; glacial plucking, abrasion, and scour; areal flooding; wind abrasion; groundwater processes; and mass movement processes in steep landscapes like landslides and debris flows. The rates at which such processes act control how fast a surface is eroded. Typically, physical erosion proceeds the fastest on steeply sloping surfaces, and rates may also be sensitive to some climatically-controlled properties including amounts of water supplied (e.g., by rain), storminess, wind speed, wave fetch, or atmospheric temperature (especially for some ice-related processes). Feedbacks are also possible between rates of erosion and the amount of eroded material that is already carried by, for example, a river or glacier. The transport of eroded materials from their original location is followed by deposition, which is arrival and emplacement of material at a new location.\nWhile erosion is a natural process, human activities have increased by 10-40 times the rate at which soil erosion is occurring globally. At agriculture sites in the Appalachian Mountains, intensive farming practices have caused erosion at up to 100 times the natural rate of erosion in the region. Excessive (or accelerated) erosion causes both \"on-site\" and \"off-site\" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, this leads to desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems worldwide.\nIntensive agriculture, deforestation, roads, anthropogenic climate change and urban sprawl are amongst the most significant human activities in regard to their effect on stimulating erosion. However, there are many prevention and remediation practices that can curtail or limit erosion of vulnerable soils.\nPhysical processes.\nRainfall and surface runoff.\nRainfall, and the surface runoff which may result from rainfall, produces four main types of soil erosion: \"splash erosion\", \"sheet erosion\", \"rill erosion\", and \"gully erosion\". Splash erosion is generally seen as the first and least severe stage in the soil erosion process, which is followed by sheet erosion, then rill erosion and finally gully erosion (the most severe of the four).\nIn \"splash erosion\", the impact of a falling raindrop creates a small crater in the soil, ejecting soil particles. The distance these soil particles travel can be as much as vertically and horizontally on level ground.\nIf the soil is saturated, or if the rainfall rate is greater than the rate at which water can infiltrate into the soil, surface runoff occurs. If the runoff has sufficient flow energy, it will transport loosened soil particles (sediment) down the slope. \"Sheet erosion\" is the transport of loosened soil particles by overland flow.\n\"Rill erosion\" refers to the development of small, ephemeral concentrated flow paths which function as both sediment source and sediment delivery systems for erosion on hillslopes. Generally, where water erosion rates on disturbed upland areas are greatest, rills are active. Flow depths in rills are typically of the order of a few centimetres (about an inch) or less and along-channel slopes may be quite steep. This means that rills exhibit hydraulic physics very different from water flowing through the deeper, wider channels of streams and rivers.\n\"Gully erosion\" occurs when runoff water accumulates and rapidly flows in narrow channels during or immediately after heavy rains or melting snow, removing soil to a considerable depth. A gully is distinguished from a rill based on a critical cross-sectional area of at least one square foot, i.e. the size of a channel that can no longer be erased via normal tillage operations.\nExtreme gully erosion can progress to formation of badlands. These form under conditions of high relief on easily eroded bedrock in climates favorable to erosion. Conditions or disturbances that limit the growth of protective vegetation (rhexistasy) are a key element of badland formation.\nRivers and streams.\n\"Valley\" or \"stream erosion\" occurs with continued water flow along a linear feature. The erosion is both downward, deepening the valley, and headward, extending the valley into the hillside, creating head cuts and steep banks. In the earliest stage of stream erosion, the erosive activity is dominantly vertical, the valleys have a typical V-shaped cross-section and the stream gradient is relatively steep. When some base level is reached, the erosive activity switches to lateral erosion, which widens the valley floor and creates a narrow floodplain. The stream gradient becomes nearly flat, and lateral deposition of sediments becomes important as the stream meanders across the valley floor. In all stages of stream erosion, by far the most erosion occurs during times of flood when more and faster-moving water is available to carry a larger sediment load. In such processes, it is not the water alone that erodes: suspended abrasive particles, pebbles, and boulders can also act erosively as they traverse a surface, in a process known as \"traction\".\n\"Bank erosion\" is the wearing away of the banks of a stream or river. This is distinguished from changes on the bed of the watercourse, which is referred to as \"scour\". Erosion and changes in the form of river banks may be measured by inserting metal rods into the bank and marking the position of the bank surface along the rods at different times.\n\"Thermal erosion\" is the result of melting and weakening permafrost due to moving water. It can occur both along rivers and at the coast. Rapid river channel migration observed in the Lena River of Siberia is due to thermal erosion, as these portions of the banks are composed of permafrost-cemented non-cohesive materials. Much of this erosion occurs as the weakened banks fail in large slumps. Thermal erosion also affects the Arctic coast, where wave action and near-shore temperatures combine to undercut permafrost bluffs along the shoreline and cause them to fail. Annual erosion rates along a segment of the Beaufort Sea shoreline averaged per year from 1955 to 2002.\nMost river erosion happens nearer to the mouth of a river. On a river bend, the longest least sharp side has slower moving water. Here deposits build up. On the narrowest sharpest side of the bend, there is faster moving water so this side tends to erode away mostly.\nRapid erosion by a large river can remove enough sediments to produce a river anticline, as isostatic rebound raises rock beds unburdened by erosion of overlying beds.\nCoastal erosion.\nShoreline erosion, which occurs on both exposed and sheltered coasts, primarily occurs through the action of currents and waves but sea level (tidal) change can also play a role.\n\"Hydraulic action\" takes place when the air in a joint is suddenly compressed by a wave closing the entrance of the joint. This then cracks it. \"Wave pounding\" is when the sheer energy of the wave hitting the cliff or rock breaks pieces off. \"Abrasion\" or \"corrasion\" is caused by waves launching sea load at the cliff. It is the most effective and rapid form of shoreline erosion (not to be confused with \"corrosion\"). \"Corrosion\" is the dissolving of rock by carbonic acid in sea water. Limestone cliffs are particularly vulnerable to this kind of erosion. \"Attrition\" is where particles/sea load carried by the waves are worn down as they hit each other and the cliffs. This then makes the material easier to wash away. The material ends up as shingle and sand. Another significant source of erosion, particularly on carbonate coastlines, is boring, scraping and grinding of organisms, a process termed \"bioerosion\".\nSediment is transported along the coast in the direction of the prevailing current (longshore drift). When the upcurrent supply of sediment is less than the amount being carried away, erosion occurs. When the upcurrent amount of sediment is greater, sand or gravel banks will tend to form as a result of deposition. These banks may slowly migrate along the coast in the direction of the longshore drift, alternately protecting and exposing parts of the coastline. Where there is a bend in the coastline, quite often a buildup of eroded material occurs forming a long narrow bank (a spit). Armoured beaches and submerged offshore sandbanks may also protect parts of a coastline from erosion. Over the years, as the shoals gradually shift, the erosion may be redirected to attack different parts of the shore.\nErosion of a coastal surface, followed by a fall in sea level, can produce a distinctive landform called a raised beach.\nChemical erosion.\nChemical erosion is the loss of matter in a landscape in the form of solutes. Chemical erosion is usually calculated from the solutes found in streams. Anders Rapp pioneered the study of chemical erosion in his work about K\u00e4rkevagge published in 1960.\nFormation of sinkholes and other features of karst topography is an example of extreme chemical erosion.\nGlaciers.\nGlaciers erode predominantly by three different processes: abrasion/scouring, plucking, and ice thrusting. In an abrasion process, debris in the basal ice scrapes along the bed, polishing and gouging the underlying rocks, similar to sandpaper on wood. Scientists have shown that, in addition to the role of temperature played in valley-deepening, other glaciological processes, such as erosion also control cross-valley variations. In a homogeneous bedrock erosion pattern, curved channel cross-section beneath the ice is created. Though the glacier continues to incise vertically, the shape of the channel beneath the ice eventually remain constant, reaching a U-shaped parabolic steady-state shape as we now see in glaciated valleys. Scientists also provide a numerical estimate of the time required for the ultimate formation of a steady-shaped U-shaped valley\u2014approximately 100,000 years. In a weak bedrock (containing material more erodible than the surrounding rocks) erosion pattern, on the contrary, the amount of over deepening is limited because ice velocities and erosion rates are reduced.\nGlaciers can also cause pieces of bedrock to crack off in the process of plucking. In ice thrusting, the glacier freezes to its bed, then as it surges forward, it moves large sheets of frozen sediment at the base along with the glacier. This method produced some of the many thousands of lake basins that dot the edge of the Canadian Shield. Differences in the height of mountain ranges are not only being the result tectonic forces, such as rock uplift, but also local climate variations. Scientists use global analysis of topography to show that glacial erosion controls the maximum height of mountains, as the relief between mountain peaks and the snow line are generally confined to altitudes less than 1500\u00a0m. The erosion caused by glaciers worldwide erodes mountains so effectively that the term \"glacial buzzsaw\" has become widely used, which describes the limiting effect of glaciers on the height of mountain ranges. As mountains grow higher, they generally allow for more glacial activity (especially in the accumulation zone above the glacial equilibrium line altitude), which causes increased rates of erosion of the mountain, decreasing mass faster than isostatic rebound can add to the mountain. This provides a good example of a negative feedback loop. Ongoing research is showing that while glaciers tend to decrease mountain size, in some areas, glaciers can actually reduce the rate of erosion, acting as a \"glacial armor\". Ice can not only erode mountains but also protect them from erosion. Depending on glacier regime, even steep alpine lands can be preserved through time with the help of ice. Scientists have proved this theory by sampling eight summits of northwestern Svalbard using Be10 and Al26, showing that northwestern Svalbard transformed from a glacier-erosion state under relatively mild glacial maxima temperature, to a glacier-armor state occupied by cold-based, protective ice during much colder glacial maxima temperatures as the Quaternary ice age progressed.\nThese processes, combined with erosion and transport by the water network beneath the glacier, leave behind glacial landforms such as moraines, drumlins, ground moraine (till), kames, kame deltas, moulins, and glacial erratics in their wake, typically at the terminus or during glacier retreat.\nThe best-developed glacial valley morphology appears to be restricted to landscapes with low rock uplift rates (less than or equal to 2mm per year) and high relief, leading to long-turnover times. Where rock uplift rates exceed 2mm per year, glacial valley morphology has generally been significantly modified in postglacial time. Interplay of glacial erosion and tectonic forcing governs the morphologic impact of glaciations on active orogens, by both influencing their height, and by altering the patterns of erosion during subsequent glacial periods via a link between rock uplift and valley cross-sectional shape.\nFloods.\nAt extremely high flows, kolks, or vortices are formed by large volumes of rapidly rushing water. Kolks cause extreme local erosion, plucking bedrock and creating pothole-type geographical features called rock-cut basins. Examples can be seen in the flood regions result from glacial Lake Missoula, which created the channeled scablands in the Columbia Basin region of eastern Washington.\nWind erosion.\nWind erosion is a major geomorphological force, especially in arid and semi-arid regions. It is also a major source of land degradation, evaporation, desertification, harmful airborne dust, and crop damage\u2014especially after being increased far above natural rates by human activities such as deforestation, urbanization, and agriculture.\nWind erosion is of two primary varieties: \"deflation\", where the wind picks up and carries away loose particles; and \"abrasion\", where surfaces are worn down as they are struck by airborne particles carried by wind. Deflation is divided into three categories: (1) \"surface creep\", where larger, heavier particles slide or roll along the ground; (2) \"saltation\", where particles are lifted a short height into the air, and bounce and saltate across the surface of the soil; and (3) \"suspension\", where very small and light particles are lifted into the air by the wind, and are often carried for long distances. Saltation is responsible for the majority (50-70%) of wind erosion, followed by suspension (30-40%), and then surface creep (5-25%).\nWind erosion is much more severe in arid areas and during times of drought. For example, in the Great Plains, it is estimated that soil loss due to wind erosion can be as much as 6100 times greater in drought years than in wet years.\nMass wasting.\n\"Mass wasting\" or \"mass movement\" is the downward and outward movement of rock and sediments on a sloped surface, mainly due to the force of gravity.\nMass wasting is an important part of the erosional process and is often the first stage in the breakdown and transport of weathered materials in mountainous areas. It moves material from higher elevations to lower elevations where other eroding agents such as streams and glaciers can then pick up the material and move it to even lower elevations. Mass-wasting processes are always occurring continuously on all slopes; some mass-wasting processes act very slowly; others occur very suddenly, often with disastrous results. Any perceptible down-slope movement of rock or sediment is often referred to in general terms as a landslide. However, landslides can be classified in a much more detailed way that reflects the mechanisms responsible for the movement and the velocity at which the movement occurs. One of the visible topographical manifestations of a very slow form of such activity is a scree slope.\n\"Slumping\" happens on steep hillsides, occurring along distinct fracture zones, often within materials like clay that, once released, may move quite rapidly downhill. They will often show a spoon-shaped isostatic depression, in which the material has begun to slide downhill. In some cases, the slump is caused by water beneath the slope weakening it. In many cases it is simply the result of poor engineering along highways where it is a regular occurrence.\n\"Surface creep\" is the slow movement of soil and rock debris by gravity which is usually not perceptible except through extended observation. However, the term can also describe the rolling of dislodged soil particles in diameter by wind along the soil surface.\nSubmarine sediment gravity flows.\nOn the continental slope, erosion of the ocean floor to create channels and submarine canyons can result from the rapid downslope flow of sediment gravity flows, bodies of sediment-laden water that move rapidly downslope as turbidity currents. Where erosion by turbidity currents creates oversteepened slopes it can also trigger underwater landslides and debris flows. Turbidity currents can erode channels and canyons into substrates ranging from recently deposited unconsolidated sediments to hard crystalline bedrock. Almost all continental slopes and deep ocean basins display such channels and canyons resulting from sediment gravity flows and submarine canyons act as conduits for the transfer of sediment from the continents and shallow marine environments to the deep sea. Turbidites, which are the sedimentary deposits resulting from turbidity currents, comprise some of the thickest and largest sedimentary sequences on Earth, indicating that the associated erosional processes must also have played a prominent role in Earth's history.\nFactors affecting erosion rates.\nClimate.\nThe amount and intensity of precipitation is the main climatic factor governing soil erosion by water. The relationship is particularly strong if heavy rainfall occurs at times when, or in locations where, the soil's surface is not well protected by vegetation. This might be during periods when agricultural activities leave the soil bare, or in semi-arid regions where vegetation is naturally sparse. Wind erosion requires strong winds, particularly during times of drought when vegetation is sparse and soil is dry (and so is more erodible). Other climatic factors such as average temperature and temperature range may also affect erosion, via their effects on vegetation and soil properties. In general, given similar vegetation and ecosystems, areas with more precipitation (especially high-intensity rainfall), more wind, or more storms are expected to have more erosion.\nIn some areas of the world (e.g. the mid-western USA), rainfall intensity is the primary determinant of erosivity (for a definition of \"erosivity\" check,) with higher intensity rainfall generally resulting in more soil erosion by water. The size and velocity of rain drops is also an important factor. Larger and higher-velocity rain drops have greater kinetic energy, and thus their impact will displace soil particles by larger distances than smaller, slower-moving rain drops.\nIn other regions of the world (e.g. western Europe), runoff and erosion result from relatively low intensities of stratiform rainfall falling onto the previously saturated soil. In such situations, rainfall amount rather than intensity is the main factor determining the severity of soil erosion by water. According to the climate change projections, erosivity will increase significantly in Europe and soil erosion may increase by 13-22.5% by 2050 \nIn Taiwan, where typhoon frequency increased significantly in the 21st century, a strong link has been drawn between the increase in storm frequency with an increase in sediment load in rivers and reservoirs, highlighting the impacts climate change can have on erosion.\nVegetative cover.\nVegetation acts as an interface between the atmosphere and the soil. It increases the permeability of the soil to rainwater, thus decreasing runoff. It shelters the soil from winds, which results in decreased wind erosion, as well as advantageous changes in microclimate. The roots of the plants bind the soil together, and interweave with other roots, forming a more solid mass that is less susceptible to both water and wind erosion. The removal of vegetation increases the rate of surface erosion.\nTopography.\nThe topography of the land determines the velocity at which surface runoff will flow, which in turn determines the erosivity of the runoff. Longer, steeper slopes (especially those without adequate vegetative cover) are more susceptible to very high rates of erosion during heavy rains than shorter, less steep slopes. Steeper terrain is also more prone to mudslides, landslides, and other forms of gravitational erosion processes.\nTectonics.\nTectonic processes control rates and distributions of erosion at the Earth's surface. If the tectonic action causes part of the Earth's surface (e.g., a mountain range) to be raised or lowered relative to surrounding areas, this must necessarily change the gradient of the land surface. Because erosion rates are almost always sensitive to the local slope (see above), this will change the rates of erosion in the uplifted area. Active tectonics also brings fresh, unweathered rock towards the surface, where it is exposed to the action of erosion.\nHowever, erosion can also affect tectonic processes. The removal by erosion of large amounts of rock from a particular region, and its deposition elsewhere, can result in a lightening of the load on the lower crust and mantle. Because tectonic processes are driven by gradients in the stress field developed in the crust, this unloading can in turn cause tectonic or isostatic uplift in the region. In some cases, it has been hypothesised that these twin feedbacks can act to localize and enhance zones of very rapid exhumation of deep crustal rocks beneath places on the Earth's surface with extremely high erosion rates, for example, beneath the extremely steep terrain of Nanga Parbat in the western Himalayas. Such a place has been called a \"tectonic aneurysm\".\nDevelopment.\nHuman land development, in forms including agricultural and urban development, is considered a significant factor in erosion and sediment transport, which aggravate food insecurity. In Taiwan, increases in sediment load in the northern, central, and southern regions of the island can be tracked with the timeline of development for each region throughout the 20th century. The intentional removal of soil and rock by humans is a form of erosion that has been named \"lisasion\".\nErosion at various scales.\nMountain ranges.\nMountain ranges are known to take many millions of years to erode to the degree they effectively cease to exist. Scholars Pitman and Golovchenko estimate that it takes probably more than 450 million years to erode a mountain mass similar to the Himalaya into an almost-flat peneplain if there are no major sea-level changes. Erosion of mountains massifs can create a pattern of equally high summits called summit accordance. It has been argued that extension during post-orogenic collapse is a more effective mechanism of lowering the height of orogenic mountains than erosion.\nExamples of heavily eroded mountain ranges include the Timanides of Northern Russia. Erosion of this orogen has produced sediments that are now found in the East European Platform, including the Cambrian Sablya Formation near Lake Ladoga. Studies of these sediments indicate that it is likely that the erosion of the orogen began in the Cambrian and then intensified in the Ordovician.\nSoils.\nIf the rate of erosion is higher than the rate of soil formation the soils are being destroyed by erosion. Where soil is not destroyed by erosion, erosion can in some cases prevent the formation of soil features that form slowly. Inceptisols are common soils that form in areas of fast erosion.\nWhile erosion of soils is a natural process, human activities have increased by 10-40 times the rate at which erosion is occurring globally. Excessive (or accelerated) erosion causes both \"on-site\" and \"off-site\" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems.\nIn the United States, farmers cultivating highly erodible land must comply with a conservation plan to be eligible for certain forms of agricultural assistance.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
