{"id": "6314", "revid": "40764242", "url": "https://en.wikipedia.org/wiki?curid=6314", "title": "Fire (classical element)", "text": "One of the four classical elements\nFire is one of the four classical elements along with earth, water and air in ancient Greek philosophy and science. Fire is considered to be both hot and dry and, according to Plato, is associated with the tetrahedron.\nGreek and Roman tradition.\nFire is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with the qualities of energy, assertiveness, and passion. In one Greek myth, Prometheus stole \"fire\" from the gods to protect the otherwise helpless humans, but was punished for this charity.\nFire was one of many \"archai\" proposed by the pre-Socratics, most of whom sought to reduce the cosmos, or its creation, to a single substance. Heraclitus (c. 535 BCE \u2013 c. 475 BCE) considered \"fire\" to be the most fundamental of all elements. He believed fire gave rise to the other three elements: \"All things are an interchange for fire, and fire for all things, just like goods for gold and gold for goods.\" He had a reputation for obscure philosophical principles and for speaking in riddles. He described how fire gave rise to the other elements as the: \"upward-downward path\", (), a \"hidden harmony\"\u2009 or series of transformations he called the \"turnings of fire\", (), first into \"sea\", and half that \"sea\" into \"earth\", and half that \"earth\" into rarefied \"air\". This is a concept that anticipates both the four classical elements of Empedocles and Aristotle's transmutation of the four elements into one another.\nThis world, which is the same for all, no one of gods or men has made. But it always was and will be: an ever-living fire, with measures of it kindling, and measures going out. \nHeraclitus regarded the soul as being a mixture of fire and water, with fire being the more noble part and water the ignoble aspect. He believed the goal of the soul is to be rid of water and become pure fire: the dry soul is the best and it is worldly pleasures that make the soul \"moist\". He was known as the \"weeping philosopher\" and died of hydropsy, a swelling due to abnormal accumulation of fluid beneath the skin.\nHowever, Empedocles of Akragas (c. 495 \u2013 c. 435 BCE), is best known for having selected all elements as his \"archai\" and by the time of Plato (427\u2013347 BCE), the four Empedoclian elements were well established. In the \"Timaeus\", Plato's major cosmological dialogue, the Platonic solid he associated with fire was the tetrahedron which is formed from four triangles and contains the least volume with the greatest surface area. This also makes fire the element with the smallest number of sides, and Plato regarded it as appropriate for the heat of fire, which he felt is sharp and stabbing, (like one of the points of a tetrahedron).\nPlato's student Aristotle (384\u2013322 BCE) did not maintain his former teacher's geometric view of the elements, but rather preferred a somewhat more naturalistic explanation for the elements based on their traditional qualities. Fire the hot and dry element, like the other elements, was an abstract principle and not identical with the normal solids, liquids and combustion phenomena we experience:\n What we commonly call fire. It is not really fire, for fire is an excess of heat and a sort of ebullition; but in reality, of what we call air, the part surrounding the earth is moist and warm, because it contains both vapour and a dry exhalation from the earth.\nAccording to Aristotle, the four elements rise or fall toward their natural place in concentric layers surrounding the center of the earth and form the terrestrial or sublunary spheres.\nIn ancient Greek medicine, each of the four humours became associated with an element. Yellow bile was the humor identified with fire, since both were hot and dry. Other things associated with fire and yellow bile in ancient and medieval medicine included the season of summer, since it increased the qualities of heat and aridity; the choleric temperament (of a person dominated by the yellow bile humour); the masculine; and the eastern point of the compass.\nIn alchemy the chemical element of sulfur was often associated with fire and its alchemical symbol and its symbol was an upward-pointing triangle. In alchemic tradition, metals are incubated by fire in the womb of the Earth and alchemists only accelerate their development.\nIndian tradition.\nAgni is a Hindu and Vedic deity. The word \"agni\" is Sanskrit for fire (noun), cognate with Latin \"ignis\" (the root of English \"ignite\"), Russian \"\u043e\u0433\u043e\u043d\u044c\" (fire), pronounced \"agon\". Agni has three forms: fire, lightning and the sun.\nAgni is one of the most important of the Vedic gods. He is the god of fire and the accepter of sacrifices. The sacrifices made to Agni go to the deities because Agni is a messenger from and to the other gods. He is ever-young, because the fire is re-lit every day, yet he is also immortal. In Indian tradition fire is also linked to Surya or the Sun and Mangala or Mars, and with the south-east direction.\nCeremonial magic.\nFire and the other Greek classical elements were incorporated into the Golden Dawn system. Philosophus (4=7) is the elemental grade attributed to fire; this grade is also attributed to the Qabalistic Sephirah Netzach and the planet Venus. The elemental weapon of fire is the Wand. Each of the elements has several associated spiritual beings. The archangel of fire is Michael, the angel is Aral, the ruler is Seraph, the king is Djin, and the fire elementals (following Paracelsus) are called salamanders. Fire is considered to be active; it is represented by the symbol for Leo and it is referred to the lower right point of the pentacle in the Supreme Invoking Ritual of the Pentacle. Many of these associations have since spread throughout the occult community.\nTarot.\nFire in tarot symbolizes conversion or passion. Many references to fire in tarot are related to the usage of fire in the practice of alchemy, in which the application of fire is a prime method of conversion, and everything that touches fire is changed, often beyond recognition. The symbol of fire was a cue pointing towards transformation, the chemical variant being the symbol delta, which is also the classical symbol for fire. Conversion symbolized can be good, for example, refining raw crudities to gold, as seen in The Devil. Conversion can also be bad, as in The Tower, symbolizing a downfall due to anger. Fire is associated with the suit of rods/wands, and as such, represents passion from inspiration. As an element, fire has mixed symbolism because it represents energy, which can be helpful when controlled, but volatile if left unchecked.\nModern witchcraft.\nFire is one of the five elements that appear in most Wiccan traditions influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.\nFreemasonry.\nIn freemasonry, fire is present, for example, during the ceremony of winter solstice, a symbol also of renaissance and energy. Freemasonry takes the ancient symbolic meaning of fire and recognizes its double nature: creation, light, on the one hand, and destruction and purification, on the other.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6315", "revid": "40764242", "url": "https://en.wikipedia.org/wiki?curid=6315", "title": "Air (classical element)", "text": "One of four primary substances in antiquity\nAir or Wind is one of the four classical elements along with water, earth and fire in ancient Greek philosophy and in Western alchemy.\nGreek and Roman tradition.\nAccording to Plato, it is associated with the octahedron; air is considered to be both hot and wet. The ancient Greeks used two words for air: \"aer\" meant the dim lower atmosphere, and \"aether\" meant the bright upper atmosphere above the clouds. Plato, for instance writes that \"So it is with air: there is the brightest variety which we call \"aether\", the muddiest which we call mist and darkness, and other kinds for which we have no name...\" Among the early Greek Pre-Socratic philosophers, Anaximenes (mid-6th century BCE) named air as the \"arche\". A similar belief was attributed by some ancient sources to Diogenes Apolloniates (late 5th century BCE), who also linked air with intelligence and soul (\"psyche\"), but other sources claim that his \"arche\" was a substance between air and fire. Aristophanes parodied such teachings in his play \"The Clouds\" by putting a prayer to air in the mouth of Socrates.\nAir was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495-c. 435 BCE) selected four \"archai\" for his four roots: air, fire, water, and earth. Ancient and modern opinions differ as to whether he identified air by the divine name Hera, Aidoneus or even Zeus. Empedocles\u2019 roots became the four classical elements of Greek philosophy. Plato (427\u2013347 BCE) took over the four elements of Empedocles. In the \"Timaeus\", his major cosmological dialogue, the Platonic solid associated with air is the octahedron which is formed from eight equilateral triangles. This places air between fire and water which Plato regarded as appropriate because it is intermediate in its mobility, sharpness, and ability to penetrate. He also said of air that its minuscule components are so smooth that one can barely feel them.\nPlato's student Aristotle (384\u2013322 BCE) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the universe to form the sublunary sphere. According to Aristotle, air is both hot and wet and occupies a place between fire and water among the elemental spheres. Aristotle definitively separated air from aether. For him, aether was an unchanging, almost divine substance that was found only in the heavens, where it formed celestial spheres.\nHumorism and temperaments.\nIn ancient Greek medicine, each of the four humours became associated with an element. Blood was the humor identified with air, since both were hot and wet. Other things associated with air and blood in ancient and medieval medicine included the season of spring, since it increased the qualities of heat and moisture; the sanguine temperament (of a person dominated by the blood humour); hermaphrodite (combining the masculine quality of heat with the feminine quality of moisture); and the northern point of the compass.\nAlchemy.\nThe alchemical symbol for air is an upward-pointing triangle, bisected by a horizontal line.\nModern reception.\nThe Hermetic Order of the Golden Dawn, founded in 1888, incorporates air and the other Greek classical elements into its teachings. The elemental weapon of air is the dagger which must be painted yellow with magical names and sigils written upon it in violet. Each of the elements has several associated spiritual beings. The archangel of air is Raphael, the angel is Chassan, the ruler is Ariel, the king is Paralda, and the air elementals (following Paracelsus) are called sylphs. Air is considerable and it is referred to the upper left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nIn the Golden Dawn and many other magical systems, each element is associated with one of the cardinal points and is placed under the care of guardian Watchtowers. The Watchtowers derive from the Enochian system of magic founded by Dee. In the Golden Dawn, they are represented by the Enochian elemental tablets. Air is associated with the east, which is guarded by the First Watchtower.\nAir is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism.\nParallels in non-Western traditions.\nAir is not one of the traditional five Chinese classical elements. Nevertheless, the ancient Chinese concept of \"Qi\" or \"chi\" is believed to be close to that of air. \"Qi\" is believed to be part of every living thing that exists, as a kind of \"life force\" or \"spiritual energy\". It is frequently translated as \"energy flow\", or literally as \"air\" or \"breath\". (For example, \"ti\u0101nq\u00ec\", literally \"sky breath\", is the Chinese word for \"weather\"). The concept of qi is often reified, however no scientific evidence supports its existence.\nThe element air also appears as a concept in the Buddhist philosophy which has an ancient history in China.\nSome Western modern occultists equate the Chinese classical element of metal with \"air\", others with wood due to the elemental association of wind and wood in the bagua.\nEnlil was the god of air in ancient Sumer. Shu was the ancient Egyptian deity of air and the husband of Tefnut, goddess of moisture. He became an emblem of strength by virtue of his role in separating Nut from Geb. Shu played a primary role in the Coffin Texts, which were spells intended to help the deceased reach the realm of the afterlife safely. On the way to the sky, the spirit had to travel through the air as one spell indicates: \"I have gone up in Shu, I have climbed on the sunbeams.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6316", "revid": "40764242", "url": "https://en.wikipedia.org/wiki?curid=6316", "title": "Water (classical element)", "text": "One of four primary substances in antiquity\nWater is one of the classical elements in ancient Greek philosophy along with air, earth and fire, in the Asian Indian system \"Panchamahabhuta\", and in the Chinese cosmological and physiological system \"Wu Xing\". In contemporary esoteric traditions, it is commonly associated with the qualities of emotion and intuition.\nGreek and Roman tradition.\nWater was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495 \u2013 c. 435 BC) selected four archai for his four roots: air, fire, water and earth. Empedocles roots became the four classical elements of Greek philosophy. Plato (427\u2013347 BC) took over the four elements of Empedocles. In the Timaeus, his major cosmological dialogue, the Platonic solid associated with water is the icosahedron which is formed from twenty equilateral triangles. This makes water the element with the greatest number of sides, which Plato regarded as appropriate because water flows out of one's hand when picked up, as if it is made of tiny little balls.\nPlato's student Aristotle (384\u2013322 BC) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the Universe to form the sublunary sphere. According to Aristotle, water is both cold and wet and occupies a place between air and earth among the elemental spheres.\nIn ancient Greek medicine, each of the four humours became associated with an element. Phlegm was the humor identified with water, since both were cold and wet. Other things associated with water and phlegm in ancient and medieval medicine included the season of Winter, since it increased the qualities of cold and moisture, the phlegmatic temperament, the feminine and the western point of the compass.\nIn alchemy, the chemical element of mercury was often associated with water and its alchemical symbol was a downward-pointing triangle.\nIndian tradition.\nAp (') is the Vedic Sanskrit term for water, in Classical Sanskrit occurring only in the plural is not an element.v, ' (sometimes re-analysed as a thematic singular, '), whence Hindi '. The term is from PIE \"hxap\" water.\nIn Hindu philosophy, the term refers to \nwater as an element, one of the \"Panchamahabhuta,\" or \"five great elements\". In Hinduism, it is also the name of the deva, a personification of water, (one of the Vasus in most later Puranic lists). The element water is also associated with Chandra or the moon and Shukra, who represent feelings, intuition and imagination.\nCeremonial magic.\nWater and the other Greek classical elements were incorporated into the Golden Dawn system. The elemental weapon of water is the cup. Each of the elements has several associated spiritual beings. The archangel of water is Gabriel, the angel is Taliahad, the ruler is Tharsis, the king is Nichsa and the water elementals are called Ondines. It is referred to the upper right point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nModern witchcraft.\nWater is one of the five elements that appear in most Wiccan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6317", "revid": "40764242", "url": "https://en.wikipedia.org/wiki?curid=6317", "title": "Earth (classical element)", "text": "Classical element in ancient Greek philosophy and science\nEarth is one of the classical elements, in some systems being one of the four along with air, fire, and water.\nEuropean tradition.\nEarth is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with qualities of heaviness, matter and the terrestrial world. Due to the hero cults, and chthonic underworld deities, the element of \"earth\" is also associated with the sensual aspects of both life and death in later occultism.\nEmpedocles of Acragas (c. 495 \u2013 c. 435 BCE) proposed four \"archai\" by which to understand the cosmos: \"fire\",\" air\", \"water\", and \"earth\". Plato (427\u2013347 BCE) believed the elements were geometric forms (the platonic solids) and he assigned the cube to the element of \"earth\" in his dialogue \"Timaeus\". Aristotle (384\u2013322 BCE) believed \"earth\" was the heaviest element, and his theory of \"natural place\" suggested that any \"earth\u2013laden\" substances, would fall quickly, straight down, towards the center of the \"cosmos\".\nIn Classical Greek and Roman myth, various goddesses \nrepresented the Earth, seasons, crops and fertility, including Demeter and Persephone; Ceres; the Horae (goddesses of the seasons), and Proserpina; and Hades (Pluto) who ruled the souls of dead in the Underworld.\nIn ancient Greek medicine, each of the four humours became associated with an element. Black bile was the humor identified with earth, since both were cold and dry. Other things associated with earth and black bile in ancient and medieval medicine included the season of fall, since it increased the qualities of cold and aridity; the melancholic temperament (of a person dominated by the black bile humour); the feminine; and the southern point of the compass.\nIn alchemy, earth was believed to be primarily dry, and secondarily cold, (as per Aristotle). Beyond those classical attributes, the chemical substance salt, was associated with earth and its alchemical symbol was a downward-pointing triangle, bisected by a horizontal line.\nIndian tradition.\nPrithvi (Sanskrit: ', also ') is the Hindu \"earth\" and mother goddess. According to one such tradition, she is the personification of the Earth itself; according to another, its actual mother, being \"Prithvi Tattwa\", the essence of the element earth.\nAs \"Prithvi Mata\", or \"Mother Earth\", she contrasts with \"Dyaus Pita\", \"father sky\". In the Rigveda, \"earth\" and sky are frequently addressed as a duality, often indicated by the idea of two complementary \"half-shells.\" In addition, the element Earth is associated with Budha or Mercury who represents communication, business, mathematics and other practical matters.\nCeremonial magic.\nEarth and the other Greek classical elements were incorporated into the Golden Dawn system. Zelator is the elemental grade attributed to earth; this grade is also attributed to the Qabbalistic sphere Malkuth. The elemental weapon of earth is the Pentacle. Each of the elements has several associated spiritual beings. The archangel of earth is Uriel, the angel is Phorlakh, the ruler is Kerub, the king is Ghob, and the earth elementals (following Paracelsus) are called gnomes. Earth is considered to be passive; it is represented by the symbol for Taurus, and it is referred to the lower left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nIt is sometimes represented by its Tattva or by a downward pointing triangle with a horizontal line through it.\nModern witchcraft.\nEarth is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism which was in turn inspired by the Golden Dawn.\nOther traditions.\n\"Earth\" is represented in the Aztec religion by a house; to the Hindus, a lotus; to the Scythians, a plough; to the Greeks, a wheel; and in Christian iconography; bulls and birds.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6319", "revid": "1135232361", "url": "https://en.wikipedia.org/wiki?curid=6319", "title": "Blue Jam", "text": "Blue Jam was an ambient, surreal dark comedy and horror radio programme created and directed by Chris Morris. It was broadcast on BBC Radio 1 in the early hours of the morning, for three series from 1997 to 1999.\nThe programme gained cult status due to its unique mix of surreal monologue, ambient soundtrack, synthesised voices, heavily edited broadcasts and recurring sketches. It featured vocal performances of Kevin Eldon, Julia Davis, Mark Heap, David Cann and Amelia Bullmore, with Morris himself delivering disturbing monologues, one of which was revamped and made into the BAFTA-winning short film \"My Wrongs #8245\u20138249 &amp; 117\". Writers who contributed to the programme included Graham Linehan, Arthur Mathews, Peter Baynham, David Quantick, Jane Bussmann, Robert Katz and the cast.\nThe programme was adapted into the TV series \"Jam\", which aired in 2000. All episodes of \"Blue Jam\" are currently available for streaming and download on the Internet Archive and Youtube.\nProduction.\nOn his inspiration for making the show, Morris commented: \"It was so singular, and it came from a mood, quite a desolate mood. I had this misty, autumnal, boggy mood anyway, so I just went with that. But no doubt getting to the end of something like Brass Eye, where you've been forced to be a sort of surrogate lawyer, well, that's the most creatively stifling thing you could possibly do.\" Morris also described the show as being \"like the nightmares you have when you fall asleep listening to the BBC World Service\" (a reference to the World Service also appears in one of the monologues read by Morris).\nMorris originally requested that the show be broadcast at 3 a.m. on Radio 1 \"because at that hour, on insomniac radio, the amplitude of terrible things is enormously overblown\". As a compromise, the show was broadcast at midnight without much promotion. Morris reportedly included sketches too graphic or transgressive for radio that he knew would be cut so as to make his other material seem less transgressive in comparison. During the airing of episode 6 of series one, a re-editing of the Archbishop of Canterbury's speech at Princess Diana's funeral was deemed too offensive for broadcast, and was switched with a different episode as it aired.\nFormat and style.\nEach episode opened (and closed) with a short spoken monologue (delivered by Morris) describing, in surreal, broken language, various bizarre feelings and situations (for example: \"when you sick so sad you cry, and in crying cry a whole leopard from your eye\"), set to ambient music interspersed with short clips of other songs and sounds. The introduction would always end with \"welcome in Blue Jam\", inviting the listener, who is presumably experiencing such feelings, to get lost in the program. (This format was replicated in the television adaptation \"Jam\", often reusing opening monologues from series 3 of the radio series.) The sketches within dealt with heavy and taboo topics, such as murder, suicide, missing or dead children, and rape.\nCommon recurring sketches.\nThe sketches not listed are often in the style of a documentary; characters speak as if being interviewed about a recent event. In one sketch, a character voiced by Morris describes a man attempting to commit suicide by jumping off a second-story balcony repeatedly; in another, an angry man (Eldon) shouts about how his car, after being picked up from the garage, is only four feet long.\nRadio stings.\nMorris included a series of 'radio stings', bizarre sequences of sounds and prose as a parody of modern DJs' own soundbites and self-advertising pieces. Each one revolves around a contemporary DJ, such as Chris Moyles, Jo Whiley and Mark Goodier, typically involving each DJ dying in a graphic way or going mad in some form \u2013 for example, Chris Moyles covering himself in jam and hanging himself from the top of a building.\nEpisodes.\nThree series were produced, with a total of eighteen episodes. All episodes were originally broadcast weekly on BBC Radio 1. Series 1 was broadcast from 14 November to 19 December 1997; series 2 was broadcast from 27 March to 1 May 1998; and series 3 broadcast from 21 January to 25 February 1999.\nThe first five episodes of series 1 of \"Blue Jam\" were repeated by BBC Radio 4 Extra in February and March 2014, and series 2 was rebroadcast in December.\nMusic.\n\"Blue Jam\" features songs, generally of a downtempo nature, interspersed between (and sometimes during) sketches. Artists featured includes Massive Attack, Air, Morcheeba, The Chemical Brothers, Bj\u00f6rk, Aphex Twin, Everything But the Girl and Dimitri from Paris, as well as various non-electronic artists including Sly and the Family Stone, Serge Gainsbourg, The Cardigans and Eels.\nReception.\n\"Blue Jam\" was favourably reviewed on several occasions by \"The Guardian\" and also received a positive review by \"The Independent\".\nDigital Spy wrote in 2014: \"It's a heady cocktail that provokes an odd, unsettling reaction in the listener, yet \"Blue Jam\" is still thumpingly and frequently laugh-out-loud hilarious.\" \"Hot Press\" called it \"as odd as comedy gets\".\nCD release.\nA CD of a number of \"Blue Jam\" sketches was released on 23 October 2000 by record label Warp. Although the CD claims to have 22 tracks, the last one, \"www.bishopslips.com\", is not a track, but rather a reference to the \"Bishopslips\" sketch, which was cut in the middle of a broadcast. Most of the sketches on the CD were remade for \"Jam\".\nRelated shows.\n\"Blue Jam\" was later made for television and broadcast on Channel 4 as \"Jam\". It used unusual editing techniques to achieve an unnerving ambience in keeping with the radio show. Many of the sketches were lifted from the radio version, even to the extent of simply setting images to the radio soundtrack. A subsequent \"re-mixed\" airing, called \"Jaaaaam\" was even more extreme in its use of post-production gadgetry, often heavily distorting the footage.\n\"Blue Jam\" shares parallels with early editions of a US public radio show \"Joe Frank: Work in Progress\" from the mid-1980s, that Joe Frank did on the NPR affiliate station, KCRW, in Santa Monica, California.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6321", "revid": "43271300", "url": "https://en.wikipedia.org/wiki?curid=6321", "title": "Channel 4", "text": "British free-to-air television channel\nChannel 4 is a British free-to-air public broadcast television channel owned and operated by the state-owned Channel Four Television Corporation. It is publicly owned but, unlike the BBC, it receives no public funding and is instead funded entirely by its own commercial activities, including publicity. It began its transmission in 1982 and was established to provide a fourth television service in the United Kingdom. At the time, the only other channels were the licence-funded BBC One and BBC Two, and a single commercial broadcasting network ITV.\nOriginally a subsidiary of the Independent Broadcasting Authority (IBA), the station is now owned and operated by Channel Four Television Corporation, a public corporation of the Department for Culture, Media and Sport, which was established in 1990 and came into operation in 1993. Until 2010, Channel 4 did not broadcast in Wales, but many of its programmes were re-broadcast there by the Welsh fourth channel S4C. In 2010, Channel 4 extended service into Wales and became a UK-wide television channel. The network's headquarters are in London and Leeds, with creative hubs in Glasgow and Bristol.\nHistory.\nConception.\nBefore Channel 4 and S4C, Britain had three terrestrial television services: BBC1, BBC2, and ITV. The Broadcasting Act 1980 began the process of adding a fourth; Channel 4 was formally created, along with its Welsh counterpart, by an act of Parliament in 1982. After some months of test broadcasts, it began scheduled transmissions on 2 November 1982 from Scala House, the former site of the Scala Theatre.\nThe notion of a second commercial broadcaster in the United Kingdom had been around since the inception of ITV in 1954 and its subsequent launch in 1955; the idea of an \"ITV2\" was long expected and pushed for. Indeed, television sets sold throughout the 1970s and early 1980s often had a spare tuning button labelled \"ITV 2\" or \"IBA 2\". Throughout ITV's history and until Channel 4 finally became a reality, a perennial dialogue existed between the GPO, the government, the ITV companies and other interested parties, concerning the form such an expansion of commercial broadcasting would take. Most likely, politics had the biggest impact in leading to a delay of almost three decades before the second commercial channel became a reality.\nOne clear benefit of the \"late arrival\" of the channel was that its frequency allocations at each transmitter had already been arranged in the early 1960s, when the launch of an ITV2 was anticipated. This led to very good coverage across most of the country and few problems of interference with other UK-based transmissions; a stark contrast to the problems associated with Channel 5's launch almost 15 years later. \"ITV2\" is not to be confused with ITV's digital television channel launched in 1998.\nWales.\nAt the time the fourth service was being considered, a movement in Wales lobbied for the creation of dedicated service that would air Welsh language programmes, then only catered for at \"off peak\" times on BBC Wales and HTV. The campaign was taken so seriously by Gwynfor Evans, former president of Plaid Cymru, that he threatened the government with a hunger strike were it not to honour the plans.\nThe result was that Channel 4 as seen by the rest of the United Kingdom would be replaced in Wales by Sianel Pedwar Cymru (S4C) (\"Channel Four Wales\"). Operated by a specially created authority, S4C would air programmes in Welsh made by HTV, the BBC and independent companies. Initially limited frequency space meant that Channel 4 could not be broadcast alongside S4C, though some Channel 4 programmes would be aired at less popular times on the Welsh variant; this practice continued until the closure of S4C's analogue transmissions in 2010, at which time S4C became a fully Welsh channel.\nWith this conversion of the Wenvoe transmitter group in Wales to digital terrestrial broadcasting on 31 March 2010, Channel 4 became a UK-wide television channel for the first time.\nSince then, carriage on digital cable, satellite and digital terrestrial has introduced Channel 4 to Welsh homes where it is now universally available.\nLaunch and IBA control.\nThe first voice heard on Channel 4's opening day of 2 November 1982 was that of continuity announcer Paul Coia who said: \"Good afternoon. It's a pleasure to be able to say to you, welcome to Channel Four.\" Following the announcement, the channel headed into a montage of clips from its programmes set to the station's signature tune, \"Fourscore\", written by David Dundas, which would form the basis of the station's jingles for its first decade. The first programme to air on the channel was the teatime game show \"Countdown\", produced by Yorkshire Television, at 16:45. The first person to be seen on Channel 4 was Richard Whiteley, with Ted Moult being the second. The first woman on the channel, contrary to popular belief, was not Whiteley's \"Countdown\" co-host Carol Vorderman, but a lexicographer only ever identified as Mary. Whiteley opened the show with the words: \"As the countdown to a brand new channel ends, a brand new countdown begins.\" On its first day, Channel 4 also broadcast soap opera \"Brookside\", which often ran storylines thought to be controversial; this ran until 2003.\nAt its launch, Channel 4 committed itself to providing an alternative to the existing channels, an agenda in part set out by its remit which required the provision of programming to minority groups. In step with its remit, the channel became well received both by minority groups and the arts and cultural worlds during this period under founding chief executive Jeremy Isaacs, where the channel gained a reputation for programmes on the contemporary arts. Two programmes captured awards from the Broadcasting Press Guild in March 1983: Best comedy for \"The Comic Strip Presents\u2026Five Go Mad in Dorset,\" and best on-screen performance in a non-acting role for Tom Keating in his series \"On Painters\". Channel 4 co-commissioned Robert Ashley's television opera \"Perfect Lives\", which it premiered over several episodes in 1984. The channel often did not receive mass audiences for much of this period, however, as might be expected for a station focusing on minority interest. During this time Channel 4 also began the funding of independent films, such as the Merchant Ivory docudrama \"The Courtesans of Bombay\".\nIn 1992, Channel 4 faced its first libel case by Jani Allan, a South African journalist, who objected to her representation in Nick Broomfield's documentary \"The Leader, His Driver and the Driver's Wife\".\nIn September 1993, the channel broadcast the direct-to-TV documentary film \"Beyond Citizen Kane\", in which it displayed the dominant position of the Rede Globo television network, and discussed its influence, power and political connections in Brazil.\nChannel Four Television Corporation.\nAfter control of the station passed from the Channel Four Television Company to the Channel Four Television Corporation in 1993, a shift in broadcasting style took place. Instead of aiming for minority tastes, it began to focus on the edges of the mainstream, and the centre of the mass market itself. It began to show many US programmes in peak viewing time, far more than it had previously done. It gave such shows as \"Friends\" and \"ER\" their UK premi\u00e8res.\nIn the early 2000s, Channel 4 began broadcasting reality formats such as \"Big Brother\" and obtained the rights to broadcast mass appeal sporting events like cricket and horse racing. This new direction increased ratings and revenues.\nIn addition, the corporation launched a number of new television channels through its new 4Ventures offshoot, including Film4, At the Races, E4 and More4.\nPartially in reaction to its new \"populist\" direction, the Communications Act 2003 directed the channel to demonstrate innovation, experimentation and creativity, appeal to the tastes and interests of a culturally diverse society, and to include programmes of an educational nature which exhibit a distinctive character.\nOn 31 December 2004, Channel 4 launched a 'brand' new look and new visual identity in which the logo is disguised as different objects and the \"4\" can be seen in an angle.\nUnder the leadership of Freeview founder Andy Duncan, 2005 saw a change of direction for Channel 4's digital channels. Channel 4 made E4 free-to-air on digital terrestrial television, and launched a new free-to-air digital channel called More4. By October, Channel 4 had joined the Freeview consortium. By July 2006, Film4 had likewise become free-to-air and restarted broadcasting on digital terrestrial.\nVenturing into radio broadcasting, 2005 saw Channel 4 purchase 51 per cent of shares in the now defunct Oneword radio station, with UBC Media holding on to the remaining shares. New programmes such as the weekly, half-hour \"The Morning Report\" news programme were among some of the new content Channel 4 provided for the station, with the name 4Radio being used. As of early 2009, however, Channel 4's future involvement in radio remained uncertain.\nOn 2 November 2007, the station celebrated its 25th birthday. It showed the first episode of \"Countdown\", an anniversary \"Countdown\" special, as well as a special edition of \"The Big Fat Quiz\" and using the original multicoloured 1982\u20131996 blocks logo on presentation and idents using the Fourscore jingle throughout the day.\nIn November 2009, Channel 4 launched a week of 3D television, broadcasting selected programmes each night using stereoscopic ColorCode 3D technology. The accompanying 3D glasses were distributed through Sainsbury's supermarkets.\nOn 29 September 2015, Channel 4 revamped its presentation for a fifth time; the new branding downplayed the \"4\" logo from most on-air usage, in favour of using the shapes from the logo in various forms. Four new idents were filmed by Jonathan Glazer, which featured the shapes in various real-world scenes depicting the \"discovery\" and \"origins\" of the shapes. The full logo was still occasionally used, but primarily for off-air marketing. Channel 4 also commissioned two new corporate typefaces, \"Chadwick\", and \"Horseferry\" (a variation of Chadwick with the aforementioned shapes incorporated into its letter forms), for use across promotional material and on-air.\nOn 31 October 2017, Channel 4 introduced a new series of idents continuing the theme, this time depicting the logo shapes as having formed an anthropomorphic \"giant\" character.\nSince 2006.\nBefore the digital switch-over, Channel 4 raised concerns over how it might finance its public service obligations afterward. In April 2006, it was announced that Channel 4's digital switch-over costs would be paid for by licence fee revenues.\nOn 28 March 2007, Channel 4 announced plans to launch a music channel \"4Music\" as a joint venture with British media company EMAP, which would include carriage on the Freeview platform. On 15 August 2008, 4Music was launched across the UK. Channel 4 announced interest in launching a high-definition version of Film4 on Freeview, to coincide with the launch of Channel 4 HD. However, the fourth HD slot was given to Channel 5 instead. Channel 4 has since acquired a 50 per cent stake in EMAP's TV business for a reported \u00a328\u00a0million.\nIn June 2017, it was announced that Alex Mahon would be the next chief executive, and would take over from David Abraham, who left in November 2017.\nOn 25 September 2021, Channel 4 and several of its sub-channels went off air after an incident at Red Bee Media's playout centre in west London. Channel 4, More4, Film4, E4, 4Music, The Box, Box Hits, Kiss, Magic and Kerrang! were impacted (4seven was not impacted), with the incident still affecting a number of the channels on 30 September 2021. The London Fire Brigade confirmed that a gas fire prevention system at the site had been activated, but firefighters found no sign of fire. Activation of the fire suppression system caused catastrophic damage to some systems, such as Channel 4's subtitles, signing and audio description system. An emergency back-up subtitling system also failed, leaving Channel 4 unable to provide access services to viewers. This situation was criticised by the National Deaf Children's Society, who complained to the broadcasting watchdog. A new subtitling, signing and audio description system had to be built from scratch. The service eventually began to return at the end of October. In June 2022 after a six month long investigation, Ofcom found that Channel 4 had breached its broadcast licence conditions on two grounds: Missing its subtitles quota on Freesat for 2021 and failure to effectively communicate with affected audiences.\nOn 23 December 2021, Jon Snow presented \"Channel 4 News\" for the last time, after 32 years as a main presenter on the programme, making Snow one of the UK's longest-serving presenters on a national news programme.\nAbandoned privatisation.\nChannel 4's parent company, Channel Four Television Corporation, was considered for privatisation by the governments of Margaret Thatcher, John Major and Tony Blair. In 2014, the Cameron-Clegg coalition government drew up proposals to privatise the corporation but the sale was blocked by the Liberal Democrat Business Secretary Vince Cable. In 2016, the future of the channel was again being looked into by the government, with analysts suggesting several options for its future. In June 2021, the government of Boris Johnson was considering selling the channel.\nIn April 2022, the Department for Culture, Media and Sport acknowledged that ministerial discussions were taking place regarding the sale of Channel Four Television Corporation. The channel's chief executive, Alex Mahon, expressed disappointment at this, saying that its vision for the future was \"rooted in continued public ownership\".\nIn January 2023, Michelle Donelan confirmed that the plans to sell Channel 4 were scrapped and that it would remain in public ownership for the foreseeable future.\nPublic service remit.\nChannel 4 was established with, and continues to hold, a remit of public service obligations which it must fulfil. The remit changes periodically, as dictated by various broadcasting and communications acts, and is regulated by the various authorities Channel 4 has been answerable to; originally the IBA, then the ITC and now Ofcom.\nThe preamble of the remit as per the Communications Act 2003 states that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe remit also involves an obligation to provide programming for schools, and a substantial amount of programming produced outside of Greater London.\nCarriage.\nChannel 4 was carried from its beginning on analogue terrestrial, which was then the standard means of television broadcast in the United Kingdom. It continued to be broadcast through these means until the changeover to digital terrestrial television in the United Kingdom was complete. Since 1998, it has been universally available on digital terrestrial, and the Sky platform (initially encrypted, though encryption was dropped on 14 April 2008 and is now free of charge and available on the Freesat platform) as well as having been available from various times in various areas, on analogue and digital cable networks.\nDue to its special status as a public service broadcaster with a specific remit, it is afforded free carriage on the terrestrial platforms, in contrast with other broadcasters such as ITV.\nChannel 4 is available outside the United Kingdom; it is widely available in the Republic of Ireland, the Netherlands, Belgium and Switzerland. The channel is registered to broadcast within the European Union/EEA through the Luxembourg Broadcasting Regulator (ALIA).\nSince 2019, it has been offered by British Forces Broadcasting Service (BFBS) to members of the British Armed Forces and their families around the world, BFBS Extra having previously carried a selection of Channel 4 programmes.\nThe Channel 4 website allows people in the United Kingdom to watch Channel 4 live on the Internet. In the past some programmes (mostly international imports) were not shown. Channel 4 is also provided by Virgin Mobile's DAB mobile TV service, which has the same restrictions as the Internet live stream had. Channel 4 is also carried by the Internet TV service TVCatchup and was previously carried by Zattoo until the operator removed the channel from its platform.\nChannel 4 also makes some of its programming available \"on demand\" via cable and the Internet through Channel 4.\nFunding.\nDuring its first decade, Channel 4 was funded by subscriptions collected by the IBA from the ITV regional companies, in return for which each company had the right to sell advertisements on the fourth channel in its own region and keep the proceeds. This meant that ITV and Channel 4 were not in competition with each other, and often promoted each other's programmes.\nA change in funding came about under the Broadcasting Act 1990 when the new corporation was afforded the ability to fund itself. Originally this arrangement left a \"safety net\" guaranteed minimum income should the revenue fall too low, funded by large insurance payments made to the ITV companies. Such a subsidy was never required, however, and these premiums were phased out by the government in 1998. After the link with ITV was cut, the cross-promotion which had existed between ITV and Channel 4 also ended.\nIn 2007, owing to severe funding difficulties, the channel sought government help and was granted a payment of \u00a314\u00a0million over a six-year period. The money was to have come from the television licence fee, and would have been the first time that money from the licence fee had been given to any broadcaster other than the BBC. However, the plan was scrapped by the Secretary of State for Culture, Media and Sport, Andy Burnham, ahead of \"broader decisions about the future framework of public service broadcasting\". The broadcasting regulator Ofcom released its review in January 2009 in which it suggested that Channel 4 would preferably be funded by \"partnerships, joint ventures or mergers\".\nAs of 2022[ [update]], it breaks even in much the same way as most privately run commercial stations through the sale of on-air advertising, programme sponsorship, and the sale of any programme content and merchandising rights it owns, such as overseas broadcasting rights and domestic video sales. For example, as of 2012[ [update]] its total revenues were \u00a3925\u00a0million with 91 per cent derived from sale of advertising. It also has the ability to subsidise the main network through any profits made on the corporation's other endeavours, which have in the past included subscription fees from stations such as E4 and Film4 (now no longer subscription services) and its \"video-on-demand\" sales. In practice, however, these other activities are loss-making, and are subsidised by the main network. According to Channel 4's last published accounts, for 2005, the extent of this cross-subsidy was some \u00a330\u00a0million.\nProgramming.\nChannel 4 is a \"publisher-broadcaster\", meaning that it commissions or \"buys\" all of its programming from companies independent of itself. It was the first UK broadcaster to do so on a significant scale; such commissioning is a stipulation which is included in its licence to broadcast. In consequence, numerous independent production companies emerged, though external commissioning on the BBC and in ITV (where a quota of 25 per cent minimum of total output has been imposed since the Broadcasting Act 1990 came into force) has become regular practice, as well as on the numerous stations that launched later. Although it was the first British broadcaster to commission all of its programmes from third parties, Channel 4 was the last terrestrial broadcaster to outsource its transmission and playout operations (to Red Bee Media), after 25 years in-house.\nThe requirement to obtain all content externally is stipulated in its licence. Additionally, Channel 4 also began a trend of owning the copyright and distribution rights of the programmes it aired, in a manner that is similar to the major Hollywood studios' ownership of television programmes that they did not directly produce. Thus, although Channel 4 does not produce programmes, many are seen as belonging to it.\nIt was established with a specific intention of providing programming to groups of minority interests, not catered for by its competitors, which at the time were only the BBC and ITV.\nChannel 4 also pioneered the concept of 'stranded programming', where seasons of programmes following a common theme would be aired and promoted together. Some would be very specific, and run for a fixed period of time; the \"4 Mation\" season, for example, showed innovative animation. Other, less specific strands, were (and still are) run regularly, such as \"T4\", a strand of programming aimed at teenagers, on weekend mornings (and weekdays during school/college holidays); \"Friday Night Comedy\", a slot where the channel would pioneer its style of comedy commissions, \"4Music\" (now a separate channel) and \"4Later\", an eclectic collection of offbeat programmes transmitted in the early hours of the morning.\nFor a period in the mid-1980s, some art-house films (dubbed by Channel 4's critics as being pornographic) would be screened with a \"red triangle\" graphic in the upper right of the screen.\nMost watched programmes.\nThe following is a list of the 10 most watched shows on Channel 4 since launch, based on Live +28 data supplied by BARB, and archival data published by Channel 4.\nComedy.\nDuring the station's early days, the screenings of innovative short one-off comedy films produced by a rotating line-up of alternative comedians went under the title of \"The Comic Strip Presents\". \"The Tube\" and \"Saturday Live/Friday Night Live\" also launched the careers of a number of comedians and writers. Channel 4 broadcast a number of popular American imports, including \"Roseanne\", \"Friends\", \"Sex and the City\", \"South Park\" and \"Will &amp; Grace\". Other significant US acquisitions include \"The Simpsons\", for which the station was reported to have paid \u00a3700,000 per episode for the terrestrial television rights.\nIn April 2010, Channel 4 became the first UK broadcaster to adapt the American comedy institution of roasting to British television, with \"A Comedy Roast\".\nIn 2010, Channel 4 organised \"Channel 4's Comedy Gala\", a comedy benefit show in aid of Great Ormond Street Children's Hospital. With over 25 comedians appearing, it billed it as \"the biggest live stand up show in United Kingdom history\". Filmed live on 30 March in front of 14,000 at The O2 Arena in London, it was broadcast on 5 April. This has continued to 2016.\nIn 2021, Channel 4 decided to revive The British Comedy Awards as part of their Stand Up To Cancer programming. The ceremony, billed as The National Comedy Awards was due to be held in the Spring of 2021 but was delayed due to the Coronavirus pandemic until 15 December 2021 and then cancelled a week before it was due to be held, due to concerns over the Omicron variant.\nThe ceremony was finally held on 2 March 2022 and broadcast on Channel 4 three days later. The National Comedy Awards was not the only live comedy event that was part of the channel's Christmas schedule that was effected by these concerns as \"Joe Lycett: Mummy's Big Christmas Do!\" was also postponed, with the 22 December show due to air as a pilot for a new series called \"Mummy's House Party\" in Spring 2022. Lycett's Birmingham-based extravaganza finally made it to air on 3 July 2022 as \"Joe Lycett's Big Pride Party\", with 0.29 million viewers tuning in (compared to 0.69 million for \"The Cruise\" on Channel 5).\nFactual and current affairs.\nChannel 4 has a strong reputation for history programmes and documentaries. Its news service, \"Channel 4 News\", is supplied by ITN whilst its long-standing investigative documentary series, \"Dispatches\", gains attention from other media outlets. Its live broadcast of the first public autopsy in the UK for 170 years, carried out by Gunther von Hagens in 2002 and the 2003 one-off stunt \"Derren Brown Plays Russian Roulette Live\" proved controversial.\nA season of television programmes about masturbation, called \"Wank Week\", was to be broadcast in the United Kingdom by Channel 4 in March 2007. The series came under public attack from senior television figures, and was pulled amid claims of declining editorial standards and concern for the channel's public service broadcasting credentials.\nFourDocs.\nFourDocs was an online documentary site provided by Channel 4. It allowed viewers to upload their own documentaries to the site for others to view. It focused on documentaries of between 3 and 5 minutes. The website also included an archive of classic documentaries, interviews with documentary filmmakers and short educational guides to documentary-making. It won a Peabody Award in 2006. The site also included a strand for documentaries of under 59 seconds, called \"Microdocs\".\nSchools programming.\nChannel 4 is obliged to carry schools programming as part of its remit and licence.\nITV Schools on Channel 4.\nSince 1957 ITV had produced schools programming, which became an obligation. In 1987, five years after the station was launched, the IBA afforded ITV free carriage of these programmes during Channel 4's then-unused weekday morning hours. This arrangement allowed the ITV companies to fulfil their obligation to provide schools programming, whilst allowing ITV itself to broadcast regular programmes complete with advertisements. During the times in which schools programmes were aired Central Television provided most of the continuity with play-out originating from Birmingham.\nChannel 4 Schools/4Learning.\nAfter the restructuring of the station in 1993, ITV's obligations to provide such programming on Channel 4's airtime passed to Channel 4 itself, and the new service became Channel 4 Schools, with the new corporation administering the service and commissioning its programmes, some still from ITV, others from independent producers.\nIn March 2008, the 4Learning interactive new media commission Slabovia.tv was launched. The Slabplayer online media player showing TV shows for teenagers was launched on 26 May 2008.\nThe schools programming has always had elements which differ from its normal presentational package. In 1993, the Channel 4 Schools idents featured famous people in one category, with light shining on them in front of an industrial-looking setting supplemented by instrumental calming music. This changed in 1996 with the circles look to numerous children touching the screen, forming circles of information then picked up by other children. The last child would produce the Channel 4 logo in the form of three vertical circles, with another in the middle and to the left containing the Channel 4 logo.\nA present feature of presentation was a countdown sequence featuring, in 1993 a slide with the programme name, and afterwards an extended sequence matching the channel branding. In 1996, this was an extended ident with timer in top left corner, and in 1999 following the adoption of the squares look, featured a square with timer slowly make its way across the right of the screen with people learning and having fun while doing so passing across the screen. It finished with the Channel 4 logo box on the right of the screen and the name 'Channel 4 Schools' being shown. This was adapted in 2000 when the service's name was changed to '4Learning'.\nIn 2001, this was altered to various scenes from classrooms around the world and different parts of school life. The countdown now flips over from the top, right, bottom and left with each second, and ends with four coloured squares, three of which are aligned vertically to the left of the Channel 4 logo, which is contained inside the fourth box. The tag 'Learning' is located directly beneath the logo. The final countdown sequence lasted between 2004 and 2005 and featured a background video of current controversial issues, overlaid with upcoming programming information. The video features people in the style of graffiti enacting the overuse of CCTV cameras, fox hunting, computer viruses and pirate videos, relationships, pollution of the seas and violent lifestyles. Following 2005, no branded section has been used for schools programmes.\nReligious programmes.\nFrom the outset, Channel 4 did not conform to the expectations of conventional religious broadcasting in the UK. John Ranelagh, first Commissioning Editor for Religion, made his priority 'broadening the spectrum of religious programming' and more 'intellectual' concerns. He also ignored the religious programme advisory structure that had been put in place by the BBC, and subsequently adopted by ITV. Ranelagh's first major commission caused a furore, a three-part documentary series called \"\". The programmes, transmitted during the Easter period of 1984, seemed to advocate the idea that the Gospels were unreliable, Jesus may have indulged in witchcraft, and that he may not have even existed. The series triggered a public outcry, and marked a significant moment in the deterioration in the relationship between the UK's broadcasting and religious institutions.\nFilm.\nNumerous genres of film-making \u2013 such as comedy, drama, documentary, adventure/action, romance and horror/thriller \u2013 are represented in the channel's schedule. From the launch of Channel 4 until 1998, film presentations on C4 would often be broadcast under the \"Film on Four\" banner.\nIn March 2005, Channel 4 screened the uncut Lars von Trier film \"The Idiots\", which includes unsimulated sexual intercourse, making it the first UK terrestrial channel to do so. The channel had previously screened other films with similar material but censored and with warnings.\nSince 1 November 1998, Channel 4 has had a digital subsidiary channel dedicated to the screening of films. This channel launched as a paid subscription channel under the name \"FilmFour\", and was relaunched in July 2006 as a free-to-air channel under the current name of \"Film4\". The Film4 channel carries a wide range of film productions, including acquired and Film4-produced projects. Channel 4's general entertainment channels E4 and More4 also screen feature films at certain points in the schedule as part of their content mix.\nGlobal warming.\nOn 8 March 2007, Channel 4 screened a documentary, \"The Great Global Warming Swindle\" stating that global warming is \"a lie\" and \"the biggest scam of modern times\". The programme's accuracy were disputed on multiple points, and commentators criticised it for being one-sided, observing that the mainstream position on global warming is supported by the scientific academies of the major industrialised nations. There were 246 complaints to Ofcom as of 25 April 2007, including allegations that the programme falsified data. The programme was criticised by scientists and scientific organisations, and various scientists who participated in the documentary claimed their views had been distorted.\n\"Against Nature\": An earlier controversial Channel 4 programme made by Martin Durkin which was also critical of the environmental movement and was charged by the UK's Independent Television Commission for misrepresenting and distorting the views of interviewees by selective editing.\n\"The Greenhouse Conspiracy\": An earlier Channel 4 documentary broadcast on 12 August 1990, as part of the \"Equinox\" series, in which similar claims were made. Three of the people interviewed (Lindzen, Michaels and Spencer) were also interviewed in \"The Great Global Warming Swindle\".\nAhmadinejad's Christmas speech.\nIn the \"Alternative Christmas address\" of 2008, a Channel 4 tradition since 1993 with a different presenter each year, Iranian President Mahmoud Ahmadinejad made a thinly veiled attack on the United States by claiming that Christ would have been against \"bullying, ill-tempered and expansionist powers\".\nThe broadcast was rebuked by human rights activists, politicians and religious figures, including Peter Tatchell, Louise Ellman, Ron Prosor and Rabbi Aaron Goldstein. A spokeswoman for the Foreign and Commonwealth Office said: \"President Ahmadinejad has, during his time in office, made a series of appalling anti-Semitic statements. The British media are rightly free to make their own editorial choices, but this invitation will cause offence and bemusement not just at home but among friendly countries abroad\".\nHowever, Channel 4 was defended by Stonewall director Ben Summerskill who stated: \"In spite of his ridiculous and often offensive views, it is an important way of reminding him that there are some countries where free speech is not repressed...If it serves that purpose, then Channel 4 will have done a significant public service\". Dorothy Byrne, Channel 4's head of news and current affairs, said in response to the station's critics: \"As the leader of one of the most powerful states in the Middle East, President Ahmadinejad's views are enormously influential... As we approach a critical time in international relations, we are offering our viewers an insight into an alternative world view...Channel 4 has devoted more airtime to examining Iran than any other broadcaster and this message continues a long tradition of offering a different perspective on the world around us\".\n4Talent.\n4Talent is an editorial branch of Channel 4's commissioning wing, which co-ordinates Channel 4's various talent development schemes for film, television, radio, new media and other platforms and provides a showcasing platform for new talent.\nThere are bases in London, Birmingham, Glasgow and Belfast, serving editorial hubs known respectively as 4Talent National, 4Talent Central England, 4Talent Scotland and 4Talent Northern Ireland. These four sites include features, profiles and interviews in text, audio and video formats, divided into five zones: TV, Film, Radio, New Media and Extras, which covers other arts such as theatre, music and design. 4Talent also collates networking, showcasing and professional development opportunities, and runs workshops, masterclasses, seminars and showcasing events across the UK.\n\"4Talent Magazine\".\n\"4Talent Magazine\" is the creative industries magazine from 4Talent, which launched in 2005 as \"TEN4\" magazine under the editorship of Dan Jones. \"4Talent Magazine\" is currently edited by Nick Carson. Other staff include deputy editor Catherine Bray and production editor Helen Byrne. The magazine covers rising and established figures of interest in the creative industries, a remit including film, radio, TV, comedy, music, new media and design.\nSubjects are usually UK-based, with contributing editors based in Northern Ireland, Scotland, London and Birmingham, but the publication has been known to source international content from Australia, America, continental Europe and the Middle East. The magazine is frequently organised around a theme for the issue, for instance giving half of November 2007's pages over to profiling winners of the annual 4Talent Awards.\nAn unusual feature of the magazine's credits is the equal prominence given to the names of writers, photographers, designers and illustrators, contradicting standard industry practice of more prominent writer bylines. It is also recognisable for its 'wraparound' covers, which use the front and back as a continuous canvas \u2013 often produced by guest artists.\nAlthough \"4Talent Magazine\" is technically a newsstand title, a significant proportion of its readers are subscribers. It started life as a quarterly 100-page title, but has since doubled in size and is now published bi-annually.\nScheduling.\nSince the 2010s, Channel 4 has become the public service broadcaster most likely to amend their schedule at short notice, if programmes are not gaining sufficient viewers in their intended slots. Programmes which have been heavily promoted by the channel before launch and then have lost their slot a week later include \"Sixteen: Class of 2021\". This was a fly-on-the-wall school documentary which lost its prime 9pm slot after one episode on 31 August 2021, even with a 4 star review in \"The Guardian\". Channel 4 moved the next episode to a late night (post-primetime) slot on a different day and continued to broadcast the remainder of the four-part series in this timeslot.\nAlso in 2021, the channel launched \"Epic Wales: Valleys, Mountains and Coast\", a version of their More4 documentaries \"The Pennines: Backbone of Britain\", \"The Yorkshire Dales and The Lakes\" and \"Devon and Cornwall\". set in Wales. \"Epic Wales: Valleys, Mountains and Coast\". was initially broadcast in a prime Friday night slot at 8pm, in the hour before their comedy shows, but was dumped by the channel before the series was completed and replaced by repeats. In February 2022, the channel scheduled a new version of the show under the title \"Wonderous Wales\" with a Saturday night slot at 8pm but after one episode, they decided to take this series out of their schedule, moving up a repeat of \"Matt Baker: Our Farm in the Dales\" to 8pm and putting an episode of \"Escape to the Chateau\" in Baker's slot at 7pm. Other programmes moved out of primetime in 2022, include \"Mega Mansion Hunters\", Channel 4's answer to \"Selling Sunset\", which saw its third and final episode moved past midnight with repeats put in the schedule before it, and \"Richard Hammond's Crazy Contraptions\", a primetime Friday night competitive engineering show which saw its grand final moved to 11pm on a Sunday night. Instead of Hammond's competition, Channel 4 decided to schedule the fifth series of \"Devon and Cornwall\" in its place at 8pm on Friday nights, with this documentary being put up against Channel 5's \"World's Most Scenic Railway Journeys\" in the same timeslot.\nA new series of \"Unreported World\" was due to start on 18 February 2022 with a report by Seyi Rhodes in South Sudan, but was dropped due to an extended storm report on \"Channel 4 News\". When the programme was rescheduled for following Fridays, it was dropped again as \"Channel 4 News\" was extended due to the 2022 Russian invasion of Ukraine. \"Winter Paralympics: Today in Beijing\" is due to take the \"Unreported World\" slot from 11 March 2022 though this sports programme may also be moved around the schedule to continue the extended news programmes reporting on the conflict. The invasion of Ukraine has also prompted Channel 4 to acquire and schedule the comedy series \"Servant of the People\" as a last minute replacement. The programme stars the current President of Ukraine Volodymyr Zelenskyy as an ordinary man who gets elected to run the country, and will be shown on 6 March 2022 along with the documentary \"Zelenskyy: The Man Who Took on Putin\".\nIn addition to these shows, O.T. Fagbenle's sitcom \"Maxxx\" was pulled from their youth TV channel E4, after one episode from the series had been broadcast on 2 April 2020, with Channel 4 deciding to keep the series off-air until Black History Month, with the series now going out on the main channel from October 2020.\nIn May 2022, the reality dating show \"Let's Make a Love Scene\" was scrapped after one episode with the second programme in the series, hosted by Ellie Taylor, pulled from the May 20 schedule and replaced with an episode of \"8 Out of 10 Cats Does Countdown\". The first edition was negatively received, with Anita Singh, the Arts and Entertainments Editor for \"The Telegraph\" writing that the show was \"the most ill-conceived programme idea since Prince Edward dreamt up \"It's a Royal Knockout\"\".\nPresentation.\nSince its launch in 1982, Channel 4 has used the same logo which consists of a stylised numeral \"4\" made up of nine differently-shaped blocks. \nThe original version was designed by Martin Lambie-Nairn and his partner Colin Robinson and was the first UK channel ident made using advanced computer generation (the first electronically generated ident was on BBC2 in 1979, but this was two-dimensional). It was designed in conjunction with Bo Gehring Aviation of Los Angeles and originally depicted the \"4\" in red, yellow, green, blue and purple. The music accompanying the ident was called \"Fourscore\" and was composed by David Dundas; it was later released as a single alongside a B-side, \"Fourscore Two\", although neither reached the UK charts. In November 1992, \"Fourscore\" was replaced by new music.\nIn 1996, Channel 4 commissioned Tomato Films to revamp the \"4\", which resulted in the \"Circles\" idents showing four white circles forming up transparently over various scenes, with the \"4\" logo depicted in white in one of the circles.\nIn 1999, Spin redesigned the logo to feature in a single square which sat on the right-hand side of the screen, whilst various stripes would move along from left to right, often lighting the squared \"4\" up. Like previous \"Circles\" idents from 1996 (which was made by Tomato Films), the stripes would be interspersed with various scenes potentially related to the upcoming programme.\nThe logo was made three-dimensional again in 2004 when it was depicted in filmed scenes that show the blocks forming the \"4\" logo for less than a second before the action moves away again.\nIn 2015, the logo was disassembled completely to allow the blocks to appear as parts of a nature scene, sometimes featuring a strange dancing creature and sometimes being excavated for scientific study, one being studied under a microscope and showing a tardigrade. The second wave of these idents, launched in 2017, depict a giant creature made of the \"4\" blocks (made to look almost like a person) interacting with everyday life, sometimes shouting the \"Fourscore\" theme as a foghorn.\nThe original 1982 logo was reintroduced for one day only on 22 January 2021, to promote Channel 4's new five-part drama, \"It's a Sin\" which focused on the 1980s AIDS crisis. It was additionally used once on 28 December 2020 as a commemoration for Lambie-Nairn, who had died three days earlier.\nThe Channel 4 logo was reassembled in 2023 in an all lime green colour to promote the network's new digital first strategy, which included its streaming service All 4 being renamed under the Channel 4 brand. This was then followed by the launch of a new idents package on 14 June 2023.\nRegions/international.\nRegions.\nChannel 4 has, since its inception, broadcast identical programmes and continuity throughout the United Kingdom (excluding Wales where it did not operate on analogue transmitters). At launch this made it unique, as both the BBC and ITV had long-established traditions of providing regional variations in their programming in different areas of the country. Since the launch of subsequent British television channels, Channel 4 has become typical in its lack of regional programming variations.\nA few exceptions exist to this rule for programming and continuity:\nPart of Channel 4's remit covers the commissioning of programmes from outside London. Channel 4 has a dedicated director of nations and regions, Stuart Cosgrove, who is based in a regional office in Glasgow. As his job title suggests, it is his responsibility to foster relations with independent producers based in areas of the United Kingdom (including Wales) outside London.\nInternational.\nChannel 4 is available in Ireland, with adverts specifically tailored towards the Irish market. The channel is registered with the broadcasting regulators in Luxembourg for terms of conduct and business within the EU/EEA while observing guidelines outlined by Ireland's BAI code. Irish advertising sales are managed by Media Link in Dublin. Where Channel 4 does not hold broadcasting rights within the Republic of Ireland such programming is unavailable. For example, the series \"Glee\" was not available on Channel 4 on Sky in Ireland due to it broadcasting on TV3 within Ireland. Currently, programming available on Channel 4 is available within the Republic of Ireland without restrictions. Elsewhere in Europe the UK version of the channel is available.\nFuture possibility of regional news.\nWith ITV plc pushing for much looser requirements on the amount of regional news and other programming it is obliged to broadcast in its ITV regions, the idea of Channel 4 taking on a regional news commitment has been considered, with the corporation in talks with Ofcom and ITV over the matter. Channel 4 believe that a scaling-back of such operations on ITV's part would be detrimental to Channel 4's national news operation, which shares much of its resources with ITV through their shared news contractor ITN. At the same time, Channel 4 also believe that such an additional public service commitment would bode well in on-going negotiations with Ofcom in securing additional funding for its other public service commitments.\nChannel 4 HD.\nIn mid-2006 Channel 4 ran a six-month closed trial of HDTV, as part of the wider Freeview HD experiment via the Crystal Palace transmitter to London and parts of the home counties, including the use of \"Lost\" and \"Desperate Housewives\" as part of the experiment, as US broadcasters such as ABC already have an HDTV back catalogue.\nOn 10 December 2007, Channel 4 launched a high-definition television simulcast of Channel 4 on Sky's digital satellite platform, after Sky agreed to contribute toward the channel's satellite distribution costs. It was the first full-time high-definition channel from a terrestrial UK broadcaster.\nOn 31 July 2009, Virgin Media added Channel 4 HD on channel 146 (later on channel 142, now on channel 141) as part of the M pack. On 25 March 2010 Channel 4 HD appeared on Freeview channel 52 with a placeholding caption, ahead of a commercial launch on 30 March 2010, coinciding with the commercial launch of Freeview HD. On 19 April 2011, Channel 4 HD was added to Freesat on channel 126. As a consequence, the channel moved from being free-to-view to free-to-air on satellite during March 2011. With the closure of S4C Clirlun in Wales on 1 December 2012, on Freeview, Channel 4 HD launched in Wales on 2 December 2012.\nThe channel carries the same schedule as Channel 4, broadcasting programmes in HD when available, acting as a simulcast. Therefore, SD programming is broadcast upscaled to HD. The first true HD programme to be shown was the 1996 Adam Sandler film \"Happy Gilmore\". From launch until 2016 the presence of the 4HD logo on screen denoted true HD content.\nOn 1 July 2014, Channel 4 +1 HD, an HD simulcast of Channel 4 +1, launched on Freeview channel 110. It closed on 22 June 2020 to help make room on COM7 following the closure of COM8 on Freeview. On 22 June 2020 Channel4+1 HD and 4Seven HD were removed from Freeview.\nOn 20 February 2018, Channel 4 announced that Channel 4 HD and All 4 would no longer be supplied on Freesat from 22 February 2018. Channel 4 HD returned to the platform on 8 December 2021, along with the music channel portfolio of The Box Plus Network.\nOn 27 September 2022, the other 6 advertising regions of Channel 4 (South, Midlands, North, Scotland, Northern Ireland and Rep of Ireland) were made available in HD on Sky and Virgin Media. Prior to this, Channel 4 HD was only available in the London advertising region.\nVideo on demand.\nChannel 4's video on demand service, known simply as \"Channel 4\" since April 2023, launched in November 2006 as \"4oD\", and was renamed \"All 4\" in March 2015. The service offers a variety of programmes recently shown on Channel 4, E4, More4 or from their archives, though some programmes and movies are not available due to rights issues.\nTeletext services.\n4-Tel/FourText.\nChannel 4 originally licensed an ancillary teletext service to provide schedules, programme information and features. The original service was called 4-Tel, and was produced by Intelfax, a company set up especially for the purpose. It was carried in the 400s on Oracle. In 1993, with Oracle losing its franchise to Teletext Ltd, 4-Tel found a new home in the 300s, and had its name shown in the header row. Intelfax continued to produce the service and in 2002 it was renamed FourText.\nTeletext on 4.\nIn 2003, Channel 4 awarded Teletext Ltd a ten-year contract to run the channel's ancillary teletext service, named Teletext on 4. The service closed in 2008, and Teletext is no longer available on Channel 4, ITV and Channel 5.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6322", "revid": "8367488", "url": "https://en.wikipedia.org/wiki?curid=6322", "title": "Carolina parakeet", "text": "Extinct species of parakeet native to North America\nThe Carolina parakeet (Conuropsis carolinensis), or Carolina conure, is an extinct species of small green neotropical parrot with a bright yellow head, reddish orange face and pale beak that was native to the Eastern, Midwest and Plains states of the United States. It was the only indigenous parrot within its range, as well as one of only three parrot species native to the United States (the others being the thick-billed parrot, now extirpated, and the green parakeet, still present in Texas; a fourth parrot species, the red-crowned amazon, is debated). It was called \"puzzi la n\u00e9e\" (\"head of yellow\") or \"pot pot chee\" by the Seminole and \"kelinky\" in Chickasaw. Though formerly prevalent within its range, the bird had become rare by the middle of the 19th century. The last confirmed sighting in the wild was of the \"ludovicianus\" subspecies in 1910. The last known specimen, a male named Incas, perished in captivity at the Cincinnati Zoo in 1918, and the species was declared extinct in 1939.\nThe earliest reference to these parrots was in 1583 in Florida reported by Sir George Peckham in \"A True Report of the Late Discoveries of the Newfound Lands\" of expeditions conducted by English explorer Sir Humphrey Gilbert who notes that explorers in North America \"doe testifie that they have found in those countryes;\u00a0... parrots.\" They were first scientifically described in English naturalist Mark Catesby's two volume \"Natural History of Carolina, Florida and the Bahama Islands\" published in London in 1731 and 1743.\nCarolina parakeets were probably poisonous\u2014American naturalist and painter John J. Audubon noted that cats apparently died from eating them, and they are known to have eaten the toxic seeds of cockleburs.\nTaxonomy.\n\"Carolinensis\" is a species of the genus \"Conuropsis\", one of numerous genera of New World Neotropical parrots in family Psittacidae of true parrots.\nThe specific name \"Psittacus carolinensis\" was assigned by Swedish zoologist Carl Linnaeus in the 10th edition of Systema Naturae published in 1758. The species was given its own genus \"Conuropsis\" by Italian zoologist and ornithologist Tommaso Salvadori in 1891 in his \"Catalogue of the Birds in the British Museum\", volume\u00a020. The name is derived from the Greek-ified \"conure\" (\"parrot of the genus \"Conurus\"\" an obsolete name of genus \"Aratinga\") + \"-opsis\" (\"likeness of\") and Latinized \"Carolina\" (from Carolana, an English colonial province) + \"-ensis\" (of or \"from a place\"), therefore a bird \"like a conure from Carolina.\"\nThere are two recognized subspecies. The Louisiana subspecies of the Carolina parakeet, \"C. c. ludovicianus\", was slightly different in color than the nominate subspecies, being more bluish-green and generally of a somewhat subdued coloration, and became extinct in much the same way, but at a somewhat earlier date (early 1910s). The Appalachian Mountains separated these birds from the eastern \"C.\u00a0c.\u00a0carolinensis\".\nEvolution.\nAccording to a study of mitochondrial DNA recovered from museum specimens, their closest living relatives include some of the South American \"Aratinga\" parakeets: The Nanday parakeet, the sun parakeet, and the golden-capped parakeet. The authors note the bright yellow and orange plumage and blue wing feathers found in \"Conuropsis carolinensis\" are traits shared by another species, the jandaya parakeet (\"A.\u00a0jandaya\"), that was not sampled in the study but is generally thought to be closely related. To help resolve the divergence time a whole genome of a preserved specimen has now been sequenced. The Carolina parakeet colonized North America about 5.5\u00a0million years ago. This was well before North America and South America were joined by the formation of the Panama land bridge about 3.5\u00a0mya. Since the Carolina parakeets' more distant relations are geographically closer to its own historic range while its closest relatives are more geographically distant to it, these data are consistent with the generally accepted hypothesis that Central and North America were colonized at different times by distinct lineages of parrots \u2013 parrots that originally invaded South America from Antarctica some time after the breakup of Gondwana, where Neotropical parrots originated approximately 50\u00a0mya.\nThe following cladogram shows the placement of the Carolina parakeet among its closest relatives, after a DNA study by Kirchman \"et al\". (2012):\nA fossil parrot, designated \"Conuropsis fratercula\", was described based on a single humerus from the Miocene Sheep Creek Formation (possibly late Hemingfordian, c.\u00a016\u00a0mya, possibly later) of Snake River, Nebraska. It was a smaller bird, three-quarters the size of the Carolina parakeet. \"The present \"species\" is of peculiar interest as it represents the first known parrot-like bird to be described as a fossil from North America.\" (Wetmore 1926; italics added) However, it is not completely certain that the species is correctly assigned to \"Conuropsis\", but some authors consider it a paleosubspecies of the Carolina parakeet.\nDescription.\nThe Carolina parakeet was a small green parrot very similar in size and coloration to the extant jenday parakeet and sun conure. The majority of the plumage was green with lighter green underparts, a bright yellow head and orange forehead and face extending to behind the eyes and upper cheeks (lores). The shoulders were yellow, continuing down the outer edge of the wings. The primary feathers were mostly green, but with yellow edges on the outer primaries. Thighs were green towards the top and yellow towards the feet. Male and female adults were identical in plumage, however males were slightly larger than females (sexually dimorphic). The legs and feet were light brown. They share the zygodactyl feet of the parrot family. The skin around the eyes was white and the beak was pale flesh colored. These birds weigh about 3.5\u00a0oz., are 13\u00a0in. long, and have wingspans of 21\u201323\u00a0in.\nYoung Carolina parakeets differed slightly in coloration from adults. The face and entire body was green, with paler underparts. They lacked yellow or orange plumage on the face, wings, and thighs. Hatchlings were covered in mouse-gray down, until about 39\u201340 days when green wings and tails appear. Fledglings had full adult plumage at around 1 year of age.\nThese birds were fairly long lived, at least in captivity - a pair was kept at the Cincinnati Zoo for over 35 years.\nDistribution and habitat.\nThe Carolina parakeet had the northernmost range of any known parrot. The Carolina parakeet was found from southern New York and Wisconsin to Kentucky, Tennessee and the Gulf of Mexico, from the Atlantic seaboard to as far west as eastern Colorado. It lived in old-growth forests along rivers and in swamps. Its range was described by early explorers thus: the 43rd parallel as the northern limit, the 26th as the most southern, the 73rd and 106th meridians as the eastern and western boundaries respectively, the range included all or portions of at least 28 states. Its habitats were old-growth wetland forests along rivers and in swamps especially in the Mississippi-Missouri drainage basin with large hollow trees including cypress and sycamore to use as roosting and nesting sites.\nOnly very rough estimates of the birds' former prevalence can be made: with an estimated range of 20,000 to 2.5 million km2, and population density of 0.5 to 2.0 parrots per km2, population estimates range from tens of thousands to a few million birds (though the densest populations occurred in Florida covering 170,000\u00a0km2, so there may have been hundreds of thousands of the birds in that state alone).\nThe species may have appeared as a very rare vagrant in places as far north as southern Ontario in Canada. A few bones, including a pygostyle found at the Calvert Site in Southern Ontario, came from the Carolina parakeet. The possibility remains open that this specimen was taken to southern Ontario for ceremonial purposes.\nBehavior and diet.\nThe bird lived in huge, noisy flocks of as many as 200\u2013300 birds. It built its nest in a hollow tree, laying two to five (most accounts say two) round white eggs. Reportedly, multiple female parakeets could deposit their eggs into one nest, similar to nesting behavior described in the monk parakeet (\"Myiopsitta monachus\").\nIt mostly ate the seeds of forest trees and shrubs including those of cypress, hackberry, beech, sycamore, elm, pine, maple, oak, and other plants such as thistles and sandspurs (\"Cenchrus\" species). It also ate fruits, including apples, grapes and figs (often from orchards by the time of its decline), as well as flower buds and, occasionally, insects. It was especially noted for its predilection for cockleburs (\"Xanthium strumarium\"), a plant which contains a toxic glucoside, and it was considered to be an agricultural pest of grain crops.\nExtinction.\nThe last captive Carolina parakeet, Incas, died at the Cincinnati Zoo on February 21, 1918, in the same cage as Martha, the last passenger pigeon, who died in 1914. There are no scientific studies or surveys of this bird by American naturalists; most information about it is from anecdotal accounts and museum specimens. Therefore, details of its prevalence and decline are unverified or speculative.\nThere are extensive accounts of the pre-colonial and early colonial prevalence of this bird. The existence of flocks of gregarious, very colorful and raucous parrots could hardly have gone unnoted by European explorers, as parrots were virtually unknown in seafaring European nations in the 16th and 17th centuries. Later accounts in the latter half of the 19th century onward noted the birds' sparseness and absence.\nGenetic evidence suggests that while populations had been in decline since the last glacial maximum, the lack of evidence of inbreeding suggests that the birds declined very quickly.\nThe birds' range collapsed from east to west with settlement and clearing of the eastern and southern deciduous forests. John J. Audubon commented as early as 1832 on the decline of the birds. The bird was rarely reported outside Florida after 1860. The last reported sighting east of the Mississippi River (except Florida) was in 1878 in Kentucky. By the turn of the century it was restricted to the swamps of central Florida. The last known wild specimen was killed in Okeechobee County, Florida, in 1904, and the last captive bird died at the Cincinnati Zoo on February 21, 1918. This was the male specimen, Incas, who died within a year of his mate, Lady Jane. Additional reports of the bird were made in Okeechobee County, Florida, until the late 1920s, but these are not supported by specimens. It was not until 1939, however, that the American Ornithologists' Union declared that the Carolina parakeet had become extinct. The IUCN has listed the species as extinct since 1920.\nIn 1937, three parakeets resembling this species were sighted and filmed in the Okefenokee Swamp of Georgia. However, the American Ornithologists' Union analyzed the film and concluded that they had probably filmed feral parakeets. A year later, in 1938, a flock of parakeets was apparently sighted by a group of experienced ornithologists in the swamps of the Santee River basin in South Carolina. However, this sighting was doubted by most other ornithologists. The birds were never seen again after this sighting, and shortly after a portion of the area was destroyed to make way for power lines, making the species' continued existence unlikely.\nAbout 720 skins and 16 skeletons are housed in museums around the world and analyzable DNA has been extracted from them.\nReasons for extinction.\nThe evidence is indicative that humans had at least a contributory role in the extinction of the Carolina parakeet, through a variety of means. Chief was deforestation in the 18th and 19th centuries. Hunting played a significant role, both for decorative use of their colorful feathers, for example, adornment of women's hats, and for reduction of crop predation. This was partially offset by the recognition of their value in controlling invasive cockleburs. Minor roles were played by capture for the pet trade and, as noted in \"Pacific Standard\", by the introduction for crop pollination of European honeybees that competed for nest sites.\nA factor that exacerbated their decline to extinction was the flocking behavior that led them to return to the vicinity of dead and dying birds (e.g., birds downed by hunting), enabling wholesale slaughter.\nThe final extinction of the species in the early years of the 20th century is somewhat of a mystery, as it happened so rapidly. Vigorous flocks with many juveniles and reproducing pairs were noted as late as 1896, and the birds were long-lived in captivity, but they had virtually disappeared by 1904. Sufficient nest sites remained intact, so deforestation was not the final cause. American ornithologist Noel F. Snyder speculates that the most likely cause seems to be that the birds succumbed to poultry disease, although no recent or historical records exist of New World parrot populations being afflicted by domestic poultry diseases. The modern poultry scourge Newcastle disease was not detected until 1926 in Indonesia, and only a subacute form of it was reported in the United States in 1938. As well, genetic research on samples did not show any significant presence of bird viruses (though this does not solely rule out disease).\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6324", "revid": "2147637", "url": "https://en.wikipedia.org/wiki?curid=6324", "title": "Collective trauma", "text": "Traumatic psychological effect shared by a group of people\nThe term collective trauma calls attention to the \"psychological reactions to a traumatic event that affect[s] an entire society.\" Collective trauma does not only represent a historical fact or event, but is a collective memory of an awful event that happened to that group of people.\nDefinition.\nAmerican sociologist Kai Erikson was one of the first to document collective trauma in his book \"Everything in Its Path\", which documented the aftermath of a catastrophic flood in 1972.\nGilad Hirschberger of Interdisciplinary Center, Herzliya, Israel, defines the term:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The term \"collective trauma\" refers to the psychological reactions to a traumatic event that affect an entire society; it does not merely reflect an historical fact, the recollection of a terrible event that happened to a group of people. It suggests that the tragedy is represented in the collective memory of the group, and like all forms of memory it comprises not only a reproduction of the events, but also an ongoing reconstruction of the trauma in an attempt to make sense of it.\nClarifying the term collective, Ursula K\u00f6nig (2018) focused on two different levels of collective trauma:\nAccording to these two distinctions, a collective trauma can only be defined as such if affects can be clearly defined at either level. For example, the traumatisation of many individuals may not be considered collective, unless their traumatic experiences are used as key identity markers in public discourses and/or as a way of self-expression/-definition. Once trauma of many individuals is framed and used as a collective identity marker we can speak of it as such.\nFurthermore, a distinction can be made between collective identity markers which in practice are all highly interwoven:\nGlobal impacts.\nTraumatic events witnessed by an entire society can stir up collective sentiment, often resulting in a shift in that society's culture and mass actions.\nWell known collective traumas include: the Holocaust, the Armenian genocide, slavery in the United States, the Nanjing Massacre, the atomic bombings of Hiroshima and Nagasaki, the Trail of Tears, the Great Irish Famine, attack on Pearl Harbor, the MS Estonia in Sweden, the September 11, 2001 attacks in the United States, the Halabja chemical attack, the Palestinian Nakba, the COVID-19 pandemic, and various others.\nCollective traumas have been shown to play a key role in group identity formation (see: Law of Common Fate). During World War II, a US submarine, the USS \"Puffer\" (SS-268), came under several hours of depth charge attack by a Japanese surface vessel until the ship became convinced the submarine had somehow escaped. Psychological studies later showed that crewmen transferred to the submarine after the event were never accepted as part of the team. Later, US naval policy was changed so that after events of such psychological trauma, the crew would be dispersed to new assignments.\nRehabilitation of survivors becomes extremely difficult when an entire nation has experienced such severe traumas as war, genocide, torture, massacre, etc. Treatment is hardly effective when everybody is traumatized. Trauma remains chronic and would reproduce itself as long as social causes are not addressed and perpetrators continue to enjoy impunity. The whole society may suffer from an everlasting culture of pain. However, ways to heal collective trauma have recently been created (see section on Healing Collective Trauma below).\nDuring the Algerian War, Frantz Omar Fanon found his practice of treatment of native Algerians ineffective due to the continuation of the horror of a colonial war. He emphasized about the social origin of traumas, joined the liberation movement and urged oppressed people to purge themselves of their degrading traumas through their collective liberation struggle. He made the following remarks in his letter of resignation, as the Head of the Psychiatry Department at the Blida-Joinville Hospital in Algeria:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"If psychiatry is the medical technique that aims to enable man no longer to be a stranger to his environment, I owe it to myself to affirm that the Arab, permanently an alien in his own country, lives in a state of absolute depersonalization\". Inculcation of horror and anxiety, through widespread torture, massacre, genocide and similar coercive measures has happened frequently in human history. There are plenty of examples in our modern history. Tyrants have always used their technique of \"psychological artillery\" in an attempt to cause havoc and confusion in the minds of people and hypnotize them with intimidation and cynicism. The result is a collective trauma that will pass through generations. There is no magic formula of rehabilitation. Collective trauma can be alleviated through cohesive and collective efforts such as recognition, remembrance, solidarity, communal therapy and massive cooperation.\nMultiple international scientific studies have shown how the emotional states of a mother has a direct impact on the developing nervous system of their child and the ensuing development of their brain systems over time.\nA study conducted in the aftermath of the Six day war in Israel in 1967 for example, found that women who were pregnant during the wars occurrence were statistically more likely to have had children with schizophrenia. What happened at the collective level of the country, was directly reflected in the individual neurobiological systems of the infants in the womb. Due to the direct correlation/connection between the nervous system and every other organ in our bodies, collective trauma is also evident at the cellular level. Trauma can thus not be understood in purely individual terms.\nCollective trauma does not merely reflect a historical fact or the recollection of a traumatic event that happened to a group of people. Collective trauma suggests that the tragedy is represented in the collective memory of the group, and like all forms of memory it comprises not only a reproduction of the events, but also an ongoing reconstruction of the trauma in an attempt to make sense of it. Collective memory of a trauma is different from individual memory because collective memory persists beyond the lives of the direct survivors of the events, and is remembered by group members that may be far removed from the traumatic events in time and space.\nLinks to mental health.\nReliving traumatic experiences as a collective can lead to a vast range on mental health problems, including Post Traumatic Stress Disorder (PTSD), depression, and disassociation. With collective traumas including events like natural disasters and even historical traumas like The Holocaust, the psychological impact of these vary based on direct and indirect experience. These traumas can result in psychological conditions to prevail, for example we see how PTSD and Alexithymia was developed by survivors of the earthquakes in L'Aquila, Italy. PTSD symptoms can include re-experiencing your traumatic event, avoidance, and emotional numbing such as alexithymia, and many more emotional and physical symptoms . These symptoms and the condition of PTSD are not limited to the victims themselves, but generations after traumatic events as well, usually up to two generations, which can be attributed to a combination of epigenetics and collective cultural trauma (see these sections below). The mental health conditions due to collective trauma are not limited to PTSD, with studies showing higher levels of low self esteem in the children of holocaust survivors and higher levels of anxiety and depression in those who have experienced a collective historical trauma, like the Native Americans. Therefore, experiencing a collective trauma directly or indirectly can result in many mental health conditions for the collective.\nNeurological effects.\nWhen collective trauma is experienced, there are neurological and neurophysiological impacts on the victims and those affected. With most collective trauma accompanied by PTSD, there are two responses that victims are most likely to adopt: reexperiencing and/or hyperarousal and dissociation. These play a part in dictating what neural pathways the brain will form. PTSD and collective trauma have an impact on limbic function, and impact parts of the brain, like the right amygdala, hippocampus, parahippocampal, and temporopolar areas, where survivors of collective trauma experience a lower intensity, which has impact on mood in a negative way. As studies from the L'Aquila earthquake survivors show, the lower intensity of limbic regions in the survivors represents a defensive approach when tasked with emotional involvement, suggesting coping strategies in the form of distancing and disassociation, and a dysfunctional emotional regulating system.\nEpigenetics.\nEpigenetics is the influence your environment and behaviours have on how your genes work, and with more studies exploring how the epigenome is changed: collective trauma can also be considered. The epigenome is shaped by both genetic variation and environmental experiences, and we see how survivors of collective trauma can alter their epigenome. Exposure to trauma and stressors can alter gene regulation and expression leading to altered patterns of biology and health. Studies show that both mental and physical health outcomes suffer due to epigenetic reasons because of collective trauma. Studies show that through intrauterine signalling, the experience of negative maternal mood or stress during pregnancy can manifest in alterations in epigenetic patterns of offspring, with potential long-term effects on health outcomes, which can continue for generations to come Further links of parental care and breastfeeding composition also indicate to changes in genetic makeup in offspring, for example if the mother experiences higher levels of the stress hormone cortisol, this will be experienced also by the offspring either in utero or through breastfeeding.\nCollective cultural trauma.\nCultural trauma is a form of collective trauma that is seen on a societal and macro-level. With collective trauma being experienced communally- psychological, and mental health consequences of cultural trauma can be explored from individual and community-level perspectives, factoring in family dynamics and geopolitical factors that can amplify the trauma experienced. The Holocaust provides an example of how survivors and their children experienced impaired functioning and poor adjustment to their environments. Studies around refugees and immigrants also indicate how cultural trauma as a collective has vast negative mental health affects and how that is transmitted throughout communities and then generations through epigenetic transmission, but also through parental care that is dictated by family dynamics set by communities. An example of this can be witnessed through Sri Lanka, where a war and tsunami caused collective trauma to be experienced. On multiple levels, Sri Lankans who were affected by the war and tsunami saw changed in the dynamics of family relations, a lack of trust between community members and child rearing changed as well. These changed the cultural norms in Sri Lankan society, and created a negative environment where communities tended to be more dependent, passive, silent, without leadership, mistrustful, and suspicious. As a collectivist culture, this shared trauma changed the dynamic of communities in a significant way, and changed the cultural identities of many Sri Lankans. This highlights how collective trauma has an impact on cultural identity on a large scale \nInfluence of technology on collective trauma.\nTechnology provides many opportunities and potential for creative connection and collaboration, such as for example through commons based peer production, see for example commons-based peer production - Wikipedia itself is an example for this.\nHowever, there is also ways in which technology and its use nowadays creates a large amount of collective trauma enhancing content. The fast pace of information flow can overwhelm the human cognition- and nervous system. Author Thomas H\u00fcbl explains that humans can create, develop and evolve only if their nervous system integrates and digests well the data and information to be transformed. However, the current speed and complexity of data spread and consumed through technological infrastructure can create an enormous pressure onto the human nervous system. If a nervous system is overwhelmed, it is unable to integrate information, and it creates increased levels of anxiety, hyperactivity, stress, disembodiment and hence disconnection from the self. These are symptoms of trauma.\nFor example, the high speed level of violence-charged global news sent around through socio-technological infrastructures can cause a nervous system to be overwhelmed. Hence, the inability of receiving (historical or current) collective trauma content at a fast pace recreates collective trauma.\nHealing collective trauma.\nThe above-mentioned author and international group facilitator Thomas H\u00fcbl worked out and finalized a facilitated group process to address, integrate and heal collective trauma. In 2016, he co-founded the international non-profit, the Pocket Project, to train facilitators - and offer direct support - to integrate and heal collective trauma in regions throughout the world. H\u00fcbl bases this work on recent scientific insights, working with what he refers to as the Collective Trauma Integration Process (CTIP). The aim of this process goes wider than merely addressing the well-being of individuals with collective trauma: the process is based on the premise that healing collective trauma, collectives (communities, societies, nations) can more effectively transform and prevent further systemic disruptions which are rooted in originating traumas (wars, various forms of oppression, etc.). This process requires a refined reflection process, usually done in groups, to safely explore historic ancestral and transgenerational trauma.\nThe application of CTIP has shown that when given the right space, hence when a coherent and safe space is created by the facilitator and the group, trauma emerges and can be digested and integrated together in a supportive and skilled facilitation environment. Thomas H\u00fcbl himself has led many of these processes and has this way helped healing collective traumata especially related to World War II and The Holocaust, and worked with groups from more than 40 countries. Furthermore, he highlights the importance of mediation practice and presence for the integration process:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn the Stanford Social Innovation Review, authors Ijeoma Njaka &amp; Duncan Peacock examine trauma in the context of social change, arguing that trauma inhibits and limits our sustained attention to the complex crises we currently face. They write:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Writer and founder of the Academy of Inner Science Thomas H\u00fcbl suggests that one of the most important connections for healing collective and intergenerational trauma is between science and spirit, which he argues brings together the \"double helix of ancient wisdom and contemporary understanding.\" Humans experience well-being when we have agency, dignity, and health, and are connected to ourselves, each other, and our world in sustainable and life-giving ways. Trauma is the disconnection from these things. Those working on social change, therefore, need to identify the connections and disconnections in the issues they care about. They also need support when they experience disconnection in their own lives.\nGlobal social witnessing.\n\"Global Social Witnessing\" is a term that was elaborated by Thomas H\u00fcbl and William Ury in 2017 as a practice of \"contemplative social cognition\". Following their understanding of collective trauma as being at the roots of most conflicts \u2013 although generally in an unrecognised and unconscious way \u2013, they defined Global Social Witnessing as a process of insight in which one has the ability to gain a precise and comprehensive picture of what is happening, which \u2013 they say \u2013 is required to make adequate peace-building and healing possible.\nAn article in \"Tricycle\" magazine covered the 2017-18 Pocket Project training on collective trauma, including an explanation of global social witnessing:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The idea is that we have unprecedented access to information about tragedies occurring around the world, but rather than become more informed, we allow the data to overwhelm us. We experience compassion fatigue, end up feeling numb or depressed, and retreat into indifference. The danger is not only inaction. By turning away from the world's traumas, GSW proponents argue, we also perpetuate, albeit unconsciously, painful cultural shadows that underlie global trauma. Collective and historical trauma, they believe, lies at the heart of many of the atrocities and conflicts in the world today. Global social witnessing practice groups create and experiment with a kind of \"relational space,\" in which participants can cultivate a greater depth of understanding about their own responses to traumatic experiences of other communities.Thomas H\u00fcbl explains the related concept of conscious experience as the ability of a person or a system to have awareness of one's own current life process. Regarding this, Global Social Witnessing deals with the collective subject's awareness of its own process. \nOn the individual level, it is the ability of compassion that enables a human to depict the inner life of another being in him. This feeling of compassion is the pre-requisite for truly healing and the potential for promoting action. It also applies on a collective level when one acquires an understanding of the processes happening in society within his/her self. This is one's transformation into an adult and integrated citizen of a community (nation, culture, etc.). Relating appropriately to the events and processes of the culture is what enables one to come to an appropriate, creative action or response. \nIn this sense, witnessing a traumatic event is also about getting out of a disconnected-unrelated position that is simply pointing out the most obvious culprits, and instead actually acquiring a larger understanding of it as phenomenon of society. Global Social Witnessing can therefore be a point of breakage to the vicious circle of indifference and inadequate responses that follow collective traumatic events, and which, unhealed, continually cause more trauma.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6325", "revid": "45808397", "url": "https://en.wikipedia.org/wiki?curid=6325", "title": "Church (building)", "text": "Building used for Christian religious activities\nA church, church building, or church house is a building used for Christian worship services and other Christian religious activities. The earliest identified Christian church is a house church founded between 233 and 256. From the 11th through the 14th centuries, there was a wave of church construction in Western Europe.\nSometimes, the word \"church\" is used by analogy and simplicity for the buildings of other religions, such as mosques and synagogues. \"Church\" is also used to describe a body or an assembly of Christian believers, while \"the Church\" may be used to refer to the worldwide Christian religious community as a whole.\nIn traditional Christian architecture, the plan view of a church often forms a Christian cross with the center aisle and seating representing the vertical beam and the bema and altar forming the horizontal. Towers or domes may inspire contemplation of the heavens. Modern churches have a variety of architectural styles and layouts. Some buildings designed for other purposes have been converted to churches, while many original church buildings have been put to other uses.\nEtymology.\nThe word \"church\" is derived from Old English , \"place of assemblage set aside for Christian worship\", from the Proto-Germanic \"kirika\". This was probably borrowed via the Gothic from the Greek , , \"the Lord's (house)\", from , \"ruler, lord\". in turn comes from the Proto-Indo-European language root \"*keue\" meaning \"to swell\".\nThe Greek , \"of the Lord\", was used of houses of Christian worship since c.\u2009300 AD, especially in the East, although it was less common in this sense than or .\nHistory.\nAntiquity.\nThe earliest archeologically identified Christian church is a house church (\"domus ecclesiae\"), the Dura-Europos church, founded between 233 and 256.\nIn the second half of the 3rd century AD, the first purpose-built halls for Christian worship (\"aula ecclesiae\") began to be constructed. Although many of these were destroyed early in the next century during the Diocletianic Persecution. Even larger and more elaborate churches began to appear during the reign of Emperor Constantine the Great.\nMedieval times.\nFrom the 11th through the 14th centuries, a wave of cathedral-building and construction of smaller parish churches occurred across Western Europe. Besides serving as a place of worship, the cathedral or parish church was frequently employed as a general gathering-place by the communities in which they were located, hosting such events as guild meetings, banquets, mystery plays, and fairs. Church grounds and buildings were also used for the threshing and storage of grain.\nRomanesque architecture.\nBetween 1000 and 1200, the Romanesque style became popular across Europe. The Romanesque style is defined by large and bulky edifices typically composed of simple, compact, sparsely decorated geometric structures. Frequent features of the Romanesque church include circular arches, round or octagonal towers, and cushion capitals on pillars. In the early romanesque era, coffering on the ceiling was fashionable, while later in the same era, groined vault gained popularity. Interiors widened, and the motifs of sculptures took on more epic traits and themes.\nGothic architecture.\nThe Gothic style emerged around 1140 in \u00cele-de-France and subsequently spread throughout Europe. Gothic churches lost the compact qualities of the Romanesque era, and decorations often contained symbolic and allegorical features. The first pointed arches, rib vaults, and buttresses began to appear, all possessing geometric properties that reduced the need for large, rigid walls to ensure structural stability. This also permitted the size of windows to increase, producing brighter and lighter interiors. Nave ceilings rose, and pillars and steeples heightened. Many architects used these developments to push the limits of structural possibility, an inclination that resulted in the collapse of several towers possessing designs that had unwittingly exceeded the boundaries of soundness. In Germany, the Netherlands, and Spain, it became popular to build hall churches, a style in which every vault would be built to the same height.\nGothic cathedrals were lavishly designed, as in the romanesque era, and many share romanesque traits. However, several also exhibit unprecedented degrees of detail and complexity in decoration. The Notre-Dame de Paris and Notre-Dame de Reims in France, as well as the San Francesco d\u2019Assisi in Palermo, and the Salisbury Cathedral and Wool Church in England and Santhome Church in Chennai, India shows the elaborate stylings characteristic of Gothic cathedrals.\nSome of the most well-known gothic churches remained unfinished for centuries, after the gothic style fell out of popularity. One such example is the construction of the Cologne Cathedral, which began in 1248, halted in 1473, and not resumed until 1842.\nRenaissance.\nIn the 15th and 16th centuries, the change in ethics and society due to the Renaissance and the Reformation also influenced the building of churches. The common style was much like the gothic style but simplified. The basilica was not the most popular type of church anymore, but instead, hall churches were built. Typical features are columns and classical capitals.\nIn Protestant churches, where the proclamation of God's Word is of particular importance, the visitor's line of view is directed towards the pulpit.\nBaroque architecture.\nThe Baroque style was first used in Italy around 1575. From there, it spread to the rest of Europe and the European colonies. The building industry increased heavily during the baroque era. Buildings, even churches, were used to indicate wealth, authority, and influence. The use of forms known from the Renaissance was extremely exaggerated. Domes and capitals were decorated with moulding and the former stucco sculptures were replaced by fresco paintings on the ceilings. For the first time, churches were seen as one connected work of art, and consistent artistic concepts were developed. Instead of long buildings, more central-plan buildings were created. The sprawling decoration with floral ornamentation and mythological motives raised until about 1720 to the Rococo era.\nThe Protestant parishes preferred lateral churches, in which all the visitors could be as close as possible to the pulpit and the altar.\nArchitecture.\nA common architecture for churches is the shape of a cross (a long central rectangle, with side rectangles and a rectangle in front for the altar space or sanctuary). These churches also often have a dome or other large vaulted space in the interior to represent or draw attention to the heavens. Other common shapes for churches include a circle, to represent eternity, or an octagon or similar star shape, to represent the church's bringing light to the world. Another common feature is the spire, a tall tower on the \"west\" end of the church or over the crossing.\nAnother common feature of many Christian churches is the eastwards orientation of the front altar. \nOften, the altar will not be oriented due east but toward the sunrise. This tradition originated in Byzantium in the 4th century and became prevalent in the West in the 8th to 9th century. \nThe old Roman custom of having the altar at the west end and the entrance at the east was sometimes followed as late as the 11th century, even in areas of northern Europe under Frankish rule, as seen in Petershausen (Constance), Bamberg Cathedral, Augsburg Cathedral, Regensburg Cathedral, and Hildesheim Cathedral.\nTypes.\nBasilica.\nThe Latin word \"basilica\" was initially used to describe a Roman public building usually located in the forum of a Roman town. After the Roman Empire became officially Christian, the term came by extension to refer to a large and influential church that has been given special ceremonial rights by the Pope. The word thus retains two senses today, one architectural and the other ecclesiastical.\nCathedral.\nA cathedral is a church, usually Catholic, Anglican, Oriental Orthodox or Eastern Orthodox, housing the seat of a bishop. The word cathedral takes its name from \"cathedra\", or Bishop's Throne (In ). The term is sometimes (improperly) used to refer to any church of great size.\nA church with a cathedral function is not necessarily a large building. It might be as small as Christ Church Cathedral in Oxford, England, Porvoo Cathedral in Porvoo, Finland, Sacred Heart Cathedral in Raleigh, United States, or Chur Cathedral in Switzerland. However, frequently, the cathedral, along with some of the abbey churches, was the largest building in any region.\nPilgrimage church.\nA pilgrimage church is a church to which pilgrimages are regularly made, or a church along a pilgrimage route, often located at the tomb of a saints, or holding icons or relics to which miraculous properties are ascribed, the site of Marian apparitions, etc.\nConventual church.\nA conventual church (or monastery church, minster, \"katholikon\") is the main church in a Christian monastery or abbey.\nProprietary church.\nDuring the Middle Ages, a proprietary church was a church, abbey, or cloister built on the private grounds of a feudal lord, over which he retained proprietary interests.\nCollegiate church.\nA collegiate church is a church where the daily office of worship is maintained by a college of canons, which may be presided over by a dean or provost.\nCollegiate churches were often supported by extensive lands held by the church, or by tithe income from appropriated benefices. They commonly provide distinct spaces for congregational worship and for the choir offices of their clerical community.\nEvangelical church structures.\nThe architecture of evangelical places of worship is mainly characterized by its sobriety. The Latin cross is a well known Christian symbol that can usually be seen on the building of an evangelical church and that identifies the place's belonging. Some services take place in theaters, schools or multipurpose rooms, rented for Sunday only. There is usually a baptistery at the front of the church (in what is known as the chancel in historic traditions) or in a separate room for baptisms by immersion.\nWorship services take on impressive proportions in the megachurches (churches where more than 2,000 people gather every Sunday). In some of these megachurches, more than 10,000 people gather every Sunday. The term gigachurch is sometimes used. For example, Lakewood Church (United States) or Yoido Full Gospel Church (South Korea).\nHouse church.\nIn some countries of the world which apply sharia or communism, government authorizations for worship are complex for Christians. Because of persecution of Christians, Evangelical house churches have thus developed. For example, there is the Evangelical house churches in China movement. The meetings thus take place in private houses, in secret and in \"illegality\".\nAlternative buildings.\nOld and disused church buildings can be seen as an interesting proposition for developers as the architecture and location often provide for attractive homes or city centre entertainment venues. On the other hand, many newer churches have decided to host meetings in public buildings such as schools, universities, cinemas or theatres.\nThere is another trend to convert old buildings for worship rather than face the construction costs and planning difficulties of a new build. Unusual venues in the UK include a former tram power station, a former bus garage, a former cinema and bingo hall, a former Territorial Army drill hall, and a former synagogue. served as a floating church for mariners at Liverpool from 1827 until she sank in 1872. A windmill has also been converted into a church at Reigate Heath.\nThere have been increased partnerships between church management and private real estate companies to redevelop church properties into mixed uses. While it has garnered criticism, the partnership allows congregations to increase revenue while preserving the property.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6326", "revid": "8372814", "url": "https://en.wikipedia.org/wiki?curid=6326", "title": "Childe's Tomb", "text": "Granite cross on Dartmoor, Devon, England\nChilde's Tomb is a granite cross on Dartmoor, Devon, England. Although not in its original form, it is more elaborate than most of the crosses on Dartmoor, being raised upon a constructed base, and it is known that a kistvaen is underneath.\nA well-known legend attached to the site, first recorded in 1630 by Tristram Risdon, concerns a wealthy hunter, Childe, who became lost in a snow storm and supposedly died there despite disembowelling his horse and climbing into its body for protection. The legend relates that Childe left a note of some sort saying that whoever found and buried his body would inherit his lands at Plymstock. After a race between the monks of Tavistock Abbey and the men of Plymstock, the Abbey won.\nThe tomb was virtually destroyed in 1812 by a man who stole most of the stones to build a house nearby, but it was partly reconstructed in 1890.\nDescription.\nChilde's Tomb is a reconstructed granite cross on the south-east edge of Foxtor Mires, about 500 metres north of Fox Tor on Dartmoor, Devon, England at grid reference . According to William Burt, in his notes to \"Dartmoor, a Descriptive Poem\" by N. T. Carrington (1826), the original tomb consisted of a pedestal of three steps, the lowest of which was built of four stones each six feet long and twelve inches square. The two upper steps were made of eight shorter but similarly shaped stones, and on top was an octagonal block about three feet high with a cross fixed upon it.\nThe tomb lies on the line of several cairns that marked the east-west route of the ancient Monks' Path between Buckfast Abbey and Tavistock Abbey and it was no doubt erected here as part of that route: it would have been particularly useful in this part of the moor with few landmarks where a traveller straying from the path could easily end up in Foxtor Mires. Tristram Risdon, writing in about 1630, said that Childe's Tomb was one of three remarkable things in the Forest of Dartmoor (the others being Crockern Tor and Wistman's Wood). Risdon also stated that the original tomb bore an inscription: \"They fyrste that fyndes and bringes mee to my grave, The priorie of Plimstoke they shall have\", but no sign of this has ever been found.\nToday the cross, which is a replacement, is about tall and across at the crosspiece, and it has its base in a socket stone which rests on a pedestal of granite blocks that raises the total height of the cross to . The original, now broken, socket stone for the cross lies nearby. The whole is surrounded by a circle of granite stones set on their edge which once surrounded the cairn\u2014the rocks of which are now scattered around\u2014that was originally built over a large kistvaen that still exists beneath the pedestal.\nDestruction.\nIn the early 19th century there was much interest in enclosing and \"improving\" the open moorland on Dartmoor, encouraged by Sir Thomas Tyrwhitt's early successes at Tor Royal near Princetown. Enclosure was aided by the greatly enhanced access provided by the construction of the first turnpike roads over the moor: the road between Ashburton and Two Bridges opened in around 1800, for instance. In February 1809 one Thomas Windeatt, from Bridgetown, Totnes, took over the lease of a plot of land (a \"newtake\") of about 582 acres in the valley of the River Swincombe. In 1812 Windeatt started to build a farmhouse, Fox Tor Farm, on his land and his workmen robbed the nearby Childe's Tomb of most of its stones for the building and its doorsteps.\nIn 1902 William Crossing wrote that he had been told by an old moorman that some of the granite blocks from the tomb's pedestal had also been used to make a clapper bridge across a stream flowing into the River Swincombe near the farm. The moorman also said that they had lettering on their undersides. This encouraged Crossing to arrange to lift the clapper bridge, but no inscription was found. However, he did locate nine out of the twelve stones that had made up the pedestal, as well as the broken socket stone for the cross.\nReconstruction.\nCrossing rediscovered the original site of the tomb in 1882 and said that all that remained was a small mound and some half buried stones. He cleared out the kistvaen, reporting that it was long by wide and that unlike most kistvaens found on the moor, the stones lining it had apparently been shaped by man, which led him to suggest that it was less old than most. Having located most of the stones of the original tomb, Crossing thought that it could be rebuilt in its original form with little effort, but it was not to be.\nJ. Brooking Rowe, writing in 1895, states that the tomb was re-erected in 1890 under the direction of Mr. E. Fearnley Tanner, who said that he was dissatisfied with the result because several stones were missing and it was difficult to recreate the original character of the monument. Tanner was the honourable secretary of the Dartmoor Preservation Association, and this reconstruction was one of the first acts of that organisation. The replacement base and cross were made in Holne in 1885.\nChilde the Hunter.\nAccording to legend, the cross was erected over the kistvaen ('chest-stone' i.e. burial chamber) of Childe the Hunter, who was Ordulf, son of Ordgar, an Anglo-Saxon Earl of Devon in the 11th century. The name \"Childe\" is probably derived from the Old English word \"cild\" which was used as a title of honour.\nLegend has it that Childe was in a party hunting on the moor when they were caught in some changeable weather. Childe became separated from the main party and was lost. In order to save himself from dying of exposure, he killed his horse, disembowelled it and crept inside the warm carcass for shelter. He nevertheless froze to death, but before he died, he wrote a note to the effect that whoever should find him and bury him in their church should inherit his Plymstock estate.\nHis body was found by the monks of Tavistock Abbey, who started to carry it back. However, they heard of a plot to ambush them by the people of Plymstock, at a bridge over the River Tavy. They took a detour and built a new bridge over the river, just outside Tavistock. They were successful in burying the body in the grounds of the Abbey and inherited the Plymstock estate.\nThe first account of this story is to be found in Risdon's \"Survey of Devon\" which was completed in around 1632:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nFinberg pointed out, however, that a document of 1651 refers to Tavistock's guildhall as \"Guilehall\", so \"Guilebridge\" is more likely to be \"guild bridge\", probably because it was built or maintained by one of the town guilds.\nIn popular culture.\nDevon folk singer Seth Lakeman sang about Childe the Hunter on his 2006 album \"Freedom Fields\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "6328", "revid": "1159845368", "url": "https://en.wikipedia.org/wiki?curid=6328", "title": "Cognate", "text": "Words inherited by different languages\nIn historical linguistics, cognates or lexical cognates are sets of words in different languages that have been inherited in direct descent from an etymological ancestor in a common parent language. Because language change can have radical effects on both the sound and the meaning of a word, cognates may not be obvious, and often it takes rigorous study of historical sources and the application of the comparative method to establish whether lexemes are cognate. Cognates are distinguished from loanwords, where a word has been borrowed from another language.\nThe term \"cognate\" derives from the Latin noun \"cognatus\" 'blood relative'.\nCharacteristics.\nCognates need not have the same meaning, which may have changed as the languages developed independently. For example English \"starve\" and Dutch \"sterven\" 'to die' or German \"sterben\" 'to die' all descend from the same Proto-Germanic verb, \"*sterban\u0105\" 'to die'.\nCognates also do not need to look or sound similar: English \"father\", French \"p\u00e8re\", and Armenian \u0570\u0561\u0575\u0580 (\"hayr\") all descend directly from Proto-Indo-European \"*ph\u2082t\u1e17r\". An extreme case is Armenian \u0565\u0580\u056f\u0578\u0582 (\"erku\") and English \"two\", which descend from Proto-Indo-European \"*dw\u00f3h\u2081\"; the sound change \"*dw\" &gt; \"erk\" in Armenian is regular.\nAn example of cognates from the same Indo-European root are: \"night\" (English), \"nicht\" (Scots), \"Nacht\" (German), \"nacht\" (Dutch, Frisian), \"nag\" (Afrikaans), \"Naach\" (Colognian), \"natt\" (Swedish, Norwegian), \"nat\" (Danish), \"n\u00e1tt\" (Faroese), \"n\u00f3tt\" (Icelandic), \"noc\" (Czech, Slovak, Polish), \u043d\u043e\u0447\u044c, \"noch\" (Russian), \u043d\u043e\u045c, \"no\u0107\" (Macedonian), \u043d\u043e\u0449, \"nosht\" (Bulgarian), \"nos\" (Welsh/Cymraeg),\"\u043d\u0456\u0447\", \"nich\" (Ukrainian), \"\u043d\u043e\u0447\", \"noch\"/\"no\u010d\" (Belarusian), \"no\u010d\" (Slovene), \"no\u0107\" (Serbo-Croatian), \"nakts\" (Latvian), \"naktis\" (Lithuanian), \u03bd\u03cd\u03be, \"nyx\" (Ancient Greek), \"\u03bd\u03cd\u03c7\u03c4\u03b1\" / \"nychta\" (Modern Greek), \"nakt-\" (Sanskrit), \"nat\u00eb\" (Albanian), \"nox\", gen. sg. \"noctis\" (Latin), \"nuit\" (French), \"noche\" (Spanish), \"nueche\" (Asturian), \"noite\" (Portuguese and Galician), \"notte\" (Italian), \"nit\" (Catalan), \"nuet/nit/nueit\" (Aragonese), \"nu\u00e8ch\" / \"nu\u00e8it\" (Occitan) and \"noapte\" (Romanian). These all mean 'night' and derive from the Proto-Indo-European *n\u00f3k\u02b7ts 'night'. The Indo-European languages have hundreds of such cognate sets, though few of them are as neat as this.\nThe Arabic \"sal\u0101m\", the Hebrew &lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05e9\u05dc\u05d5\u05dd\u200e \"shalom\", the Assyrian Neo-Aramaic \"shlama\" and the Amharic \"selam\" 'peace' are cognates, derived from the Proto-Semitic *\u0161al\u0101m- 'peace'.\nFalse cognates.\nFalse cognates are pairs of words that appear to have a common origin, but which in fact do not. For example, Latin and German both mean 'to have' and are phonetically similar. However, the words evolved from different Proto-Indo-European (PIE) roots: , like English \"have\", comes from PIE \"*kh\u2082py\u00e9-\" 'to grasp', and has the Latin cognate \"capere\" 'to seize, grasp, capture'. , on the other hand, is from PIE \"*g\u02b0ab\u02b0\" 'to give, to receive', and hence cognate with English \"give\" and German .\nLikewise, English \"much\" and Spanish look similar and have a similar meaning, but are not cognates: \"much\" is from Proto-Germanic \"*mikilaz\" &lt; PIE \"*me\u01f5-\" and is from Latin \"multum\" &lt; PIE \"*mel-\". A true cognate of \"much\" is the archaic Spanish 'big'.\nDistinctions.\nCognates are distinguished from other kinds of relationships.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6329", "revid": "1750837", "url": "https://en.wikipedia.org/wiki?curid=6329", "title": "Chromatography", "text": "Set of physico-chemical techniques for separation of mixtures\nIn chemical analysis, chromatography is a laboratory technique for the separation of a mixture into its components. The mixture is dissolved in a fluid solvent (gas or liquid) called the \"mobile phase\", which carries it through a system (a column, a capillary tube, a plate, or a sheet) on which a material called the \"stationary phase\" is fixed. Because the different constituents of the mixture tend to have different affinities for the stationary phase and are retained for different lengths of time depending on their interactions with its surface sites, the constituents travel at different apparent velocities in the mobile fluid, causing them to separate. The separation is based on the differential partitioning between the mobile and the stationary phases. Subtle differences in a compound's partition coefficient result in differential retention on the stationary phase and thus affect the separation.\nChromatography may be \"preparative\" or \"analytical\". The purpose of preparative chromatography is to separate the components of a mixture for later use, and is thus a form of purification. This process is associated with higher costs due to its mode of production. Analytical chromatography is done normally with smaller amounts of material and is for establishing the presence or measuring the relative proportions of analytes in a mixture. The two types are not mutually exclusive.\nEtymology and pronunciation.\nChromatography, pronounced , is derived from Greek \u03c7\u03c1\u1ff6\u03bc\u03b1 \"chroma\", which means \"color\", and \u03b3\u03c1\u03ac\u03c6\u03b5\u03b9\u03bd \"graphein\", which means \"to write\". The combination of these two terms was directly inherited from the invention of the technique first used to separate pigments.\nHistory.\nChromatography was first devised at the University of Kazan by the Italian-born Russian scientist Mikhail Tsvet in 1900. He developed the technique and coined the term \"chromatography\" in the first decade of the 20th century, primarily for the separation of plant pigments such as chlorophyll, carotenes, and xanthophylls. Since these components separate in bands of different colors (green, orange, and yellow, respectively) they directly inspired the name of the technique. New types of chromatography developed during the 1930s and 1940s made the technique useful for many separation processes.\nChromatography technique developed substantially as a result of the work of Archer John Porter Martin and Richard Laurence Millington Synge during the 1940s and 1950s, for which they won the 1952 Nobel Prize in Chemistry. They established the principles and basic techniques of partition chromatography, and their work encouraged the rapid development of several chromatographic methods: paper chromatography, gas chromatography, and what would become known as high-performance liquid chromatography. Since then, the technology has advanced rapidly. Researchers found that the main principles of Tsvet's chromatography could be applied in many different ways, resulting in the different varieties of chromatography described below. Advances are continually improving the technical performance of chromatography, allowing the separation of increasingly similar molecules.\nChromatography terms.\nChromatography is based on the concept of partition coefficient. Any solute partitions between two immiscible solvents. When we make one solvent immobile (by adsorption on a solid support matrix) and another mobile it results in most common applications of chromatography. If the matrix support, or stationary phase, is polar (e.g. paper, silica etc.) it is forward phase chromatography, and if it is non-polar (C-18) it is reverse phase.\nTechniques by chromatographic bed shape.\nColumn chromatography.\nColumn chromatography is a separation technique in which the stationary bed is within a tube. The particles of the solid stationary phase or the support coated with a liquid stationary phase may fill the whole inside volume of the tube (packed column) or be concentrated on or along the inside tube wall leaving an open, unrestricted path for the mobile phase in the middle part of the tube (open tubular column). Differences in rates of movement through the medium are calculated to different retention times of the sample.\nIn 1978, W. Clark Still introduced a modified version of column chromatography called \"flash column chromatography\" (flash). The technique is very similar to the traditional column chromatography, except that the solvent is driven through the column by applying positive pressure. This allowed most separations to be performed in less than 20 minutes, with improved separations compared to the old method. Modern flash chromatography systems are sold as pre-packed plastic cartridges, and the solvent is pumped through the cartridge. Systems may also be linked with detectors and fraction collectors providing automation. The introduction of gradient pumps resulted in quicker separations and less solvent usage.\nIn expanded bed adsorption, a fluidized bed is used, rather than a solid phase made by a packed bed. This allows omission of initial clearing steps such as centrifugation and filtration, for culture broths or slurries of broken cells.\nPhosphocellulose chromatography utilizes the binding affinity of many DNA-binding proteins for phosphocellulose. The stronger a protein's interaction with DNA, the higher the salt concentration needed to elute that protein.\nPlanar chromatography.\n\"Planar chromatography\" is a separation technique in which the stationary phase is present as or on a plane. The plane can be a paper, serving as such or impregnated by a substance as the stationary bed (paper chromatography) or a layer of solid particles spread on a support such as a glass plate (thin-layer chromatography). Different compounds in the sample mixture travel different distances according to how strongly they interact with the stationary phase as compared to the mobile phase. The specific Retention factor (Rf) of each chemical can be used to aid in the identification of an unknown substance.\nPaper chromatography.\nPaper chromatography is a technique that involves placing a small dot or line of sample solution onto a strip of \"chromatography paper\". The paper is placed in a container with a shallow layer of solvent and sealed. As the solvent rises through the paper, it meets the sample mixture, which starts to travel up the paper with the solvent. This paper is made of cellulose, a polar substance, and the compounds within the mixture travel further if they are less polar. More polar substances bond with the cellulose paper more quickly, and therefore do not travel as far\nThin-layer chromatography (TLC).\nThin-layer chromatography (TLC) is a widely employed laboratory technique used to separate different biochemicals on the basis of their relative attractions to the stationary and mobile phases. It is similar to paper chromatography. However, instead of using a stationary phase of paper, it involves a stationary phase of a thin layer of adsorbent like silica gel, alumina, or cellulose on a flat, inert substrate. TLC is very versatile; multiple samples can be separated simultaneously on the same layer, making it very useful for screening applications such as testing drug levels and water purity. Possibility of cross-contamination is low since each separation is performed on a new layer. Compared to paper, it has the advantage of faster runs, better separations, better quantitative analysis, and the choice between different adsorbents. For even better resolution and faster separation that utilizes less solvent, high-performance TLC can be used. An older popular use had been to differentiate chromosomes by observing distance in gel (separation of was a separate step).\nDisplacement chromatography.\nThe basic principle of displacement chromatography is:\nA molecule with a high affinity for the chromatography matrix (the displacer) competes effectively for binding sites, and thus displaces all molecules with lesser affinities.\nThere are distinct differences between displacement and elution chromatography. In elution mode, substances typically emerge from a column in narrow, Gaussian peaks. Wide separation of peaks, preferably to baseline, is desired for maximum purification. The speed at which any component of a mixture travels down the column in elution mode depends on many factors. But for two substances to travel at different speeds, and thereby be resolved, there must be substantial differences in some interaction between the biomolecules and the chromatography matrix. Operating parameters are adjusted to maximize the effect of this difference. In many cases, baseline separation of the peaks can be achieved only with gradient elution and low column loadings. Thus, two drawbacks to elution mode chromatography, especially at the preparative scale, are operational complexity, due to gradient solvent pumping, and low throughput, due to low column loadings. Displacement chromatography has advantages over elution chromatography in that components are resolved into consecutive zones of pure substances rather than \"peaks\". Because the process takes advantage of the nonlinearity of the isotherms, a larger column feed can be separated on a given column with the purified components recovered at significantly higher concentrations.\nTechniques by physical state of mobile phase.\nGas chromatography.\nGas chromatography (GC), also sometimes known as gas-liquid chromatography, (GLC), is a separation technique in which the mobile phase is a gas. Gas chromatographic separation is always carried out in a column, which is typically \"packed\" or \"capillary\". Packed columns are the routine work horses of gas chromatography, being cheaper and easier to use and often giving adequate performance. Capillary columns generally give far superior resolution and although more expensive are becoming widely used, especially for complex mixtures. Further, capillary columns can be split into three classes: porous layer open tubular (PLOT), wall-coated open tubular (WCOT) and support-coated open tubular (SCOT) columns. PLOT columns are unique in a way that the stationary phase is adsorbed to the column walls, while WCOT columns have a stationary phase that is chemically bonded to the walls. SCOT columns are in a way the combination of the two types mentioned in a way that they have support particles adhered to column walls, but those particles have liquid phase chemically bonded onto them. Both types of column are made from non-adsorbent and chemically inert materials. Stainless steel and glass are the usual materials for packed columns and quartz or fused silica for capillary columns.\nGas chromatography is based on a partition equilibrium of analyte between a solid or viscous liquid stationary phase (often a liquid silicone-based material) and a mobile gas (most often helium). The stationary phase is adhered to the inside of a small-diameter (commonly 0.53 \u2013 0.18mm inside diameter) glass or fused-silica tube (a capillary column) or a solid matrix inside a larger metal tube (a packed column). It is widely used in analytical chemistry; though the high temperatures used in GC make it unsuitable for high molecular weight biopolymers or proteins (heat denatures them), frequently encountered in biochemistry, it is well suited for use in the petrochemical, environmental monitoring and remediation, and industrial chemical fields. It is also used extensively in chemistry research.\nLiquid chromatography.\nLiquid chromatography (LC) is a separation technique in which the mobile phase is a liquid. It can be carried out either in a column or a plane. Present day liquid chromatography that generally utilizes very small packing particles and a relatively high pressure is referred to as high-performance liquid chromatography.\nIn HPLC the sample is forced by a liquid at high pressure (the mobile phase) through a column that is packed with a stationary phase composed of irregularly or spherically shaped particles, a porous monolithic layer, or a porous membrane. Monoliths are \"sponge-like chromatographic media\" and are made up of an unending block of organic or inorganic parts. HPLC is historically divided into two different sub-classes based on the polarity of the mobile and stationary phases. Methods in which the stationary phase is more polar than the mobile phase (e.g., toluene as the mobile phase, silica as the stationary phase) are termed normal phase liquid chromatography (NPLC) and the opposite (e.g., water-methanol mixture as the mobile phase and C18 (octadecylsilyl) as the stationary phase) is termed reversed phase liquid chromatography (RPLC).\nSpecific techniques under this broad heading are listed below.\nAffinity chromatography.\nAffinity chromatography is based on selective non-covalent interaction between an analyte and specific molecules. It is very specific, but not very robust. It is often used in biochemistry in the purification of proteins bound to tags. These fusion proteins are labeled with compounds such as His-tags, biotin or antigens, which bind to the stationary phase specifically. After purification, these tags are usually removed and the pure protein is obtained.\nAffinity chromatography often utilizes a biomolecule's affinity for a metal (Zn, Cu, Fe, etc.). Columns are often manually prepared and could be designed specifically for the proteins of interest. Traditional affinity columns are used as a preparative step to flush out unwanted biomolecules, or as a primary step in analyzing a protein with unknown physical properties.\nHowever, liquid chromatography techniques exist that do utilize affinity chromatography properties. Immobilized metal affinity chromatography (IMAC) is useful to separate the aforementioned molecules based on the relative affinity for the metal. Often these columns can be loaded with different metals to create a column with a targeted affinity. \nSupercritical fluid chromatography.\nSupercritical fluid chromatography is a separation technique in which the mobile phase is a fluid above and relatively close to its critical temperature and pressure.\nTechniques by separation mechanism.\nIon exchange chromatography.\nIon exchange chromatography (usually referred to as ion chromatography) uses an ion exchange mechanism to separate analytes based on their respective charges. It is usually performed in columns but can also be useful in planar mode. Ion exchange chromatography uses a charged stationary phase to separate charged compounds including anions, cations, amino acids, peptides, and proteins. In conventional methods the stationary phase is an ion-exchange resin that carries charged functional groups that interact with oppositely charged groups of the compound to retain. There are two types of ion exchange chromatography: Cation-Exchange and Anion-Exchange. In the Cation-Exchange Chromatography the stationary phase has negative charge and the exchangeable ion is a cation, whereas, in the Anion-Exchange Chromatography the stationary phase has positive charge and the exchangeable ion is an anion. Ion exchange chromatography is commonly used to purify proteins using FPLC.\nSize-exclusion chromatography.\nSize-exclusion chromatography (SEC) is also known as \"gel permeation chromatography\" (GPC) or \"gel filtration chromatography\" and separates molecules according to their size (or more accurately according to their hydrodynamic diameter or hydrodynamic volume).\nSmaller molecules are able to enter the pores of the media and, therefore, molecules are trapped and removed from the flow of the mobile phase. The average residence time in the pores depends upon the effective size of the analyte molecules. However, molecules that are larger than the average pore size of the packing are excluded and thus suffer essentially no retention; such species are the first to be eluted. It is generally a low-resolution chromatography technique and thus it is often reserved for the final, \"polishing\" step of a purification. It is also useful for determining the tertiary structure and quaternary structure of purified proteins, especially since it can be carried out under native solution conditions.\nExpanded bed adsorption chromatographic separation.\nAn expanded bed chromatographic adsorption (EBA) column for a biochemical separation process comprises a pressure equalization liquid distributor having a self-cleaning function below a porous blocking sieve plate at the bottom of the expanded bed, an upper part nozzle assembly having a backflush cleaning function at the top of the expanded bed, a better distribution of the feedstock liquor added into the expanded bed ensuring that the fluid passed through the expanded bed layer displays a state of piston flow. The expanded bed layer displays a state of piston flow. The expanded bed chromatographic separation column has advantages of increasing the separation efficiency of the expanded bed.\nExpanded-bed adsorption (EBA) chromatography is a convenient and effective technique for the capture of proteins directly from unclarified crude sample. In EBA chromatography, the settled bed is first expanded by upward flow of equilibration buffer. The crude feed, a mixture of soluble proteins, contaminants, cells, and cell debris, is then passed upward through the expanded bed. Target proteins are captured on the adsorbent, while particulates and contaminants pass through. A change to elution buffer while maintaining upward flow results in desorption of the target protein in expanded-bed mode. Alternatively, if the flow is reversed, the adsorbed particles will quickly settle and the proteins can be desorbed by an elution buffer. The mode used for elution (expanded-bed versus settled-bed) depends on the characteristics of the feed. After elution, the adsorbent is cleaned with a predefined cleaning-in-place (CIP) solution, with cleaning followed by either column regeneration (for further use) or storage.\nSpecial techniques.\nReversed-phase chromatography.\nReversed-phase chromatography (RPC) is any liquid chromatography procedure in which the mobile phase is significantly more polar than the stationary phase. It is so named because in normal-phase liquid chromatography, the mobile phase is significantly less polar than the stationary phase. Hydrophobic molecules in the mobile phase tend to adsorb to the relatively hydrophobic stationary phase. Hydrophilic molecules in the mobile phase will tend to elute first. Separating columns typically comprise a C8 or C18 carbon-chain bonded to a silica particle substrate.\nHydrophobic interaction chromatography.\nHydrophobic Interaction Chromatography (HIC) is a purification and analytical technique that separates analytes, such as proteins, based on hydrophobic interactions between that analyte and the chromatographic matrix. It can provide a non-denaturing orthogonal approach to reversed phase separation, preserving native structures and potentially protein activity. In hydrophobic interaction chromatography, the matrix material is lightly substituted with hydrophobic groups. These groups can range from methyl, ethyl, propyl, butyl, octyl, or phenyl groups. At high salt concentrations, non-polar sidechains on the surface on proteins \"interact\" with the hydrophobic groups; that is, both types of groups are excluded by the polar solvent (hydrophobic effects are augmented by increased ionic strength). Thus, the sample is applied to the column in a buffer which is highly polar, which drives an association of hydrophobic patches on the analyte with the stationary phase. The eluent is typically an aqueous buffer with decreasing salt concentrations, increasing concentrations of detergent (which disrupts hydrophobic interactions), or changes in pH. Of critical importance is the type of salt used, with more kosmotropic salts as defined by the Hofmeister series providing the most water structuring around the molecule and resulting hydrophobic pressure. Ammonium sulfate is frequently used for this purpose. The addition of organic solvents or other less polar constituents may assist in improving resolution. \nIn general, Hydrophobic Interaction Chromatography (HIC) is advantageous if the sample is sensitive to pH change or harsh solvents typically used in other types of chromatography but not high salt concentrations. Commonly, it is the amount of salt in the buffer which is varied. In 2012, M\u00fcller and Franzreb described the effects of temperature on HIC using Bovine Serum Albumin (BSA) with four different types of hydrophobic resin. The study altered temperature as to effect the binding affinity of BSA onto the matrix. It was concluded that cycling temperature from 50 to 10 degrees would not be adequate to effectively wash all BSA from the matrix but could be very effective if the column would only be used a few times. Using temperature to effect change allows labs to cut costs on buying salt and saves money.\nIf high salt concentrations along with temperature fluctuations want to be avoided you can use a more hydrophobic to compete with your sample to elute it. [source] This so-called salt independent method of HIC showed a direct isolation of Human Immunoglobulin G (IgG) from serum with satisfactory yield and used Beta-cyclodextrin as a competitor to displace IgG from the matrix. This largely opens up the possibility of using HIC with samples which are salt sensitive as we know high salt concentrations precipitate proteins.\nHydrodynamic chromatography.\nHydrodynamic chromatography (HDC) is derived from the observed phenomenon that large droplets move faster than small ones. In a column, this happens because the center of mass of larger droplets is prevented from being as close to the sides of the column as smaller droplets because of their larger overall size. Larger droplets will elute first from the middle of the column while smaller droplets stick to the sides of the column and elute last. This form of chromatography is useful for separating analytes by molar mass, size, shape, and structure when used in conjunction with light scattering detectors, viscometers, and refractometers. The two main types of HDC are open tube and packed column. Open tube offers rapid separation times for small particles, whereas packed column HDC can increase resolution and is better suited for particles with an average molecular mass larger than formula_1 daltons. HDC differs from other types of chromatography because the separation only takes place in the interstitial volume, which is the volume surrounding and in between particles in a packed column.\nHDC shares the same order of elution as Size Exclusion Chromatography (SEC) but the two processes still vary in many ways. In a study comparing the two types of separation, Isenberg, Brewer, C\u00f4t\u00e9, and Striegel use both methods for polysaccharide characterization and conclude that HDC coupled with multiangle light scattering (MALS) achieves more accurate molar mass distribution when compared to off-line MALS than SEC in significantly less time. This is largely due to SEC being a more destructive technique because of the pores in the column degrading the analyte during separation, which tends to impact the mass distribution. However, the main disadvantage of HDC is low resolution of analyte peaks, which makes SEC a more viable option when used with chemicals that are not easily degradable and where rapid elution is not important.\nHDC plays an especially important role in the field of microfluidics. The first successful apparatus for HDC-on-a-chip system was proposed by Chmela, et al. in 2002. Their design was able to achieve separations using an 80\u00a0mm long channel on the timescale of 3 minutes for particles with diameters ranging from 26 to 110\u00a0nm, but the authors expressed a need to improve the retention and dispersion parameters. In a 2010 publication by Jellema, Markesteijn, Westerweel, and Verpoorte, implementing HDC with a recirculating bidirectional flow resulted in high resolution, size based separation with only a 3\u00a0mm long channel. Having such a short channel and high resolution was viewed as especially impressive considering that previous studies used channels that were 80\u00a0mm in length. For a biological application, in 2007, Huh, et al. proposed a microfluidic sorting device based on HDC and gravity, which was useful for preventing potentially dangerous particles with diameter larger than 6 microns from entering the bloodstream when injecting contrast agents in ultrasounds. This study also made advances for environmental sustainability in microfluidics due to the lack of outside electronics driving the flow, which came as an advantage of using a gravity based device.\nTwo-dimensional chromatography.\nIn some cases, the selectivity provided by the use of one column can be insufficient to provide resolution of analytes in complex samples. Two-dimensional chromatography aims to increase the resolution of these peaks by using a second column with different physico-chemical (chemical classification) properties. Since the mechanism of retention on this new solid support is different from the first dimensional separation, it can be possible to separate compounds by two-dimensional chromatography that are indistinguishable by one-dimensional chromatography. Furthermore, the separation on the second dimension occurs faster than the first dimension. An example of a two-dimensional TLC separation is where the sample is spotted at one corner of a square plate, developed, air-dried, then rotated by 90\u00b0 and usually redeveloped in a second solvent system. Two-dimensional chromatography can be applied to GC or LC separations. This separation method can also be used in a heart-cutting approach, where specific regions of interest on the first dimension are selected for separation by the second dimension, or in a comprehensive approach, where all the analytes from the first dimension undergo the second dimension separation.\nSimulated moving-bed chromatography.\nThe simulated moving bed (SMB) technique is a variant of high performance liquid chromatography; it is used to separate particles and/or chemical compounds that would be difficult or impossible to resolve otherwise. This increased separation is brought about by a valve-and-column arrangement that is used to lengthen the stationary phase indefinitely.\nIn the moving bed technique of preparative chromatography the feed entry and the analyte recovery are simultaneous and continuous, but because of practical difficulties with a continuously moving bed, simulated moving bed technique was proposed. In the simulated moving bed technique instead of moving the bed, the sample inlet and the analyte exit positions are moved continuously, giving the impression of a moving bed.\nTrue moving bed chromatography (TMBC) is only a theoretical concept. Its simulation, SMBC is achieved by the use of a multiplicity of columns in series and a complex valve arrangement, which provides for sample and solvent feed, and also analyte and waste takeoff at appropriate locations of any column, whereby it allows switching at regular intervals the sample entry in one direction, the solvent entry in the opposite direction, whilst changing the analyte and waste takeoff positions appropriately as well.\nPyrolysis gas chromatography.\nPyrolysis\u2013gas chromatography\u2013mass spectrometry is a method of chemical analysis in which the sample is heated to decomposition to produce smaller molecules that are separated by gas chromatography and detected using mass spectrometry.\nPyrolysis is the thermal decomposition of materials in an inert atmosphere or a vacuum. The sample is put into direct contact with a platinum wire, or placed in a quartz sample tube, and rapidly heated to 600\u20131000\u00a0\u00b0C. Depending on the application even higher temperatures are used. Three different heating techniques are used in actual pyrolyzers: Isothermal furnace, inductive heating (Curie Point filament), and resistive heating using platinum filaments. Large molecules cleave at their weakest points and produce smaller, more volatile fragments. These fragments can be separated by gas chromatography. Pyrolysis GC chromatograms are typically complex because a wide range of different decomposition products is formed. The data can either be used as fingerprints to prove material identity or the GC/MS data is used to identify individual fragments to obtain structural information. To increase the volatility of polar fragments, various methylating reagents can be added to a sample before pyrolysis.\nBesides the usage of dedicated pyrolyzers, pyrolysis GC of solid and liquid samples can be performed directly inside Programmable Temperature Vaporizer (PTV) injectors that provide quick heating (up to 30\u00a0\u00b0C/s) and high maximum temperatures of 600\u2013650\u00a0\u00b0C. This is sufficient for some pyrolysis applications. The main advantage is that no dedicated instrument has to be purchased and pyrolysis can be performed as part of routine GC analysis. In this case, quartz GC inlet liners have to be used. Quantitative data can be acquired, and good results of derivatization inside the PTV injector are published as well.\nFast protein liquid chromatography.\nFast protein liquid chromatography (FPLC), is a form of liquid chromatography that is often used to analyze or purify mixtures of proteins. As in other forms of chromatography, separation is possible because the different components of a mixture have different affinities for two materials, a moving fluid (the \"mobile phase\") and a porous solid (the stationary phase). In FPLC the mobile phase is an aqueous solution, or \"buffer\". The buffer flow rate is controlled by a positive-displacement pump and is normally kept constant, while the composition of the buffer can be varied by drawing fluids in different proportions from two or more external reservoirs. The stationary phase is a resin composed of beads, usually of cross-linked agarose, packed into a cylindrical glass or plastic column. FPLC resins are available in a wide range of bead sizes and surface ligands depending on the application.\nCountercurrent chromatography.\nCountercurrent chromatography (CCC) is a type of liquid-liquid chromatography, where both the stationary and mobile phases are liquids and the liquid stationary phase is held stagnant by a strong centrifugal force.\nHydrodynamic countercurrent chromatography (CCC).\nThe operating principle of CCC instrument requires a column consisting of an open tube coiled around a bobbin. The bobbin is rotated in a double-axis gyratory motion (a cardioid), which causes a variable gravity (G) field to act on the column during each rotation. This motion causes the column to see one partitioning step per revolution and components of the sample separate in the column due to their partitioning coefficient between the two immiscible liquid phases used. There are many types of CCC available today. These include HSCCC (High Speed CCC) and HPCCC (High Performance CCC). HPCCC is the latest and best-performing version of the instrumentation available currently.\nCentrifugal partition chromatography (CPC).\nIn the CPC (centrifugal partition chromatography or hydrostatic countercurrent chromatography) instrument, the column consists of a series of cells interconnected by ducts attached to a rotor. This rotor rotates on its central axis creating the centrifugal field necessary to hold the stationary phase in place. The separation process in CPC is governed solely by the partitioning of solutes between the stationary and mobile phases, which mechanism can be easily described using the partition coefficients (\"KD\") of solutes. CPC instruments are commercially available for laboratory, pilot, and industrial-scale separations with different sizes of columns ranging from some 10 milliliters to 10 liters volume.\nPeriodic counter-current chromatography.\nIn contrast to Counter current chromatography (see above), periodic counter-current chromatography (PCC) uses a solid stationary phase and only a liquid mobile phase. It thus is much more similar to conventional affinity chromatography than to counter current chromatography. PCC uses multiple columns, which during the loading phase are connected in line. This mode allows for overloading the first column in this series without losing product, which already breaks through the column before the resin is fully saturated. The breakthrough product is captured on the subsequent column(s). In a next step the columns are disconnected from one another. The first column is washed and eluted, while the other column(s) are still being loaded. Once the (initially) first column is re-equilibrated, it is re-introduced to the loading stream, but as last column. The process then continues in a cyclic fashion.\nChiral chromatography.\nChiral chromatography involves the separation of stereoisomers. In the case of enantiomers, these have no chemical or physical differences apart from being three-dimensional mirror images. To enable chiral separations to take place, either the mobile phase or the stationary phase must themselves be made chiral, giving differing affinities between the analytes. Chiral chromatography HPLC columns (with a chiral stationary phase) in both normal and reversed phase are commercially available.\nConventional chromatography are incapable of separating racemic mixtures of enantiomers. However, in some cases \"nonracemic\" mixtures of enantiomers may be separated unexpectedly by conventional liquid chromatography (e. g. HPLC without chiral mobile phase or stationary phase ).\nAqueous normal-phase chromatography.\nAqueous normal-phase (ANP) chromatography is characterized by the elution behavior of classical normal phase mode (i.e. where the mobile phase is significantly less polar than the stationary phase) in which water is one of the mobile phase solvent system components. It is distinguished from hydrophilic interaction liquid chromatography (HILIC) in that the retention mechanism is due to adsorption rather than partitioning.\nApplications.\nChromatography is used in many fields including the pharmaceutical industry, the food and beverage industry, the chemical industry, forensic science, environment analysis, and hospitals.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6330", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=6330", "title": "Clement Martyn Doke", "text": "South African linguist\nClement Martyn Doke (16 May 1893 in Bristol, United Kingdom \u2013 24 February 1980 in East London, South Africa) was a South African linguist working mainly on African languages. Realizing that the grammatical structures of Bantu languages are quite different from those of European languages, he was one of the first African linguists of his time to abandon the Euro-centric approach to language description for a more locally grounded one. A most prolific writer, he published a string of grammars, several dictionaries, comparative work, and a history of Bantu linguistics.\nMissionary in Lambaland.\nThe Doke family had been engaged in missionary activity for the Baptist Church for some generations. His father Reverend Joseph J. Doke left England and travelled to South Africa in 1882, where he met and married Agnes Biggs. They returned to England, where Clement was born as the third of four children. The family moved to New Zealand and eventually returned to South Africa in 1903, where they later on settled in Johannesburg.\nAt the age of 18, Clement received a bachelor's degree from Transvaal University College in Pretoria (now the University of Pretoria). He decided to devote his life to missionary activity. In 1913, he accompanied his father on a tour of north-western Rhodesia, to an area called Lambaland, now known as Ilamba. It is situated at the watershed of the Congo and Zambesi rivers, part of the district lay in Northern Rhodesia and part in the Belgian Congo State. The Cape-Cairo Railway threaded through its eastern portion; otherwise, travelling mostly had to be done on foot.\nThe Reverend William Arthur Phillips of the Nyasa Industrial Mission in Blantyre had established a Baptist mission there in 1905, serving an area of and 50,000 souls. The Dokes were supposed to investigate, whether the mission in Lambaland could be taken over by the Baptist Union of South Africa. It was on this trip that Doke's father contracted enteric fever and died soon afterwards (Gandhi attended the memorial service and addressed the congregation). Clement assumed his father's role.\nThe South African Baptists decided to take over Kafulafuta Mission, while its founder Reverend Phillips remained as superintendent. Clement Doke returned to Kafulafuta as missionary in 1914, followed by his sister Olive two years later.\nThe Lamba language.\nAt first, Clement Doke was frustrated by his inability to communicate with the Lamba. The only written material available at the time was a translation of Jonah and a collection of 47 hymns. Soon he mastered the language and published his first book \"Ifintu Fyakwe Lesa\" (The Things of God, a Primer of Scripture Knowledge) in 1917. He enrolled in Johannesburg as the extension of Transvaal University College for an MA degree. His thesis was published as \"The Grammar of the Lamba language\". The book is couched in traditional grammatical terms as Doke had not yet established his innovative method of analysis and description for the Bantu languages. His later \"Textbook of Lamba Grammar\" is far superior in this respect.\nClement Doke was also interested in ethnology. In 1931 he compiled \"The Lambas of Northern Rhodesia\", which remains one of the outstanding ethnographic descriptions of the peoples of Central Africa. For Doke, literacy was part of the evangelisation since people had to be able to read to appreciate the message of the Bible, but it was only after his retirement that he completed the translation of the Bible into Lamba. It was published under the title of \"Amasiwi AwaLesa\" (The Words of God) in 1959.\nUniversity of the Witwatersrand.\nIn 1919 Doke married Hilda Lehmann, who accompanied him back to Lambaland. They both contracted malaria during their work and she was forbidden to return to Lambaland. Clement Doke also realised that his field work couldn't continue much longer and left in 1921. He was recruited by the newly founded University of the Witwatersrand. In order to secure a qualification as a lecturer, the family moved to England, where he registered at the School of Oriental and African Studies. His major languages were Lamba and Luba, but as no suitable examiner was available, he eventually had to change his language to Zulu.\nDoke took up his appointment in the new Department of Bantu Studies at the University of Witwatersrand in 1923. In 1925 he received his D. Litt. for his doctoral thesis \"The Phonetics of the Zulu Language\" and was promoted to Senior Lecturer. In 1931 he was appointed to the Chair of Bantu Studies and thus headed the Department of Bantu Studies. The Department acted as a catalyst for the admission of Africans to the university: as early as 1925 a limited number were admitted to the vacation course in African Studies. Doke supported the appointment of Benedict Wallet Vilakazi as member of the staff, as he believed a native speaker was essential for acquiring a language. This provoked a storm of criticism and controversy from the public. They both collaborated on the \"Zulu-English Dictionary\", first published in 1948. It is still one of the best examples of lexicography for any of the Bantu languages.\nAt the request of the government of Southern Rhodesia, Doke investigated the range of dialect diversity among the languages of the country and made recommendations for \"Unified Shona\". This formed the basis for Standard Shona. He devised a unified orthography based on the Zezuru, Karanga and Manyika dialects. However, Doke's orthography was never fully accepted and the South African government introduced an alternative, leaving Shona with two competing orthographies between 1935 and 1955.\nDuring his tenure Doke developed and promoted a method of linguistic analysis and description of the Bantu languages that was based upon the structure of these languages. The \"Dokean model\" continues to be one of the dominant models of linguistic description in Southern and Central Africa. His classification of the Bantu languages was for many years the dominant view of the interrelations among the African languages. He was also an early describer of Khoisan and Bantu click consonants, devising phonetic symbols for a number of them.\nDoke served the University of the Witwatersrand until his retirement in 1953. He was awarded the honorary degree of Doctor of Letters by Rhodes University and the honorary degree of Doctor of Laws by the University of the Witwatersrand in 1972.\nThe former missionary always remained devoted to the Baptist Church. He was elected President of the South African Baptist Union in 1949 and spent a year visiting churches and mission stations. He used his presidential address in condemning the recently established apartheid policy: \"I solemnly warn the Government that the spirit behind their apartheid legislation, and the way in which they are introducing discriminatory measures of all types today, will bring disaster upon this fair land of ours.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6331", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=6331", "title": "Carl Meinhof", "text": "German linguist (1857\u20131944)\nCarl Friedrich Michael Meinhof (23 July 1857 \u2013 11 February 1944) was a German linguist and one of the first linguists to study African languages.\nEarly years and career.\nMeinhof was born in Barzwitz near R\u00fcgenwalde in the Province of Pomerania. He studied at the University of T\u00fcbingen and at the University of Greifswald. In 1905 he became professor at the School of Oriental Studies in Berlin. On 5 May 1933 he became a member of the Nazi Party.\nWorks.\nHis most notable work was developing comparative grammar studies of the Bantu languages, building on the pioneering work of Wilhelm Bleek. In his work, Meinhof looked at the common Bantu languages such as Swahili and Zulu to determine similarities and differences.\nIn his work, Meinhof looked at noun classes with all Bantu languages having at least 10 classes and with 22 classes of nouns existing throughout the Bantu languages, though his definition of noun class differs slightly from the accepted one, considering the plural form of a word as belonging to a different class from the singular form (thus leading, for example, to consider a language like French as having four classes instead of two). While no language has all 22 (later: 23) classes active, Venda has 20, Lozi has 18, and Ganda has 16 or 17 (depending on whether the locative class 23 \"e-\" is included). All Bantu languages have a noun class specifically for humans (sometimes including other animate beings).\nMeinhof also examined other African languages, including groups classified at the time as Kordofanian, Bushman, Khoikhoi, and Hamitic.\nMeinhof developed a comprehensive classification scheme for African languages. His classification was the standard one for many years (Greenberg 1955:3). It was replaced by those of Joseph Greenberg in 1955 and in 1963.\nIn 1902, Meinhof made recordings of East African music. These are among the first recordings made of traditional African music.\nControversial views.\nIn 1912, Carl Meinhof published \"Die Sprachen der Hamiten\" (The Languages of the Hamites). He used the term Hamitic. Meinhof's system of classification of the Hamitic languages was based on a belief that \"speakers of Hamitic became largely coterminous with cattle herding peoples with essentially Caucasian origins, intrinsically different from and superior to the 'Negroes of Africa'.\" However, in the case of the so-called Nilo-Hamitic languages (a concept he introduced), it was based on the typological feature of gender and a \"fallacious theory of language mixture.\" Meinhof did this in spite of earlier work by scholars such as Lepsius and Johnston demonstrating that the languages which he would later dub \"Nilo-Hamitic\" were in fact Nilotic languages with numerous similarities in vocabulary with other Nilotic languages.\nFamily.\nCarl Meinhof was the great-uncle (the brother of the grandfather) of Ulrike Meinhof, a founding member of the German Red Army Faction (RAF), a left-wing militant group, which operated in West Germany in the 1970s and 1980s.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6335", "revid": "12943951", "url": "https://en.wikipedia.org/wiki?curid=6335", "title": "Cucurbitaceae", "text": "Family of plants\nThe Cucurbitaceae, also called cucurbits or the gourd family, are a plant family consisting of about 965 species in around 95 genera. Those most important to humans are the following:\nThe plants in this family are grown around the tropics and in temperate areas, where those with edible fruits were among the earliest cultivated plants in both the Old and New Worlds. The family Cucurbitaceae ranks among the highest of plant families for number and percentage of species used as human food. The name \"Cucurbitaceae\" comes to international scientific vocabulary from Neo-Latin, from \"Cucurbita\", the type genus, + \"-aceae\", a standardized suffix for plant family names in modern taxonomy. The genus name comes from the Classical Latin word \"\", meaning \"gourd\".\nDescription.\nMost of the plants in this family are annual vines, but some are woody lianas, thorny shrubs, or trees (\"Dendrosicyos\"). Many species have large, yellow or white flowers. The stems are hairy and pentangular. Tendrils are present at 90\u00b0 to the leaf petioles at nodes. Leaves are exstipulate, alternate, simple palmately lobed or palmately compound. The flowers are unisexual, with male and female flowers on different plants (dioecious) or on the same plant (monoecious). The female flowers have inferior ovaries. The fruit is often a kind of modified berry called a pepo.\nFossil history.\nOne of the oldest fossil cucurbits so far is \u2020\"Cucurbitaciphyllum lobatum\" from the Paleocene epoch, found at Shirley Canal, Montana. It was described for the first time in 1924 by the paleobotanist Frank Hall Knowlton. The fossil leaf is palmate, trilobed with rounded lobal sinuses and an entire or serrate margin. It has a leaf pattern similar to the members of the genera \"Kedrostis\", \"Melothria\" and \"Zehneria\".\nClassification.\nTribal classification.\nThe most recent classification of Cucurbitaceae delineates 15 tribes:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSystematics.\nModern molecular phylogenetics suggest the following relationships:\n \nPests and diseases.\nSweet potato whitefly is the vector of a number of cucurbit viruses that cause yellowing symptoms throughout the southern United States."}
{"id": "6336", "revid": "15748968", "url": "https://en.wikipedia.org/wiki?curid=6336", "title": "Chorded keyboard", "text": "Computer input device\nA keyset or chorded keyboard (also called a chorded keyset, \"chord keyboard\" or \"chording keyboard\") is a computer input device that allows the user to enter characters or commands formed by pressing several keys together, like playing a \"chord\" on a piano. The large number of combinations available from a small number of keys allows text or commands to be entered with one hand, leaving the other hand free. A secondary advantage is that it can be built into a device (such as a pocket-sized computer or a bicycle handlebar) that is too small to contain a normal-sized keyboard.\nA chorded keyboard minus the board, typically designed to be used while held in the hand, is called a keyer. Douglas Engelbart introduced the chorded keyset as a computer interface in 1968 at what is often called \"The Mother of All Demos\".\nPrinciples of operation.\nEach key is mapped to a number and then can be mapped to a corresponding letter or command. By pressing two or more keys together the user can generate many combinations. In Engelbart's original mapping, he used five keys: 1, 2, 4, 8, 16. The keys were mapped as follows: a = 1, b = 2, c = 3, d = 4, and so on. If the user pressed keys 1 and 2 simultaneously, and then released the keys, 1 and 2 would be added to 3, and since C is the 3rd letter of the alphabet, and the letter \"c\" appeared. Unlike pressing a chord on a piano, the chord is recognized only after all the keys or mouse buttons are released. Since Engelbart introduced the keyset, several different designs have been developed based on similar concepts.\nAs a crude example, each finger might control one key which corresponds to one bit in a byte, so that using seven keys and seven fingers, one could enter any character in the ASCII set\u2014if the user could remember the binary codes. Due to the small number of keys required, chording is easily adapted from a desktop to mobile environment.\nPractical devices generally use simpler chords for common characters (\"e.g.,\" Baudot), or may have ways to make it easier to remember the chords (\"e.g.,\" Microwriter), but the same principles apply. These portable devices first became popular with the wearable computer movement in the 1980s.\nThad Starner from Georgia Institute of Technology and others published numerous studies showing that two-handed chorded text entry was faster and yielded fewer errors than on a QWERTY keyboard. Currently stenotype machines hold the record for fastest word entry. Many stenotype users can reach 300 words per minute. However, stenographers typically train for three years before reaching professional levels of speed and accuracy.\nHistory.\nThe earliest known chord keyboard was part of the \"five-needle\" telegraph operator station, designed by Wheatstone and Cooke in 1836, in which any two of the five needles could point left or right to indicate letters on a grid. It was designed to be used by untrained operators (who would determine which keys to press by looking at the grid), and was not used where trained telegraph operators were available.\nThe first widespread use of a chord keyboard was in the stenotype machine used by court reporters, which was invented in 1868 and is still in use. The output of the stenotype was originally a phonetic code that had to be transcribed later (usually by the same operator who produced the original output), rather than arbitrary text\u2014automatic conversion software is now commonplace.\nIn 1874, the five-bit Baudot telegraph code and a matching 5-key chord keyboard was designed to be used with the operator forming the codes manually. The code is optimized for speed and low wear: chords were chosen so that the most common characters used the simplest chords. But telegraph operators were already using typewriters with QWERTY keyboards to \"copy\" received messages, and at the time it made more sense to build a typewriter that could generate the codes automatically, rather than making them learn to use a new input device.\nSome early keypunch machines used a keyboard with 12 labeled keys to punch the correct holes in paper cards. The numbers 0 through 9 were represented by one punch; 26 letters were represented by combinations of two punches, and symbols were represented by combinations of two or three punches.\nBraille (a writing system for the blind) uses either 6 or 8 tactile 'points' from which all letters and numbers are formed. When Louis Braille invented it, it was produced with a needle holing successively all needed points in a cardboard sheet. In 1892, Frank Haven Hall, superintendent of the Illinois Institute for the Education of the Blind, created the Hall Braille Writer, which was like a typewriter with 6 keys, one for each dot in a braille cell. The Perkins Brailler, first manufactured in 1951, uses a 6-key chord keyboard (plus a spacebar) to produce braille output, and has been very successful as a mass market affordable product. Braille, like Baudot, uses a number symbol and a shift symbol, which may be repeated for shift lock, to fit numbers and upper case into the 63 codes that 6 bits offer.\nAfter World War II, with the arrival of electronics for reading chords and looking in tables of \"codes\", the postal sorting offices started to research chordic solutions to be able to employ people other than trained and expensive typists. In 1954, an important concept was discovered: chordic production is easier to master when the production is done at the release of the keys instead of when they are pressed.\nResearchers at IBM investigated chord keyboards for both typewriters and computer data entry as early as 1959, with the idea that it might be faster than touch-typing if some chords were used to enter whole words or parts of words. A 1975 design by IBM Fellow Nat Rochester had 14 keys that were dimpled on the edges as well as the top, so one finger could press two adjacent keys for additional combinations. Their results were inconclusive, but research continued until at least 1978.\nDoug Engelbart began experimenting with keysets to use with the mouse in the mid 1960s. In a famous 1968 demonstration, Engelbart introduced a computer human interface that included the QWERTY keyboard, a three button mouse, and a five key keyset. Engelbart used the keyset with his left hand and the mouse with his right to type text and enter commands. The mouse buttons marked selections and confirmed or aborted commands.\nUsers in Engelbart's Augmentation Research Center at SRI became proficient with the mouse and keyset. In the 1970s the funding Engelbart's group received from the Advanced Research Projects Agency (ARPA) was cut and many key members of Engelbart's team went to work for Xerox PARC where they continued to experiment with the mouse and keyset. Keychord sets were used at Xerox PARC in the early 1980s, along with mice, GUIs, on the Xerox Star and Alto workstations. A one-button version of the mouse was incorporated into the Apple Macintosh but Steve Jobs decided against incorporating the chorded keyset.\nIn the early 1980s, Philips Research labs at Redhill, Surrey did a brief study into small, cheap keyboards for entering text on a telephone. One solution used a grid of hexagonal keys with symbols inscribed into dimples in the keys that were either in the center of a key, across the boundary of two keys, or at the joining of three keys. Pressing down on one of the dimples would cause either one, two or three of the hexagonal buttons to be depressed at the same time, forming a chord that would be unique to that symbol. With this arrangement, a nine button keyboard with three rows of three hexagonal buttons could be fitted onto a telephone and could produce up to 33 different symbols. By choosing widely separated keys, one could employ one dimple as a 'shift' key to allow both letters and numbers to be produced. With eleven keys in a 3/4/4 arrangement, 43 symbols could be arranged allowing for lowercase text, numbers and a modest number of punctuation symbols to be represented along with a 'shift' function for accessing uppercase letters. While this had the advantage of being usable by untrained users via 'hunt and peck' typing and requiring one less key switch than a conventional 12 button keypad, it had the disadvantage that some symbols required three times as much force to depress them as others which made it hard to achieve any speed with the device. That solution is still alive and proposed by Fastap and Unitap among others, and a commercial phone has been produced and promoted in Canada during 2006.\nStandards.\nHistorically, the baudot and braille keyboards were standardized to some extent, but they are unable to replicate the full character set of a modern keyboard. Braille comes closest, as it has been extended to eight bits.\nThe only proposed modern standard, GKOS (or Global Keyboard Open Standard) can support most characters and functions found on a computer keyboard but has had little commercial development. There is, however, a GKOS keyboard application available for iPhone since May 8, 2010, for Android since October 3, 2010 and for MeeGo Harmattan since October 27, 2011.\nStenography.\nStenotype machines (sometimes used by court reporters) use a chording keyboard to represent sounds: on the standard keyboard, the 'U' represents the sound (and word) 'you', and the three-key trigraph 'K' 'A' 'T' represents the sound and word 'cat'. The stenotype keyboard is explicitly ordered 'K', on the left, is the starting sound. 'S' and 'T', which are common starting sounds and also common ending sounds, are available on both sides of the keyboard: 'TAT' is 3-key chord, using both T keys. .\nOpen-source designs.\nFour open-source keyer/keyset designs are available: The pickey, a PS/2 device based on the PIC microcontroller; the spiffchorder, a USB device based on the Atmel AVR family of microcontrollers; the FeatherChorder, a BLE chorder based on the Adafruit Feather, an all-in-one board incorporating an Arduino-compatible microcontroller; and the GKOS keypad driver for Linux as well as the Gkos library for the Atmel/Arduino open-source board.\nPlover is a free, open-source, cross-platform program intended to bring real-time stenographic technology not just to stenographers, but also to hobbyists using anything from professional Stenotype machines to low-cost NKRO gaming keyboards. It is available for Linux, Windows, and macOS.\nJoy2chord is a chorded keyboard driver for Linux. With a configuration file, any joystick or gamepad can be turned into a chorded keyboard. This design philosophy was decided on to lower the cost of building devices, and in turn lower the entry barrier to becoming familiar with chorded keyboards. Macro keys, and multiple modes are also easily implemented with a user space driver.\nCommercial devices.\nOne minimal chordic keyboard example is Edgar Matias' Half-Qwerty keyboard described in patent &lt;templatestyles src=\"Citation/styles.css\"/&gt;\u00a0 circa 1992 that produces the letters of the missing half when the user simultaneously presses the space bar along with the mirror key. INTERCHI '93 published a study by Matias, MacKenzie and Buxton showing that people who have already learned to touch-type can quickly recover 50 to 70% of their two-handed typing speed. The loss contributes to the speed discussion above. It is implemented on two popular mobile phones, each provided with software disambiguation, which allows users to avoid using the space-bar.\n\"Multiambic\" keyers for use with wearable computers were invented in Canada in the 1970s. Multiambic keyers are similar to chording keyboards but without the board, in that the keys are grouped in a cluster for being handheld, rather than for sitting on a flat surface.\nChording keyboards are also used as portable but two handed input devices for the visually impaired (either combined with a refreshable braille display or vocal synthesis). Such keyboards use a minimum of seven keys, where each key corresponds to an individual braille point, except one key which is used as a spacebar. In some applications, the spacebar is used to produce additional chords which enable the user to issue editing commands, such as moving the cursor, or deleting words. Note that the number of points used in braille computing is not 6, but 8, as this allows the user, among other things, to distinguish between small and capital letters, as well as identify the position of the cursor. As a result, most newer chorded keyboards for braille input include at least nine keys.\nTouch screen chordic keyboards are available to smartphone users as an optional way of entering text. As the number of keys is low, the button areas can be made bigger and easier to hit on the small screen. The most common letters do not necessarily require chording as is the case with the GKOS keyboard optimised layouts (Android app) where the twelve most frequent characters only require single keys.\nThe company CharaChorder commerially sells chorded entry devices. Their first commercially available device is the CharaChorder One, which features a split design with each having access to 9 switches that can be moved in five directions (up, down, left, right, and pressed) in contrast to typical keyboards. This device allows for both chorded entry as well as traditional character entry. The set of words that can be chorded can be dynamically changed by the user in real time, but by default includes the 300 most common words in the english language. This chorded entry feature allows for potentially extremely fast typing speeds, so much so the founder of the company has been banned from online typing competitions. Additionally, they create the Charachorder Lite with a more traditional keyboard design. The manufacturer claimed that users of the Charachorder One can reach speeds of 300 words per minute, while users of the Charachorder Lite can reach 250 words per minute. \nHistorical.\nThe WriteHander, a 12-key chord keyboard from NewO Company, appeared in 1978 issues of ROM Magazine, an early microcomputer applications magazine.\nAnother early commercial model was the six-button Microwriter, designed by Cy Endfield and Chris Rainey, and first sold in 1980. Microwriting is the system of chord keying and is based on a set of mnemonics. It was designed only for right-handed use.\nIn 1982 the Octima 8 keys cord keyboard was presented by Ergoplic Kebords Ltd an Israeli Startup that was founded by Israeli researcher with intensive experience in Man Machine Interface design. The keyboard had 8 keys one for each finger and additional 3 keys that enabled the production of numbers, punctuations and control functions. The keyboard was fully compatible with the IBM PC and AT keyboards and had an Apple IIe version as well. Its key combinations were based on a mnemonic system that enabled fast and easy touch type learning. Within a few hours the user could achieve a typing speed similar to hand writing speed. The unique design also gave a relief from hand stress (Carpal Tunnel Syndrome) and allowed longer typing sessions than traditional keyboards. It was multi-lingual supporting English, German, French and Hebrew.\nThe BAT is a 7-key hand-sized device from Infogrip, and has been sold since 1985. It provides one key for each finger and three for the thumb. It is proposed for the hand which does not hold the mouse, in an exact continuation of Engelbart's vision.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6337", "revid": "16185737", "url": "https://en.wikipedia.org/wiki?curid=6337", "title": "Carolyn Beug", "text": "American filmmaker and producer (1952-2001)\nCarolyn Ann Mayer-Beug (December 11, 1952 \u2013 September 11, 2001) was a filmmaker and video producer from Santa Monica, California. She died in the September 11 attacks as a passenger of the American Airlines Flight 11.\nCareer.\nIn addition to her work as video producer, Beug also directed three music videos for country singer Dwight Yoakam: \"Ain't That Lonely Yet\", \"A Thousand Miles from Nowhere\" and \"Fast as You.\" Beug co-directed the former two videos with Yoakam and was the sole director of the latter video. She won an MTV Video Music award for the Van Halen music video of the song \"Right Now\", which she produced. She also served as senior vice president of Walt Disney Records.\nPersonal life.\nBeug lived in a Tudor-style home in the North 25th Street neighborhood. She hosted an annual backyard barbecue for the Santa Monica High School cross country and track team, which her daughters captained. Beug was a Latter-day Saint.\nDeath and legacy.\nBeug was killed at the age of 48 in the crash of American Airlines Flight 11 in the September 11, 2001 attacks. At the time of her death, Carolyn Beug was working on a children's book about Noah's Ark which was to be told from Noah's wife's point of view. On the plane with her was her mother, Mary Alice Wahlstrom. Beug was survived by her twin eighteen-year-old daughters Lauren and Lindsey Mayer-Beug, her 13-year-old son, Nick, and her husband, John Beug, a senior vice president in charge of filmed production for Warner Brothers' record division. She was returning home from taking her daughters to college at the Rhode Island School of Design.\nAt the National 9/11 Memorial, Beug is memorialized at the North Pool, on Panel N-1.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6339", "revid": "43051325", "url": "https://en.wikipedia.org/wiki?curid=6339", "title": "Cell biology", "text": "Branch of biology that studies cells\nCell biology (also cellular biology or cytology) is a branch of biology that studies the structure, function, and behavior of cells. All living organisms are made of cells. A cell is the basic unit of life that is responsible for the living and functioning of organisms. Cell biology is the study of the structural and functional units of cells. Cell biology encompasses both prokaryotic and eukaryotic cells and has many subtopics which may include the study of cell metabolism, cell communication, cell cycle, biochemistry, and cell composition. The study of cells is performed using several microscopy techniques, cell culture, and cell fractionation. These have allowed for and are currently being used for discoveries and research pertaining to how cells function, ultimately giving insight into understanding larger organisms. Knowing the components of cells and how cells work is fundamental to all biological sciences while also being essential for research in biomedical fields such as cancer, and other diseases. Research in cell biology is interconnected to other fields such as genetics, molecular genetics, molecular biology, medical microbiology, immunology, and cytochemistry.\nHistory.\nCells were first seen in 17th century Europe with the invention of the compound microscope. In 1665, Robert Hooke termed the building block of all living organisms as \"cells\" (published in \"Micrographia\") after looking at a piece of cork and observing a cell-like structure, however, the cells were dead and gave no indication to the actual overall components of a cell. A few years later, in 1674, Anton Van Leeuwenhoek was the first to analyze live cells in his examination of algae. All of this preceded the cell theory which states that all living things are made up of cells and that cells are the functional and structural unit of organisms. This was ultimately concluded by plant scientist Matthias Schleiden and animal scientist Theodor Schwann in 1838, who viewed live cells in plant and animal tissue, respectively. 19 years later, Rudolf Virchow further contributed to the cell theory, adding that all cells come from the division of pre-existing cells. Viruses are not considered in cell biology \u2013 they lack the characteristics of a living cell, and instead are studied in the microbiology subclass of virology.\nTechniques.\nCell biology research looks at different ways to culture and manipulate cells outside of a living body to further research in human anatomy and physiology, and to derive medications.The techniques by which cells are studied have evolved. Due to advancements in microscopy, techniques and technology have allowed scientists to hold a better understanding of the structure and function of cells. Many techniques commonly used to study cell biology are listed below:\nCell types.\nThere are two fundamental classifications of cells: prokaryotic and eukaryotic. Prokaryotic cells are distinguished from eukaryotic cells by the absence of a cell nucleus or other membrane-bound organelle. Prokaryotic cells are much smaller than eukaryotic cells, making them the smallest form of life. Prokaryotic cells include Bacteria and Archaea, and lack an enclosed cell nucleus. \u00a0Eukaryotic cells are found in plants, animals, fungi, and protists. They range from 10 to 100 \u03bcm in diameter, and their DNA is contained within a membrane-bound nucleus. Eukaryotes are organisms containing eukaryotic cells. The four eukaryotic kingdoms are Animalia, Plantae, Fungi, and Protista. \nThey both reproduce through binary fission. Bacteria, the most prominent type, have several different shapes, although most are spherical or rod-shaped. Bacteria can be classed as either gram-positive or gram-negative depending on the cell wall composition. Gram-positive bacteria have a thicker peptidoglycan layer than gram-negative bacteria. Bacterial structural features include a flagellum that helps the cell to move, ribosomes for the translation of RNA to protein, and a nucleoid that holds all the genetic material in a circular structure. There are many processes that occur in prokaryotic cells that allow them to survive. In prokaryotes, mRNA synthesis is initiated at a promoter sequence on the DNA template comprising two consensus sequences that recruit RNA polymerase. The prokaryotic polymerase consists of a core enzyme of four protein subunits and a \u03c3 protein that assists only with initiation. For instance, in a process termed conjugation, the fertility factor allows the bacteria to possess a pilus which allows it to transmit DNA to another bacteria which lacks the F factor, permitting the transmittance of resistance allowing it to survive in certain environments.\nStructure and function.\nStructure of eukaryotic cells.\nEukaryotic cells are composed of the following organelles:\nEukaryotic cells may also be composed of the following molecular components:\nCell metabolism.\nCell metabolism is necessary for the production of energy for the cell and therefore its survival and includes many pathways. For cellular respiration, once glucose is available, glycolysis occurs within the cytosol of the cell to produce pyruvate. Pyruvate undergoes decarboxylation using the multi-enzyme complex to form acetyl coA which can readily be used in the TCA cycle to produce NADH and FADH2. These products are involved in the electron transport chain to ultimately form a proton gradient across the inner mitochondrial membrane. This gradient can then drive the production of ATP and during oxidative phosphorylation. Metabolism in plant cells includes photosynthesis which is simply the exact opposite of respiration as it ultimately produces molecules of glucose.\nCell signaling.\nCell signaling or cell communication is important for cell regulation and for cells to process information from the environment and respond accordingly. Signaling can occur through direct cell contact or endocrine, paracrine, and autocrine signaling. Direct cell-cell contact is when a receptor on a cell binds a molecule that is attached to the membrane of another cell. Endocrine signaling occurs through molecules secreted into the bloodstream. Paracrine signaling uses molecules diffusing between two cells to communicate. Autocrine is a cell sending a signal to itself by secreting a molecule that binds to a receptor on its surface. Forms of communication can be through:\nGrowth and development.\nEukaryotic cell cycle.\nCells are the foundation of all organisms and are the fundamental units of life. The growth and development of cells are essential for the maintenance of the host and survival of the organism. For this process, the cell goes through the steps of the cell cycle and development which involves cell growth, DNA replication, cell division, regeneration, and cell death.\nThe cell cycle is divided into four distinct phases: G1, S, G2, and M. The G phase \u2013 which is the cell growth phase \u2013 makes up approximately 95% of the cycle. The proliferation of cells is instigated by progenitors. All cells start out in an identical form and can essentially become any type of cells. Cell signaling such as induction can influence nearby cells to determinate the type of cell it will become. Moreover, this allows cells of the same type to aggregate and form tissues, then organs, and ultimately systems. The G1, G2, and S phase (DNA replication, damage and repair) are considered to be the interphase portion of the cycle, while the M phase (mitosis) is the cell division portion of the cycle. Mitosis is composed of many stages which include, prophase, metaphase, anaphase, telophase, and cytokinesis, respectively. The ultimate result of mitosis is the formation of two identical daughter cells.\nThe cell cycle is regulated in cell cycle checkpoints, by a series of signaling factors and complexes such as cyclins, cyclin-dependent kinase, and p53. When the cell has completed its growth process and if it is found to be damaged or altered, it undergoes cell death, either by apoptosis or necrosis, to eliminate the threat it can cause to the organism's survival.\nCell mortality, cell lineage immortality.\nThe ancestry of each present day cell presumably traces back, in an unbroken lineage for over 3 billion years to the origin of life. It is not actually cells that are immortal but multi-generational cell lineages. The immortality of a cell lineage depends on the maintenance of cell division potential. This potential may be lost in any particular lineage because of cell damage, terminal differentiation as occurs in nerve cells, or programmed cell death (apoptosis) during development. Maintenance of cell division potential over successive generations depends on the avoidance and the accurate repair of cellular damage, particularly DNA damage. In sexual organisms, continuity of the germline depends on the effectiveness of processes for avoiding DNA damage and repairing those DNA damages that do occur. Sexual processes in eukaryotes, as well as in prokaryotes, provide an opportunity for effective repair of DNA damages in the germ line by homologous recombination.\nCell cycle phases.\nThe cell cycle is a four-stage process that a cell goes through as it develops and divides. It includes Gap 1 (G1), synthesis (S), Gap 2 (G2), and mitosis (M).The cell either restarts the cycle from G1 or leaves the cycle through G0 after completing the cycle. The cell can progress from G0 through terminal differentiation.\nThe interphase refers to the phases of the cell cycle that occur between one mitosis and the next, and includes G1, S, and G2.\nG1 phase.\nThe size of the cell grows.\nThe contents of cells are replicated.\nS phase.\nReplication of DNA\nThe cell replicates each of the 46 chromosomes (23 pairs).\nG2 phase.\nThe cell multiplies.\nIn preparation for cell division, organelles and proteins form.\nM phase.\nAfter mitosis, cytokinesis occurs (cell separation)\nFormation of two daughter cells that are identical\nG0 phase.\nThese cells leave G1 and enter G0, a resting stage. A cell in G0 is doing its job without actively preparing to divide.\nPathology.\nThe scientific branch that studies and diagnoses diseases on the cellular level is called cytopathology. Cytopathology is generally used on samples of free cells or tissue fragments, in contrast to the pathology branch of histopathology, which studies whole tissues. Cytopathology is commonly used to investigate diseases involving a wide range of body sites, often to aid in the diagnosis of cancer but also in the diagnosis of some infectious diseases and other inflammatory conditions. For example, a common application of cytopathology is the Pap smear, a screening test used to detect cervical cancer, and precancerous cervical lesions that may lead to cervical cancer.\nCell cycle checkpoints and DNA damage repair system.\nThe cell cycle is composed of a number of well-ordered, consecutive stages that result in cellular division. The fact that cells do not begin the next stage until the last one is finished, is a significant element of cell cycle regulation. Cell cycle checkpoints are characteristics that constitute an excellent monitoring strategy for accurate cell cycle and divisions. Cdks, associated cyclin counterparts, protein kinases, and phosphatases regulate cell growth and division from one stage to another. The cell cycle is controlled by the temporal activation of Cdks, which is governed by cyclin partner interaction, phosphorylation by particular protein kinases, and de-phosphorylation by Cdc25 family phosphatases. In response to DNA damage, a cell's DNA repair reaction is a cascade of signaling pathways that leads to checkpoint engagement, regulates, the repairing mechanism in DNA, cell cycle alterations, and apoptosis. Numerous biochemical structures, as well as processes that detect damage in DNA, are ATM and ATR, which induce the DNA repair checkpoints\nThe cell cycle is a sequence of activities in which cell organelles are duplicated and subsequently separated into daughter cells with precision. There are major events that happen during a cell cycle. The processes that happen in the cell cycle include cell development, replication and segregation of chromosomes.\u00a0 The cell cycle checkpoints are surveillance systems that keep track of the cell cycle's integrity, accuracy, and chronology. Each checkpoint serves as an alternative cell cycle endpoint, wherein the cell's parameters are examined and only when desirable characteristics are fulfilled does the cell cycle advance through the distinct steps. The cell cycle's goal is to precisely copy each organism's DNA and afterwards equally split the cell and its components between the two new cells. Four main stages occur in the eukaryotes. In G1, the cell is usually active and continues to grow rapidly, while in G2, the cell growth continues while protein molecules become ready for separation. These are not dormant times; they are when cells gain mass, integrate growth factor receptors, establish a replicated genome, and prepare for chromosome segregation. DNA replication is restricted to a separate Synthesis in eukaryotes, which is also known as the S-phase. During mitosis, which is also known as the M-phase, the segregation of the chromosomes occur. DNA, like every other molecule, is capable of undergoing a wide range of chemical reactions. Modifications in DNA's sequence, on the other hand, have a considerably bigger impact than modifications in other cellular constituents like RNAs or proteins because DNA acts as a permanent copy of the cell genome. When erroneous nucleotides are incorporated during DNA replication, mutations can occur. The majority of DNA damage is fixed by removing the defective bases and then re-synthesizing the excised area. On the other hand, some DNA lesions can be mended by reversing the damage, which may be a more effective method of coping with common types of DNA damage. Only a few forms of DNA damage are mended in this fashion, including pyrimidine dimers caused by ultraviolet (UV) light changed by the insertion of methyl or ethyl groups at the purine ring's O6 position.\nMitochondrial membrane dynamics.\nMitochondria are commonly referred to as the cell's \"powerhouses\" because of their capacity to effectively produce ATP which is essential to maintain cellular homeostasis and metabolism. Moreover, researchers have gained a better knowledge of mitochondria's significance in cell biology because of the discovery of cell signaling pathways by mitochondria which are crucial platforms for cell function regulation such as apoptosis. Its physiological adaptability is strongly linked to the cell mitochondrial channel's ongoing reconfiguration through a range of mechanisms known as mitochondrial membrane dynamics, which include endomembrane fusion and fragmentation (separation) as well as ultrastructural membrane remodeling. As a result, mitochondrial dynamics regulate and frequently choreograph not only metabolic but also complicated cell signaling processes such as cell pluripotent stem cells, proliferation, maturation, aging, and mortality. Mutually, post-translational alterations of mitochondrial apparatus and the development of transmembrane contact sites among mitochondria and other structures, which both have the potential to link signals from diverse routes that affect mitochondrial membrane dynamics substantially, Mitochondria are wrapped by two membranes: an inner mitochondrial membrane (IMM) and an outer mitochondrial membrane (OMM), each with a distinctive function and structure, which parallels their dual role as cellular powerhouses and signaling organelles. The inner mitochondrial membrane divides the mitochondrial lumen into two parts: the inner border membrane, which runs parallel to the OMM, and the cristae, which are deeply twisted, multinucleated invaginations that give room for surface area enlargement and house the mitochondrial respiration apparatus. The outer mitochondrial membrane, on the other hand, is soft and permeable. It, therefore, acts as a foundation for cell signaling pathways to congregate, be deciphered, and be transported into mitochondria. Furthermore, the OMM connects to other cellular organelles, such as the endoplasmic reticulum (ER), lysosomes, endosomes, and the plasma membrane. Mitochondria play a wide range of roles in cell biology, which is reflected in their morphological diversity. Ever since the beginning of the mitochondrial study, it has been well documented that mitochondria can have a variety of forms, with both their general and ultra-structural morphology varying greatly among cells, during the cell cycle, and in response to metabolic or cellular cues. Mitochondria can exist as independent organelles or as part of larger systems; they can also be unequally distributed in the cytosol through regulated mitochondrial transport and placement to meet the cell's localized energy requirements. Mitochondrial dynamics refers to the adaptive and variable aspect of mitochondria, including their shape and subcellular distribution.\nAutophagy.\nAutophagy is a self-degradative mechanism that regulates energy sources during growth and reaction to dietary stress. Autophagy also cleans up after itself, clearing aggregated proteins, cleaning damaged structures including mitochondria and endoplasmic reticulum and eradicating intracellular infections. Additionally, autophagy has antiviral and antibacterial roles within the cell, and it is involved at the beginning of distinctive and adaptive immune responses to viral and bacterial contamination. Some viruses include virulence proteins that prevent autophagy, while others utilize autophagy elements for intracellular development or cellular splitting. Macro autophagy, micro autophagy, and chaperon-mediated autophagy are the three basic types of autophagy. When macro autophagy is triggered, an exclusion membrane incorporates a section of the cytoplasm, generating the autophagosome, a distinctive double-membraned organelle. The autophagosome then joins the lysosome to create an autolysosome, with lysosomal enzymes degrading the components. In micro autophagy, the lysosome or vacuole engulfs a piece of the cytoplasm by invaginating or protruding the lysosomal membrane to enclose the cytosol or organelles. The chaperone-mediated autophagy (CMA) protein quality assurance by digesting oxidized and altered proteins under stressful circumstances and supplying amino acids through protein denaturation. Autophagy is the primary intrinsic degradative system for peptides, fats, carbohydrates, and other cellular structures. In both physiologic and stressful situations, this cellular progression is vital for upholding the correct cellular balance. Autophagy instability leads to a variety of illness symptoms, including inflammation, biochemical disturbances, aging, and neurodegenerative, due to its involvement in controlling cell integrity. The modification of the autophagy-lysosomal networks is a typical hallmark of many neurological and muscular illnesses. As a result, autophagy has been identified as a potential strategy for the prevention and treatment of various disorders. Many of these disorders are prevented or improved by consuming polyphenol in the meal. As a result, natural compounds with the ability to modify the autophagy mechanism are seen as a potential therapeutic option. The creation of the double membrane (phagophore), which would be known as nucleation, is the first step in macro-autophagy. The phagophore approach indicates dysregulated polypeptides or defective organelles that come from the cell membrane, Golgi apparatus, endoplasmic reticulum, and mitochondria. With the conclusion of the autophagocyte, the phagophore's enlargement comes to an end. The auto-phagosome combines with the lysosomal vesicles to formulate an auto-lysosome that degrades the encapsulated substances, referred to as phagocytosis.\nNotable cell biologists.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6340", "revid": "40057568", "url": "https://en.wikipedia.org/wiki?curid=6340", "title": "Canadian English", "text": "Set of varieties of the English language native to Canada\nCanadian English (CanE, CE, en-CA) encompasses the varieties of English native to Canada. According to the 2016 census, English was the first language of 19.4 million Canadians or 58.1% of the total population; the remainder spoke French (20.8%) or other languages (21.1%). In Quebec, 7.5% of the population are anglophone, as most of Quebec's residents are native speakers of Quebec French.\nPhonologically, Standard Canadian and General American English may be grouped together as North American English, emphasizing the two varieties' identical phonemic inventories, whose realizations, however, differ. While Canadian English tends to be closer to American English in most regards, it does possess elements from British English and some uniquely Canadian characteristics. The precise influence of American English, British English and other sources on Canadian English varieties has been the ongoing focus of systematic studies since the 1950s.\nCanadians and Americans themselves often have trouble differentiating their own two accents, particularly when someone speaks with an urban Standard Canadian English accent because it sounds very similar to Western American English. There is also evidence that Standard Canadian English and Western American English have been undergoing a very similar vowel shift since the 1980s. Canadian English varies very little from Central Canada to British Columbia. But, some noticeably different accents can be found in the Atlantic provinces, most especially in Newfoundland with Newfoundland English. Accent differences can sometimes be heard between those who live in urban centres versus those living in rural settings.\nIn the early 20th century, western Canada was largely populated by farmers from Central and Eastern Europe who were not anglophones. At the time, most anglophones there were re-settlers from Ontario or Quebec who had British, Irish and/or Loyalist ancestry. Throughout the 20th century, the prairies underwent anglicization and linguistic homogenization through education and exposure to Canadian and American media.\nHistory.\nThe term \"Canadian English\" is first attested in a speech by the Reverend A. Constable Geikie in an address to the Canadian Institute in 1857 (see DCHP-1 Online, s.v. \"Canadian English\", Avis \"et al.,\" 1967). Geikie, a Scottish-born Canadian, reflected the Anglocentric attitude that would be prevalent in Canada for the next hundred years when he referred to the language as \"a corrupt dialect\", in comparison with what he considered the proper English spoken by immigrants from Britain.\nOne of the earliest influences on Canadian English was the French language, which was brought to Canada by the French colonists in the 17th century. French words and expressions were adopted into Canadian English, especially in the areas of cuisine, politics, and social life. For example, words like beavertail, and toque are uniquely Canadian French terms that have become part of the Canadian English lexicon.\nAn important influence on Canadian English was British English, which was brought to Canada by British settlers in the 18th and 19th centuries. Canadian English borrowed many words and expressions from British English, including words like lorry, flat, and lift. However, Canadian English also developed its own unique vocabulary, including words like tuque, chesterfield, and double-double.\nAmerican English also had a significant impact on Canadian English, especially in the 20th century as a result of increased cultural and economic ties between the two countries. American English terms like gasoline, truck, and apartment are commonly used in Canadian English, and some Canadian English speakers have adopted American English pronunciation and grammar.\nThe growth of Canadian media, including television, film, and literature, has also played a role in shaping Canadian English. Chambers (1998) notes that Canadian media has helped to create new words and expressions that reflect Canadian culture and values. Canadian institutions, such as the CBC and the Canadian Oxford Dictionary, have also played a role in promoting and defining Canadian English.\nIn addition to these influences, Canadian English has also been shaped by Indigenous languages. Indigenous words like moose, toboggan, and moccasin have become part of the Canadian English lexicon.\nCanadian English is the product of five waves of immigration and settlement over a period of more than two centuries. The first large wave of permanent English-speaking settlement in Canada, and linguistically the most important, was the influx of Loyalists fleeing the American Revolution, chiefly from the Mid-Atlantic States\u2014as such, Canadian English is believed by some scholars to have derived from northern American English. Canadian English has been developing features of its own since the early 19th century. The second wave from Britain and Ireland was encouraged to settle in Canada after the War of 1812 by the governors of Canada, who were worried about American dominance and influence among its citizens. Further waves of immigration from around the globe peaked in 1910, 1960 and at the present time had a lesser influence, but they did make Canada a multicultural country, ready to accept linguistic change from around the world during the current period of globalization.\nThe languages of Aboriginal peoples in Canada started to influence European languages used in Canada even before widespread settlement took place, and the French of Lower Canada provided vocabulary, with words such as \"toque\" and \"portage\", to the English of Upper Canada.\nOverall, the history of Canadian English is a reflection of the country's diverse linguistic and cultural heritage. While Canadian English has borrowed many words and expressions from other languages, it has also developed its own unique vocabulary and pronunciation that reflects the country's distinct identity.\nHistorical linguistics.\nStudies on earlier forms of English in Canada are rare, yet connections with other work to historical linguistics can be forged. An overview of diachronic work on Canadian English, or diachronically relevant work, is Dollinger (2012, updated to 2017). Until the 2000s, basically all commentators on the history of CanE have argued from the \"language-external\" history, i.e. social and political history. An exception has been in the area of lexis, where Avis \"et al.\"'s 1967 \"Dictionary of Canadianisms on Historical Principles\" offered real-time historical data through its quotations. Recently, historical linguists have started to study earlier Canadian English with historical linguistic data. DCHP-1 is now available in open access. Most notably, Dollinger (2008) pioneered the historical corpus linguistic approach for English in Canada with CONTE (Corpus of Early Ontario English, 1776\u20131849) and offers a developmental scenario for 18th- and 19th-century Ontario. Recently, Reuter (2015), with a 19th-century newspaper corpus from Ontario, has confirmed the scenario laid out in Dollinger (2008).\n Historically, Canadian English included a class-based sociolect known as \"Canadian dainty\". Treated as a marker of upper-class prestige in the 19th and early 20th centuries, Canadian dainty was marked by the use of some features of British English pronunciation, resulting in an accent similar, but not identical, to the Mid-Atlantic accent known in the United States. This accent faded in prominence following World War II, when it became stigmatized as pretentious, and is now almost never heard in modern Canadian life outside of archival recordings used in film, television or radio documentaries.\nSpelling.\nCanadian spelling of the English language combines British and American conventions, the two dominant varieties, and adds some domestic idiosyncrasies. For many words, American and British spelling are both acceptable. Spelling in Canadian English co-varies with regional and social variables, somewhat more so, perhaps, than in the two dominant varieties of English, yet general trends have emerged since the 1970s.\nCanadian spelling conventions can be partly explained by Canada's trade history. For instance, the British spelling of the word \"cheque\" probably relates to Canada's once-important ties to British financial institutions. Canada's automobile industry, on the other hand, has been dominated by American firms from its inception, explaining why Canadians use the American spelling of \"tire\" (hence, \"Canadian Tire\") and American terminology for automobiles and their parts (for example, \"truck\" instead of \"lorry\", \"gasoline\" instead of \"petrol\", \"trunk\" instead of \"boot\").\nCanada's political history has also had an influence on Canadian spelling. Canada's first prime minister, John A. Macdonald, once advised the Governor General of Canada to issue an order-in-council directing that government papers be written in the British style.\nA contemporary reference for formal Canadian spelling is the spelling used for Hansard transcripts of the Parliament of Canada &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;. Many Canadian editors, though, use the \"Canadian Oxford Dictionary\", often along with the chapter on spelling in \"Editing Canadian English\", and, where necessary (depending on context), one or more other references. &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;\nThroughout part of the 20th century, some Canadian newspapers adopted American spellings, for example, \"color\" as opposed to the British-based \"colour\". Some of the most substantial historical spelling data can be found in Dollinger (2010) and Grue (2013). The use of such spellings was the long-standing practice of the Canadian Press perhaps since that news agency's inception, but visibly the norm prior to World War II. The practice of dropping the letter \"u\" in such words was also considered a labour-saving technique during the early days of printing in which movable type was set manually. Canadian newspapers also received much of their international content from American press agencies, therefore it was much easier for editorial staff to leave the spellings from the wire services as provided.\nIn the 1990s, Canadian newspapers began to adopt the British spelling variants such as \"-our\" endings, notably with \"The Globe and Mail\" changing its spelling policy in October 1990. Other Canadian newspapers adopted similar changes later that decade, such as the Southam newspaper chain's conversion in September 1998. The \"Toronto Star\" adopted this new spelling policy in September 1997 after that publication's ombudsman discounted the issue earlier in 1997. The \"Star\" had always avoided using recognized Canadian spelling, citing the \"Gage Canadian Dictionary\" in their defence. Controversy around this issue was frequent. When the \"Gage Dictionary\" finally adopted standard Canadian spelling, the \"Star\" followed suit. Some publishers, e.g. \"Maclean's\", continue to prefer American spellings.\nDictionaries.\nThe first Canadian dictionaries of Canadian English were edited by Walter Spencer Avis and published by Gage Ltd. The \"Beginner's Dictionary\" (1962), the \"Intermediate Dictionary\" (1964) and, finally, the \"Senior Dictionary\" (1967) were milestones in Canadian English lexicography. In November 1967 A Dictionary of Canadianisms on Historical Principles (DCHP) was published and completed the first edition of Gage's Dictionary of Canadian English Series. The DCHP documents the historical development of Canadian English words that can be classified as \"Canadianisms\". It therefore includes words such as mukluk, Canuck, and bluff, but does not list common core words such as desk, table or car. Many secondary schools in Canada use the graded dictionaries. The dictionaries have regularly been updated since: the \"Senior Dictionary,\" edited by Robert John Gregg, was renamed \"Gage Canadian Dictionary\". Its fifth edition was printed beginning in 1997. Gage was acquired by Thomson Nelson around 2003. The latest editions were published in 2009 by HarperCollins. On 17 March 2017 a second edition of DCHP, the online Dictionary of Canadianisms on Historical Principles 2 (DCHP-2), was published. DCHP-2 incorporates the c. 10\u200a000 lexemes from DCHP-1 and adds c. 1\u200a300 novel meanings or 1\u200a002 lexemes to the documented lexicon of Canadian English.\nIn 1997, the \"ITP Nelson Dictionary of the Canadian English Language\" was another product, but has not been updated since.\nIn 1998, Oxford University Press produced a Canadian English dictionary, after five years of lexicographical research, entitled \"The Oxford Canadian Dictionary\". A second edition, retitled \"The Canadian Oxford Dictionary\", was published in 2004. Just as the older dictionaries it includes uniquely Canadian words and words borrowed from other languages, and surveyed spellings, such as whether \"colour\" or \"color\" was the more popular choice in common use. Paperback and concise versions (2005, 2006), with minor updates, are available.\nPhonology and phonetics.\nIn terms of the major sound systems (phonologies) of English around the world, Canadian English aligns most closely to American English, though it does also possess certain elements of British English. Both Canadian and American English are grouped together under a common North American English sound system; the mainstream Canadian accent (\"Standard Canadian\") is often compared to the very similar and largely overlapping \"General American\" accent, an accent widely spoken throughout the United States and perceived there as being relatively lacking in any noticeable regional features.\nWestern Canada (British Columbia, Alberta, Saskatchewan, Manitoba) shows the largest dialect diversity. Northern Canada is, according to William Labov, a dialect region in formation where a homogeneous English dialect has not yet formed. A very homogeneous dialect exists in Western and Central Canada, a situation that is similar to that of the Western United States. Labov identifies an \"Inland Canada\" region that concentrates all of the defining features of the dialect centred on the Prairies (a region in Western Canada that mainly includes Alberta, Saskatchewan, and Manitoba and is known for its grasslands and plains), with more variable patterns including the metropolitan areas of Vancouver and Toronto. This dialect forms a dialect continuum with Western US English, sharply differentiated from Inland Northern US English of the central and eastern Great Lakes region.\nCanadian English raises the diphthong onsets of diphthongs /a\u026a/ and /a\u028a/ to or before voiceless segments.\nStandard.\nStandard Canadian English is socially defined. Standard Canadian English is spoken by those who live in urban Canada, in a middle-class job (or one of their parents holds such employment), who are second generation or later (born and raised in Canada) and speak English as (one of their) dominant language(s) (Dollinger 2019a, adapted from Chambers 1998). It is the variety spoken, in Chambers' (1998: 252) definition, by Anglophone or multilingual residents, who are second generation or later (i.e. born in Canada) and who live in urban settings. Applying this definition, c. 36% of the Canadian population speak Standard Canadian English in the 2006 population, with 38% in the 2011 census.\nRegional variation.\nThe literature has for a long time conflated the notions of Standard Canadian English (StCE) and regional variation. While some regional dialects are close to Standard Canadian English, they are not identical to it. To the untrained ear, for instance, a BC middle-class speaker from a rural setting may seemingly be speaking Standard Canadian English, but, given Chambers' definition, such a person, because of the rural provenance, would not be included in the accepted definition (see the previous section). The \"Atlas of North American English\", while being the best source for US regional variation, is not a good source for Canadian regional variation, as its analysis is based on only 33 Canadian speakers. Boberg's (2005, 2008) studies offer the best data for the delimitation of dialect zones. The results for vocabulary and phonetics overlap to a great extent, which has allowed the proposal of dialect zones. Dollinger and Clarke distinguish between:\nIndigenous.\nFirst Nations and Inuit from Northern Canada speak a version of Canadian English influenced by the phonology of their first languages. European Canadians in these regions are relatively recent arrivals, and have not produced a dialect that is distinct from southern Canadian English.\nOverall, First Nations Canada English dialects rest between language loss and language revitalization. British Columbia has the greatest linguistic diversity, as it is home to about half of the Indigenous languages spoken in Canada. However, most of the languages spoken in the province are endangered due to the small number of speakers. To some extent, the dialects reflect the historical contexts where English has been a major colonizing language. On the other hand, the dialects are also a result of the late stages of depidginization and decreolization, which resulted in linguistic markers of Indigenous identity and solidarity. These dialects are observed to have developed a lingua francas due to the contact between English and Indigenous populations, and eventually, the various dialects began to converge with standard English.\nHowever, certain First Nations English have also shown to have phonological standard Canadian English, thus resulting in a more distinct dialect formation. Plains Cree, for instance, is a language that has less phonological contrasts compared to standard Canadian English. Plains Cree has no voicing contrast. The stops /p/, /t/, and /k/ are mostly voiceless and unaspirated, though they may vary in other phonetic environments from voiceless to voiced. Plains Cree also does not have the liquids or fricatives found in the standard form. Dene Suline, on the other hand, has more phonological contrasts, resulting from the use of features not seen in the standard form. The language has 39 phonemic consonants and a higher proportion of glottalized consonants.\nMaritimes.\nMany in the Maritime provinces\u00a0\u2013 Nova Scotia, New Brunswick and Prince Edward Island\u00a0\u2013 have an accent that sounds more like Scottish English and, in some places, Irish English than General American. Outside of major communities, dialects can vary markedly from community to community, as well as from province to province, reflecting ethnic origin as well as a past in which there were few roads and many communities, with some villages very isolated. Into the 1980s, residents of villages in northern Nova Scotia could identify themselves by dialects and accents distinctive to their village. The dialects of Prince Edward Island are often considered the most distinct grouping.\nThe phonology of Maritimer English has some unique features:\nAs with many other distinct dialects, vowels are a marker of Halifax English as a distinctive variant of Canadian English. Typically, Canadian dialects have a merger of the low back vowels in palm, lot, thought and cloth. The merged vowel in question is usually /\u0251/ or sometimes the rounded variant /\u0252/. Meanwhile, in Halifax, the vowel is raised and rounded. For example, body; popped; and gone. In the homophones, caught-cot and stalk-stock, the rounding in the merged vowel is also much more pronounced here than in other Canadian varieties. The Canadian Shift is also not as evident in the traditional dialect. Instead, the front vowels are raised. For example, the vowel in had is raised to [h\u00e6ed]; and camera is raised to [k\u00e6mra].\nAlthough it has not been studied extensively, the speech of Cape Breton specifically seems to bear many similarities with the nearby island of Newfoundland, which is often why Westerners can have a hard time differentiating the two accents. For instance, they both use the fronting of the low back vowel. These similarities can be attributed to geographic proximity, the fact that about one-quarter of the Cape Breton population descends from Irish immigrants - many of whom arrived via Newfoundland - and the Scottish and Irish influences on both provinces. The speech of Cape Breton can almost be seen as a continuum between the two extremes of the Halifax variant and the Newfoundland variant. In addition, there is heavy influence of standard varieties of Canadian English on Cape Breton English, especially in the diphthongization of the goat and goose vowels and the frequent use of Canadian raising.\nNewfoundland.\nCompared to the commonly spoken English dominating neighbouring provinces, Newfoundland English is famously distinct in its dialects and accents. Newfoundland English differs in vowel pronunciation, morphology, syntax, and preservation of archaic adverbial-intensifiers. The dialect varies markedly from community to community, as well as from region to region. Its distinctiveness partly results from a European settlement history that dates back centuries, which explains Newfoundland's most notable linguistic regions: an Irish-settled area in the southeast (the southern Avalon Peninsula) and an English-settled area in the southwest.\nA well-known phonetic feature many Newfoundland speakers possess is the kit-dress merger. The mid lax /\u025b/ here is raised to the high lax stressed /\u026a/, particularly before oral stops and nasals, so consequently \"pen\" is pronounced more like \"pin\".\nAnother phonetic feature more unique to Newfoundland English is TH-stopping. Here, the voiceless dental fricative /\u03b8/ in words like \"myth\" and \"width\" are pronounced more like \"t\" or the voiced dental fricative /\u00f0/ in words like \"the\" and \"these\". TH-stopping is more common for /\u00f0/, especially in unstressed function words (e.g. that, those, their, etc.).\nOntario.\nCanadian raising is quite strong throughout the province of Ontario, except within the Ottawa Valley. The introduction of Canadian raising to Canada can be attributed to the Scottish and Irish immigrants who arrived in the 18th and 19th centuries.The origins of Canadian raising to Scotland and revealed that the Scottish dialects spoken by these immigrants had a probable impact on its development. This feature impacts the pronunciation of the /a\u026a/ sound in \"right\" and the /a\u028a/ sound in \"lout\". Canadian Raising indicates a scenario where the start of the diphthong is nearer to the destination of the glide before voiceless consonants than before voiced consonants. The Canadian Shift is also a common vowel shift found in Ontario. The retraction of /\u00e6/ was found to be more advanced for women in Ontario than for people from the Prairies or Atlantic Canada and men.\nIn the southern part of Southwestern Ontario (roughly in the line south from Sarnia to St. Catharines), despite the existence of many characteristics of West/Central Canadian English, many speakers, especially those under 30, speak a dialect influenced by the Inland Northern American English dialect (in part due to proximity to cities like Detroit and Buffalo, New York) though there are minor differences such as Canadian raising (e.g. \"ice\" vs \"my\").\nThe north and northwestern parts of Southwestern Ontario, the area consisting of the Counties of Huron, Bruce, Grey, and Perth, referred to as the \"Queen's Bush\" in the 19th century, did not experience communication with the dialects of the southern part of Southwestern Ontario and Central Ontario until the early 20th century. Thus, a strong accent similar to Central Ontarian is heard, yet many different phrasings exist. It is typical in the area to drop phonetic sounds to make shorter contractions, such as: \"prolly\" (probably), \"goin\"' (going), and \"Wuts goin' on tonight? D'ya wanna do sumthin'?\" It is particularly strong in the County of Bruce, so much that it is commonly referred to as being the Bruce Cownian (Bruce Countian) accent. Also 'er' sounds are often pronounced 'air', with \"were\" sounding more like \"wear\".\nResidents of the Golden Horseshoe (including the Greater Toronto Area) are known to merge the second /t/ with the /n/ in \"Toronto\", pronouncing the name variously as [to\u02c8\u0279\u0252\u027e\u0303o], [t\u0259\u02c8\u0279\u0252\u027e\u0303o] or even [\u02c8t\u0279\u0252\u027e\u0303o] or [\u02c8t\u0279\u0252\u027e\u0303\u0259]. This is not unique to Toronto; Atlanta is often pronounced \"Atlanna\" by residents. In the Greater Toronto Area, the \"th\" sound /\u00f0/ is sometimes pronounced [d]. Sometimes /\u00f0/ is elided altogether, resulting in \"Do you want this one er'iss one?\" The word \"southern\" is often pronounced with [a\u028a]. In the area north of the Regional Municipality of York and south of Parry Sound, notably among those who were born in the surrounding communities, the cutting down of syllables and consonants often heard, e.g. \"probably\" is reduced to \"prolly\" or \"probly\" when used as a response. In Greater Toronto, the diphthong tends to be fronted (as a result the word \"about\" is pronounced as [\u0259\u02c8b\u025b\u028at]). The Greater Toronto Area is linguistically diverse, with 43 percent of its people having a mother tongue other than English. As a result Toronto English has distinctly more variability than Inland Canada.\nIn Eastern Ontario, Canadian raising is not as strong as it is in the rest of the province. In Prescott and Russell, parts of Stormont-Dundas-Glengarry and Eastern Ottawa, French accents are often mixed with English ones due to the high Franco-Ontarian population there. In Lanark County, Western Ottawa and Leeds-Grenville and the rest of Stormont-Dundas-Glengarry, the accent spoken is nearly identical to that spoken in Central Ontario and the Quinte area.\nA linguistic enclave has also formed in the Ottawa Valley, heavily influenced by original Scottish, Irish, and German settlers, and existing along the Ontario-Quebec boundary, which has its own distinct accent known as the Ottawa Valley twang (or brogue). Phonetically, the Ottawa Valley twang is characterized by the lack of Canadian raising as well as the cot\u2013caught merger, two common elements of mainstream Canadian English. This accent is quite rare in the region today.\nQuebec.\nEnglish is a minority language in Quebec (with French the majority), but has many speakers in Montreal, the Eastern Townships and in the Gatineau-Ottawa region. A person whose mother tongue is English and who still speaks English is called an \"Anglophone\", versus a \"Francophone\", or French speaker.\nMany people in Montreal distinguish between words like \"marry\" versus \"merry\" and \"parish\" versus \"perish\", which are homophones to most other speakers of Canadian English. Quebec Anglophones generally pronounce French street names in Montreal as French words. \"Pie IX\" Boulevard is pronounced as in French: not as \"pie nine\" but as (compare French /pi.n\u0153f/). On the other hand, Anglophones pronounce the final \"d\" as in \"Bernard\" and \"Bouchard\"; the word \"Montreal\" is pronounced as an English word and \"Rue Lambert-Closse\" is known as \"Clossy Street\" (vs French /kl\u0254s/). In the city of Montreal, especially in some of the western suburbs like C\u00f4te-St-Luc and Hampstead, there is a strong Jewish influence in the English spoken in those areas. A large wave of Jewish immigration from Eastern Europe and the former Soviet Union before and after World War II is also evident today. Their English has a strong Yiddish influence, and there are some similarities to English spoken in New York. Words used mainly in Quebec and especially in Montreal are: \"stage\" for \"apprenticeship\" or \"internship\", \"copybook\" for a notebook, \"d\u00e9panneur\" or \"dep\" for a convenience store, and \"guichet\" for an ABM/ATM. It is also common for Anglophones, particularly those of Greek or Italian descent, to use translated French words instead of common English equivalents such as \"open\" and \"close\" for \"on\" and \"off\" or \"Open the lights, please\" for \"Turn on the lights, please\".\nWest.\nWestern Canadian English describes the English spoken in the four most western provinces\u2014British Columbia, Alberta, Saskatchewan, and Manitoba. British Columbia, in particular is a sub-zone on the lexical level. Phonetically, Western Canadian English has much more /\u00e6\u0261/ raising and much less /\u00e6n/ than further east, and Canadian raised /a\u028a/ is further back.\nBritish Columbia.\nBritish Columbia English shares dialect features with both Standard Canadian English and the American Pacific Northwest English. In Vancouver, speakers exhibit more vowel retraction of /\u00e6/ before nasals than people from Toronto, and this retraction may become a regional marker of West Coast English. /\u025b\u0261/ raising (found in words such as beg, leg, and peg) and /\u00e6\u0261/ raising (found words such as bag, lag and rag), a prominent feature in Northwestern American speakers, is also found in Vancouver speakers, causing \"beg\" to sound like the first syllable of \"bagel\" and \"bag\" to be very similar. In the past, the ANAE reported that Vancouverites' participation in the Canadian raising of /a\u026a/ was questionable, but nowadays they tend to raise both /a\u026a/ and /a\u028a/. The \"o\" in such words as \"holy, goal, load, know,\" etc. is pronounced as a close-mid back rounded vowel, [o], but not as rounded as in the Prairies where there are strong Scandinavian, Slavic and German influences, which can lend to a more stereotypical \"Canadian\" accent.\nFinally, there is also the /t/ sound which according to Gregg (2016), \"with many [Vancouver] speakers [is] intrusive between /l/ or /n/ and /s/ in words like sense /s\u025bnts/, Wilson /w\u026alts\u0259n/ [and] also /'\u0252ltso\u028a/ \".\nSaskatchewan.\nEnglish in Saskatchewan has its pool of phonetic features shared with other provinces used by certain demographics. For instance, we have the consonant variables /ntV/ and /VtV/, the latter being a common feature of North American English and is defined as the intervoicing of /t/ between vowels. Meanwhile, /ntV/ \"frequently occurs in words such as \"centre\" and \"twenty\" where /t/ follows the alveolar nasal /n/ and precedes an unstressed vowel\". According to Nylvek (1992), both variables of /t/ are generally more often used by younger male over older female speakers.\nGrammar.\nThere are a handful of syntactical practices unique to Canadian English. When writing, Canadians may start a sentence with \"As well\", in the sense of \"in addition\"; this construction is a Canadianism.\nNorth American English prefers \"have got\" to \"have\" to denote possession or obligation (as in \"I've got a car\" vs. \"I have a car\"); Canadian English differs from American English in tending to eschew plain \"got\" (\"I got a car\"), which is a common third option in very informal US English.\nThe grammatical construction \"\"be done\" something\" means roughly \"\"have/has finished\" something\". For example, \"I am done my homework\" and \"The dog is done dinner\" are genuine sentences in this dialect, respectively meaning \"I have finished my homework\" and \"The dog has finished dinner\". Another example, \"Let's start after you're done all the coffee\", means \"Let's start after you've finished all the coffee\". This is not exactly the same as the standard construction \"\"to be done with\" something\", since \"She is done the computer\" can only mean \"She is done with the computer\" in one sense: \"She has finished (building) the computer\".\nDate and time notation.\nDate and time notation in Canadian English is a mixture of British and American practices. The date can be written in the form of either \"July 1, 2017\" or \"1 July 2017\"; the latter is common in more formal writing and bilingual contexts. The Government of Canada only recommends writing all-numeric dates in the form of YYYY-MM-DD (e.g. 2017-07-01), following ISO 8601. Nonetheless, the traditional DD/MM/YY and MM/DD/YY systems remain in everyday use, which can be interpreted in multiple ways: 01/07/17 can mean either 1 July 2017 or 7 January 2017. Private members' bills have repeatedly attempted to clarify the situation. In business communication and filing systems the YYMMDD is used to assist in automatic ordering of electronic files.\nThe government also recommends use of the 24-hour clock, which is widely used in contexts such as transportation schedules, parking meters, and data transmission. Many speakers of English use the 12-hour clock in everyday speech, even when reading from a 24-hour display, similar to the use of the 24-hour clock in the United Kingdom.\nVocabulary.\nWhere Canadian English shares vocabulary with other English dialects, it tends to share most with American English, but also has many non-American terms distinctively shared instead with Britain. British and American terms also can coexist in Canadian English to various extents, sometimes with new nuances in meaning; a classic example is (British) often used interchangeably with (American), though, in Canadian speech, the latter can more narrowly mean a trip elsewhere and the former can mean general time off work. In addition, the vocabulary of Canadian English also features some words that are seldom (if ever) found elsewhere. A good resource for these and other words is the Dictionary of Canadianisms on Historical Principles, which is currently being revised at the University of British Columbia in Vancouver, British Columbia. The Canadian public appears to take interest in unique \"Canadianisms\": words that are distinctively characteristic of Canadian English\u2014though perhaps not exclusive to Canada; there is some disagreement about the extent to which \"Canadianism\" means a term actually unique to Canada, with such an understanding possibly overstated by the popular media. As a member of the Commonwealth of Nations, Canada shares many items of institutional terminology and professional designations with the countries of the former British Empire\u2014for example, , for a police officer of the lowest rank, and .\nRegional Variation.\nWhile Canadian English has vocabulary that distinguishes it from other varieties of World Englishes (Walter Avis, Introduction to DCHP-1), there is significant regional variation in its lexis within Canada as well. A balanced cross-continental sample of 1800 Canadians and 360 Americans the Canada and the USA is the result of Boberg's North American Regional Vocabulary Survey (NARVS), a questionnaire employed by Boberg from 1999-2007 () that sought out lexical items that vary regionally within Canada. Six regions were identified in the NARVS data collection: The West, which includes British Columbia and the Prairies; Ontario; Quebec, which represents data from Montreal mostly; New Brunswick and Nova Scotia; Prince Edward Island; and Newfoundland (). Many regional differences in the lexis are item-specific. For example, one of these items has to do with the nationally enjoyed meal of pizza, and more specifically, the term used to refer to a pizza that features all available toppings. While Atlantic Canada refers to this order as the works, the majority term used from eastern Ontario to the West Coast is deluxe, and terms such as all-dressed and everything-on-it are used in Quebec and Toronto, respectively. Other examples include the regionally varied usage of running shoes/runners/sneakers to describe athletic shoes, and notebook/scribbler/cahier to describe a book in which one may write (). Despite the regional variation of vocabulary items within Canada, the lexis of Canadian English still maintains greater commonality between its own regions than it does with American English or British English.\nQuebec.\nQuebec recognizes French as its primary language. As a result, English has no official status in Qu\u00e9b\u00e9cois public life, and is not recognized as an official language within the province. French is the primary recognized language in Quebec, and even the provincial government must officially be referred to as the Gouvernement du Qu\u00e9bec, regardless of the language being used. While the lexical catalog of Quebec English contains items influenced or borrowed by French, the influence of the dominant French language on Quebec English is marginal. (). The francophone dominance in Quebec makes the province a linguistic anomaly within Canada, where English maintains a negligible role in government and public domains ().\nThe French influence on Quebec English operates through five distinct processes, as identified by Charles Boberg: elective direct lexical transfer of non-English words (e.g., garderie for daycare), imposed direct lexical transfer of non-English words (e.g., SAQ for Soci\u00e9t\u00e9 des alcools du Qu\u00e9bec), loan translation/calques (e.g., all-dressed for the French equivalent toute garnie), semantic shifts of existing English words (e.g., magasin for store), and syntactic influences (e.g., \"we're living here three years\" instead of the English \"we've been living here for three years\") (). Although Quebec English differs from other Canadian regional lexes due to its special contact with French, it still shares some similarities with the lexis of other Canadian regions. For instance, the use of lexical items such as all-dressed has been successfully transferred to most other Canadian other Canadian regional lexes ().\nOntario.\nSouthern Ontario was initially settled by white Protestants, with the late 19th century witnessing the migration of white Protestant settlers from Ontario to western Canada following the suppression of the M\u00e9tis opposition. This migration facilitated the transplantation of the Ontario accent and the emergence of a homogeneous Canadian English dialect (). Distinctive to Ontario are Canadianisms such as concession roads, which refer to roads that transect a township, dew-worm, which refers to an earthworm, and fire-reel, which refer to a fire truck (). Walter S. Avis identified several linguistic features characteristic of Ontarians, including their preference for the word vacation, rather than holiday which is considered more British English and sack over paper bag. While there may be numerous such lexical differences in the speech of provincial and national borderers, Avis asserts that these are relatively minor compared to the linguistic features held in common(). Furthermore, Avis suggests that the difference between American English and Ontario English is relatively small near the border due to their close proximity. The historical settlement patterns of southern Ontario, coupled with linguistic research, indicate the existence of distinctively Ontarian lexical items. However, Ontario maintains greater similarities with other Canadian regions than it does with the neighbouring American English and its regional variations ().\nPrairies (Manitoba, Saskatchewan and Alberta).\nThe Prairies, consisting of Manitoba, Saskatchewan, and Alberta, have their own lexical features. The linguistic legacy from the settlement patterns in these regions, along with the Indigenous communities, specifically the large M\u00e9tis population in Saskatchewan and Manitoba also carry certain linguistic traits inherited from the French, Aboriginal and Celtic forebears. The linguistic features brought by Ukrainian, German, and Mennonite populations in the Saskatchewan Valley of Saskatchewan and Red River Valley of Manitoba have also influenced the lexis of the Prairies. Some terms are derived from these groups and some are formed within the region by locals throughout time. An example of the former is the high-profile variable bunnyhug, a term for a hooded sweatshirt in Saskatchewan (). As discussed in The Dictionary of Canadianisms on Historical Principles, bunnyhug is purposely and commonly used by young Saskatchewan speakers to indicate a sense of provincial identity, and is referred to as a Saskatchewanism. It should be further noted that it is assumed based on circumstantial evidence that teenagers played a crucial and special role in the spread and adoption of the term bunnyhug for hooded sweatshirts (). Across Saskatchewan, Alberta, and Manitoba there are other terms consistent in or throughout the 3 provinces. Biffed is a term for falling, such as \"John biffed it over there\". Pickerel is Manitoba's official fish, also known as Walleye. Play structure is used to describe a playground for children consisting of monkey bars, slides, etc. ()\nAtlantic Canada (New Brunswick &amp; Nova Scotia, PEI, Newfoundland).\nCanada's Atlantic provinces were the first part of North America to be discovered by Europeans. The Atlantic provinces, historically and collectively called the Maritimes, consist of New Brunswick, Nova Scotia, Prince Edward Island. Newfoundland and Labrador, which is not part of the Maritimes, is also part of Atlantic Canada.The historical immigrants from Europe have shaped cultures and lexical catalogs across the regions of Atlantic Canada that reflect British, Scottish, Gaelic, and French customs (). The vernacular variations of English spoken in the Atlantic region of Canada. Newfoundland and Labrador English (NLE) possesses unique vocabulary compared to standard Canadian English. The Dictionary of Newfoundland English covers the vocabulary common to Newfoundlanders, such as Newfoundland \"screech rum\", a Newfoundland-specific brand of rum; mummering, referring to a Christmas tradition; and gut-foundered, meaning very hungry or fastened (). Nova Scotia also is home to its own vocabulary. The term \"Sobey's bag\", used to refer to a plastic grocery bag, originates from the Nova Scotian grocery store chain Sobey's. (). Similarly, Prince Edward Island (PEI) has its own vocabulary and dictionary. For example, angishore refers to a fisherman who is too lazy to fish and likely is a lexical item originating from Irish Gaelic settlers in Newfoundland (). Sarah Sawler, a writer from Halifax, highlights terms that are common to Maritimes, such as dooryard for front yard, owly for when someone is angry or irritable, and biff for throw (). These are a few examples of the lexical variations of English vocabulary across Atlantic Canada.\nEducation.\nThe term \"college\", which refers to post-secondary education in general in the US, refers in Canada to either a post-secondary technical or vocational institution, or to one of the colleges that exist as federated schools within some Canadian universities. Most often, a \"college\" is a community college, not a university. It may also refer to a CEGEP in Quebec. In Canada, might denote someone obtaining a diploma in business management (this would be an associate degree in the United States); while is the term for someone earning a bachelor's degree. For that reason, in Canada does not have the same meaning as , unless the speaker or context clarifies the specific level of post-secondary education that is meant.\nWithin the public school system the chief administrator of a school is generally \"the principal\", as in the United States, but the term is not used preceding their name, i.e., \"Principal Smith\". The assistant to the principal is not titled as \"assistant principal\", but rather as \"vice-principal\", although the former is not unknown. This usage is identical to that in Northern Ireland.\nCanadian universities publish \"calendars\" or \"schedules\", not \"catalogs\" as in the US. Canadian students \"write\" or \"take\" exams (in the US, students generally \"take\" exams while teachers \"write\" them); they rarely \"sit\" them (standard British usage). Those who supervise students during an exam are sometimes called \"invigilators\" as in Britain, or sometimes \"proctors\" as in the US; usage may depend on the region or even the individual institution.\nSuccessive years of school are usually referred to as \"grade one\", \"grade two\", and so on. In Quebec, the speaker (if Francophone) will often say \"primary one\", \"primary two\" (a direct translation from the French), and so on; while Anglophones will say \"grade one\", \"grade two\". (Compare American \"first grade, second grade\" (sporadically found in Canada), and English/Welsh \"Year 1, Year 2\", Scottish/Northern Irish \"Primary 1, Primary 2\" or \"P1, P2\", and Southern Irish \"First Class, Second Class\" and so on.). The year of school before grade 1 is usually called \"Kindergarten\", with the exception of Nova Scotia, where it is called \"grade primary\".\nIn the US, the four years of high school are termed the freshman, sophomore, junior, and senior years (terms also used for college years); in Canada, the specific levels are used instead (i.e., \"grade nine\"). As for higher education, only the term \"freshman\" (often reduced to \"frosh\") has some currency in Canada. The American usages \"sophomore\", \"junior\" and \"senior\" are not used in Canadian university terminology, or in speech. The specific high-school grades and university years are therefore stated and individualized; for example, \"the grade 12s failed to graduate\"; \"John is in his second year at McMaster\". The \"first year\", \"third year\" designation also applies to Canadian law school students, as opposed to the common American usage of \"1L\", \"2L\" and \"3L\".\nCanadian students use the term \"marks\" (more common in England) or \"grades\" (more common in the US) to refer to their results. Usage is very mixed, although \"marks\" more commonly refer to a single score whereas \"grades\" often refers to the cumulative score in that class.\nUnits of measurement.\nUnlike in the United States, use of metric units within a majority of (but not all) industries is standard in Canada, as a result of the partial national adoption of the metric system during the mid-to-late 1970s that was eventually stalled; this has spawned some colloquial usages such as \"klick\" for kilometre (as also heard in the US military).\nNonetheless, US units are still used in many situations. Imperial volumes are also used, albeit very rarely\u2014although many Canadians and Americans mistakenly conflate the measurement systems despite their slight differences from each other.\nFor example, most English Canadians state their weight and height in pounds and feet/inches, respectively. This is also the case for many Quebec Francophones. Distances while playing golf are always marked and discussed in yards, though official scorecards may also show metres. Temperatures for cooking or pools are often given in Fahrenheit, while the weather is given in Celsius. Directions in the Prairie provinces are sometimes given using miles, because the country roads generally follow the mile-based grid of the Dominion Land Survey. Motor vehicle speed limits are measured in kilometres per hour.\nCanadians measure property, both residential and commercial, floor areas are in square feet or square metres, property is in square feet, square metres, acres or hectares. Fuel efficiency is more often discussed in the metric L/100\u00a0km than miles per US gallon. The Letter paper size of 8.5\u00a0inches \u00d7 11\u00a0inches is used instead of the international and metric equivalent A4 size of 210\u00a0mm \u00d7 297\u00a0mm. Beer cans are 355 mL (12 US oz), while beer bottles are typically 341 mL (12 Imperial oz), and draft beer is sold in various units; US or Imperial oz, US or Imperial pint, or occasionally mL.\nBuilding materials are used in soft conversions of imperial sizes, but often purchased in relation to the imperial sizes. For example, 8-inch concrete masonry units can be referred to as an 8-inch CMU or 190 CMU. The actual material used in the US and Canada is the same.\nTransport.\n\"Expressway\" may also refer to a limited-access road that has control of access but has at-grade junctions, railway crossings (for example, the Harbour Expressway in Thunder Bay.) Sometimes the term \"Parkway\" is also used (for example, the Hanlon Parkway in Guelph). In Saskatchewan, the term 'grid road' is used to refer to minor highways or rural roads, usually gravel, referring to the 'grid' upon which they were originally designed. In Quebec, freeways and expressways are called autoroutes.\nIn Alberta, the generic \"Trail\" is often used to describe a freeway, expressway or major urban street (for example, Deerfoot Trail, Macleod Trail or Crowchild Trail in Calgary, Yellowhead Trail, Victoria Trail or Mark Messier/St.Albert Trail in Edmonton). The British term \"motorway\" is not used. The American terms \"turnpike\" and \"tollway\" for a toll road are not common. The term \"throughway\" or \"thruway\" was used for first tolled limited-access highways (for example, the Deas Island Throughway, now Highway 99, from Vancouver, BC, to Blaine, Washington, USA or the Saint John Throughway (Highway 1) in Saint John, NB), but this term is not common anymore. In everyday speech, when a particular roadway is not being specified, the term \"highway\" is generally or exclusively used.\nLaw.\nLawyers in all parts of Canada, except Quebec, which has its own civil law system, are called \"barristers and solicitors\" because any lawyer licensed in any of the common law provinces and territories must pass bar exams for, and is permitted to engage in, both types of legal practice in contrast to other common-law jurisdictions such as England, Wales and Ireland where the two are traditionally separated (i.e., Canada has a fused legal profession). The words \"lawyer\" and \"counsel\" (not \"counsellor\") predominate in everyday contexts; the word \"attorney\" refers to any personal representative. Canadian lawyers generally do not refer to themselves as \"attorneys\", a term that is common in the United States.\nThe equivalent of an American \"district attorney\", meaning the barrister representing the state in criminal proceedings, is called a \"crown attorney\" (in Ontario), \"crown counsel\" (in British Columbia), \"crown prosecutor\" or \"the crown\", on account of Canada's status as a constitutional monarchy in which the Crown is the locus of state power.\nThe words \"advocate\" and \"notary\"\u00a0\u2013 two distinct professions in Quebec civil law\u00a0\u2013 are used to refer to that province's approximate equivalents of barrister and solicitor, respectively. It is not uncommon for English-speaking advocates in Quebec to refer to themselves in English as \"barrister(s) and solicitor(s)\", as most advocates chiefly perform what would traditionally be known as \"solicitor's work\", while only a minority of advocates actually appear in court. In Canada's common law provinces and territories, the word \"notary\" means strictly a notary public.\nWithin the Canadian legal community itself, the word \"solicitor\" is often used to refer to any Canadian lawyer in general (much like the way the word \"attorney\" is used in the United States to refer to any American lawyer in general). Despite the conceptual distinction between \"barrister\" and \"solicitor\", Canadian court documents would contain a phrase such as \"\"John Smith, \"solicitor\" for the Plaintiff\"\" even though \"John Smith\" may well himself be the barrister who argues the case in court. In a letter introducing him/herself to an opposing lawyer, a Canadian lawyer normally writes something like \"\"I am the \"solicitor\" for Mr. Tom Jones.\"\nThe word \"litigator\" is also used by lawyers to refer to a fellow lawyer who specializes in lawsuits even though the more traditional word \"barrister\" is still employed to denote the same specialization.\nJudges of Canada's superior courts, which exist at the provincial and territorial levels, are traditionally addressed as \"My Lord\" or \"My Lady\". This varies by jurisdiction, and some superior court judges prefer the titles \"Mister Justice\" or \"Madam Justice\" to \"Lordship\".\nMasters are addressed as \"Mr. Master\" or simply \"Sir.\" In British Columbia, masters are addressed as \"Your Honour.\"\nJudges of provincial or inferior courts are traditionally referred to in person as \"Your Honour\". Judges of the Supreme Court of Canada and of the federal-level courts prefer the use of \"Mister/Madam (Chief) Justice\". Justices of The Peace are addressed as \"Your Worship\". \"Your Honour\" is also the correct form of address for a Lieutenant Governor.\nA serious crime is called an indictable offence, while a less-serious crime is called a summary conviction offence. The older words felony and misdemeanour, which are still used in the United States, are not used in Canada's current \"Criminal Code\" (R.S.C. 1985, c. C-46) or by today's Canadian legal system. As noted throughout the \"Criminal Code\", a person accused of a crime is called \"the accused\" and not \"the defendant\", a term used instead in civil lawsuits.\nIn Canada, \"visible minority\" refers to a non-aboriginal person or group visibly not one of the majority race in a given population. The term comes from the \"Canadian Employment Equity Act\", which defines such people as \"persons, other than Aboriginal people, who are non-Caucasian in race or non-white in colour.\" The term is used as a demographic category by Statistics Canada. The qualifier \"visible\" is used to distinguish such minorities from the \"invisible\" minorities determined by language (English vs. French) and certain distinctions in religion (Catholics vs. Protestants).\nA county in British Columbia means only a regional jurisdiction of the courts and justice system and is not otherwise connected to governance as with counties in other provinces and in the United States. The rough equivalent to \"county\" as used elsewhere is a \"Regional District\".\nPlaces.\nDistinctive Canadianisms are:\nDaily life.\nTerms common in Canada, Britain and Ireland but less frequent or nonexistent in the United States are:\nThe following are more or less distinctively Canadian:\nApparel.\nThe following are common in Canada, but not in the United States or the United Kingdom.\nOntario.\nNorthern Ontario English has several distinct qualities stemming from its large Franco-Ontarian population. As a result several French and English words are used interchangeably. A number of phrases and expressions may also be found in Northern Ontario that are not present in the rest of the province, such as the use of \"camp\" for a summer home where Southern Ontario speakers would idiomatically use cottage.\nIn the early 2010s, certain words from London slang, Jamaican Patois, and Arabic were incorporated into the local variety of English by Toronto youth, especially in immigrant communities, thus giving rise to Toronto slang. These examples included words such as \"mandem\", \"styll\", \"wallahi\", \"wasteman\", and \"yute\".\nInformal speech.\nOne of the most distinctive Canadian phrases is the spoken interrogation or tag \"eh\". The only usage of \"eh\" exclusive to Canada, according to the \"Canadian Oxford Dictionary\", is for \"ascertaining the comprehension, continued interest, agreement, etc., of the person or persons addressed\" as in, \"It's four kilometres away, eh, so I have to go by bike.\" In that case, \"eh?\" is used to confirm the attention of the listener and to invite a supportive noise such as \"mm\" or \"oh\" or \"okay\". This usage is also common in Queensland, Australia and New Zealand. Other uses of \"eh\"\u00a0\u2013 for instance, in place of \"huh?\" or \"what?\" meaning \"please repeat or say again\"\u00a0\u2013 are also found in parts of the British Isles and Australia. It is common in Northern/Central Ontario, the Maritimes and the Prairie provinces. The word \"eh\" is used quite frequently in the North Central dialect, so a Canadian accent is often perceived in people from North Dakota, Michigan, Minnesota, and Wisconsin.\nA \"rubber\" in the US and Canada is slang for a condom. In Canada, it sometimes means an eraser (as in the United Kingdom and Ireland).\nThe word \"bum\" can refer either to the buttocks (as in Britain), or to a homeless person (as in the US). The \"buttocks\" sense does not have the indecent character it retains in British use, as it and \"butt\" are commonly used as a polite or childish euphemism for ruder words such as \"arse\" (commonly used in Atlantic Canada and among older people in Ontario and to the west) or \"ass\", or \"mitiss\" (used in the Prairie Provinces, especially in northern and central Saskatchewan; probably originally a Cree loanword). Older Canadians may see \"bum\" as more polite than \"butt\", which before the 1980s was often considered rude.\nSimilarly the word \"pissed\" can refer either to being drunk (as in Britain), or being angry (as in the US), though anger is more often said as \"pissed off\", while \"piss drunk\" or \"pissed up\" is said to describe inebriation (though \"piss drunk\" is sometimes also used in the US, especially in the northern states).\nThe term \"Canuck\" simply means \"Canadian\" in its demonymic form, and, as a term used even by Canadians themselves, it is not considered derogatory. (In the 19th century and early 20th century it tended to refer to French-Canadians.) The only Canadian-built version of the popular World War I-era American Curtiss JN-4 \"Jenny\" training biplane aircraft, the JN-4C, 1,260 of which were built, got the \"Canuck\" nickname; so did another aircraft, the Fleet Model 80, built from the mid-1940s until the late 1950s. The nickname Janey Canuck was used by Anglophone women's rights writer Emily Murphy in the 1920s and the \"Johnny Canuck\" comic book character of the 1940s. Throughout the 1970s, Canada's winning World Cup men's downhill ski team was called the \"Crazy Canucks\" for their fearlessness on the slopes. It is also the name of the Vancouver Canucks, the National Hockey League team of Vancouver, British Columbia.\nThe term \"hoser\", popularized by Bob &amp; Doug McKenzie, typically refers to an uncouth, beer-swilling male and is a euphemism for \"loser\" coming from the earlier days of hockey played on an outdoor rink and the losing team would have to hose down the ice after the game so it froze smooth. Bob &amp; Doug also popularized the use of \"Beauty, eh\", another western slang term which may be used to describe something as being of interest or note or deserving approval. \nA \"Newf\" or \"Newfie\" is someone from Newfoundland and Labrador; sometimes considered derogatory. In Newfoundland, the term \"Mainlander\" refers to any Canadian (sometimes American, occasionally Labradorian) not from the island of Newfoundland. \"Mainlander\" is also occasionally used derogatorily.\nIn the Maritimes, a \"Caper\" or \"Cape Bretoner\" is someone from Cape Breton Island, a \"Bluenoser\" is someone with a thick, usually southern Nova Scotia accent or as a general term for a Nova Scotian (including Cape Bretoners), while an \"Islander\" is someone from Prince Edward Island (the same term is used in British Columbia for people from Vancouver Island, or the numerous islands along it). A \"Haligonian\" refers to someone from the city of Halifax.\nCape Bretoners and Newfies (from Newfoundland and Labrador) often have similar slang. \"Barmp\" is often used as the sound a car horn makes, example: \"He cut me off so I barmped the horn at him\". When saying \"B'y\", while sounds like the traditional farewell, it is a syncopated shortening of the word \"boy\", referring to a person, example: \"How's it goin, b'y?\". Another slang that is commonly used is \"doohickey\" which means an object, example: \"Pass me that doohickey over there\". When an individual uses the word \"biffed\", they mean that they threw something. Example: \"I got frustrated so I biffed it across the room\".\nSurvey and Research Methodology.\nIn language studies, there are three basic types of data collection: introspection, elicitation, and observation. Introspection relies on the idea that native speakers are the best judges of sentence structure and can provide valuable data, but it can be limiting because it only requires one native speaker. Elicitation requires more effort, but is a widespread technique used to gather linguistic structures by asking informants how they say certain things in their language. Observation is considered the \"gold standard\" by many linguists because it involves collecting utterances after the fact and systematically analyzing them. This can be done through corpora, which are collections of spoken or written text, but it's important to note that most corpus material today consists of written texts since they are more easily accessible. Variationist sociolinguistics aim to elicit data that is as natural and informal as possible, using techniques such as sociolinguistic interviews to gather different speech styles.\nThe use of written questionnaires (WQs) in dialectology were once popular for surveying language use, but fell out of favor before being re-examined in recent years. While they were once considered less effective than other survey methods, scholars have started to recognize their potential in social dialectology and variation studies. In the early 1950s, McDavid noted the value of using a lexical WQ for the Linguistic Atlas of Scotland, but later, Chambers and Trudgill stated that WQs were no longer the primary method of data-gathering. However, within the past 15 years, WQs have experienced renewed interest in social dialectology and variation studies. WQs can provide linguistic information about behavior and can be used for self-reporting or community reporting.\nScholars have used five types of questionnaires in sociolinguistics. Dollinger suggests a three-tiered WQ question typology. The first tier covers questions about regional language variation and social language variation. The second tier covers language perception and attitudes, while the third tier deals with acceptability judgments of grammaticality. The questions can be classified by subject area, type of reporting, and the type of information sought. This classification can help scholars better utilize WQs and understand their potential.\nWritten surveys are commonly used in dialectology as regional differences are less socially sensitive. However, they can still be used in sociolinguistics if handled properly. A survey's advantage is its quantitative approach since it is capable of collecting large amounts of data within a relatively short time. This would allow researchers to have a more robust statistical analysis and reliable or accurate conclusions about regional or social patterns. Despite its advantages, there are still disadvantages using surveys for a research study particularly in capturing natural speech patterns due to the observer's paradox. Through its unique format, surveys containing direct questions about language may not provide sufficient enough information on how often or in what social or linguistic contexts people use distinct language features. Therefore, by relying on systematic observations, local participants may adhere to perceived norms or expectations. While written surveys can provide valuable information about sociolinguistic variables in Canadian English, data gathered from surveys or questionnaires should not be perceived as equivalent to data gathered from the usage of actual speech. William Labov, a linguist, suggests that in order to solve this problem is to change the style of approach of surveys. Therefore, he suggests that researchers design sociolinguistic interviews that manipulate attention to speech. By comparing the speech among research participants when they are being directly questioned about language with their speech when talking about their personal experience, Labov could observe how the usage of language within different contexts or environments. This newly suggested approach allowed Labov to capture the \"vernacular\" which is the casual style of speech that people use within a day-to-day basis when they are not being observed.\nCanadian English dialectology examines Canadian English through the use of written surveys due to the vastness of the country and the difficulties of conducting face-to-face interviews on a nationwide level. The historical overview of written surveys in Canadian-English dialectology includes Avis's study of speech differences among the Ontario-United States borders through the use of questionnaires. Another example is the Survey of Canadian English directed by Scargill. A more recent example would be Nylvek's survey of Saskatchewan English and Chambers' trans-Canada dialect questionnaires.\nAttitudes.\nAn attitude study in the late 1970s revealed a positive attitude toward Canadian linguistic features. Features include front vowel merger before/r/, low-back vowel merger, Canadian Raising, and Canadian lexical items. Still, the sample group in British Columbia showed a preference for UK and US English.\nThis attitude sees a change years later. A survey about attitudes towards CE was conducted with a diverse sample group in Vancouver, BC, in 2009. Among 429 Vancouverites, 81.1% believe there is a Canadian way of speaking English, 72.9% can tell CanE speakers from American English speakers, 69.1% consider CanE a part of their Canadian identity, and 74.1% think CanE should be taught in schools. Due to the unavailability of free and easy-to-access CanE dictionaries, many Canadian opt for other non-Canadian English dictionaries today. Historically, American, British, and Irish texts are used in Canadian schools for the most part; even though Canadian reference work was written and became available in the 1960s, they were never preferred as teaching material.\nA preference change can be seen at the end of higher education in Canada. At the University of Toronto's Graduate English department, \"Canadian English\" and a \"consistent spelling\" are officially \"the standard for all Ph.D. dissertations,\" with the Canadian Oxford English Dictionary as the official guideline. However, there is no mention of which grammar guide was to be followed because there was never a solid standard developed for spelling and grammar.\nIn 2011, just under 21.5\u00a0million Canadians, representing 65% of the population, spoke English most of the time at home, while 58% declared it their mother language. English is the major language everywhere in Canada except Quebec, and most Canadians (85%) can speak English. While English is not the preferred language in Quebec, 36.1% of the Qu\u00e9b\u00e9cois can speak English. Nationally, Francophones are five times more likely to speak English than Anglophones are to speak French \u2013 44% and 9% respectively. Only 3.2% of Canada's English-speaking population resides in Quebec\u2014mostly in Montreal.\nA study conducted in 2002 inquired Canadians from Ontario and Alberta about the \"pleasantness\" and \"correctness\" of different varieties of Canadian English based on province. Albertans and Ontarians all seem to rate their English and BC English in the top three. However, both hold a low opinion of Quebec English. Unlike the assumption that Toronto or Ontario English would be the most prestigious considering these regions are the most economically robust, BC had the best public opinion regarding pleasantness and correctness among the participants.\nJaan Lilles argues in an essay for \"English Today\" that there is no variety of \"Canadian English\". According to Lilles, a former M.A. student, Canadian English is simply not a \"useful fiction\". He goes on to argue that too often supposedly unique features of Canadian speakers, such as certain lexical terms such as \"muskeg\" are artificially exaggerated to distinguish Canadian speech primarily from that found in the United States. Lilles was heavily critiqued in the next issue of \"English Today\" by lexicographer Fraser Sutherland and others. According to Stefan Dollinger, Lilles' paper \"is not a paper based on any data or other new information but more of a pamphlet \u2013 so much so that it should not have been published without a public critique\". He continues: \"The paper is insightful for different reasons: it is a powerful testimony of personal anecdote and opinion [...]. As an opinion piece, it offers a good debating case.\" As a linguistic account, however, it \"essentializes a prior state, before Canada was an independent political entity\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nDollinger, Stefan (2015). The Written Questionnaire in Social Dialectology: History, Theory, Practice. Amsterdam/Philadelphia: Benjamins. The book's examples are exclusive taken from Canadian English and represent one of the more extensive collections of variables for Canadian English.\nExternal links.\n The dictionary definition of \"Canadian English\" at Wiktionary"}
{"id": "6343", "revid": "17678816", "url": "https://en.wikipedia.org/wiki?curid=6343", "title": "Czech language", "text": "West Slavic language\nCzech (; Czech ]), historically also Bohemian (; \"lingua Bohemica\" in Latin), is a West Slavic language of the Czech\u2013Slovak group, written in Latin script. Spoken by over 10 million people, it serves as the official language of the Czech Republic. Czech is closely related to Slovak, to the point of high mutual intelligibility, as well as to Polish to a lesser degree. Czech is a fusional language with a rich system of morphology and relatively flexible word order. Its vocabulary has been extensively influenced by Latin and German.\nThe Czech\u2013Slovak group developed within West Slavic in the high medieval period, and the standardization of Czech and Slovak within the Czech\u2013Slovak dialect continuum emerged in the early modern period. In the later 18th to mid-19th century, the modern written standard became codified in the context of the Czech National Revival. The main non-standard variety, known as Common Czech, is based on the vernacular of Prague, but is now spoken as an interdialect throughout most of the Czech Republic. The Moravian dialects spoken in the eastern part of the country are also classified as Czech, although some of their eastern variants are closer to Slovak.\nCzech has a moderately-sized phoneme inventory, comprising ten monophthongs, three diphthongs and 25 consonants (divided into \"hard\", \"neutral\" and \"soft\" categories). Words may contain complicated consonant clusters or lack vowels altogether. Czech has a raised alveolar trill, which is known to occur as a phoneme in only a few other languages, represented by the grapheme \"\u0159\".\nClassification.\nCzech is a member of the West Slavic sub-branch of the Slavic branch of the Indo-European language family. This branch includes Polish, Kashubian, Upper and Lower Sorbian and Slovak. Slovak is the most closely related language to Czech, followed by Polish and Silesian.\nThe West Slavic languages are spoken in Central Europe. Czech is distinguished from other West Slavic languages by a more-restricted distinction between \"hard\" and \"soft\" consonants (see Phonology below).\nHistory.\nMedieval/Old Czech.\nThe term \"Old Czech\" is applied to the period predating the 16th century, with the earliest records of the high medieval period also classified as \"early Old Czech\", but the term \"Medieval Czech\" is also used. The function of the written language was initially performed by Old Slavonic written in Glagolitic, later by Latin written in Latin script. \nAround the 7th century, the Slavic expansion reached Central Europe, settling on the eastern fringes of the Frankish Empire. The West Slavic polity of Great Moravia formed by the 9th century. The Christianization of Bohemia took place during the 9th and 10th centuries. The diversification of the Czech-Slovak group within West Slavic began around that time, marked among other things by its use of the voiced velar fricative consonant (/\u0263/) and consistent stress on the first syllable.\nThe Bohemian (Czech) language is first recorded in writing in glosses and short notes during the 12th to 13th centuries. Literary works written in Czech appear in the late 13th and early 14th century and administrative documents first appear towards the late 14th century. The first complete Bible translation, the Leskovec-Dresden Bible, also dates to this period. Old Czech texts, including poetry and cookbooks, were also produced outside universities.\nLiterary activity becomes widespread in the early 15th century in the context of the Bohemian Reformation. Jan Hus contributed significantly to the standardization of Czech orthography, advocated for widespread literacy among Czech commoners (particularly in religion) and made early efforts to model written Czech after the spoken language.\nEarly Modern Czech.\nThere was no standardization distinguishing between Czech and Slovak prior to the 15th century. In the 16th century, the division between Czech and Slovak becomes apparent, marking the confessional division between Lutheran Protestants in Slovakia using Czech orthography and Catholics, especially Slovak Jesuits, beginning to use a separate Slovak orthography based on Western Slovak dialects.\nThe publication of the Kralice Bible between 1579 and 1593 (the first complete Czech translation of the Bible from the original languages) became very important for standardization of the Czech language in the following centuries as it was used as a model for the standard language.\nIn 1615, the Bohemian diet tried to declare Czech to be the only official language of the kingdom. After the Bohemian Revolt (of predominantly Protestant aristocracy) which was defeated by the Habsburgs in 1620, the Protestant intellectuals had to leave the country. This emigration together with other consequences of the Thirty Years' War had a negative impact on the further use of the Czech language. In 1627, Czech and German became official languages of the Kingdom of Bohemia and in the 18th century German became dominant in Bohemia and Moravia, especially among the upper classes.\nModern Czech.\nThe modern standard Czech language originates in standardization efforts of the 18th century. By then the language had developed a literary tradition, and since then it has changed little; journals from that period have no substantial differences from modern standard Czech, and contemporary Czechs can understand them with little difficulty. Sometime before the 18th century, the Czech language abandoned a distinction between phonemic /l/ and /\u028e/ which survives in Slovak.\nWith the beginning of the national revival of the mid-18th century, Czech historians began to emphasize their people's accomplishments from the 15th through the 17th centuries, rebelling against the Counter-Reformation (the Habsburg re-catholization efforts which had denigrated Czech and other non-Latin languages). Czech philologists studied sixteenth-century texts, advocating the return of the language to high culture. This period is known as the Czech National Revival (or Renaissance).\nDuring the national revival, in 1809 linguist and historian Josef Dobrovsk\u00fd released a German-language grammar of Old Czech entitled \"Ausf\u00fchrliches Lehrgeb\u00e4ude der b\u00f6hmischen Sprache\" (\"Comprehensive Doctrine of the Bohemian Language\"). Dobrovsk\u00fd had intended his book to be descriptive, and did not think Czech had a realistic chance of returning as a major language. However, Josef Jungmann and other revivalists used Dobrovsk\u00fd's book to advocate for a Czech linguistic revival. Changes during this time included spelling reform (notably, \"\u00ed\" in place of the former \"j\" and \"j\" in place of \"g\"), the use of \"t\" (rather than \"ti\") to end infinitive verbs and the non-capitalization of nouns (which had been a late borrowing from German). These changes differentiated Czech from Slovak. Modern scholars disagree about whether the conservative revivalists were motivated by nationalism or considered contemporary spoken Czech unsuitable for formal, widespread use.\nAdherence to historical patterns was later relaxed and standard Czech adopted a number of features from Common Czech (a widespread, informally used interdialectal variety), such as leaving some proper nouns undeclined. This has resulted in a relatively high level of homogeneity among all varieties of the language.\nGeographic distribution.\nCzech is spoken by about 10 million residents of the Czech Republic. A Eurobarometer survey conducted from January to March 2012 found that the first language of 98 percent of Czech citizens was Czech, the third-highest proportion of a population in the European Union (behind Greece and Hungary).\nAs the official language of the Czech Republic (a member of the European Union since 2004), Czech is one of the EU's official languages and the 2012 Eurobarometer survey found that Czech was the foreign language most often used in Slovakia. Economist Jonathan van Parys collected data on language knowledge in Europe for the 2012 European Day of Languages. The five countries with the greatest use of Czech were the Czech Republic (98.77 percent), Slovakia (24.86 percent), Portugal (1.93 percent), Poland (0.98 percent) and Germany (0.47 percent).\nCzech speakers in Slovakia primarily live in cities. Since it is a recognized minority language in Slovakia, Slovak citizens who speak only Czech may communicate with the government in their language to the extent that Slovak speakers in the Czech Republic may do so.\nUnited States.\nImmigration of Czechs from Europe to the United States occurred primarily from 1848 to 1914. Czech is a Less Commonly Taught Language in U.S. schools, and is taught at Czech heritage centers. Large communities of Czech Americans live in the states of Texas, Nebraska and Wisconsin. In the 2000 United States Census, Czech was reported as the commonest language spoken at home (besides English) in Valley, Butler and Saunders Counties, Nebraska and Republic County, Kansas. With the exception of Spanish (the non-English language most commonly spoken at home nationwide), Czech was the most common home language in more than a dozen additional counties in Nebraska, Kansas, Texas, North Dakota and Minnesota. As of 2009,[ [update]] 70,500 Americans spoke Czech as their first language (49th place nationwide, after Turkish and before Swedish).\nPhonology.\nVowels.\nStandard Czech contains ten basic vowel phonemes, and three diphthongs. The vowels are /a/, /\u025b/, /\u026a/, /o/, and /u/, and their long counterparts /a\u02d0/, /\u025b\u02d0/, /i\u02d0/, /o\u02d0/ and /u\u02d0/. The diphthongs are /ou\u032f/, /au\u032f/ and /\u025bu\u032f/; the last two are found only in loanwords such as \"car\" and \"euro\".\nIn Czech orthography, the vowels are spelled as follows:\nThe letter \u27e8\u011b\u27e9 indicates that the previous consonant is palatalised (e.g. /\u0272\u025bt\u0361so/). After a labial it represents /j\u025b/ (e.g. /bj\u025bs/); but \u27e8m\u011b\u27e9 is pronounced /m\u0272\u025b/, cf. (/m\u0272\u025bki\u02d0/).\nConsonants.\nThe consonant phonemes of Czech and their equivalent letters in Czech orthography are as follows:\nCzech consonants are categorized as \"hard\", \"neutral\", or \"soft\":\nHard consonants may not be followed by \"i\" or \"\u00ed\" in writing, or soft ones by \"y\" or \"\u00fd\" (except in loanwords such as \"kilogram\"). Neutral consonants may take either character. Hard consonants are sometimes known as \"strong\", and soft ones as \"weak\". This distinction is also relevant to the declension patterns of nouns, which vary according to whether the final consonant of the noun stem is hard or soft.\nVoiced consonants with unvoiced counterparts are unvoiced at the end of a word before a pause, and in consonant clusters voicing assimilation occurs, which matches voicing to the following consonant. The unvoiced counterpart of /\u0266/ is /x/.\nThe phoneme represented by the letter \"\u0159\" (capital \"\u0158\") is very rare among languages and often claimed to be unique to Czech, though it also occurs in some dialects of Kashubian, and formerly occurred in Polish. It represents the raised alveolar non-sonorant trill (IPA: [r\u031d]), a sound somewhere between Czech \"r\" and \"\u017e\" (example: ), and is present in \"Dvo\u0159\u00e1k\". In unvoiced environments, /r\u031d/ is realized as its voiceless allophone [r\u031d\u030a], a sound somewhere between Czech \"r\" and \"\u0161\".\nThe consonants /r/, /l/, and /m/ can be syllabic, acting as syllable nuclei in place of a vowel. \"Str\u010d prst skrz krk\" (\"Stick [your] finger through [your] throat\") is a well-known Czech tongue twister using syllabic consonants but no vowels.\nStress.\nEach word has primary stress on its first syllable, except for enclitics (minor, monosyllabic, unstressed syllables). In all words of more than two syllables, every odd-numbered syllable receives secondary stress. Stress is unrelated to vowel length; both long and short vowels can be stressed or unstressed. Vowels are never reduced in tone (e.g. to schwa sounds) when unstressed. When a noun is preceded by a monosyllabic preposition, the stress usually moves to the preposition, e.g. \"to Prague\".\nGrammar.\nCzech grammar, like that of other Slavic languages, is fusional; its nouns, verbs, and adjectives are inflected by phonological processes to modify their meanings and grammatical functions, and the easily separable affixes characteristic of agglutinative languages are limited. \nCzech inflects for case, gender and number in nouns and tense, aspect, mood, person and subject number and gender in verbs.\nParts of speech include adjectives, adverbs, numbers, interrogative words, prepositions, conjunctions and interjections. Adverbs are primarily formed from adjectives by taking the final \"\u00fd\" or \"\u00ed\" of the base form and replacing it with \"e\", \"\u011b\", \"y\", or \"o\". Negative statements are formed by adding the affix \"ne-\" to the main verb of a clause, with one exception: \"je\" (he, she or it is) becomes \"nen\u00ed\".\nSentence and clause structure.\nBecause Czech uses grammatical case to convey word function in a sentence (instead of relying on word order, as English does), its word order is flexible. As a pro-drop language, in Czech an intransitive sentence can consist of only a verb; information about its subject is encoded in the verb. Enclitics (primarily auxiliary verbs and pronouns) appear in the second syntactic slot of a sentence, after the first stressed unit. The first slot can contain a subject or object, a main form of a verb, an adverb, or a conjunction (except for the light conjunctions \"a\", \"and\", \"i\", \"and even\" or \"ale\", \"but\").\nCzech syntax has a subject\u2013verb\u2013object sentence structure. In practice, however, word order is flexible and used to distinguish topic and focus, with the topic or theme (known referents) preceding the focus or rheme (new information) in a sentence; Czech has therefore been described as a topic-prominent language. Although Czech has a periphrastic passive construction (like English), in colloquial style, word-order changes frequently replace the passive voice. For example, to change \"Peter killed Paul\" to \"Paul was killed by Peter\" the order of subject and object is inverted: \"Petr zabil Pavla\" (\"Peter killed Paul\") becomes \"Paul, Peter killed\" (\"Pavla zabil Petr\"). \"Pavla\" is in the accusative case, the grammatical object of the verb.\nA word at the end of a clause is typically emphasized, unless an upward intonation indicates that the sentence is a question:\nIn parts of Bohemia (including Prague), questions such as \"J\u00ed pes bagetu?\" without an interrogative word (such as \"co\", \"what\" or \"kdo\", \"who\") are intoned in a slow rise from low to high, quickly dropping to low on the last word or phrase.\nIn modern Czech syntax, adjectives precede nouns, with few exceptions. Relative clauses are introduced by relativizers such as the adjective \"kter\u00fd\", analogous to the English relative pronouns \"which\", \"that\" and \"who\"/\"whom\". As with other adjectives, it agrees with its associated noun in gender, number and case. Relative clauses follow the noun they modify. The following is a glossed example:\nDeclension.\nIn Czech, nouns and adjectives are declined into one of seven grammatical cases which indicate their function in a sentence, two numbers (singular and plural) and three genders (masculine, feminine and neuter). The masculine gender is further divided into animate and inanimate classes.\nCase.\nA nominative\u2013accusative language, Czech marks subject nouns of transitive and intransitive verbs in the nominative case, which is the form found in dictionaries, and direct objects of transitive verbs are declined in the accusative case. The vocative case is used to address people. The remaining cases (genitive, dative, locative and instrumental) indicate semantic relationships, such as noun adjuncts (genitive), indirect objects (dative), or agents in passive constructions (instrumental). Additionally prepositions and some verbs require their complements to be declined in a certain case. The locative case is only used after prepositions. An adjective's case agrees with that of the noun it modifies. When Czech children learn their language's declension patterns, the cases are referred to by number: \nSome prepositions require the nouns they modify to take a particular case. The cases assigned by each preposition are based on the physical (or metaphorical) direction, or location, conveyed by it. For example, \"od\" (from, away from) and \"z\" (out of, off) assign the genitive case. Other prepositions take one of several cases, with their meaning dependent on the case; \"na\" means \"onto\" or \"for\" with the accusative case, but \"on\" with the locative.\nThis is a glossed example of a sentence using several cases:\nGender.\nCzech distinguishes three genders\u2014masculine, feminine, and neuter\u2014and the masculine gender is subdivided into animate and inanimate. With few exceptions, feminine nouns in the nominative case end in \"-a\", \"-e\", or a consonant; neuter nouns in \"-o\", \"-e\", or \"-\u00ed\", and masculine nouns in a consonant. Adjectives, participles, most pronouns, and the numbers \"one\" and \"two\" are marked for gender and agree with the gender of the noun they modify or refer to. Past tense verbs are also marked for gender, agreeing with the gender of the subject, e.g. \"d\u011blal\" (he did, or made); \"d\u011blala\" (she did, or made) and \"d\u011blalo\" (it did, or made). Gender also plays a semantic role; most nouns that describe people and animals, including personal names, have separate masculine and feminine forms which are normally formed by adding a suffix to the stem, for example \"\u010cech\" (Czech man) has the feminine form \"\u010ce\u0161ka\" (Czech woman).\nNouns of different genders follow different declension patterns. Examples of declension patterns for noun phrases of various genders follow:\nNumber.\nNouns are also inflected for number, distinguishing between singular and plural. Typical of a Slavic language, Czech cardinal numbers one through four allow the nouns and adjectives they modify to take any case, but numbers over five require subject and direct object noun phrases to be declined in the genitive plural instead of the nominative or accusative, and when used as subjects these phrases take singular verbs. For example:\nNumbers decline for case, and the numbers one and two are also inflected for gender. Numbers one through five are shown below as examples. The number one has declension patterns identical to those of the demonstrative pronoun \"ten\".\nAlthough Czech's grammatical numbers are singular and plural, several residuals of dual forms remain, such as the words \"dva\" (\"two\") and \"oba\" (\"both\"), which decline the same way. Some nouns for paired body parts use a historical dual form to express plural in some cases: \"ruka\" (hand)\u2014\"ruce\" (nominative); \"noha\" (leg)\u2014\"nohama\" (instrumental), \"nohou\" (genitive/locative); \"oko\" (eye)\u2014\"o\u010di\", and \"ucho\" (ear)\u2014\"u\u0161i\". While two of these nouns are neuter in their singular forms, all plural forms are considered feminine; their gender is relevant to their associated adjectives and verbs. These forms are plural semantically, used for any non-singular count, as in \"mezi \u010dty\u0159ma o\u010dima\" (face to face, lit. \"among four eyes\"). The plural number paradigms of these nouns are a mixture of historical dual and plural forms. For example, \"nohy\" (legs; nominative/accusative) is a standard plural form of this type of noun.\nVerb conjugation.\nCzech verbs agree with their subjects in person (first, second or third), number (singular or plural), and in constructions involving participles, which includes the past tense, also in gender. They are conjugated for tense (past, present or future) and mood (indicative, imperative or conditional). For example, the conjugated verb \"mluv\u00edme\" (we speak) is in the present tense and first-person plural; it is distinguished from other conjugations of the infinitive \"mluvit\" by its ending, \"-\u00edme\". The infinitive form of Czech verbs ends in \"-t\" (archaically, \"-ti\" or \"-ci\"). It is the form found in dictionaries and the form that follows auxiliary verbs (for example, \"m\u016f\u017eu t\u011b sly\u0161et\"\u2014\"I can \"hear\" you\").\nAspect.\nTypical of Slavic languages, Czech marks its verbs for one of two grammatical aspects: perfective and imperfective. Most verbs are part of inflected aspect pairs\u2014for example, \"koupit\" (perfective) and \"kupovat\" (imperfective). Although the verbs' meaning is similar, in perfective verbs the action is completed and in imperfective verbs it is ongoing or repeated. This is distinct from past and present tense. Any verb of either aspect can be conjugated into either the past or present tense, but the future tense is only used with imperfective verbs. Aspect describes the state of the action at the time specified by the tense.\nThe verbs of most aspect pairs differ in one of two ways: by prefix or by suffix. In prefix pairs, the perfective verb has an added prefix\u2014for example, the imperfective \"ps\u00e1t\" (to write, to be writing) compared with the perfective \"napsat\" (to write down). The most common prefixes are \"na-\", \"o-\", \"po-\", \"s-\", \"u-\", \"vy-\", \"z-\" and \"za-\". In suffix pairs, a different infinitive ending is added to the perfective stem; for example, the perfective verbs \"koupit\" (to buy) and \"prodat\" (to sell) have the imperfective forms \"kupovat\" and \"prod\u00e1vat\". Imperfective verbs may undergo further morphology to make other imperfective verbs (iterative and frequentative forms), denoting repeated or regular action. The verb \"j\u00edt\" (to go) has the iterative form \"chodit\" (to go regularly) and the frequentative form \"chod\u00edvat\" (to go occasionally; to tend to go).\nMany verbs have only one aspect, and verbs describing continual states of being\u2014\"b\u00fdt\" (to be), \"cht\u00edt\" (to want), \"moct\" (to be able to), \"le\u017eet\" (to lie down, to be lying down)\u2014have no perfective form. Conversely, verbs describing immediate states of change\u2014for example, \"ot\u011bhotn\u011bt\" (to become pregnant) and \"nadchnout se\" (to become enthusiastic)\u2014have no imperfective aspect.\nTense.\nThe present tense in Czech is formed by adding an ending that agrees with the person and number of the subject at the end of the verb stem. As Czech is a null-subject language, the subject pronoun can be omitted unless it is needed for clarity. The past tense is formed using a participle which ends in \"-l\" and a further ending which agrees with the gender and number of the subject. For the first and second persons, the auxiliary verb \"b\u00fdt\" conjugated in the present tense is added.\nIn some contexts, the present tense of perfective verbs (which differs from the English present perfect) implies future action; in others, it connotes habitual action. The perfective present is used to refer to completion of actions in the future and is distinguished from the imperfective future tense, which refers to actions that will be ongoing in the future. The future tense is regularly formed using the future conjugation of \"b\u00fdt\" (as shown in the table on the left) and the infinitive of an imperfective verb, for example, \"budu j\u00edst\"\u2014\"I will eat\" or \"I will be eating\". Where \"budu\" has a noun or adjective complement it means \"I will be\", for example, \"budu \u0161\u0165astn\u00fd\" (I will be happy). Some verbs of movement form their future tense by adding the prefix \"po-\" to the present tense forms instead, e.g. \"jedu\" (\"I go\") &gt; \"pojedu\" (\"I will go\").\nMood.\nCzech verbs have three grammatical moods: indicative, imperative and conditional. The imperative mood is formed by adding specific endings for each of three person\u2013number categories: \"-\u00d8/-i/-ej\" for second-person singular, \"-te/-ete/-ejte\" for second-person plural and \"-me/-eme/-ejme\" for first-person plural. Imperatives are usually expressed using perfective verbs if positive and imperfective verbs if negative. The conditional mood is formed with a conditional auxiliary verb after the participle ending in -l which is used to form the past tense. This mood indicates hypothetical events and can also be used to express wishes.\nVerb classes.\nMost Czech verbs fall into one of five classes, which determine their conjugation patterns. The future tense of \"b\u00fdt\" would be classified as a Class I verb because of its endings. Examples of the present tense of each class and some common irregular verbs follow in the tables below:\nOrthography.\nCzech has one of the most phonemic orthographies of all European languages. Its alphabet contains 42 graphemes, most of which correspond to individual phonemes, and only contains only one digraph: \"ch\", which follows \"h\" in the alphabet. The characters \"q\", \"w\" and \"x\" appear only in foreign words. The h\u00e1\u010dek (\u02c7) is used with certain letters to form new characters: \"\u0161\", \"\u017e\", and \"\u010d\", as well as \"\u0148\", \"\u011b\", \"\u0159\", \"\u0165\", and \"\u010f\" (the latter five uncommon outside Czech). The last two letters are sometimes written with a comma above (\u02bc, an abbreviated h\u00e1\u010dek) because of their height. Czech orthography has influenced the orthographies of other Balto-Slavic languages and some of its characters have been adopted for transliteration of Cyrillic.\nCzech orthography reflects vowel length; long vowels are indicated by an acute accent or, in the case of the character \"\u016f\", a ring. Long \"u\" is usually written \"\u00fa\" at the beginning of a word or morpheme (\"\u00faroda\", \"ne\u00farodn\u00fd\") and \"\u016f\" elsewhere, except for loanwords (\"sk\u00fatr\") or onomatopoeia (\"b\u00fa\"). Long vowels and \"\u011b\" are not considered separate letters in the alphabetical order. The character \"\u00f3\" exists only in loanwords and onomatopoeia.\nCzech typographical features not associated with phonetics generally resemble those of most European languages that use the Latin script, including English. Proper nouns, honorifics, and the first letters of quotations are capitalized, and punctuation is typical of other Latin European languages. Ordinal numbers (1st) use a point, as in German (1.). The Czech language uses a decimal comma instead of a decimal point. When writing a long number, spaces between every three digits, including those in decimal places, may be used for better orientation in handwritten texts. The number 1,234,567.89101 may be written as 1234567,89101 or 1 234 567,891 01. In proper noun phrases (except personal and settlement names), only the first word and proper nouns inside such phrases are capitalized (\"Pra\u017esk\u00fd hrad\", Prague Castle).\nVarieties.\nThe modern literary standard and prestige variety, known as \"Standard Czech\" () is based on the standardization during the Czech National Revival in the 1830s, significantly influenced by Josef Jungmann's Czech\u2013German dictionary published during 1834\u20131839. Jungmann used vocabulary of the Bible of Kralice (1579\u20131613) period and of the language used by his contemporaries. He borrowed words not present in Czech from other Slavic languages or created neologisms. Standard Czech is the formal register of the language which is used in official documents, formal literature, newspaper articles, education and occasionally public speeches. It is codified by the Czech Language Institute, who publish occasional reforms to the codification. The most recent reform took place in 1993. The term (lit. \"Colloquial Czech\") is sometimes used to refer to the spoken variety of standard Czech.\nThe most widely spoken vernacular form of the language is called \"Common Czech\" (), an interdialect influenced by spoken Standard Czech and the Central Bohemian dialects of the Prague region. Other Bohemian regional dialects have become marginalized, while Moravian dialects remain more widespread and diverse, with a political movement for Moravian linguistic revival active since the 1990s.\nThese varieties of the language (Standard Czech, spoken/colloquial Standard Czech, Common Czech, and regional dialects) form a stylistic continuum, in which contact between varieties of a similar prestige influences change within them.\nCommon Czech.\nThe main Czech vernacular, spoken primarily in Bohemia including the capital Prague, is known as Common Czech (\"obecn\u00e1 \u010de\u0161tina\"). This is an academic distinction; most Czechs are unaware of the term or associate it with deformed or \"incorrect\" Czech. Compared to Standard Czech, Common Czech is characterized by simpler inflection patterns and differences in sound distribution.\nCommon Czech is distinguished from spoken/colloquial Standard Czech (), which is a stylistic variety within standard Czech. Tomasz Kamusella defines the spoken variety of Standard Czech as a compromise between Common Czech and the written standard, while Miroslav Kom\u00e1rek calls Common Czech an intersection of spoken Standard Czech and regional dialects.\nCommon Czech has become ubiquitous in most parts of the Czech Republic since the later 20th century. It is usually defined as an interdialect used in common speech in Bohemia and western parts of Moravia (by about two thirds of all inhabitants of the Czech Republic). Common Czech is not codified, but some of its elements have become adopted in the written standard. Since the second half of the 20th century, Common Czech elements have also been spreading to regions previously unaffected, as a consequence of media influence. Standard Czech is still the norm for politicians, businesspeople and other Czechs in formal situations, but Common Czech is gaining ground in journalism and the mass media. The colloquial form of Standard Czech finds limited use in daily communication due to the expansion of the Common Czech interdialect. It is sometimes defined as a theoretical construct rather than an actual tool of colloquial communication, since in casual contexts, the non-standard interdialect is preferred.\nCommon Czech phonology is based on that of the Central Bohemian dialect group, which has a slightly different set of vowel phonemes to Standard Czech. The phoneme /\u025b\u02d0/ is peripheral and usually merges with /i\u02d0/, e.g. in \"mal\u00fd m\u011bsto\" (small town), \"plam\u00ednek\" (little flame) and \"l\u00edtat\" (to fly), and a second native diphthong /\u025b\u026a\u032f/ occurs, usually in places where Standard Czech has /i\u02d0/, e.g. \"malej d\u016fm\" (small house), \"mlejn\" (mill), \"plejtvat\" (to waste), \"bejt\" (to be). In addition, a prothetic \"v-\" is added to most words beginning \"o-\", such as \"votev\u0159\u00edt vokno\" (to open the window).\nNon-standard morphological features that are more or less common among all Common Czech speakers include:\nExamples of declension (Standard Czech is added in italics for comparison):\n\"mlad\u00fd \u010dlov\u011bk \u2013 young man/person, mlad\u00ed lid\u00e9 \u2013 young people, mlad\u00fd st\u00e1t \u2013 young state, mlad\u00e1 \u017eena \u2013 young woman, mlad\u00e9 zv\u00ed\u0159e \u2013 young animal\"\nBohemian dialects.\nApart from the Common Czech vernacular, there remain a variety of other Bohemian dialects, mostly in marginal rural areas. Dialect use began to weaken in the second half of the 20th century, and by the early 1990s regional dialect use was stigmatized, associated with the shrinking lower class and used in literature or other media for comedic effect. Increased travel and media availability to dialect-speaking populations has encouraged them to shift to (or add to their own dialect) Standard Czech.\nThe Czech Statistical Office in 2003 recognized the following Bohemian dialects:\n*\"Podskupina chodsk\u00e1\" (Chod subgroup)\n*\"Podskupina doudlebsk\u00e1\" (Doudleby subgroup)\n*\"Podskupina podkrkno\u0161sk\u00e1\" (Krkono\u0161e subgroup)\nMoravian dialects.\nThe Czech dialects spoken in Moravia and Silesia are known as Moravian (\"morav\u0161tina\"). In the Austro-Hungarian Empire, \"Bohemian-Moravian-Slovak\" was a language citizens could register as speaking (with German, Polish and several others). In the 2011 census, where respondents could optionally specify up to two first languages, 62,908 Czech citizens specified Moravian as their first language and 45,561 specified both Moravian and Czech.\nBeginning in the sixteenth century, some varieties of Czech resembled Slovak; the southeastern Moravian dialects, in particular, are sometimes considered dialects of Slovak rather than Czech. These dialects form a continuum between the Czech and Slovak languages, using the same declension patterns for nouns and pronouns and the same verb conjugations as Slovak.\nThe Czech Statistical Office in 2003 recognized the following Moravian dialects:\n*\"Podskupina ti\u0161novsk\u00e1\" (Ti\u0161nov subgroup)\n*\"Podskupina slov\u00e1ck\u00e1\" (Moravian Slovak subgroup)\n*\"Podskupina vala\u0161sk\u00e1\" (Moravian Wallachian subgroup)\nSample.\nIn a 1964 textbook on Czech dialectology, B\u0159etislav Koudela used the following sentence to highlight phonetic differences between dialects:\nMutual intelligibility with Slovak.\nCzech and Slovak have been considered mutually intelligible; speakers of either language can communicate with greater ease than those of any other pair of West Slavic languages. Following the 1993 dissolution of Czechoslovakia, mutual intelligibility declined for younger speakers, probably because Czech speakers began to experience less exposure to Slovak and vice versa. A 2015 study involving participants with a mean age of around 23 nonetheless concluded that there remained a high degree of mutual intelligibility between the two languages. Grammatically, both languages share a common syntax.\nOne study showed that Czech and Slovak lexicons differed by 80 percent, but this high percentage was found to stem primarily from differing orthographies and slight inconsistencies in morphological formation; Slovak morphology is more regular (when changing from the nominative to the locative case, \"Praha\" becomes \"Praze\" in Czech and \"Prahe\" in Slovak). The two lexicons are generally considered similar, with most differences found in colloquial vocabulary and some scientific terminology. Slovak has slightly more borrowed words than Czech.\nThe similarities between Czech and Slovak led to the languages being considered a single language by a group of 19th-century scholars who called themselves \"Czechoslavs\" (\"\u010cechoslovan\u00e9\"), believing that the peoples were connected in a way which excluded German Bohemians and (to a lesser extent) Hungarians and other Slavs. During the First Czechoslovak Republic (1918\u20131938), although \"Czechoslovak\" was designated as the republic's official language, both Czech and Slovak written standards were used. Standard written Slovak was partially modeled on literary Czech, and Czech was preferred for some official functions in the Slovak half of the republic. Czech influence on Slovak was protested by Slovak scholars, and when Slovakia broke off from Czechoslovakia in 1938 as the Slovak State (which then aligned with Nazi Germany in World War II), literary Slovak was deliberately distanced from Czech. When the Axis powers lost the war and Czechoslovakia reformed, Slovak developed somewhat on its own (with Czech influence); during the Prague Spring of 1968, Slovak gained independence from (and equality with) Czech, due to the transformation of Czechoslovakia from a unitary state to a federation. Since the dissolution of Czechoslovakia in 1993, \"Czechoslovak\" has referred to improvised pidgins of the languages which have arisen from the decrease in mutual intelligibility.\nVocabulary.\nCzech vocabulary derives primarily from Slavic, Baltic and other Indo-European roots. Although most verbs have Balto-Slavic origins, pronouns, prepositions and some verbs have wider, Indo-European roots. Some loanwords have been restructured by folk etymology to resemble native Czech words (e.g. \"h\u0159bitov\", \"graveyard\" and \"listina\", \"list\").\nMost Czech loanwords originated in one of two time periods. Earlier loanwords, primarily from German, Greek and Latin, arrived before the Czech National Revival. More recent loanwords derive primarily from English and French, and also from Hebrew, Arabic and Persian. Many Russian loanwords, principally animal names and naval terms, also exist in Czech.\nAlthough older German loanwords were colloquial, recent borrowings from other languages are associated with high culture. During the nineteenth century, words with Greek and Latin roots were rejected in favor of those based on older Czech words and common Slavic roots; \"music\" is \"muzyka\" in Polish and \"\u043c\u0443\u0437\u044b\u043a\u0430\" (\"muzyka\") in Russian, but in Czech it is \"hudba\". Some Czech words have been borrowed as loanwords into English and other languages\u2014for example, \"robot\" (from \"robota\", \"labor\") and \"polka\" (from \"polka\", \"Polish woman\" or from \"p\u016flka\" \"half\").\nExample text.\nArticle 1 of the \"Universal Declaration of Human Rights\" in Czech:\n\"V\u0161ichni lid\u00e9 rod\u00ed se svobodn\u00ed a sob\u011b rovn\u00ed co do d\u016fstojnosti a pr\u00e1v. Jsou nad\u00e1ni rozumem a sv\u011bdom\u00edm a maj\u00ed spolu jednat v duchu bratrstv\u00ed.\"\nArticle 1 of the \"Universal Declaration of Human Rights\" in English:\n\"All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6344", "revid": "6334945", "url": "https://en.wikipedia.org/wiki?curid=6344", "title": "Capsid", "text": "Protein shell of a virus\nA capsid is the protein shell of a virus, enclosing its genetic material. It consists of several oligomeric (repeating) structural subunits made of protein called protomers. The observable 3-dimensional morphological subunits, which may or may not correspond to individual proteins, are called capsomeres. The proteins making up the capsid are called capsid proteins or viral coat proteins (VCP). The capsid and inner genome is called the nucleocapsid.\nCapsids are broadly classified according to their structure. The majority of the viruses have capsids with either helical or icosahedral structure. Some viruses, such as bacteriophages, have developed more complicated structures due to constraints of elasticity and electrostatics. The icosahedral shape, which has 20 equilateral triangular faces, approximates a sphere, while the helical shape resembles the shape of a spring, taking the space of a cylinder but not being a cylinder itself. The capsid faces may consist of one or more proteins. For example, the foot-and-mouth disease virus capsid has faces consisting of three proteins named VP1\u20133.\nSome viruses are \"enveloped\", meaning that the capsid is coated with a lipid membrane known as the viral envelope. The envelope is acquired by the capsid from an intracellular membrane in the virus' host; examples include the inner nuclear membrane, the Golgi membrane, and the cell's outer membrane.\nOnce the virus has infected a cell and begins replicating itself, new capsid subunits are synthesized using the protein biosynthesis mechanism of the cell. In some viruses, including those with helical capsids and especially those with RNA genomes, the capsid proteins co-assemble with their genomes. In other viruses, especially more complex viruses with double-stranded DNA genomes, the capsid proteins assemble into empty precursor procapsids that include a specialized portal structure at one vertex. Through this portal, viral DNA is translocated into the capsid.\nStructural analyses of major capsid protein (MCP) architectures have been used to categorise viruses into lineages. For example, the bacteriophage PRD1, the algal virus \"Paramecium bursaria Chlorella virus-1\" (PBCV-1), mimivirus and the mammalian adenovirus have been placed in the same lineage, whereas tailed, double-stranded DNA bacteriophages (\"Caudovirales\") and herpesvirus belong to a second lineage.\nSpecific shapes.\nIcosahedral.\nThe icosahedral structure is extremely common among viruses. The icosahedron consists of 20 triangular faces delimited by 12 fivefold vertexes and consists of 60 asymmetric units. Thus, an icosahedral virus is made of 60N protein subunits. The number and arrangement of capsomeres in an icosahedral capsid can be classified using the \"quasi-equivalence principle\" proposed by Donald Caspar and Aaron Klug. Like the Goldberg polyhedra, an icosahedral structure can be regarded as being constructed from pentamers and hexamers. The structures can be indexed by two integers \"h\" and \"k\", with formula_1 and formula_2; the structure can be thought of as taking \"h\" steps from the edge of a pentamer, turning 60 degrees counterclockwise, then taking \"k\" steps to get to the next pentamer. The triangulation number \"T\" for the capsid is defined as:\nformula_3\nIn this scheme, icosahedral capsids contain 12 pentamers plus 10(\"T\"\u00a0\u2212\u00a01) hexamers. The \"T\"-number is representative of the size and complexity of the capsids. Geometric examples for many values of \"h\", \"k\", and \"T\" can be found at List of geodesic polyhedra and Goldberg polyhedra.\nMany exceptions to this rule exist: For example, the polyomaviruses and papillomaviruses have pentamers instead of hexamers in hexavalent positions on a quasi T = 7 lattice. Members of the double-stranded RNA virus lineage, including reovirus, rotavirus and bacteriophage \u03c66 have capsids built of 120 copies of capsid protein, corresponding to a T = 2 capsid, or arguably a T = 1 capsid with a dimer in the asymmetric unit. Similarly, many small viruses have a pseudo T = 3 (or P = 3) capsid, which is organized according to a T = 3 lattice, but with distinct polypeptides occupying the three quasi-equivalent positions \nT-numbers can be represented in different ways, for example \"T\"\u00a0=\u00a01 can only be represented as an icosahedron or a dodecahedron and, depending on the type of quasi-symmetry, \"T\"\u00a0=\u00a03 can be presented as a truncated dodecahedron, an icosidodecahedron, or a truncated icosahedron and their respective duals a triakis icosahedron, a rhombic triacontahedron, or a pentakis dodecahedron.\nProlate.\nAn elongated icosahedron is a common shape for the heads of bacteriophages. Such a structure is composed of a cylinder with a cap at either end. The cylinder is composed of 10 elongated triangular faces. The Q number (or Tmid), which can be any positive integer, specifies the number of triangles, composed of asymmetric subunits, that make up the 10 triangles of the cylinder. The caps are classified by the T (or Tend) number.\nThe bacterium \"E. coli\" is the host for bacteriophage T4 that has a prolate head structure. The bacteriophage encoded gp31 protein appears to be functionally homologous to \"E. coli\" chaperone protein GroES and able to substitute for it in the assembly of bacteriophage T4 virions during infection. Like GroES, gp31 forms a stable complex with GroEL chaperonin that is absolutely necessary for the folding and assembly \"in vivo\" of the bacteriophage T4 major capsid protein gp23.\nHelical.\nMany rod-shaped and filamentous plant viruses have capsids with helical symmetry. The helical structure can be described as a set of \"n\" 1-D molecular helices related by an \"n\"-fold axial symmetry. The helical transformation are classified into two categories: one-dimensional and two-dimensional helical systems. Creating an entire helical structure relies on a set of translational and rotational matrices which are coded in the protein data bank. Helical symmetry is given by the formula \"P\"\u00a0=\u00a0\"\u03bc\"\u00a0x\u00a0\"\u03c1\", where \"\u03bc\" is the number of structural units per turn of the helix, \"\u03c1\" is the axial rise per unit and \"P\" is the pitch of the helix. The structure is said to be open due to the characteristic that any volume can be enclosed by varying the length of the helix. The most understood helical virus is the tobacco mosaic virus. The virus is a single molecule of (+) strand RNA. Each coat protein on the interior of the helix bind three nucleotides of the RNA genome. Influenza A viruses differ by comprising multiple ribonucleoproteins, the viral NP protein organizes the RNA into a helical structure. The size is also different; the tobacco mosaic virus has a 16.33 protein subunits per helical turn, while the influenza A virus has a 28 amino acid tail loop.\nFunctions.\nThe functions of the capsid are to:\nThe virus must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents. These include extremes of pH or temperature and proteolytic and nucleolytic enzymes. For non-enveloped viruses, the capsid itself may be involved in interaction with receptors on the host cell, leading to penetration of the host cell membrane and internalization of the capsid. Delivery of the genome occurs by subsequent uncoating or disassembly of the capsid and release of the genome into the cytoplasm, or by ejection of the genome through a specialized portal structure directly into the host cell nucleus.\nOrigin and evolution.\nIt has been suggested that many viral capsid proteins have evolved on multiple occasions from functionally diverse cellular proteins. The recruitment of cellular proteins appears to have occurred at different stages of evolution so that some cellular proteins were captured and refunctionalized prior to the divergence of cellular organisms into the three contemporary domains of life, whereas others were hijacked relatively recently. As a result, some capsid proteins are widespread in viruses infecting distantly related organisms (e.g., capsid proteins with the jelly-roll fold), whereas others are restricted to a particular group of viruses (e.g., capsid proteins of alphaviruses).\nA computational model (2015) has shown that capsids may have originated before viruses and that they served as a means of horizontal transfer between replicator communities since these communities could not survive if the number of gene parasites increased, with certain genes being responsible for the formation of these structures and those that favored the survival of self-replicating communities. The displacement of these ancestral genes between cellular organisms could favor the appearance of new viruses during evolution.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "6345", "revid": "5364", "url": "https://en.wikipedia.org/wiki?curid=6345", "title": "Central Dogma Of Genetics", "text": ""}
{"id": "6346", "revid": "18040497", "url": "https://en.wikipedia.org/wiki?curid=6346", "title": "Chloramphenicol", "text": "Antibiotic\nChloramphenicol is an antibiotic useful for the treatment of a number of bacterial infections. This includes use as an eye ointment to treat conjunctivitis. By mouth or by injection into a vein, it is used to treat meningitis, plague, cholera, and typhoid fever. Its use by mouth or by injection is only recommended when safer antibiotics cannot be used. Monitoring both blood levels of the medication and blood cell levels every two days is recommended during treatment.\nCommon side effects include bone marrow suppression, nausea, and diarrhea. The bone marrow suppression may result in death. To reduce the risk of side effects treatment duration should be as short as possible. People with liver or kidney problems may need lower doses. In young children a condition known as gray baby syndrome may occur which results in a swollen stomach and low blood pressure. Its use near the end of pregnancy and during breastfeeding is typically not recommended. Chloramphenicol is a broad-spectrum antibiotic that typically stops bacterial growth by stopping the production of proteins.\nChloramphenicol was discovered after being isolated from \"Streptomyces venezuelae\" in 1947. Its chemical structure was identified and it was first synthesized in 1949. It is on the World Health Organization's List of Essential Medicines. It is available as a generic medication.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nMedical uses.\nThe original indication of chloramphenicol was in the treatment of typhoid, but the presence of multiple drug-resistant \"Salmonella\" Typhi has meant it is seldom used for this indication except when the organism is known to be sensitive.\nIn low-income countries, the WHO no longer recommends only chloramphenicol as first-line to treat meningitis, but recognises it may be used with caution if there are no available alternatives.\nDuring the last decade chloramphenicol has been re-evaluated as an old agent with potential against systemic infections due to multidrug-resistant gram positive microorganisms (including vancomycin resistant enterococci). \"In vitro\" data have shown an activity against the majority (&gt; 80%) of vancomycin resistant \"E. faecium\" strains.\nIn the context of preventing endophthalmitis, a complication of cataract surgery, a 2017 systematic review found moderate evidence that using chloramphenicol eye drops in addition to an antibiotic injection (cefuroxime or penicillin) will likely lower the risk of endophthalmitis, compared to eye drops or antibiotic injections alone.\nSpectrum.\nChloramphenicol has a broad spectrum of activity and has been effective in treating ocular infections such as conjunctivitis, blepharitis etc. caused by a number of bacteria including \"Staphylococcus aureus, Streptococcus pneumoniae\", and \"Escherichia coli\". It is not effective against \"Pseudomonas aeruginosa\". The following susceptibility data represent the minimum inhibitory concentration for a few medically significant organisms.\nEach of these concentrations is dependent upon the bacterial strain being targeted. Some strains of \"E. coli\", for example, show spontaneous emergence of chloramphenicol resistance.\nResistance.\nThree mechanisms of resistance to chloramphenicol are known: reduced membrane permeability, mutation of the 50S ribosomal subunit, and elaboration of chloramphenicol acetyltransferase. It is easy to select for reduced membrane permeability to chloramphenicol \"in vitro\" by serial passage of bacteria, and this is the most common mechanism of low-level chloramphenicol resistance. High-level resistance is conferred by the \"cat\"-gene; this gene codes for an enzyme called chloramphenicol acetyltransferase, which inactivates chloramphenicol by covalently linking one or two acetyl groups, derived from acetyl-\"S\"-coenzyme A, to the hydroxyl groups on the chloramphenicol molecule. The acetylation prevents chloramphenicol from binding to the ribosome. Resistance-conferring mutations of the 50S ribosomal subunit are rare.\nChloramphenicol resistance may be carried on a plasmid that also codes for resistance to other drugs. One example is the ACCoT plasmid (A=ampicillin, C=chloramphenicol, Co=co-trimoxazole, T=tetracycline), which mediates multiple drug resistance in typhoid (also called R factors).\nAs of 2014 some \"Enterococcus faecium\" and\" Pseudomonas aeruginosa\" strains are resistant to chloramphenicol. Some \"Veillonella\" spp. and \"Staphylococcus capitis\" strains have also developed resistance to chloramphenicol to varying degrees.\nAdverse effects.\nAplastic anemia.\nThe most serious side effect of chloramphenicol treatment is aplastic anaemia. This effect is rare but sometimes fatal. The risk of AA is high enough that alternatives should be strongly considered. Treatments are available but expensive. No way exists to predict who may or may not suffer this side effect. The effect usually occurs weeks or months after treatment has been stopped, and a genetic predisposition may be involved. It is not known whether monitoring the blood counts of patients can prevent the development of aplastic anaemia, but patients are recommended to have a baseline blood count with a repeat blood count every few days while on treatment. Chloramphenicol should be discontinued if the complete blood count drops. The highest risk is with oral chloramphenicol (affecting 1 in 24,000\u201340,000) and the lowest risk occurs with eye drops (affecting less than one in 224,716 prescriptions).\nThiamphenicol, a related compound with a similar spectrum of activity, is available in Italy and China for human use, and has never been associated with aplastic anaemia. Thiamphenicol is available in the U.S. and Europe as a veterinary antibiotic, but is not approved for use in humans.\nBone marrow suppression.\nChloramphenicol may cause bone marrow suppression during treatment; this is a direct toxic effect of the drug on human mitochondria. This effect manifests first as a fall in hemoglobin levels, which occurs quite predictably once a cumulative dose of 20\u00a0g has been given. The anaemia is fully reversible once the drug is stopped and does not predict future development of aplastic anaemia. Studies in mice have suggested existing marrow damage may compound any marrow damage resulting from the toxic effects of chloramphenicol.\nLeukemia.\nLeukemia, a cancer of the blood or bone marrow, is characterized by an abnormal increase of immature white blood cells. The risk of childhood leukemia is increased, as demonstrated in a Chinese case\u2013control study, and the risk increases with length of treatment.\nGray baby syndrome.\nIntravenous chloramphenicol use has been associated with the so-called gray baby syndrome.\nThis phenomenon occurs in newborn infants because they do not yet have fully functional liver enzymes (i.e. UDP-glucuronyl transferase), so chloramphenicol remains unmetabolized in the body.\nThis causes several adverse effects, including hypotension and cyanosis. The condition can be prevented by using the drug at the recommended doses, and monitoring blood levels.\nHypersensitivity reactions.\nFever, macular and vesicular rashes, angioedema, urticaria, and anaphylaxis may occur. Herxheimer's reactions have occurred during therapy for typhoid fever.\nNeurotoxic reactions.\nHeadache, mild depression, mental confusion, and delirium have been described in patients receiving chloramphenicol. Optic and peripheral neuritis have been reported, usually following long-term therapy. If this occurs, the drug should be promptly withdrawn.\nPharmacokinetics.\nChloramphenicol is extremely lipid-soluble; it remains relatively unbound to protein and is a small molecule. It has a large apparent volume of distribution and penetrates effectively into all tissues of the body, including the brain. Distribution is not uniform, with highest concentrations found in the liver and kidney, with lowest in the brain and cerebrospinal fluid. The concentration achieved in brain and cerebrospinal fluid is around 30 to 50% of the overall average body concentration, even when the meninges are not inflamed; this increases to as high as 89% when the meninges are inflamed.\nChloramphenicol increases the absorption of iron.\nUse in special populations.\nChloramphenicol is metabolized by the liver to chloramphenicol glucuronate (which is inactive). In liver impairment, the dose of chloramphenicol must therefore be reduced. No standard dose reduction exists for chloramphenicol in liver impairment, and the dose should be adjusted according to measured plasma concentrations.\nThe majority of the chloramphenicol dose is excreted by the kidneys as the inactive metabolite, chloramphenicol glucuronate. Only a tiny fraction of the chloramphenicol is excreted by the kidneys unchanged. Plasma levels should be monitored in patients with renal impairment, but this is not mandatory. Chloramphenicol succinate ester (an intravenous prodrug form) is readily excreted unchanged by the kidneys, more so than chloramphenicol base, and this is the major reason why levels of chloramphenicol in the blood are much lower when given intravenously than orally.Chloramphenicol passes into breast milk, so should therefore be avoided during breast feeding, if possible.\nDose monitoring.\nPlasma levels of chloramphenicol must be monitored in neonates and patients with abnormal liver function. Plasma levels should be monitored in all children under the age of four, the elderly, and patients with kidney failure.\nBecause efficacy and toxicity of chloramphenicol are associated with a maximum serum concentration, peak levels (one hour after the intravenous dose is given) should be 10\u201320\u00a0\u00b5g/ml with toxicity &gt; 40 \u00b5g/ml; trough levels (taken immediately before a dose) should be 5\u201310\u00a0\u00b5g/ml.\nDrug interactions.\nAdministration of chloramphenicol concomitantly with bone marrow depressant drugs is contraindicated, although concerns over aplastic anaemia associated with ocular chloramphenicol have largely been discounted.\nChloramphenicol is a potent inhibitor of the cytochrome P450 isoforms CYP2C19 and CYP3A4 in the liver. Inhibition of CYP2C19 causes decreased metabolism and therefore increased levels of, for example, antidepressants, antiepileptics, proton-pump inhibitors, and anticoagulants if they are given concomitantly. Inhibition of CYP3A4 causes increased levels of, for example, calcium channel blockers, immunosuppressants, chemotherapeutic drugs, benzodiazepines, azole antifungals, tricyclic antidepressants, macrolide antibiotics, SSRIs, statins, cardiac antiarrhythmics, antivirals, anticoagulants, and PDE5 inhibitors.\nDrug antagonistic.\nChloramphenicol is antagonistic with most cephalosporins and using both together should be avoided in the treatment of infections.\nDrug synergism.\nChloramphenicol has been demonstrated a synergistic effect when combined with fosfomycin against clinical isolates of \"Enterococcus faecium\".\nMechanism of action.\nChloramphenicol is a bacteriostatic agent, inhibiting protein synthesis. It prevents protein chain elongation by inhibiting the peptidyl transferase activity of the bacterial ribosome. It specifically binds to A2451 and A2452 residues in the 23S rRNA of the 50S ribosomal subunit, preventing peptide bond formation. Chloramphenicol directly interferes with substrate binding in the ribosome, as compared to macrolides, which sterically block the progression of the growing peptide.\nHistory.\nChloramphenicol was first isolated from \"Streptomyces venezuelae\" in 1947 and in 1949 a team of scientists at Parke-Davis including Mildred Rebstock published their identification of the chemical structure and their synthesis.\nIn 1972, Senator Ted Kennedy combined the two examples of the Tuskegee Syphilis Study and the 1958 Los Angeles Infant Chloramphenicol experiments as initial subjects of a Senate Subcommittee investigation into dangerous medical experimentation on human subjects.\nIn 2007, the accumulation of reports associating aplastic anemia and blood dyscrasia with chloramphenicol eye drops led to the classification of \u201cprobable human carcinogen\u201d according to World Health Organization criteria, based on the known published case reports and the spontaneous reports submitted to the National Registry of Drug-Induced Ocular Side Effects.\nSociety and culture.\nNames.\nChloramphenicol is available as a generic worldwide under many brandnames and also under various generic names in eastern Europe and Russia, including chlornitromycin, levomycetin, and chloromycetin; the racemate is known as synthomycetin.\nFormulations.\nChloramphenicol is available as a capsule or as a liquid. In some countries, it is sold as chloramphenicol palmitate ester (CPE). CPE is inactive, and is hydrolysed to active chloramphenicol in the small intestine. No difference in bioavailability is noted between chloramphenicol and CPE.\nManufacture of oral chloramphenicol in the U.S. stopped in 1991, because the vast majority of chloramphenicol-associated cases of aplastic anaemia are associated with the oral preparation. No oral formulation of chloramphenicol is available in the U.S. for human use.\nIn molecular biology, chloramphenicol is prepared in ethanol.\nIntravenous.\nThe intravenous (IV) preparation of chloramphenicol is the succinate ester. This creates a problem: Chloramphenicol succinate ester is an inactive prodrug and must first be hydrolysed to chloramphenicol; however, the hydrolysis process is often incomplete, and 30% of the dose is lost and removed in the urine. Serum concentrations of IV chloramphenicol are only 70% of those achieved when chloramphenicol is given orally. For this reason, the dose needs to be increased to 75\u00a0mg/kg/day when administered IV to achieve levels equivalent to the oral dose.\nOily.\nOily chloramphenicol (or chloramphenicol oil suspension) is a long-acting preparation of chloramphenicol first introduced by Roussel in 1954; marketed as Tifomycine, it was originally used as a treatment for typhoid. Roussel stopped production of oily chloramphenicol in 1995; the International Dispensary Association Foundation has manufactured it since 1998, first in Malta and then in India from December 2004.\nOily chloramphenicol was first used to treat meningitis in 1975 and numerous studies since have demonstrated its efficacy. It is the cheapest treatment available for meningitis (US$5 per treatment course, compared to US$30 for ampicillin and US$15 for five days of ceftriaxone). It has the great advantage of requiring only a single injection, whereas ceftriaxone is traditionally given daily for five days. This recommendation may yet change, now that a single dose of ceftriaxone (cost US$3) has been shown to be equivalent to one dose of oily chloramphenicol.\nEye drops.\nChloramphenicol is used in topical preparations (ointments and eye drops) for the treatment of bacterial conjunctivitis. Isolated case reports of aplastic anaemia following use of chloramphenicol eyedrops exist, but the risk is estimated to be of the order of less than one in 224,716 prescriptions. In Mexico, this is the treatment used prophylactically in newborns for neonatal conjunctivitis.\nVeterinary uses.\nAlthough its use in veterinary medicine is highly restricted, chloramphenicol still has some important veterinary uses. It is currently considered the most useful treatment of chlamydial disease in koalas. The pharmacokinetics of chloramphenicol have been investigated in koalas.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6347", "revid": "11308236", "url": "https://en.wikipedia.org/wiki?curid=6347", "title": "Cut-up technique", "text": "Literary technique of rearranging text\nThe cut-up technique (or \"d\u00e9coup\u00e9\" in French) is an aleatory literary technique in which a written text is cut up and rearranged to create a new text. The concept can be traced to the Dadaists of the 1920s, but it was developed and popularized in the 1950s and early 1960s, especially by writer William S. Burroughs. It has since been used in a wide variety of contexts.\nTechnique.\nThe cut-up and the closely associated fold-in are the two main techniques:\nWilliam Burroughs cited T. S. Eliot's 1922 poem, \"The Waste Land\", and John Dos Passos' \"U.S.A.\" trilogy, which incorporated newspaper clippings, as early examples of the cut ups he popularized.\nGysin introduced Burroughs to the technique at the Beat Hotel. The pair later applied the technique to printed media and audio recordings in an effort to decode the material's implicit content, hypothesizing that such a technique could be used to discover the true meaning of a given text. Burroughs also suggested cut-ups may be effective as a form of divination saying, \"When you cut into the present the future leaks out.\" Burroughs also further developed the \"fold-in\" technique. In 1977, Burroughs and Gysin published \"The Third Mind\", a collection of cut-up writings and essays on the form. Jeff Nuttall's publication \"My Own Mag\" was another important outlet for the then-radical technique.\nIn an interview, Alan Burns noted that for \"Europe After The Rain\" (1965) and subsequent novels he used a version of cut-ups: \"I did not actually use scissors, but I folded pages, read across columns, and so on, discovering for myself many of the techniques Burroughs and Gysin describe\".\nHistory.\nIn literature.\nA precedent of the technique occurred during a Dadaist rally in the 1920s in which Tristan Tzara offered to create a poem on the spot by pulling words at random from a hat. Collage, which was popularized roughly contemporaneously with the Surrealist movement, sometimes incorporated texts such as newspapers or brochures. Prior to this event, the technique had been published in an issue of 391 in the poem by Tzara, \"dada manifesto on feeble love and bitter love\" under the sub-title, \"TO MAKE A DADAIST POEM\".\nIn the 1950s, painter and writer Brion Gysin more fully developed the cut-up method after accidentally rediscovering it. He had placed layers of newspapers as a mat to protect a tabletop from being scratched while he cut papers with a razor blade. Upon cutting through the newspapers, Gysin noticed that the sliced layers offered interesting juxtapositions of text and image. He began deliberately cutting newspaper articles into sections, which he randomly rearranged. The book \"Minutes to Go\" resulted from his initial cut-up experiment: unedited and unchanged cut-ups which emerged as coherent and meaningful prose. South African poet Sinclair Beiles also used this technique and co-authored \"Minutes To Go\".\nArgentine writer Julio Cort\u00e1zar used cut ups in his 1963 novel \"Hopscotch\".\nIn 1969, poets Howard W. Bergerson and J. A. Lindon developed a cut-up technique known as vocabularyclept poetry, in which a poem is formed by taking all the words of an existing poem and rearranging them, often preserving the metre and stanza lengths.\nA drama scripted for five voices by performance poet Hedwig Gorski in 1977 originated the idea of creating poetry only for performance instead of for print publication. The \"neo-verse drama\" titled \"Booby, Mama!\" written for \"guerilla theater\" performances in public places used a combination of newspaper cut-ups that were edited and choreographed for a troupe of non-professional street actors.\nKathy Acker, a literary and intermedia artist, sampled external sources and reconfigured them into the creation of shifting versions of her own constructed identity. In her late 1970s novel \"Blood and Guts in High School\", Acker explored literary cut-up and appropriation as an integral part of her method.\nIn film.\nAntony Balch and Burroughs created a collaboration film, \"The Cut-Ups\" that opened in London in 1967. This was part of an abandoned project called \"Guerrilla Conditions\" meant as a documentary on Burroughs and filmed throughout 1961\u20131965. Inspired by Burroughs' and Gysin's technique of cutting up text and rearranging it in random order, Balch had an editor cut his footage for the documentary into little pieces and impose no control over its reassembly. The film opened at Oxford Street's Cinephone cinema and had a disturbing reaction. Many audience members claimed the film made them ill, others demanded their money back, while some just stumbled out of the cinema ranting \"it's disgusting\". Other cut-up films include \"Ghost at n\u00b09 (Paris)\" (1963\u20131972), a posthumously released short film compiled from reels found at Balch's office after his death, and \"William Buys a Parrott\" (1982), \"Bill and Tony\" (1972), \"Towers Open Fire\" (1963) and \"The Junky's Christmas\" (1966).\nIn music.\nIn 1962, the satirical comedy group Bonzo Dog Doo-Dah Band, got their name after using the cut-up technique, resulting in \"Bonzo Dog Dada\": \"Bonzo Dog\", after the cartoon Bonzo the Dog, and \"Dada\" after the Dada avant-garde art movement. The group's eventual frontman, Vivian Stanshall, would quote about wanting to form a band with that name. The \"Dada\" in the phrase was eventually changed to \"Doo-Dah\".\nFrom the early 1970s, David Bowie used cut-ups to create some of his lyrics. In 1995 he worked with Ty Roberts to develop a program called \"Verbasizer\" for his Apple PowerBook that could automatically rearrange multiple sentences written into it. Thom Yorke applied a similar method in Radiohead's \"Kid A\" (2000) album, writing single lines, putting them into a hat, and drawing them out at random while the band rehearsed the songs. Perhaps indicative of Thom Yorke's influences, instructions for \"How to make a Dada poem\" appeared on Radiohead's website at this time.\nStephen Mallinder of Cabaret Voltaire reported to \"Inpress\" magazine's Andrez Bergen that \"I do think the manipulation of sound in our early days \u2013 the physical act of cutting up tapes, creating tape loops and all that \u2013 has a strong reference to Burroughs and Gysin.\" Another industrial music pioneer, Al Jourgensen of Ministry, named Burroughs and his cut-up technique as the most important influence on how he approached the use of samples.\nMany Elephant 6 bands used decoupe as well, one prominent example of this is seen in \"Pree-Sisters Swallowing A Donkey's Eye\" by Neutral Milk Hotel."}
{"id": "6348", "revid": "835", "url": "https://en.wikipedia.org/wiki?curid=6348", "title": "Congressional Medal of Honour", "text": ""}
{"id": "6352", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=6352", "title": "Congenital iodine deficiency syndrome", "text": "Medical condition\nCongenital iodine deficiency syndrome is a medical condition present at birth marked by impaired physical and mental development, due to insufficient thyroid hormone (hypothyroidism) often caused by insufficient dietary iodine during pregnancy. It is one cause of underactive thyroid function at birth, called congenital hypothyroidism, historically referred to as cretinism (obsolete). If untreated, it results in impairment of both physical and mental development. Symptoms may include goiter, poor length growth in infants, reduced adult stature, thickened skin, hair loss, enlarged tongue, a protruding abdomen; delayed bone maturation and puberty in children; and mental deterioration, neurological impairment, impeded ovulation, and infertility in adults.\nIn developed countries, thyroid function testing of newborns has assured that in those affected, treatment with the thyroid hormone thyroxine is begun promptly. This screening and treatment have virtually eliminated the consequences of the disease.\nSigns and symptoms.\nIodine deficiency causes gradual enlargement of the thyroid gland, referred to as a goiter. Poor length growth is apparent as early as the first year of life. Adult stature without treatment ranges from , depending on severity, sex, and other genetic factors. Other signs include thickened skin, hair loss, enlarged tongue, and a protruding abdomen. In children, bone maturation and puberty are severely delayed. In adults, ovulation is impeded and infertility is common.\nMental deterioration is common. Neurological impairment may be mild, with reduced muscle tone and coordination, or so severe that the person cannot stand or walk. Cognitive impairment may also range from mild to so severe that the person is nonverbal and dependent on others for basic care. Thought and reflexes are slower.\nCause.\nAround the world, the most common cause of congenital iodine deficiency syndrome (endemic cretinism) is dietary iodine deficiency.\nIodine is an essential trace element, necessary for the synthesis of thyroid hormones. Iodine deficiency is the most common preventable cause of neonatal and childhood brain damage worldwide. Although iodine is found in many foods, it is not universally present in all soils in adequate amounts. Most iodine, in iodide form, is in the oceans, where the iodide ions are reduced to elemental iodine, which then enters the atmosphere and falls to earth in rain, introducing iodine to soils. Soil deficient in iodine is most common inland, in mountainous areas, and in areas of frequent flooding. It can also occur in coastal regions, where iodine might have been removed from the soil by glaciation, as well as leaching by snow, water and heavy rainfall. Plants and animals grown in iodine-deficient soils are correspondingly deficient. Populations living in those areas without outside food sources are most at risk of iodine deficiency diseases.\nDiagnosis.\nDifferential diagnosis.\nDwarfism may also be caused by malnutrition or other hormonal deficiencies, such as insufficient growth hormone secretion, hypopituitarism, decreased secretion of growth hormone-releasing hormone, deficient growth hormone receptor activity and downstream causes, such as insulin-like growth factor 1 (IGF-1) deficiency.\nPrevention.\nThere are public health campaigns in many countries which involve iodine administration. As of December 2019, 122 countries have mandatory iodine food fortification programs.\nTreatment.\nCongenital iodine deficiency has been almost eliminated in developed countries through iodine supplementation of food and by newborn screening utilizing a blood test for thyroid function.\nTreatment consists of lifelong administration of thyroxine (T4). Thyroxine must be dosed as tablets only, even to newborns, as the liquid oral suspensions and compounded forms cannot be depended on for reliable dosing. For infants, the T4 tablets are generally crushed and mixed with breast milk, formula milk or water. If the medication is mixed with formulas containing iron or soya products, larger doses may be required, as these substances may alter the absorption of thyroid hormone from the gut. Monitoring TSH blood levels every 2\u20133 weeks during the first months of life is recommended to ensure that affected infants are at the high end of normal range.\nHistory.\nA goiter is the most specific clinical marker of either the direct or indirect insufficient intake of iodine in the human body. There is evidence of goiter, and its medical treatment with iodine-rich algae and burnt sponges, in Chinese, Egyptian, and Roman ancient medical texts. In 1848, King Carlo Alberto of Sardinia commissioned the first epidemiological study of congenital iodine deficiency syndrome, in northern Savoy where it was frequent. In past centuries, the well reported social diseases prevalent among the poorer social classes and farmers, caused by dietary and agricultural monocultures, were: pellagra, rickets, beriberi, scurvy in long-term sailors, and the endemic goiter caused by iodine deficiency. However, this disease was less mentioned in medical books because it was erroneously considered to be an aesthetic rather than a clinical disorder.\nCongenital iodine-deficiency syndrome was especially common in areas of southern Europe around the Alps and was often described by ancient Roman writers and depicted by artists. The earliest Alpine mountain climbers sometimes came upon whole villages affected by it. The prevalence of the condition was described from a medical perspective by several travellers and physicians in the late 18th and early 19th centuries. At that time the cause was not known and it was often attributed to \"stagnant air\" in mountain valleys or \"bad water\". The proportion of people affected varied markedly throughout southern Europe and even within very small areas; it might be common in one valley and not another. The number of severely affected persons was always a minority, and most persons were only affected to the extent of having a goitre and some degree of reduced cognition and growth. The majority of such cases were still socially functional in their pastoral villages.\nMore mildly affected areas of Europe and North America in the 19th century were referred to as \"goitre belts\". The degree of iodine deficiency was milder and manifested primarily as thyroid enlargement rather than severe mental and physical impairment. In Switzerland, for example, where soil does not contain a large amount of iodine, cases of congenital iodine deficiency syndrome were very abundant and even considered genetically caused. As the variety of food sources dramatically increased in Europe and North America and the populations became less completely dependent on locally grown food, the prevalence of endemic goitre diminished. This is supported by a 1979 WHO publication which concluded that \"changes in the origin of food supplies may account for the otherwise unexplained disappearance of endemic goitre from a number of localities during the past 50 years\".\nThe early 20th century saw the discovery of the relationships of neurological impairment with hypothyroidism due to iodine deficiency. Both have been largely eliminated in the developed world.\nTerminology.\nThe term \"cretin\" was originally used to describe a person affected by this condition, but, as with words such as \"spastic\" and \"lunatic\", it underwent pejoration and is now considered derogatory and inappropriate. \"Cretin\" became a medical term in the 18th century, from an Occitan and an Alpine French expression, prevalent in a region where persons with such a condition were especially common (see below); it saw wide medical use in the 19th and early 20th centuries, and was a \"tick box\" category on Victorian-era census forms in the UK. The term spread more widely in popular English as a markedly derogatory term for a person who behaves stupidly. Because of its pejorative connotations in popular speech, current usage among health care professionals has abandoned the noun \"cretin\" referring to a person. The noun \"cretinism\", referring to the condition, still occurs in medical literature and textbooks but its use is waning.\nThe etymology of \"cretin\" is uncertain. Several hypotheses exist. The most common derivation provided in English dictionaries is from the Alpine French dialect pronunciation of the word \"Chr\u00e9tien\" (\"(a) Christian\"), which was a greeting there. According to the \"Oxford English Dictionary\", the translation of the French term into \"human creature\" implies that the label \"Christian\" is a reminder of the humanity of the affected, in contrast to brute beasts. Other sources suggest that \"Christian\" describes the person's \"Christ-like\" inability to sin, stemming, in such cases, from an incapacity to distinguish right from wrong.\nOther speculative etymologies have been offered:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n Media related to at Wikimedia Commons"}
{"id": "6353", "revid": "55327", "url": "https://en.wikipedia.org/wiki?curid=6353", "title": "Cretin", "text": "Cretin may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "6354", "revid": "8372814", "url": "https://en.wikipedia.org/wiki?curid=6354", "title": "Council of Trent", "text": "Catholic Church ecumenical council 1545\u20131563\nThe Council of Trent (), held between 1545 and 1563 in Trent (or Trento), now in northern Italy, was the 19th ecumenical council of the Catholic Church. Prompted by the Protestant Reformation at the time, it has been described as the embodiment of the Counter-Reformation.\nThe Council issued condemnations of what it defined to be heresies committed by proponents of Protestantism, and also issued key statements and clarifications of the Church's doctrine and teachings, including scripture, the biblical canon, sacred tradition, original sin, justification, salvation, the sacraments, the Mass, and the veneration of saints. The Council met for twenty-five sessions between 13 December 1545 and 4 December 1563. Pope Paul III, who convoked the Council, oversaw the first eight sessions (1545\u201347), while the twelfth to sixteenth sessions (1551\u201352) were overseen by Pope Julius III and the seventeenth to twenty-fifth sessions (1562\u201363) by Pope Pius IV.\nThe consequences of the Council were also significant with regard to the Church's liturgy and practices. In its decrees, the Council made the Latin Vulgate the official biblical text of the Roman Church (without prejudice to the original texts in Hebrew and Greek, nor to other traditional translations of the Church, but favoring the Latin language over vernacular translations, such as the controversial English-language Tyndale Bible). In doing so, they commissioned the creation of a revised and standardized Vulgate in light of textual criticism, although this was not achieved until the 1590s. The Council also officially affirmed (for the second time at an ecumenical council) the traditional Catholic Canon of biblical books in response to the increasing Protestant exclusion of the deuterocanonical books. The former dogmatic affirmation of the Canonical books was at the Council of Florence in the 1441 bull \"Cantate Domino\", as affirmed by Pope Leo XIII in his 1893 encyclical \"Providentissimus Deus\" (#20). In 1565, a year after the Council finished its work, Pius IV issued the Tridentine Creed (after \"Tridentum\", Trent's Latin name) and his successor Pius V then issued the Roman Catechism and revisions of the Breviary and Missal in, respectively, 1566, 1568 and 1570. These, in turn, led to the codification of the Tridentine Mass, which remained the Church's primary form of the Mass for the next four hundred years.\nMore than three hundred years passed until the next ecumenical council, the First Vatican Council, was convened in 1869.\nBackground information.\nObstacles and events before the Council's problem area.\nOn 15 March 1517, the Fifth Council of the Lateran closed its activities with a number of reform proposals (on the selection of bishops, taxation, censorship and preaching) but not on the major problems that confronted the Church in Germany and other parts of Europe. A few months later, on 31 October 1517, Martin Luther issued his \"95 Theses\" in Wittenberg.\nA general, free council in Germany.\nLuther's position on ecumenical councils shifted over time, but in 1520 he appealed to the German princes to oppose the papal Church at the time, if necessary with a council in Germany, open and free of the Papacy. After the Pope condemned in \"Exsurge Domine\" fifty-two of Luther's theses as heresy, German opinion considered a council the best method to reconcile existing differences. German Catholics, diminished in number, hoped for a council to clarify matters.\nIt took a generation for the council to materialise, partly due to papal fears over potentially renewing a schism over conciliarism; partly because Lutherans demanded the exclusion of the papacy from the Council; partly because of ongoing political rivalries between France and the Holy Roman Empire; and partly due to the Turkish dangers in the Mediterranean. Under Pope Clement VII (1523\u201334), troops of the Catholic Holy Roman Emperor Charles V sacked Papal Rome in 1527, \"raping, killing, burning, stealing, the like had not been seen since the Vandals\". Saint Peter's Basilica and the Sistine Chapel were used for horses. Pope Clement, fearful of the potential for more violence, delayed calling the Council.\nCharles V strongly favoured a council but needed the support of King Francis I of France, who attacked him militarily. Francis I generally opposed a general council due to partial support of the Protestant cause within France. In 1532 he agreed to the Nuremberg Religious Peace granting religious liberty to the Protestants, and in 1533 he further complicated matters when suggesting a general council to include both Catholic and Protestant rulers of Europe that would devise a compromise between the two theological systems. This proposal met the opposition of the Pope for it gave recognition to Protestants and also elevated the secular Princes of Europe above the clergy on church matters. Faced with a Turkish attack, Charles held the support of the Protestant German rulers, all of whom delayed the opening of the Council of Trent.\nOccasion, sessions, and attendance.\nIn reply to the Papal bull \"Exsurge Domine\" of Pope Leo X (1520), Martin Luther burned the document and appealed for a general council. In 1522 German diets joined in the appeal, with Charles V seconding and pressing for a council as a means of reunifying the Church and settling the Reformation controversies. Pope Clement VII (1523\u20131534) was vehemently against the idea of a council, agreeing with Francis I of France, after Pope Pius II, in his bull \"Execrabilis\" (1460) and his reply to the University of Cologne (1463), set aside the theory of the supremacy of general councils laid down by the Council of Constance.\nPope Paul III (1534\u20131549), seeing that the Protestant Reformation was no longer confined to a few preachers, but had won over various princes, especially in Germany, to its ideas, desired a council. Yet when he proposed the idea to his cardinals, it was almost unanimously opposed. Nonetheless, he sent nuncios throughout Europe to propose the idea. Paul III issued a decree for a general council to be held in Mantua, Italy, to begin on 23 May 1537. Martin Luther wrote the Smalcald Articles in preparation for the general council. The Smalcald Articles were designed to sharply define where the Lutherans could and could not compromise. The council was ordered by the Emperor and Pope Paul III to convene in Mantua on 23 May 1537. It failed to convene after another war broke out between France and Charles V, resulting in a non-attendance of French prelates. Protestants refused to attend as well. Financial difficulties in Mantua led the Pope in the autumn of 1537 to move the council to Vicenza, where participation was poor. The Council was postponed indefinitely on 21 May 1539. Pope Paul III then initiated several internal Church reforms while Emperor Charles V convened with Protestants and Cardinal Gasparo Contarini at the Diet of Regensburg, to reconcile differences. Mediating and conciliatory formulations were developed on certain topics. In particular, a two-part doctrine of justification was formulated that would later be rejected at Trent. Unity failed between Catholic and Protestant representatives \"because of different concepts of \"Church\" and \"justification\"\".\nHowever, the council was delayed until 1545 and, as it happened, convened right before Luther's death. Unable, however, to resist the urging of Charles V, the pope, after proposing Mantua as the place of meeting, convened the council at Trent (at that time ruled by a prince-bishop under the Holy Roman Empire), on 13 December 1545; the Pope's decision to transfer it to Bologna in March 1547 on the pretext of avoiding a plague failed to take effect and the Council was indefinitely prorogued on 17 September 1549. None of the three popes reigning over the duration of the council ever attended, which had been a condition of Charles V. Papal legates were appointed to represent the Papacy.\nReopened at Trent on 1 May 1551 by the convocation of Pope Julius III (1550\u20131555), it was broken up by the sudden victory of Maurice, Elector of Saxony over Emperor Charles V and his march into surrounding state of Tirol on 28 April 1552. There was no hope of reassembling the council while the very anti-Protestant Paul IV was Pope. The council was reconvened by Pope Pius IV (1559\u20131565) for the last time, meeting from 18 January 1562 at Santa Maria Maggiore, and continued until its final adjournment on 4 December 1563. It closed with a series of ritual acclamations honouring the reigning Pope, the Popes who had convoked the Council, the emperor and the kings who had supported it, the papal legates, the cardinals, the ambassadors present, and the bishops, followed by acclamations of acceptance of the faith of the Council and its decrees, and of anathema for all heretics.\nThe history of the council is thus divided into three distinct periods: 1545\u20131549, 1551\u20131552 and 1562\u20131563. During the second period, the Protestants present asked for a renewed discussion on points already defined and for bishops to be released from their oaths of allegiance to the Pope. When the last period began, all intentions of conciliating the Protestants was gone and the Jesuits had become a strong force. This last period was begun especially as an attempt to prevent the formation of a general council including Protestants, as had been demanded by some in France.\nThe number of attending members in the three periods varied considerably. The council was small to begin with, opening with only about 30 bishops. It increased toward the close, but never reached the number of the First Council of Nicaea (which had 318 members) nor of the First Vatican Council (which numbered 744). The decrees were signed in 1563 by 255 members, the highest attendance of the whole council, including four papal legates, two cardinals, three patriarchs, twenty-five archbishops, and 168 bishops, two-thirds of whom were Italians. The Italian and Spanish prelates were vastly preponderant in power and numbers. At the passage of the most important decrees, not more than sixty prelates were present. Although most Protestants did not attend, ambassadors and theologians of Brandenburg, W\u00fcrttemberg, and Strasbourg attended having been granted an improved safe conduct.\nThe French monarchy boycotted the entire council until the last minute when a delegation led by Charles de Guise, Cardinal of Lorraine finally arrived in November 1562. The first outbreak of the French Wars of Religion had occurred earlier in the year and the French Church, facing a significant and powerful Protestant minority in France, experienced iconoclasm violence regarding the use of sacred images. Such concerns were not primary in the Italian and Spanish Churches. The last-minute inclusion of a decree on sacred images was a French initiative, and the text, never discussed on the floor of the council or referred to council theologians, was based on a French draft.\nObjectives and overall results.\nThe main objectives of the council were twofold, although there were other issues that were also discussed:\nThe doctrinal decisions of the council are set forth in decrees (\"decreta\"), which are divided into chapters (\"capita\"), which contain the positive statement of the conciliar dogmas, and into short canons (\"canones\"), which condemn the dissenting Protestant views with the concluding \"anathema sit\" (\"let him be anathema\").\nDecrees.\nThe doctrinal acts are as follows: after reaffirming the Niceno-Constantinopolitan Creed (third session), the decree was passed (fourth session) confirming that the deuterocanonical books were on a par with the other books of the canon (against Luther's placement of these books in the Apocrypha of his edition) and coordinating church tradition with the Scriptures as a rule of faith. The Vulgate translation was affirmed to be authoritative for the text of Scripture.\nJustification (sixth session) was declared to be offered upon the basis of human cooperation with divine grace as opposed to the Protestant doctrine of passive reception of grace. Understanding the Protestant \"faith alone\" doctrine to be one of simple human confidence in Divine Mercy, the Council rejected the \"vain confidence\" of the Protestants, stating that no one can know who has received the grace of God. Furthermore, the Council affirmed\u2014against some Protestants\u2014that the grace of God can be forfeited through mortal sin.\nThe greatest weight in the Council's decrees is given to the sacraments. The seven sacraments were reaffirmed and the Eucharist pronounced to be a true propitiatory sacrifice as well as a sacrament, in which the bread and wine were consecrated into the Eucharist (thirteenth and twenty-second sessions). The term transubstantiation was used by the Council, but the specific Aristotelian explanation given by Scholasticism was not cited as dogmatic. Instead, the decree states that Christ is \"really, truly, substantially present\" in the consecrated forms. The sacrifice of the Mass was to be offered for dead and living alike and in giving to the apostles the command \"do this in remembrance of me,\" Christ conferred upon them a sacerdotal power. The practice of withholding the cup from the laity was confirmed (twenty-first session) as one which the Church Fathers had commanded for good and sufficient reasons; yet in certain cases the Pope was made the supreme arbiter as to whether the rule should be strictly maintained. On the language of the Mass, \"contrary to what is often said\", the council condemned the belief that only vernacular languages should be used, while insisting on the use of Latin.\nOrdination (twenty-third session) was defined to imprint an indelible character on the soul. The priesthood of the New Testament takes the place of the Levitical priesthood. To the performance of its functions, the consent of the people is not necessary.\nIn the decrees on marriage (twenty-fourth session) the excellence of the celibate state was reaffirmed, concubinage condemned and the validity of marriage made dependent upon the wedding taking place before a priest and two witnesses, although the lack of a requirement for parental consent ended a debate that had proceeded from the 12th century. In the case of a divorce, the right of the innocent party to marry again was denied so long as the other party was alive, even if the other party had committed adultery. However the council \"refused \u2026 to assert the necessity or usefulness of clerical celibacy\".\nIn the twenty-fifth and last session, the doctrines of purgatory, the invocation of saints and the veneration of relics were reaffirmed, as was also the efficacy of indulgences as dispensed by the Church according to the power given her, but with some cautionary recommendations, and a ban on the sale of indulgences. Short and rather inexplicit passages concerning religious images, were to have great impact on the development of Catholic Church art. Much more than the Second Council of Nicaea (787), the Council fathers of Trent stressed the pedagogical purpose of Christian images.\nThe council appointed, in 1562 (eighteenth session), a commission to prepare a list of forbidden books (\"Index Librorum Prohibitorum\"), but it later left the matter to the Pope. The preparation of a catechism and the revision of the Breviary and Missal were also left to the pope. The catechism embodied the council's far-reaching results, including reforms and definitions of the sacraments, the Scriptures, church dogma, and duties of the clergy.\nRatification and promulgation.\nOn adjourning, the Council asked the supreme pontiff to ratify all its decrees and definitions. This petition was complied with by Pope Pius IV, on 26 January 1564, in the papal bull, \"Benedictus Deus\", which enjoins strict obedience upon all Catholics and forbids, under pain of ex-communication, all unauthorised interpretation, reserving this to the Pope alone and threatens the disobedient with \"the indignation of Almighty God and of his blessed apostles, Peter and Paul.\" Pope Pius appointed a commission of cardinals to assist him in interpreting and enforcing the decrees.\nThe \"Index Librorum Prohibitorum\" was announced in 1564 and the following books were issued with the papal imprimatur: the Profession of the Tridentine Faith and the Tridentine Catechism (1566), the Breviary (1568), the Missal (1570) and the Vulgate (1590 and then 1592).\nThe decrees of the council were acknowledged in Italy, Portugal, Poland and by the Catholic princes of Germany at the Diet of Augsburg in 1566. Philip II of Spain accepted them for Spain, the Netherlands and Sicily inasmuch as they did not infringe the royal prerogative. In France, they were officially recognised by the king only in their doctrinal parts. Although the disciplinary or moral reformatory decrees were never published by the throne, they received official recognition at provincial synods and were enforced by the bishops. Holy Roman Emperors Ferdinand I and Maximilian II never recognized the existence of any of the decrees. No attempt was made to introduce it into England. Pius IV sent the decrees to Mary, Queen of Scots, with a letter dated 13 June 1564, requesting that she publish them in Scotland, but she dared not do it in the face of John Knox and the Reformation.\nThese decrees were later supplemented by the First Vatican Council of 1870.\nPublication of documents.\nA comprehensive history is found in Hubert Jedin's \"The History of the Council of Trent (Geschichte des Konzils von Trient)\" with about 2,500 pages in four volumes: \"The History of the Council of Trent: The fight for a Council\" (Vol I, 1951); \"The History of the Council of Trent: The first Sessions in Trent (1545\u20131547)\" (Vol II, 1957); \"The History of the Council of Trent: Sessions in Bologna 1547\u20131548 and Trento 1551\u20131552\" (Vol III, 1970, 1998); \"The History of the Council of Trent: Third Period and Conclusion\" (Vol IV, 1976).\nThe canons and decrees of the council have been published very often and in many languages. The first issue was by Paulus Manutius (Rome, 1564). Commonly used Latin editions are by Judocus Le Plat (Antwerp, 1779) and by Johann Friedrich von Schulte and Aemilius Ludwig Richter (Leipzig, 1853). Other editions are in vol. vii. of the \"Acta et decreta conciliorum recentiorum. Collectio Lacensis\" (7 vols., Freiburg, 1870\u201390), reissued as independent volume (1892); \"Concilium Tridentinum: Diariorum, actorum, epistularum, \u2026 collectio\", ed. Sebastianus Merkle (4 vols., Freiburg, 1901 sqq.); as well as Mansi, \"Concilia\", xxxv. 345 sqq. Note also Carl Mirbt, \"Quellen\", 2d ed, pp.\u00a0202\u2013255. An English edition is by James Waterworth (London, 1848; \"With Essays on the External and Internal History of the Council\").\nThe original acts and debates of the council, as prepared by its general secretary, Bishop Angelo Massarelli, in six large folio volumes, are deposited in the Vatican Library and remained there unpublished for more than 300 years and were brought to light, though only in part, by Augustin Theiner, priest of the oratory (d. 1874), in \"Acta genuina sancti et oecumenici Concilii Tridentini nunc primum integre edita\" (2 vols., Leipzig, 1874).\nMost of the official documents and private reports, however, which bear upon the council, were made known in the 16th century and since. The most complete collection of them is that of J. Le Plat, \"Monumentorum ad historicam Concilii Tridentini collectio\" (7 vols., Leuven, 1781\u201387). New materials(Vienna, 1872); by JJI von D\u00f6llinger \"(Ungedruckte Berichte und Tageb\u00fccher zur Geschichte des Concilii von Trient)\" (2 parts, N\u00f6rdlingen, 1876); and August von Druffel, \"Monumenta Tridentina\" (Munich, 1884\u201397).\nProtestant response.\nOut of 87 books written between 1546 and 1564 attacking the Council of Trent, 41 were written by Pier Paolo Vergerio, a former papal nuncio turned Protestant Reformer. The 1565\u201373 \"Examen decretorum Concilii Tridentini\" (\"Examination of the Council of Trent\") by Martin Chemnitz was the main Lutheran response to the Council of Trent. Making extensive use of scripture and patristic sources, it was presented in response to a polemical writing which Diogo de Payva de Andrada had directed against Chemnitz. The \"Examen\" had four parts: Volume I examined sacred scripture, free will, original sin, justification, and good works. Volume II examined the sacraments, including baptism, confirmation, the sacrament of the eucharist, communion under both kinds, the mass, penance, extreme unction, holy orders, and matrimony. Volume III examined virginity, celibacy, purgatory, and the invocation of saints. Volume IV examined the relics of the saints, images, indulgences, fasting, the distinction of foods, and festivals.\nIn response, Andrada wrote the five-part \"Defensio Tridentin\u00e6 fidei\", which was published posthumously in 1578. However, the \"Defensio\" did not circulate as extensively as the \"Examen\", nor were any full translations ever published. A French translation of the \"Examen\" by Eduard Preuss was published in 1861. German translations were published in 1861, 1884, and 1972. In English, a complete translation by Fred Kramer drawing from the original Latin and the 1861 German was published beginning in 1971.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6355", "revid": "1750837", "url": "https://en.wikipedia.org/wiki?curid=6355", "title": "Chloroplast", "text": "Plant organelle that conducts photosynthesis\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nStructure of a typical higher-plant chloroplast \nA chloroplast () is a type of membrane-bound organelle known as a plastid that conducts photosynthesis mostly in plant and algal cells. The photosynthetic pigment chlorophyll captures the energy from sunlight, converts it, and stores it in the energy-storage molecules ATP and NADPH while freeing oxygen from water in the cells. The ATP and NADPH is then used to make organic molecules from carbon dioxide in a process known as the Calvin cycle. Chloroplasts carry out a number of other functions, including fatty acid synthesis, amino acid synthesis, and the immune response in plants. The number of chloroplasts per cell varies from one, in unicellular algae, up to 100 in plants like \"Arabidopsis\" and wheat.\nA chloroplast is characterized by its two membranes and a high concentration of chlorophyll. Other plastid types, such as the leucoplast and the chromoplast, contain little chlorophyll and do not carry out photosynthesis.\nChloroplasts are highly dynamic\u2014they circulate and are moved around within plant cells, and occasionally pinch in two to reproduce. Their behavior is strongly influenced by environmental factors like light color and intensity. Chloroplasts, like mitochondria, contain their own DNA, which is thought to be inherited from their ancestor\u2014a photosynthetic cyanobacterium that was engulfed by an early eukaryotic cell. Chloroplasts cannot be made by the plant cell and must be inherited by each daughter cell during cell division.\nWith one exception (the amoeboid \"Paulinella chromatophora\"), all chloroplasts can probably be traced back to a single endosymbiotic event, when a cyanobacterium was engulfed by the eukaryote. Despite this, chloroplasts can be found in an extremely wide set of organisms, some not even directly related to each other\u2014a consequence of many secondary and even tertiary endosymbiotic events.\nThe word \"chloroplast\" is derived from the Greek words \"chloros\" (\u03c7\u03bb\u03c9\u03c1\u03cc\u03c2), which means green, and \"plastes\" (\u03c0\u03bb\u03ac\u03c3\u03c4\u03b7\u03c2), which means \"the one who forms\".\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nDiscovery.\nThe first definitive description of a chloroplast (\"Chlorophyllk\u00f6rnen\", \"grain of chlorophyll\") was given by Hugo von Mohl in 1837 as discrete bodies within the green plant cell. In 1883, Andreas Franz Wilhelm Schimper would name these bodies as \"chloroplastids\" (\"Chloroplastiden\"). In 1884, Eduard Strasburger adopted the term \"chloroplasts\" (\"Chloroplasten\").\nLineages and evolution.\nChloroplasts are one of many types of organelles in the plant cell. They are considered to have evolved from endosymbiotic cyanobacteria. Mitochondria are thought to have come from a similar endosymbiosis event, where an aerobic prokaryote was engulfed. This origin of chloroplasts was first suggested by the Russian biologist Konstantin Mereschkowski in 1905 after Andreas Franz Wilhelm Schimper observed in 1883 that chloroplasts closely resemble cyanobacteria. Chloroplasts are only found in plants, algae, and three species of amoeba \u2013 \"Paulinella chromatophora\", \"P. micropora\", and marine \"P. longichromatophora\".\nParent group: Cyanobacteria.\nChloroplasts are considered endosymbiotic Cyanobacteria. Cyanobacteria are sometimes called blue-green algae even though they are prokaryotes. They are a diverse phylum of gram-negative bacteria capable of carrying out photosynthesis. Cyanobacteria also contain a peptidoglycan cell wall, which is thicker than in other gram-negative bacteria, and which is located between their two cell membranes. Like chloroplasts, they have thylakoids within them. On the thylakoid membranes are photosynthetic pigments, including chlorophyll \"a\". Phycobilins are also common cyanobacterial pigments, usually organized into hemispherical phycobilisomes attached to the outside of the thylakoid membranes (phycobilins are not shared with all chloroplasts though).\nPrimary endosymbiosis.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nPrimary endosymbiosisA eukaryote with mitochondria engulfed a cyanobacterium in an event of serial primary endosymbiosis, creating a lineage of cells with both organelles. It is important to note that the cyanobacterial endosymbiont already had a double membrane\u2014the phagosomal vacuole-derived membrane was lost. \nSomewhere between 1 and 2 billion years ago,\na free-living cyanobacterium entered an early eukaryotic cell, either as food or as an internal parasite, but managed to escape the phagocytic vacuole it was contained in. The two innermost lipid-bilayer membranes that surround all chloroplasts correspond to the outer and inner membranes of the ancestral cyanobacterium's gram negative cell wall, and not the phagosomal membrane from the host, which was probably lost.\nThe new cellular resident quickly became an advantage, providing food for the eukaryotic host, which allowed it to live within it. Over time, the cyanobacterium was assimilated, and many of its genes were lost or transferred to the nucleus of the host. From genomes that probably originally contained over 3000 genes only about 130 genes remain in the chloroplasts of contemporary plants. Some of its proteins were then synthesized in the cytoplasm of the host cell, and imported back into the chloroplast (formerly the cyanobacterium). Separately, somewhere about 90\u2013140 million years ago, it happened again and led to the amoeboid \"Paulinella chromatophora\".\nThis event is called \"endosymbiosis\", or \"cell living inside another cell with a mutual benefit for both\". The external cell is commonly referred to as the \"host\" while the internal cell is called the \"endosymbiont\".\nChloroplasts are believed to have arisen after mitochondria, since all eukaryotes contain mitochondria, but not all have chloroplasts. This is called \"serial endosymbiosis\"\u2014an early eukaryote engulfing the mitochondrion ancestor, and some descendants of it then engulfing the chloroplast ancestor, creating a cell with both chloroplasts and mitochondria.\nWhether or not primary chloroplasts came from a single endosymbiotic event, or many independent engulfments across various eukaryotic lineages, has long been debated. It is now generally held that organisms with primary chloroplasts share a single ancestor that took in a cyanobacterium 600\u20132000 million years ago. It has been proposed this the closest living relative of this bacterium is \"Gloeomargarita lithophora.\" The exception is the amoeboid \"Paulinella chromatophora\", which descends from an ancestor that took in a \"Prochlorococcus\" cyanobacterium 90\u2013500 million years ago.\nThese chloroplasts, which can be traced back directly to a cyanobacterial ancestor, are known as \"primary plastids\" (\"plastid\" in this context means almost the same thing as chloroplast). All primary chloroplasts belong to one of four chloroplast lineages\u2014the glaucophyte chloroplast lineage, the amoeboid \"Paulinella chromatophora\" lineage, the rhodophyte (red algal) chloroplast lineage, or the chloroplastidan (green) chloroplast lineage. The rhodophyte and chloroplastidan lineages are the largest, with chloroplastidan (green) being the one that contains the land plants.\nGlaucophyta.\nUsually the endosymbiosis event is considered to have occurred in the Archaeplastida, within which the glaucophyta being the possible earliest diverging lineage. The glaucophyte chloroplast group is the smallest of the three primary chloroplast lineages, being found in only 13 species, and is thought to be the one that branched off the earliest. Glaucophytes have chloroplasts that retain a peptidoglycan wall between their double membranes, like their cyanobacterial parent. For this reason, glaucophyte chloroplasts are also known as 'muroplasts' (besides 'cyanoplasts' or 'cyanelles'). Glaucophyte chloroplasts also contain concentric unstacked thylakoids, which surround a carboxysome \u2013 an icosahedral structure that glaucophyte chloroplasts and cyanobacteria keep their carbon fixation enzyme RuBisCO in. The starch that they synthesize collects outside the chloroplast. Like cyanobacteria, glaucophyte and rhodophyte chloroplast thylakoids are studded with light collecting structures called phycobilisomes. For these reasons, glaucophyte chloroplasts are considered a primitive intermediate between cyanobacteria and the more evolved chloroplasts in red algae and plants.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nDiversity of red algae Clockwise from top left: \"Bornetia secundiflora\", \"Peyssonnelia squamaria\", \"Cyanidium\", \"Laurencia\", \"Callophyllis laciniata\". Red algal chloroplasts are characterized by phycobilin pigments which often give them their reddish color. \nRhodophyceae (red algae).\nThe rhodophyte, or red algae chloroplast group is another large and diverse chloroplast lineage. Rhodophyte chloroplasts are also called \"rhodoplasts\", literally \"red chloroplasts\".\nRhodoplasts have a double membrane with an intermembrane space and phycobilin pigments organized into phycobilisomes on the thylakoid membranes, preventing their thylakoids from stacking. Some contain pyrenoids. Rhodoplasts have chlorophyll \"a\" and phycobilins for photosynthetic pigments; the phycobilin phycoerythrin is responsible for giving many red algae their distinctive red color. However, since they also contain the blue-green chlorophyll \"a\" and other pigments, many are reddish to purple from the combination. The red phycoerytherin pigment is an adaptation to help red algae catch more sunlight in deep water\u2014as such, some red algae that live in shallow water have less phycoerythrin in their rhodoplasts, and can appear more greenish. Rhodoplasts synthesize a form of starch called floridean starch, which collects into granules outside the rhodoplast, in the cytoplasm of the red alga.\nChloroplastida (green algae and plants).\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nDiversity of green algae Clockwise from top left: \"Scenedesmus\", \"Micrasterias\", \"Hydrodictyon\", \"Volvox\", \"Stigeoclonium\". Green algal chloroplasts are characterized by their pigments chlorophyll \"a\" and chlorophyll \"b\" which give them their green color. \nThe chloroplastida chloroplasts, or green chloroplasts, are another large, highly diverse primary chloroplast lineage. Their host organisms are commonly known as green algae and land plants. They differ from glaucophyte and red algal chloroplasts in that they have lost their phycobilisomes, and contain chlorophyll \"b\" instead. Most green chloroplasts are (obviously) green, though some aren't, like some forms of \"H\u00e6matococcus pluvialis\", due to accessory pigments that override the chlorophylls' green colors. Chloroplastida chloroplasts have lost the peptidoglycan wall between their double membrane, leaving an intermembrane space. Some plants seem to have kept the genes for the synthesis of the peptidoglycan layer, though they've been repurposed for use in chloroplast division instead.\nMost of the chloroplasts depicted in this article are green chloroplasts.\nGreen algae and plants keep their starch \"inside\" their chloroplasts, and in plants and some algae, the chloroplast thylakoids are arranged in grana stacks. Some green algal chloroplasts contain a structure called a pyrenoid, which is functionally similar to the glaucophyte carboxysome in that it is where RuBisCO and CO2 are concentrated in the chloroplast.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nTransmission electron micrograph of \"Chlamydomonas reinhardtii\", a green alga that contains a pyrenoid surrounded by starch. \n\"Helicosporidium\" is a genus of nonphotosynthetic parasitic green algae that is thought to contain a vestigial chloroplast. Genes from a chloroplast and nuclear genes indicating the presence of a chloroplast have been found in \"Helicosporidium\" even if nobody's seen the chloroplast itself.\n\"Paulinella chromatophora\".\nWhile most chloroplasts originate from that first set of endosymbiotic events, \"Paulinella chromatophora\" is an exception that acquired a photosynthetic cyanobacterial endosymbiont more recently. It is not clear whether that symbiont is closely related to the ancestral chloroplast of other eukaryotes. Being in the early stages of endosymbiosis, \"Paulinella chromatophora\" can offer some insights into how chloroplasts evolved. \"Paulinella\" cells contain one or two sausage-shaped blue-green photosynthesizing structures called chromatophores, descended from the cyanobacterium \"Synechococcus\". Chromatophores cannot survive outside their host. Chromatophore DNA is about a million base pairs long, containing around 850 protein-encoding genes\u2014far less than the three million base pair \"Synechococcus\" genome, but much larger than the approximately 150,000 base pair genome of the more assimilated chloroplast. Chromatophores have transferred much less of their DNA to the nucleus of their host. About 0.3\u20130.8% of the nuclear DNA in \"Paulinella\" is from the chromatophore, compared with 11\u201314% from the chloroplast in plants.\nSecondary and tertiary endosymbiosis.\nCyanobacteria\nArch\u00e6plastida\nLand plants\nGlaucophyta\nGreen algae\nExcavata\nEuglenophyta\nRhodophyta\nChromalveolata\nRhizaria\u00a0a\n\"Paulinella\"\nChlorarachniophyta\nHaptophyta\nCryptophyta\nHeterokontophyta\nDinoflagellata\nApicomplexa\nCiliatea\nPossible cladogram of chloroplast evolutionCircles represent endosymbiotic events. For clarity, dinophyte tertiary endosymbioses and many nonphotosynthetic lineages have been omitted.\na It is now established that Chromalveolata is paraphyletic to Rhizaria.\nMany other organisms obtained chloroplasts from the primary chloroplast lineages through secondary endosymbiosis\u2014engulfing a red or green alga that contained a chloroplast. These chloroplasts are known as secondary plastids.\nWhile primary chloroplasts have a double membrane from their cyanobacterial ancestor, secondary chloroplasts have additional membranes outside of the original two, as a result of the secondary endosymbiotic event, when a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it\u2014much like the cyanobacterium at the beginning of this story. The engulfed alga was broken down, leaving only its chloroplast, and sometimes its cell membrane and nucleus, forming a chloroplast with three or four membranes\u2014the two cyanobacterial membranes, sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell membrane.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nSecondary endosymbiosis consisted of a eukaryotic alga being engulfed by another eukaryote, forming a chloroplast with three or four membranes. \n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nDiagram of a four membraned chloroplast containing a nucleomorph. \nThe genes in the phagocytosed eukaryote's nucleus are often transferred to the secondary host's nucleus.\nCryptomonads and chlorarachniophytes retain the phagocytosed eukaryote's nucleus, an object called a nucleomorph, located between the second and third membranes of the chloroplast.\nAll secondary chloroplasts come from green and red algae\u2014no secondary chloroplasts from glaucophytes have been observed, probably because glaucophytes are relatively rare in nature, making them less likely to have been taken up by another eukaryote.\nGreen algal derived chloroplasts.\nGreen algae have been taken up by the euglenids, chlorarachniophytes, a lineage of dinoflagellates, and possibly the ancestor of the CASH lineage (cryptomonads, alveolates, stramenopiles and haptophytes) in three or four separate engulfments. Many green algal derived chloroplasts contain pyrenoids, but unlike chloroplasts in their green algal ancestors, storage product collects in granules outside the chloroplast.\nEuglenophytes.\nEuglenophytes are a group of common flagellated protists that contain chloroplasts derived from a green alga. Euglenophyte chloroplasts have three membranes\u2014it is thought that the membrane of the primary endosymbiont was lost, leaving the cyanobacterial membranes, and the secondary host's phagosomal membrane. Euglenophyte chloroplasts have a pyrenoid and thylakoids stacked in groups of three. Photosynthetic product is stored in the form of paramylon, which is contained in membrane-bound granules in the cytoplasm of the euglenophyte.\nChlorarachniophytes.\nChlorarachniophytes are a rare group of organisms that also contain chloroplasts derived from green algae, though their story is more complicated than that of the euglenophytes. The ancestor of chlorarachniophytes is thought to have been a eukaryote with a \"red\" algal derived chloroplast. It is then thought to have lost its first red algal chloroplast, and later engulfed a green alga, giving it its second, green algal derived chloroplast.\nChlorarachniophyte chloroplasts are bounded by four membranes, except near the cell membrane, where the chloroplast membranes fuse into a double membrane. Their thylakoids are arranged in loose stacks of three. Chlorarachniophytes have a form of polysaccharide called chrysolaminarin, which they store in the cytoplasm, often collected around the chloroplast pyrenoid, which bulges into the cytoplasm.\nChlorarachniophyte chloroplasts are notable because the green alga they are derived from has not been completely broken down\u2014its nucleus still persists as a nucleomorph found between the second and third chloroplast membranes\u2014the periplastid space, which corresponds to the green alga's cytoplasm.\nPrasinophyte-derived dinophyte chloroplast.\n\"Lepidodinium viride\" and its close relatives are dinophytes (see below) that lost their original peridinin chloroplast and replaced it with a green algal derived chloroplast (more specifically, a prasinophyte). \"Lepidodinium\" is the only dinophyte that has a chloroplast that's not from the rhodoplast lineage. The chloroplast is surrounded by two membranes and has no nucleomorph\u2014all the nucleomorph genes have been transferred to the dinophyte nucleus. The endosymbiotic event that led to this chloroplast was serial secondary endosymbiosis rather than tertiary endosymbiosis\u2014the endosymbiont was a green alga containing a primary chloroplast (making a secondary chloroplast).\nRed algal derived chloroplasts.\nCryptophytes.\nCryptophytes, or cryptomonads are a group of algae that contain a red-algal derived chloroplast. Cryptophyte chloroplasts contain a nucleomorph that superficially resembles that of the chlorarachniophytes. Cryptophyte chloroplasts have four membranes, the outermost of which is continuous with the rough endoplasmic reticulum. They synthesize ordinary starch, which is stored in granules found in the periplastid space\u2014outside the original double membrane, in the place that corresponds to the red alga's cytoplasm. Inside cryptophyte chloroplasts is a pyrenoid and thylakoids in stacks of two.\nTheir chloroplasts do not have phycobilisomes, but they do have phycobilin pigments which they keep in their thylakoid space, rather than anchored on the outside of their thylakoid membranes.\nCryptophytes may have played a key role in the spreading of red algal based chloroplasts.\nHaptophytes.\nHaptophytes are similar and closely related to cryptophytes or heterokontophytes. Their chloroplasts lack a nucleomorph, their thylakoids are in stacks of three, and they synthesize chrysolaminarin sugar, which they store completely outside of the chloroplast, in the cytoplasm of the haptophyte.\nHeterokontophytes (stramenopiles).\nThe heterokontophytes, also known as the stramenopiles, are a very large and diverse group of eukaryotes. The photoautotrophic lineage, Ochrophyta, including the diatoms and the brown algae, golden algae, and yellow-green algae, also contains red algal derived chloroplasts.\nHeterokont chloroplasts are very similar to haptophyte chloroplasts, containing a pyrenoid, triplet thylakoids, and with some exceptions, having four layer plastidic envelope, the outermost epiplastid membrane connected to the endoplasmic reticulum. Like haptophytes, heterokontophytes store sugar in chrysolaminarin granules in the cytoplasm. Heterokontophyte chloroplasts contain chlorophyll \"a\" and with a few exceptions chlorophyll \"c\", but also have carotenoids which give them their many colors.\nApicomplexans, chromerids, and dinophytes.\nThe alveolates are a major clade of unicellular eukaryotes of both autotrophic and heterotrophic members. The most notable shared characteristic is the presence of cortical (outer-region) alveoli (sacs). These are flattened vesicles (sacs) packed into a continuous layer just under the membrane and supporting it, typically forming a flexible pellicle (thin skin). In dinoflagellates they often form armor plates. Many members contain a red-algal derived plastid. One notable characteristic of this diverse group is the frequent loss of photosynthesis. However, a majority of these heterotrophs continue to process a non-photosynthetic plastid.\nApicomplexans are a group of alveolates. Like the helicosproidia, they're parasitic, and have a nonphotosynthetic chloroplast. They were once thought to be related to the helicosproidia, but it is now known that the helicosproida are green algae rather than part of the CASH lineage. The apicomplexans include \"Plasmodium\", the malaria parasite. Many apicomplexans keep a vestigial red algal derived chloroplast called an apicoplast, which they inherited from their ancestors. Other apicomplexans like \"Cryptosporidium\" have lost the chloroplast completely. Apicomplexans store their energy in amylopectin granules that are located in their cytoplasm, even though they are nonphotosynthetic.\nApicoplasts have lost all photosynthetic function, and contain no photosynthetic pigments or true thylakoids. They are bounded by four membranes, but the membranes are not connected to the endoplasmic reticulum. The fact that apicomplexans still keep their nonphotosynthetic chloroplast around demonstrates how the chloroplast carries out important functions other than photosynthesis. Plant chloroplasts provide plant cells with many important things besides sugar, and apicoplasts are no different\u2014they synthesize fatty acids, isopentenyl pyrophosphate, iron-sulfur clusters, and carry out part of the heme pathway. This makes the apicoplast an attractive target for drugs to cure apicomplexan-related diseases. The most important apicoplast function is isopentenyl pyrophosphate synthesis\u2014in fact, apicomplexans die when something interferes with this apicoplast function, and when apicomplexans are grown in an isopentenyl pyrophosphate-rich medium, they dump the organelle.\nThe Chromerida is a newly discovered group of algae from Australian corals which comprises some close photosynthetic relatives of the apicomplexans. The first member, \"Chromera velia\", was discovered and first isolated in 2001. The discovery of \"Chromera velia\" with similar structure to the apicomplexans, provides an important link in the evolutionary history of the apicomplexans and dinophytes. Their plastids have four membranes, lack chlorophyll c and use the type II form of RuBisCO obtained from a horizontal transfer event.\nThe dinoflagellates are yet another very large and diverse group of protists, around half of which are (at least partially) photosynthetic.\nMost dinophyte chloroplasts are secondary red algal derived chloroplasts. Many other dinophytes have lost the chloroplast (becoming the nonphotosynthetic kind of dinoflagellate), or replaced it though \"tertiary\" endosymbiosis\u2014the engulfment of another eukaryotic algae containing a red algal derived chloroplast. Others replaced their original chloroplast with a green algal derived one.\nMost dinophyte chloroplasts contain form II RuBisCO, at least the photosynthetic pigments chlorophyll \"a\", chlorophyll \"c2\", \"beta\"-carotene, and at least one dinophyte-unique xanthophyll (peridinin, dinoxanthin, or diadinoxanthin), giving many a golden-brown color. All dinophytes store starch in their cytoplasm, and most have chloroplasts with thylakoids arranged in stacks of three.\nThe most common dinophyte chloroplast is the peridinin-type chloroplast, characterized by the carotenoid pigment peridinin in their chloroplasts, along with chlorophyll \"a\" and chlorophyll \"c\"2. Peridinin is not found in any other group of chloroplasts. The peridinin chloroplast is bounded by three membranes (occasionally two), having lost the red algal endosymbiont's original cell membrane. The outermost membrane is not connected to the endoplasmic reticulum. They contain a pyrenoid, and have triplet-stacked thylakoids. Starch is found outside the chloroplast. An important feature of these chloroplasts is that their chloroplast DNA is highly reduced and fragmented into many small circles. Most of the genome has migrated to the nucleus, and only critical photosynthesis-related genes remain in the chloroplast.\nThe peridinin chloroplast is thought to be the dinophytes' \"original\" chloroplast, which has been lost, reduced, replaced, or has company in several other dinophyte lineages.\nFucoxanthin-containing (haptophyte-derived) dinophyte chloroplasts.\nThe fucoxanthin dinophyte lineages (including \"Karlodinium\" and \"Karenia\") lost their original red algal derived chloroplast, and replaced it with a new chloroplast derived from a haptophyte endosymbiont. \"Karlodinium\" and \"Karenia\" probably took up different heterokontophytes. Because the haptophyte chloroplast has four membranes, tertiary endosymbiosis would be expected to create a six membraned chloroplast, adding the haptophyte's cell membrane and the dinophyte's phagosomal vacuole. However, the haptophyte was heavily reduced, stripped of a few membranes and its nucleus, leaving only its chloroplast (with its original double membrane), and possibly one or two additional membranes around it.\nFucoxanthin-containing chloroplasts are characterized by having the pigment fucoxanthin (actually 19\u2032-hexanoyloxy-fucoxanthin and/or 19\u2032-butanoyloxy-fucoxanthin) and no peridinin. Fucoxanthin is also found in haptophyte chloroplasts, providing evidence of ancestry.\nDiatom-derived dinophyte chloroplasts.\nSome dinophytes, like \"Kryptoperidinium\" and \"Durinskia\", have a diatom (heterokontophyte)-derived chloroplast. These chloroplasts are bounded by up to \"five\" membranes, (depending on whether the entire diatom endosymbiont is counted as the chloroplast, or just the red algal derived chloroplast inside it). The diatom endosymbiont has been reduced relatively little\u2014it still retains its original mitochondria, and has endoplasmic reticulum, ribosomes, a nucleus, and of course, red algal derived chloroplasts\u2014practically a complete cell, all inside the host's endoplasmic reticulum lumen. However the diatom endosymbiont can't store its own food\u2014its storage polysaccharide is found in granules in the dinophyte host's cytoplasm instead. The diatom endosymbiont's nucleus is present, but it probably can't be called a nucleomorph because it shows no sign of genome reduction, and might have even been \"expanded\". Diatoms have been engulfed by dinoflagellates at least three times.\nThe diatom endosymbiont is bounded by a single membrane, inside it are chloroplasts with four membranes. Like the diatom endosymbiont's diatom ancestor, the chloroplasts have triplet thylakoids and pyrenoids.\nIn some of these genera, the diatom endosymbiont's chloroplasts aren't the only chloroplasts in the dinophyte. The original three-membraned peridinin chloroplast is still around, converted to an eyespot.\nKleptoplasty.\nIn some groups of mixotrophic protists, like some dinoflagellates (e.g. \"Dinophysis\"), chloroplasts are separated from a captured alga and used temporarily. These klepto chloroplasts may only have a lifetime of a few days and are then replaced.\nCryptophyte-derived dinophyte chloroplast.\nMembers of the genus \"Dinophysis\" have a phycobilin-containing chloroplast taken from a cryptophyte. However, the cryptophyte is not an endosymbiont\u2014only the chloroplast seems to have been taken, and the chloroplast has been stripped of its nucleomorph and outermost two membranes, leaving just a two-membraned chloroplast. Cryptophyte chloroplasts require their nucleomorph to maintain themselves, and \"Dinophysis\" species grown in cell culture alone cannot survive, so it is possible (but not confirmed) that the \"Dinophysis\" chloroplast is a kleptoplast\u2014if so, \"Dinophysis\" chloroplasts wear out and \"Dinophysis\" species must continually engulf cryptophytes to obtain new chloroplasts to replace the old ones.\nChloroplast DNA.\nChloroplasts, like other types of plastid, contain a genome separate from that in the cell nucleus. The existence of chloroplast DNA (cpDNA) was identified biochemically in 1959, and confirmed by electron microscopy in 1962. The discoveries that the chloroplast contains ribosomes and performs protein synthesis revealed that the chloroplast is genetically semi-autonomous. Chloroplast DNA was first sequenced in 1986. Since then, hundreds of chloroplast DNAs from various species have been sequenced, but they are mostly those of land plants and green algae\u2014glaucophytes, red algae, and other algal groups are extremely underrepresented, potentially introducing some bias in views of \"typical\" chloroplast DNA structure and content.\nMolecular structure.\ncytochrome\nphotosystem I\nacetyl-CoA carboxylase\nrubisco\ntRNAs\ntRNA\nphotosystem II\ntRNAs\ntRNAs\nphotosystem II\nribosomal&lt;br&gt;proteins\ntRNA\ntRNA\nnadh dehydrogenase\nribosomal proteins\ntRNA\nreplication origin regions\ntRNA\nsmall RNA\nribosomal protein\nreplication origin regions\nribosomal RNA\ntRNAs\nribosomal RNA\ntRNA\ncytochromes\nphotosystem II\nribosomal proteins\nphotosystem I\ncytochromes\nphotosystem II\natp synthase\ntRNAs\nnadh dehydrogenase\ntRNA\nribosomal proteins\nphotosystem I\ntRNAs\nphotosystem II\nRNA polymerase\nribosomal protein\natp synthase\ntRNAs\nribosomal protein\ntRNA\nphotosystem II\ntRNA\ntRNA\nribosomal RNA\ntRNA\nribosomal RNA\ntRNA\nribosomal protein\nphotosystem I\nnadh dehydrogenase\ntRNA\nribosomal protein\nnadh dehydrogenase\ntRNA\ntRNA\nribosomal proteins\ninitiation factor 1\nribosomal proteins\nRNA polymerase\natp-dependent protease\nribosomal proteins\ntRNAs\n\"nicotiana tabacum\"\nChloroplast DNA Interactive gene map of chloroplast DNA from \"Nicotiana tabacum\". Segments with labels on the inside reside on the B strand of DNA, segments with labels on the outside are on the A strand. Notches indicate introns.\nWith few exceptions, most chloroplasts have their entire chloroplast genome combined into a single large circular DNA molecule, typically 120,000\u2013170,000 base pairs long. They can have a contour length of around 30\u201360 micrometers, and have a mass of about 80\u2013130 million daltons.\nWhile usually thought of as a circular molecule, there is some evidence that chloroplast DNA molecules more often take on a linear shape.\nInverted repeats.\nMany chloroplast DNAs contain two \"inverted repeats\", which separate a long single copy section (LSC) from a short single copy section (SSC).\nWhile a given pair of inverted repeats are rarely completely identical, they are always very similar to each other, apparently resulting from concerted evolution.\nThe inverted repeats vary wildly in length, ranging from 4,000 to 25,000 base pairs long each and containing as few as four or as many as over 150 genes. Inverted repeats in plants tend to be at the upper end of this range, each being 20,000\u201325,000 base pairs long.\nThe inverted repeat regions are highly conserved among land plants, and accumulate few mutations. Similar inverted repeats exist in the genomes of cyanobacteria and the other two chloroplast lineages (glaucophyta and rhodophyceae), suggesting that they predate the chloroplast, though some chloroplast DNAs have since lost or flipped the inverted repeats (making them direct repeats). It is possible that the inverted repeats help stabilize the rest of the chloroplast genome, as chloroplast DNAs which have lost some of the inverted repeat segments tend to get rearranged more.\nNucleoids.\nNew chloroplasts may contain up to 100 copies of their DNA, though the number of chloroplast DNA copies decreases to about 15\u201320 as the chloroplasts age. They are usually packed into nucleoids, which can contain several identical chloroplast DNA rings. Many nucleoids can be found in each chloroplast.\nIn primitive red algae, the chloroplast DNA nucleoids are clustered in the center of the chloroplast, while in green plants and green algae, the nucleoids are dispersed throughout the stroma.\nThough chloroplast DNA is not associated with true histones, in red algae, similar proteins that tightly pack each chloroplast DNA ring into a nucleoid have been found.\nDNA repair.\nIn chloroplasts of the moss \"Physcomitrella patens\", the DNA mismatch repair protein Msh1 interacts with the recombinational repair proteins RecA and RecG to maintain chloroplast genome stability. In chloroplasts of the plant \"Arabidopsis thaliana\" the RecA protein maintains the integrity of the chloroplast's DNA by a process that likely involves the recombinational repair of DNA damage.\nDNA replication.\nThe mechanism for chloroplast DNA (cpDNA) replication has not been conclusively determined, but two main models have been proposed. Scientists have attempted to observe chloroplast replication via electron microscopy since the 1970s. The results of the microscopy experiments led to the idea that chloroplast DNA replicates using a double displacement loop (D-loop). As the D-loop moves through the circular DNA, it adopts a theta intermediary form, also known as a Cairns replication intermediate, and completes replication with a rolling circle mechanism. Transcription starts at specific points of origin. Multiple replication forks open up, allowing replication machinery to transcribe the DNA. As replication continues, the forks grow and eventually converge. The new cpDNA structures separate, creating daughter cpDNA chromosomes.\nIn addition to the early microscopy experiments, this model is also supported by the amounts of deamination seen in cpDNA. Deamination occurs when an amino group is lost and is a mutation that often results in base changes. When adenine is deaminated, it becomes hypoxanthine. Hypoxanthine can bind to cytosine, and when the XC base pair is replicated, it becomes a GC (thus, an A \u2192 G base change).\nIn cpDNA, there are several A \u2192 G deamination gradients. DNA becomes susceptible to deamination events when it is single stranded. When replication forks form, the strand not being copied is single stranded, and thus at risk for A \u2192 G deamination. Therefore, gradients in deamination indicate that replication forks were most likely present and the direction that they initially opened (the highest gradient is most likely nearest the start site because it was single stranded for the longest amount of time). This mechanism is still the leading theory today; however, a second theory suggests that most cpDNA is actually linear and replicates through homologous recombination. It further contends that only a minority of the genetic material is kept in circular chromosomes while the rest is in branched, linear, or other complex structures.\nOne of competing model for cpDNA replication asserts that most cpDNA is linear and participates in homologous recombination and replication structures similar to the linear and circular DNA structures of bacteriophage T4. It has been established that some plants have linear cpDNA, such as maize, and that more species still contain complex structures that scientists do not yet understand. When the original experiments on cpDNA were performed, scientists did notice linear structures; however, they attributed these linear forms to broken circles. If the branched and complex structures seen in cpDNA experiments are real and not artifacts of concatenated circular DNA or broken circles, then a D-loop mechanism of replication is insufficient to explain how those structures would replicate. At the same time, homologous recombination does not expand the multiple A --&gt; G gradients seen in plastomes. Because of the failure to explain the deamination gradient as well as the numerous plant species that have been shown to have circular cpDNA, the predominant theory continues to hold that most cpDNA is circular and most likely replicates via a D loop mechanism.\nGene content and protein synthesis.\nThe chloroplast genome most commonly includes around 100 genes that code for a variety of things, mostly to do with the protein pipeline and photosynthesis. As in prokaryotes, genes in chloroplast DNA are organized into operons. Unlike prokaryotic DNA molecules, chloroplast DNA molecules contain introns (plant mitochondrial DNAs do too, but not human mtDNAs).\nAmong land plants, the contents of the chloroplast genome are fairly similar.\nChloroplast genome reduction and gene transfer.\nOver time, many parts of the chloroplast genome were transferred to the nuclear genome of the host, a process called \"endosymbiotic gene transfer\". As a result, the chloroplast genome is heavily reduced compared to that of free-living cyanobacteria. Chloroplasts may contain 60\u2013100 genes whereas cyanobacteria often have more than 1500 genes in their genome. Recently, a plastid without a genome was found, demonstrating chloroplasts can lose their genome during endosymbiotic the gene transfer process.\nEndosymbiotic gene transfer is how we know about the lost chloroplasts in many CASH lineages. Even if a chloroplast is eventually lost, the genes it donated to the former host's nucleus persist, providing evidence for the lost chloroplast's existence. For example, while diatoms (a heterokontophyte) now have a red algal derived chloroplast, the presence of many green algal genes in the diatom nucleus provide evidence that the diatom ancestor had a green algal derived chloroplast at some point, which was subsequently replaced by the red chloroplast.\nIn land plants, some 11\u201314% of the DNA in their nuclei can be traced back to the chloroplast, up to 18% in \"Arabidopsis\", corresponding to about 4,500 protein-coding genes. There have been a few recent transfers of genes from the chloroplast DNA to the nuclear genome in land plants.\nOf the approximately 3000 proteins found in chloroplasts, some 95% of them are encoded by nuclear genes. Many of the chloroplast's protein complexes consist of subunits from both the chloroplast genome and the host's nuclear genome. As a result, protein synthesis must be coordinated between the chloroplast and the nucleus. The chloroplast is mostly under nuclear control, though chloroplasts can also give out signals regulating gene expression in the nucleus, called \"retrograde signaling\".\nProtein synthesis.\nProtein synthesis within chloroplasts relies on two RNA polymerases. One is coded by the chloroplast DNA, the other is of nuclear origin. The two RNA polymerases may recognize and bind to different kinds of promoters within the chloroplast genome. The ribosomes in chloroplasts are similar to bacterial ribosomes.\nProtein targeting and import.\nBecause so many chloroplast genes have been moved to the nucleus, many proteins that would originally have been translated in the chloroplast are now synthesized in the cytoplasm of the plant cell. These proteins must be directed back to the chloroplast, and imported through at least two chloroplast membranes.\nCuriously, around half of the protein products of transferred genes aren't even targeted back to the chloroplast. Many became exaptations, taking on new functions like participating in cell division, protein routing, and even disease resistance. A few chloroplast genes found new homes in the mitochondrial genome\u2014most became nonfunctional pseudogenes, though a few tRNA genes still work in the mitochondrion. Some transferred chloroplast DNA protein products get directed to the secretory pathway, though many secondary plastids are bounded by an outermost membrane derived from the host's cell membrane, and therefore topologically outside of the cell because to reach the chloroplast from the cytosol, the cell membrane must be crossed, which signifies entrance into the extracellular space. In those cases, chloroplast-targeted proteins do initially travel along the secretory pathway.\nBecause the cell acquiring a chloroplast already had mitochondria (and peroxisomes, and a cell membrane for secretion), the new chloroplast host had to develop a unique protein targeting system to avoid having chloroplast proteins being sent to the wrong organelle.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \n The two ends of a polypeptide are called the N-terminus, or \"amino end\", and the C-terminus, or \"carboxyl end\". This polypeptide has four amino acids linked together. At the left is the N-terminus, with its amino (H2N) group in green. The blue C-terminus, with its carboxyl group (CO2H) is at the right. \nIn most, but not all cases, nuclear-encoded chloroplast proteins are translated with a \"cleavable transit peptide\" that's added to the N-terminus of the protein precursor. Sometimes the transit sequence is found on the C-terminus of the protein, or within the functional part of the protein.\nTransport proteins and membrane translocons.\nAfter a chloroplast polypeptide is synthesized on a ribosome in the cytosol, an enzyme specific to chloroplast proteins phosphorylates, or adds a phosphate group to many (but not all) of them in their transit sequences.\nPhosphorylation helps many proteins bind the polypeptide, keeping it from folding prematurely. This is important because it prevents chloroplast proteins from assuming their active form and carrying out their chloroplast functions in the wrong place\u2014the cytosol. At the same time, they have to keep just enough shape so that they can be recognized by the chloroplast. These proteins also help the polypeptide get imported into the chloroplast.\nFrom here, chloroplast proteins bound for the stroma must pass through two protein complexes\u2014the TOC complex, or translocon on the outer chloroplast membrane\", and the TIC translocon, or translocon on the inner chloroplast membrane translocon\". Chloroplast polypeptide chains probably often travel through the two complexes at the same time, but the TIC complex can also retrieve preproteins lost in the intermembrane space.\nStructure.\nIn land plants, chloroplasts are generally lens-shaped, 3\u201310 \u03bcm in diameter and 1\u20133 \u03bcm thick. Corn seedling chloroplasts are \u224820 \u00b5m3 in volume. Greater diversity in chloroplast shapes exists among the algae, which often contain a single chloroplast that can be shaped like a net (e.g., \"Oedogonium\"), a cup (e.g., \"Chlamydomonas\"), a ribbon-like spiral around the edges of the cell (e.g., \"Spirogyra\"), or slightly twisted bands at the cell edges (e.g., \"Sirogonium\"). Some algae have two chloroplasts in each cell; they are star-shaped in \"Zygnema\", or may follow the shape of half the cell in order Desmidiales. In some algae, the chloroplast takes up most of the cell, with pockets for the nucleus and other organelles, for example, some species of \"Chlorella\" have a cup-shaped chloroplast that occupies much of the cell.\nAll chloroplasts have at least three membrane systems\u2014the outer chloroplast membrane, the inner chloroplast membrane, and the thylakoid system. Chloroplasts that are the product of secondary endosymbiosis may have additional membranes surrounding these three. Inside the outer and inner chloroplast membranes is the chloroplast stroma, a semi-gel-like fluid that makes up much of a chloroplast's volume, and in which the thylakoid system floats.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \n500px\ncircle 756 320 5 Ribosome\ncircle 456 267 15 Plastoglobule\npoly 676 279 668 274 668 264 673 252 683 243 680 238 677 230 682 230 689 233 692 230 684 226 682 220 684 217 686 213 687 207 695 206 700 209 699 214 706 214 714 221 715 228 724 240 726 244 725 250 718 252 712 255 723 259 723 266 721 274 716 279 713 278 710 284 703 287 696 286 692 280 684 271 676 278 Chloroplast DNA\npoly 502 396 508 391 522 393 532 401 534 404 536 408 535 413 536 418 536 428 536 437 526 438 518 442 518 450 510 452 502 444 494 445 485 446 480 442 494 431 503 421 506 412 506 404 Chloroplast DNA\npoly 524 372 523 357 532 354 532 329 546 329 559 312 558 304 561 301 566 302 575 310 583 312 581 320 581 327 577 331 560 340 562 353 552 362 542 362 538 370 532 372 Starch granule\npoly 436 486 447 478 454 483 460 482 474 486 480 483 476 474 470 466 444 460 439 464 428 462 430 476 Starch granule\npoly 358 308 376 320 385 317 388 310 396 312 403 306 408 294 412 291 410 288 400 287 392 296 378 293 372 298 362 298 Starch granule\npoly 649 206 653 206 662 214 671 214 677 219 685 213 677 192 668 191 Starch granule\npoly 478 232 487 235 494 241 499 250 511 243 520 234 527 222 518 219 508 220 490 226 Thylakoid space\npoly 594 262 594 260 597 258 605 259 632 268 640 272 643 276 638 278 646 284 647 289 642 289 649 294 650 300 644 301 606 288 601 285 602 280 604 278 599 273 586 273 562 282 557 279 559 276 581 268 586 269 592 269 598 270 600 268 594 262 Thylakoid space\npoly 442 275 438 268 439 256 447 246 459 238 474 229 487 222 499 218 512 216 525 215 534 218 534 224 520 246 508 257 492 266 474 274 454 277 Thylakoid\npoly 604 287 601 282 602 278 600 274 598 271 600 269 594 265 594 258 597 258 608 248 626 241 640 236 653 235 661 238 664 248 664 251 668 254 668 261 671 263 672 268 672 274 666 286 650 301 643 302 Granal thylakoid\npoly 577 199 572 198 567 190 567 180 573 170 586 160 601 152 610 146 632 148 649 150 660 153 654 166 642 176 629 182 597 196 Granal thylakoid\npoly 355 308 366 302 383 290 404 263 403 280 406 286 414 288 427 286 442 280 448 288 458 287 474 280 495 268 511 254 522 245 535 228 532 246 522 260 510 274 494 286 474 298 459 305 456 306 458 308 466 310 484 300 505 287 522 271 533 258 542 237 541 230 536 226 532 217 521 214 541 210 552 204 560 196 566 192 569 196 576 200 599 195 630 182 622 192 604 202 587 216 592 216 606 210 622 198 636 186 648 176 661 155 679 160 672 170 652 194 632 212 610 227 592 234 581 238 570 240 563 241 558 254 560 260 570 260 587 257 603 253 594 258 593 263 600 268 597 274 586 273 557 282 538 284 529 287 524 293 508 306 494 316 475 325 458 331 443 334 434 332 429 326 430 319 433 313 424 312 418 310 408 311 392 313 375 320 368 323 Stromal thylakoid\npoly 664 244 664 251 668 256 668 259 672 261 674 266 671 280 661 296 644 313 625 328 609 337 598 341 593 341 588 340 586 332 576 336 568 343 554 347 535 349 516 347 508 344 500 341 484 340 468 342 458 345 473 344 480 347 485 354 489 359 490 368 485 382 474 396 462 410 440 426 428 434 430 448 434 450 452 440 467 427 488 404 500 391 509 377 518 371 532 366 546 364 562 365 574 365 595 362 622 349 641 337 659 320 673 306 687 289 688 296 686 306 679 318 668 333 656 343 645 353 632 362 617 370 608 370 603 370 600 360 586 369 577 378 578 390 586 394 597 392 608 394 615 396 613 406 630 398 646 394 637 388 643 374 657 364 672 351 693 328 707 308 713 293 713 284 707 274 696 272 698 260 690 244 676 243 664 244 Stromal thylakoid\npoly 325 275 342 264 366 255 389 249 400 250 406 259 410 267 412 271 412 275 416 279 417 287 402 311 386 322 372 328 351 303 333 285 Granum\npoly 441 274 443 281 458 309 485 321 510 311 529 300 546 286 548 267 542 236 536 228 518 251 502 261 478 272 461 277 446 277 Granum\npoly 572 198 582 216 608 225 638 212 662 196 674 181 676 173 672 169 661 160 634 182 592 201 Granum\npoly 604 288 585 303 580 316 583 329 588 340 606 369 656 367 682 349 696 335 701 327 700 321 673 270 663 287 649 301 640 300 Granum\npoly 398 375 413 364 432 354 452 347 465 345 477 344 484 351 489 364 506 406 505 415 496 427 482 439 464 449 446 457 437 459 429 461 429 443 427 432 420 413 406 389 Granum\npoly 586 438 591 424 608 410 627 400 650 392 666 387 678 389 682 393 684 398 686 403 687 409 654 431 609 458 597 465 594 458 591 455 590 449 Granum\ncircle 689 350 15 Plastoglobule\npoly 326 279 321 262 332 244 366 215 410 191 472 167 522 154 566 147 606 146 644 149 685 161 728 181 756 199 776 221 787 242 790 274 784 305 766 335 760 345 745 361 715 387 679 415 622 450 585 469 539 485 496 496 466 497 442 490 430 479 429 452 428 437 415 405 398 373 384 347 360 313 Stroma\npoly 383 344 352 304 328 280 311 250 332 218 365 194 411 171 463 153 529 137 589 130 626 130 683 140 724 156 762 176 786 197 802 219 809 241 808 268 801 289 790 309 764 343 726 379 694 404 655 430 608 459 564 478 524 491 490 497 461 497 442 491 431 478 428 467 430 448 426 429 416 408 400 379 386 349 Inner chloroplast membrane\npoly 198 679 132 675 83 660 47 627 26 576 20 534 22 488 42 423 73 366 117 311 186 252 241 213 316 172 404 139 480 120 558 110 611 107 673 110 737 120 805 142 851 171 875 194 891 233 893 268 890 297 868 348 830 398 775 449 685 520 610 564 522 605 428 640 348 662 277 674 Outer chloroplast membrane\ndesc none\n&lt;/imagemap&gt;\n1 Granum\n2 Chloroplast envelope\n2.1 Outer membrane\n2.2 Intermembrane space\n2.3 Inner membrane\n3 Thylakoid\n3.1 Thylakoid space (lumen)\n3.2 Thylakoid membrane\n4 Stromal thylakoids&lt;br&gt;(lamell\u00e6 or frets)\n5 Granal thylakoids\n6 Stroma\n7 Nucleoid&lt;br&gt;(DNA rings)\n8 Ribosome\n9 Plastoglobulus\n10 Starch granule\nChloroplast ultrastructure \"(interactive diagram)\" Chloroplasts have at least three distinct membrane systems, and a variety of things can be found in their stroma. \nThere are some common misconceptions about the outer and inner chloroplast membranes. The fact that chloroplasts are surrounded by a double membrane is often cited as evidence that they are the descendants of endosymbiotic cyanobacteria. This is often interpreted as meaning the outer chloroplast membrane is the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium\u2014which is not true\u2014both chloroplast membranes are homologous to the cyanobacterium's original double membranes.\nThe chloroplast double membrane is also often compared to the mitochondrial double membrane. This is not a valid comparison\u2014the inner mitochondria membrane is used to run proton pumps and carry out oxidative phosphorylation across to generate ATP energy. The only chloroplast structure that can considered analogous to it is the internal thylakoid system. Even so, in terms of \"in-out\", the direction of chloroplast H+ ion flow is in the opposite direction compared to oxidative phosphorylation in mitochondria. In addition, in terms of function, the inner chloroplast membrane, which regulates metabolite passage and synthesizes some materials, has no counterpart in the mitochondrion.\nOuter chloroplast membrane.\nThe outer chloroplast membrane is a semi-porous membrane that small molecules and ions can easily diffuse across. However, it is not permeable to larger proteins, so chloroplast polypeptides being synthesized in the cell cytoplasm must be transported across the outer chloroplast membrane by the TOC complex, or \"translocon on the outer chloroplast\" membrane.\nThe chloroplast membranes sometimes protrude out into the cytoplasm, forming a stromule, or stroma-containing tubule. Stromules are very rare in chloroplasts, and are much more common in other plastids like chromoplasts and amyloplasts in petals and roots, respectively. They may exist to increase the chloroplast's surface area for cross-membrane transport, because they are often branched and tangled with the endoplasmic reticulum. When they were first observed in 1962, some plant biologists dismissed the structures as artifactual, claiming that stromules were just oddly shaped chloroplasts with constricted regions or dividing chloroplasts. However, there is a growing body of evidence that stromules are functional, integral features of plant cell plastids, not merely artifacts.\nIntermembrane space and peptidoglycan wall.\nUsually, a thin intermembrane space about 10\u201320 nanometers thick exists between the outer and inner chloroplast membranes.\nGlaucophyte algal chloroplasts have a peptidoglycan layer between the chloroplast membranes. It corresponds to the peptidoglycan cell wall of their cyanobacterial ancestors, which is located between their two cell membranes. These chloroplasts are called \"muroplasts\" (from Latin \"mura\", meaning \"wall\"). Other chloroplasts were assumed to have lost the cyanobacterial wall, leaving an intermembrane space between the two chloroplast envelope membranes, but has since been found also in moss, lycophytes and ferns.\nInner chloroplast membrane.\nThe inner chloroplast membrane borders the stroma and regulates passage of materials in and out of the chloroplast. After passing through the TOC complex in the outer chloroplast membrane, polypeptides must pass through the TIC complex \"(translocon on the inner chloroplast membrane)\" which is located in the inner chloroplast membrane.\nIn addition to regulating the passage of materials, the inner chloroplast membrane is where fatty acids, lipids, and carotenoids are synthesized.\nPeripheral reticulum.\nSome chloroplasts contain a structure called the chloroplast peripheral reticulum. It is often found in the chloroplasts of C4 plants, though it has also been found in some C3 angiosperms, and even some gymnosperms. The chloroplast peripheral reticulum consists of a maze of membranous tubes and vesicles continuous with the inner chloroplast membrane that extends into the internal stromal fluid of the chloroplast. Its purpose is thought to be to increase the chloroplast's surface area for cross-membrane transport between its stroma and the cell cytoplasm. The small vesicles sometimes observed may serve as transport vesicles to shuttle stuff between the thylakoids and intermembrane space.\nStroma.\nThe protein-rich, alkaline, aqueous fluid within the inner chloroplast membrane and outside of the thylakoid space is called the stroma, which corresponds to the cytosol of the original cyanobacterium. Nucleoids of chloroplast DNA, chloroplast ribosomes, the thylakoid system with plastoglobuli, starch granules, and many proteins can be found floating around in it. The Calvin cycle, which fixes CO2 into G3P takes place in the stroma.\nChloroplast ribosomes.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nChloroplast ribosomes Comparison of a chloroplast ribosome (green) and a bacterial ribosome (yellow). Important features common to both ribosomes and chloroplast-unique features are labeled. \nChloroplasts have their own ribosomes, which they use to synthesize a small fraction of their proteins. Chloroplast ribosomes are about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm). They take mRNAs transcribed from the chloroplast DNA and translate them into protein. While similar to bacterial ribosomes, chloroplast translation is more complex than in bacteria, so chloroplast ribosomes include some chloroplast-unique features.\nSmall subunit ribosomal RNAs in several Chlorophyta and euglenid chloroplasts lack motifs for Shine-Dalgarno sequence recognition, which is considered essential for translation initiation in most chloroplasts and prokaryotes. Such loss is also rarely observed in other plastids and prokaryotes. An additional 4.5S rRNA with homology to the 3' tail of 23S is found in \"higher\" plants.\nPlastoglobuli.\nPlastoglobuli (singular \"plastoglobulus\", sometimes spelled \"plastoglobule(s)\"), are spherical bubbles of lipids and proteins about 45\u201360 nanometers across. They are surrounded by a lipid monolayer. Plastoglobuli are found in all chloroplasts, but become more common when the chloroplast is under oxidative stress, or when it ages and transitions into a gerontoplast. Plastoglobuli also exhibit a greater size variation under these conditions. They are also common in etioplasts, but decrease in number as the etioplasts mature into chloroplasts.\nPlastoglobuli contain both structural proteins and enzymes involved in lipid synthesis and metabolism. They contain many types of lipids including plastoquinone, vitamin E, carotenoids and chlorophylls.\nPlastoglobuli were once thought to be free-floating in the stroma, but it is now thought that they are permanently attached either to a thylakoid or to another plastoglobulus attached to a thylakoid, a configuration that allows a plastoglobulus to exchange its contents with the thylakoid network. In normal green chloroplasts, the vast majority of plastoglobuli occur singularly, attached directly to their parent thylakoid. In old or stressed chloroplasts, plastoglobuli tend to occur in linked groups or chains, still always anchored to a thylakoid.\nPlastoglobuli form when a bubble appears between the layers of the lipid bilayer of the thylakoid membrane, or bud from existing plastoglobuli\u2014though they never detach and float off into the stroma. Practically all plastoglobuli form on or near the highly curved edges of the thylakoid disks or sheets. They are also more common on stromal thylakoids than on granal ones.\nStarch granules.\nStarch granules are very common in chloroplasts, typically taking up 15% of the organelle's volume, though in some other plastids like amyloplasts, they can be big enough to distort the shape of the organelle. Starch granules are simply accumulations of starch in the stroma, and are not bounded by a membrane.\nStarch granules appear and grow throughout the day, as the chloroplast synthesizes sugars, and are consumed at night to fuel respiration and continue sugar export into the phloem, though in mature chloroplasts, it is rare for a starch granule to be completely consumed or for a new granule to accumulate.\nStarch granules vary in composition and location across different chloroplast lineages. In red algae, starch granules are found in the cytoplasm rather than in the chloroplast. In C4 plants, mesophyll chloroplasts, which do not synthesize sugars, lack starch granules.\nRuBisCO.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nRuBisCO, shown here in a space-filling model, is the main enzyme responsible for carbon fixation in chloroplasts. \nThe chloroplast stroma contains many proteins, though the most common and important is RuBisCO, which is probably also the most abundant protein on the planet. RuBisCO is the enzyme that fixes CO2 into sugar molecules. In C3 plants, RuBisCO is abundant in all chloroplasts, though in C4 plants, it is confined to the bundle sheath chloroplasts, where the Calvin cycle is carried out in C4 plants.\nPyrenoids.\nThe chloroplasts of some hornworts and algae contain structures called pyrenoids. They are not found in higher plants. Pyrenoids are roughly spherical and highly refractive bodies which are a site of starch accumulation in plants that contain them. They consist of a matrix opaque to electrons, surrounded by two hemispherical starch plates. The starch is accumulated as the pyrenoids mature. In algae with carbon concentrating mechanisms, the enzyme RuBisCO is found in the pyrenoids. Starch can also accumulate around the pyrenoids when CO2 is scarce. Pyrenoids can divide to form new pyrenoids, or be produced \"de novo\".\nThylakoid system.\nThylakoids (sometimes spelled \"thylako\u00efds\"), are small interconnected sacks which contain the membranes that the light reactions of photosynthesis take place on. The word \"thylakoid\" comes from the Greek word \"thylakos\" which means \"sack\".\nSuspended within the chloroplast stroma is the thylakoid system, a highly dynamic collection of membranous sacks called thylakoids where chlorophyll is found and the light reactions of photosynthesis happen.\nIn most vascular plant chloroplasts, the thylakoids are arranged in stacks called grana, though in certain C4 plant chloroplasts and some algal chloroplasts, the thylakoids are free floating.\nThylakoid structure.\nUsing a light microscope, it is just barely possible to see tiny green granules\u2014which were named grana. With electron microscopy, it became possible to see the thylakoid system in more detail, revealing it to consist of stacks of flat thylakoids which made up the grana, and long interconnecting stromal thylakoids which linked different grana.\nIn the transmission electron microscope, thylakoid membranes appear as alternating light-and-dark bands, 8.5 nanometers thick.\nFor a long time, the three-dimensional structure of the thylakoid membrane system had been unknown or disputed. Many models have been proposed, the most prevalent being the helical model, in which granum stacks of thylakoids are wrapped by helical stromal thylakoids. Another model known as the 'bifurcation model', which was based on the first electron tomography study of plant thylakoid membranes, depicts the stromal membranes as wide lamellar sheets perpendicular to the grana columns which bifurcates into multiple parallel discs forming the granum-stroma assembly. The helical model was supported by several additional works, but ultimately it was determined in 2019 that features from both the helical and bifurcation models are consolidated by newly discovered left-handed helical membrane junctions. Likely for ease, the thylakoid system is still commonly depicted by older \"hub and spoke\" models where the grana are connected to each other by tubes of stromal thylakoids.\nGrana consist of a stacks of flattened circular granal thylakoids that resemble pancakes. Each granum can contain anywhere from two to a hundred thylakoids, though grana with 10\u201320 thylakoids are most common. Wrapped around the grana are multiple parallel right-handed helical stromal thylakoids, also known as frets or lamellar thylakoids. The helices ascend at an angle of ~20\u00b0, connecting to each granal thylakoid at a bridge-like slit junction.\nThe stroma lamellae extend as large sheets perpendicular to the grana columns. These sheets are connected to the right-handed helices either directly or through bifurcations that form left-handed helical membrane surfaces. The left-handed helical surfaces have a similar tilt angle to the right-handed helices (~20\u00b0), but \u00bc the pitch. Approximately 4 left-handed helical junctions are present per granum, resulting in a pitch-balanced array of right- and left-handed helical membrane surfaces of different radii and pitch that consolidate the network with minimal surface and bending energies. While different parts of the thylakoid system contain different membrane proteins, the thylakoid membranes are continuous and the thylakoid space they enclose form a single continuous labyrinth.\nThylakoid composition.\nEmbedded in the thylakoid membranes are important protein complexes which carry out the light reactions of photosynthesis. Photosystem II and photosystem I contain light-harvesting complexes with chlorophyll and carotenoids that absorb light energy and use it to energize electrons. Molecules in the thylakoid membrane use the energized electrons to pump hydrogen ions into the thylakoid space, decreasing the pH and turning it acidic. ATP synthase is a large protein complex that harnesses the concentration gradient of the hydrogen ions in the thylakoid space to generate ATP energy as the hydrogen ions flow back out into the stroma\u2014much like a dam turbine.\nThere are two types of thylakoids\u2014granal thylakoids, which are arranged in grana, and stromal thylakoids, which are in contact with the stroma. Granal thylakoids are pancake-shaped circular disks about 300\u2013600 nanometers in diameter. Stromal thylakoids are helicoid sheets that spiral around grana. The flat tops and bottoms of granal thylakoids contain only the relatively flat photosystem II protein complex. This allows them to stack tightly, forming grana with many layers of tightly appressed membrane, called granal membrane, increasing stability and surface area for light capture.\nIn contrast, photosystem I and ATP synthase are large protein complexes which jut out into the stroma. They can't fit in the appressed granal membranes, and so are found in the stromal thylakoid membrane\u2014the edges of the granal thylakoid disks and the stromal thylakoids. These large protein complexes may act as spacers between the sheets of stromal thylakoids.\nThe number of thylakoids and the total thylakoid area of a chloroplast is influenced by light exposure. Shaded chloroplasts contain larger and more grana with more thylakoid membrane area than chloroplasts exposed to bright light, which have smaller and fewer grana and less thylakoid area. Thylakoid extent can change within minutes of light exposure or removal.\nPigments and chloroplast colors.\nInside the photosystems embedded in chloroplast thylakoid membranes are various photosynthetic pigments, which absorb and transfer light energy. The types of pigments found are different in various groups of chloroplasts, and are responsible for a wide variety of chloroplast colorations.\n box-shadow: 1px 1px 3px rgba(0,0,0,0.2);\"&gt;\nPaper chromatography of some spinach leaf extract shows the various pigments present in their chloroplasts.\nXanthophylls\nChlorophyll \"a\"\nChlorophyll \"b\"\nChlorophylls.\nChlorophyll \"a\" is found in all chloroplasts, as well as their cyanobacterial ancestors. Chlorophyll \"a\" is a blue-green pigment partially responsible for giving most cyanobacteria and chloroplasts their color. Other forms of chlorophyll exist, such as the accessory pigments chlorophyll \"b\", chlorophyll \"c\", chlorophyll \"d\", and chlorophyll \"f\".\nChlorophyll \"b\" is an olive green pigment found only in the chloroplasts of plants, green algae, any secondary chloroplasts obtained through the secondary endosymbiosis of a green alga, and a few cyanobacteria. It is the chlorophylls \"a\" and \"b\" together that make most plant and green algal chloroplasts green.\nChlorophyll \"c\" is mainly found in secondary endosymbiotic chloroplasts that originated from a red alga, although it is not found in chloroplasts of red algae themselves. Chlorophyll \"c\" is also found in some green algae and cyanobacteria.\nChlorophylls \"d\" and \"f\" are pigments found only in some cyanobacteria.\nCarotenoids.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \n\"Delesseria sanguinea\", a red alga, has chloroplasts that contain red pigments like phycoerytherin that mask their blue-green chlorophyll \"a\". \nIn addition to chlorophylls, another group of yellow\u2013orange pigments called carotenoids are also found in the photosystems. There are about thirty photosynthetic carotenoids. They help transfer and dissipate excess energy, and their bright colors sometimes override the chlorophyll green, like during the fall, when the leaves of some land plants change color. \u03b2-carotene is a bright red-orange carotenoid found in nearly all chloroplasts, like chlorophyll \"a\". Xanthophylls, especially the orange-red zeaxanthin, are also common. Many other forms of carotenoids exist that are only found in certain groups of chloroplasts.\nPhycobilins.\nPhycobilins are a third group of pigments found in cyanobacteria, and glaucophyte, red algal, and cryptophyte chloroplasts. Phycobilins come in all colors, though phycoerytherin is one of the pigments that makes many red algae red. Phycobilins often organize into relatively large protein complexes about 40 nanometers across called phycobilisomes. Like photosystem I and ATP synthase, phycobilisomes jut into the stroma, preventing thylakoid stacking in red algal chloroplasts. Cryptophyte chloroplasts and some cyanobacteria don't have their phycobilin pigments organized into phycobilisomes, and keep them in their thylakoid space instead.\nSpecialized chloroplasts in C4 plants.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nMany C4 plants have their mesophyll cells and bundle sheath cells arranged radially around their leaf veins. The two types of cells contain different types of chloroplasts specialized for a particular part of photosynthesis. \nTo fix carbon dioxide into sugar molecules in the process of photosynthesis, chloroplasts use an enzyme called RuBisCO. RuBisCO has trouble distinguishing between carbon dioxide and oxygen, so at high oxygen concentrations, RuBisCO starts accidentally adding oxygen to sugar precursors. This has the result of ATP energy being wasted and CO2 being released, all with no sugar being produced. This is a big problem, since O2 is produced by the initial light reactions of photosynthesis, causing issues down the line in the Calvin cycle which uses RuBisCO.\nC4 plants evolved a way to solve this\u2014by spatially separating the light reactions and the Calvin cycle. The light reactions, which store light energy in ATP and NADPH, are done in the mesophyll cells of a C4 leaf. The Calvin cycle, which uses the stored energy to make sugar using RuBisCO, is done in the bundle sheath cells, a layer of cells surrounding a vein in a leaf.\nAs a result, chloroplasts in C4 mesophyll cells and bundle sheath cells are specialized for each stage of photosynthesis. In mesophyll cells, chloroplasts are specialized for the light reactions, so they lack RuBisCO, and have normal grana and thylakoids, which they use to make ATP and NADPH, as well as oxygen. They store CO2 in a four-carbon compound, which is why the process is called \"C4 photosynthesis\". The four-carbon compound is then transported to the bundle sheath chloroplasts, where it drops off CO2 and returns to the mesophyll. Bundle sheath chloroplasts do not carry out the light reactions, preventing oxygen from building up in them and disrupting RuBisCO activity. Because of this, they lack thylakoids organized into grana stacks\u2014though bundle sheath chloroplasts still have free-floating thylakoids in the stroma where they still carry out cyclic electron flow, a light-driven method of synthesizing ATP to power the Calvin cycle without generating oxygen. They lack photosystem II, and only have photosystem I\u2014the only protein complex needed for cyclic electron flow. Because the job of bundle sheath chloroplasts is to carry out the Calvin cycle and make sugar, they often contain large starch grains.\nBoth types of chloroplast contain large amounts of chloroplast peripheral reticulum, which they use to get more surface area to transport stuff in and out of them. Mesophyll chloroplasts have a little more peripheral reticulum than bundle sheath chloroplasts.\nLocation.\nDistribution in a plant.\nNot all cells in a multicellular plant contain chloroplasts. All green parts of a plant contain chloroplasts\u2014the chloroplasts, or more specifically, the chlorophyll in them are what make the photosynthetic parts of a plant green. The plant cells which contain chloroplasts are usually parenchyma cells, though chloroplasts can also be found in collenchyma tissue. A plant cell which contains chloroplasts is known as a chlorenchyma cell. A typical chlorenchyma cell of a land plant contains about 10 to 100 chloroplasts.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nA cross section of a leaf, showing chloroplasts in its mesophyll cells. Stomal guard cells also have chloroplasts, though much fewer than mesophyll cells. \nIn some plants such as cacti, chloroplasts are found in the stems, though in most plants, chloroplasts are concentrated in the leaves. One square millimeter of leaf tissue can contain half a million chloroplasts. Within a leaf, chloroplasts are mainly found in the mesophyll layers of a leaf, and the guard cells of stomata. Palisade mesophyll cells can contain 30\u201370 chloroplasts per cell, while stomatal guard cells contain only around 8\u201315 per cell, as well as much less chlorophyll. Chloroplasts can also be found in the bundle sheath cells of a leaf, especially in C4 plants, which carry out the Calvin cycle in their bundle sheath cells. They are often absent from the epidermis of a leaf.\nCellular location.\nChloroplast movement.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nWhen chloroplasts are exposed to direct sunlight, they stack along the anticlinal cell walls to minimize exposure. In the dark they spread out in sheets along the periclinal walls to maximize light absorption. \nThe chloroplasts of plant and algal cells can orient themselves to best suit the available light. In low-light conditions, they will spread out in a sheet\u2014maximizing the surface area to absorb light. Under intense light, they will seek shelter by aligning in vertical columns along the plant cell's cell wall or turning sideways so that light strikes them edge-on. This reduces exposure and protects them from photooxidative damage. This ability to distribute chloroplasts so that they can take shelter behind each other or spread out may be the reason why land plants evolved to have many small chloroplasts instead of a few big ones.\nChloroplast movement is considered one of the most closely regulated stimulus-response systems that can be found in plants. Mitochondria have also been observed to follow chloroplasts as they move.\nIn higher plants, chloroplast movement is run by phototropins, blue light photoreceptors also responsible for plant phototropism. In some algae, mosses, ferns, and flowering plants, chloroplast movement is influenced by red light in addition to blue light, though very long red wavelengths inhibit movement rather than speeding it up. Blue light generally causes chloroplasts to seek shelter, while red light draws them out to maximize light absorption.\nStudies of \"Vallisneria gigantea\", an aquatic flowering plant, have shown that chloroplasts can get moving within five minutes of light exposure, though they don't initially show any net directionality. They may move along microfilament tracks, and the fact that the microfilament mesh changes shape to form a honeycomb structure surrounding the chloroplasts after they have moved suggests that microfilaments may help to anchor chloroplasts in place.\nFunction and chemistry.\nGuard cell chloroplasts.\nUnlike most epidermal cells, the guard cells of plant stomata contain relatively well-developed chloroplasts. However, exactly what they do is controversial.\nPlant innate immunity.\nPlants lack specialized immune cells\u2014all plant cells participate in the plant immune response. Chloroplasts, along with the nucleus, cell membrane, and endoplasmic reticulum, are key players in pathogen defense. Due to its role in a plant cell's immune response, pathogens frequently target the chloroplast.\nPlants have two main immune responses\u2014the hypersensitive response, in which infected cells seal themselves off and undergo programmed cell death, and systemic acquired resistance, where infected cells release signals warning the rest of the plant of a pathogen's presence.\nChloroplasts stimulate both responses by purposely damaging their photosynthetic system, producing reactive oxygen species. High levels of reactive oxygen species will cause the hypersensitive response. The reactive oxygen species also directly kill any pathogens within the cell. Lower levels of reactive oxygen species initiate systemic acquired resistance, triggering defense-molecule production in the rest of the plant.\nIn some plants, chloroplasts are known to move closer to the infection site and the nucleus during an infection.\nChloroplasts can serve as cellular sensors. After detecting stress in a cell, which might be due to a pathogen, chloroplasts begin producing molecules like salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species which can serve as defense-signals. As cellular signals, reactive oxygen species are unstable molecules, so they probably don't leave the chloroplast, but instead pass on their signal to an unknown second messenger molecule. All these molecules initiate retrograde signaling\u2014signals from the chloroplast that regulate gene expression in the nucleus.\nIn addition to defense signaling, chloroplasts, with the help of the peroxisomes, help synthesize an important defense molecule, jasmonate. Chloroplasts synthesize all the fatty acids in a plant cell\u2014linoleic acid, a fatty acid, is a precursor to jasmonate.\nPhotosynthesis.\nOne of the main functions of the chloroplast is its role in photosynthesis, the process by which light is transformed into chemical energy, to subsequently produce food in the form of sugars. Water (H2O) and carbon dioxide (CO2) are used in photosynthesis, and sugar and oxygen (O2) is made, using light energy. Photosynthesis is divided into two stages\u2014the light reactions, where water is split to produce oxygen, and the dark reactions, or Calvin cycle, which builds sugar molecules from carbon dioxide. The two phases are linked by the energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+).\nLight reactions.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nThe light reactions of photosynthesis take place across the thylakoid membranes. \nThe light reactions take place on the thylakoid membranes. They take light energy and store it in NADPH, a form of NADP+, and ATP to fuel the dark reactions.\nEnergy carriers.\nATP is the phosphorylated version of adenosine diphosphate (ADP), which stores energy in a cell and powers most cellular activities. ATP is the energized form, while ADP is the (partially) depleted form. NADP+ is an electron carrier which ferries high energy electrons. In the light reactions, it gets reduced, meaning it picks up electrons, becoming NADPH.\nPhotophosphorylation.\nLike mitochondria, chloroplasts use the potential energy stored in an H+, or hydrogen ion, gradient to generate ATP energy. The two photosystems capture light energy to energize electrons taken from water, and release them down an electron transport chain. The molecules between the photosystems harness the electrons' energy to pump hydrogen ions into the thylakoid space, creating a concentration gradient, with more hydrogen ions (up to a thousand times as many) inside the thylakoid system than in the stroma. The hydrogen ions in the thylakoid space then diffuse back down their concentration gradient, flowing back out into the stroma through ATP synthase. ATP synthase uses the energy from the flowing hydrogen ions to phosphorylate adenosine diphosphate into adenosine triphosphate, or ATP. Because chloroplast ATP synthase projects out into the stroma, the ATP is synthesized there, in position to be used in the dark reactions.\nNADP+ reduction.\nElectrons are often removed from the electron transport chains to charge NADP+ with electrons, reducing it to NADPH. Like ATP synthase, ferredoxin-NADP+ reductase, the enzyme that reduces NADP+, releases the NADPH it makes into the stroma, right where it is needed for the dark reactions.\nBecause NADP+ reduction removes electrons from the electron transport chains, they must be replaced\u2014the job of photosystem II, which splits water molecules (H2O) to obtain the electrons from its hydrogen atoms.\nCyclic photophosphorylation.\nWhile photosystem II photolyzes water to obtain and energize new electrons, photosystem I simply reenergizes depleted electrons at the end of an electron transport chain. Normally, the reenergized electrons are taken by NADP+, though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP. This is termed cyclic photophosphorylation because the electrons are recycled. Cyclic photophosphorylation is common in C4 plants, which need more ATP than NADPH.\nDark reactions.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nThe Calvin cycle \"(Interactive diagram)\" The Calvin cycle incorporates carbon dioxide into sugar molecules. \nThe Calvin cycle, also known as the dark reactions, is a series of biochemical reactions that fixes CO2 into G3P sugar molecules and uses the energy and electrons from the ATP and NADPH made in the light reactions. The Calvin cycle takes place in the stroma of the chloroplast.\nWhile named \"the dark reactions\", in most plants, they take place in the light, since the dark reactions are dependent on the products of the light reactions.\nCarbon fixation and G3P synthesis.\nThe Calvin cycle starts by using the enzyme RuBisCO to fix CO2 into five-carbon Ribulose bisphosphate (RuBP) molecules. The result is unstable six-carbon molecules that immediately break down into three-carbon molecules called 3-phosphoglyceric acid, or 3-PGA.\nThe ATP and NADPH made in the light reactions is used to convert the 3-PGA into glyceraldehyde-3-phosphate, or G3P sugar molecules. Most of the G3P molecules are recycled back into RuBP using energy from more ATP, but one out of every six produced leaves the cycle\u2014the end product of the dark reactions.\nSugars and starches.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nSucrose is made up of a glucose monomer (left), and a fructose monomer (right). \nGlyceraldehyde-3-phosphate can double up to form larger sugar molecules like glucose and fructose. These molecules are processed, and from them, the still larger sucrose, a disaccharide commonly known as table sugar, is made, though this process takes place outside of the chloroplast, in the cytoplasm.\nAlternatively, glucose monomers in the chloroplast can be linked together to make starch, which accumulates into the starch grains found in the chloroplast.\nUnder conditions such as high atmospheric CO2 concentrations, these starch grains may grow very large, distorting the grana and thylakoids. The starch granules displace the thylakoids, but leave them intact.\nWaterlogged roots can also cause starch buildup in the chloroplasts, possibly due to less sucrose being exported out of the chloroplast (or more accurately, the plant cell). This depletes a plant's free phosphate supply, which indirectly stimulates chloroplast starch synthesis.\nWhile linked to low photosynthesis rates, the starch grains themselves may not necessarily interfere significantly with the efficiency of photosynthesis, and might simply be a side effect of another photosynthesis-depressing factor.\nPhotorespiration.\nPhotorespiration can occur when the oxygen concentration is too high. RuBisCO cannot distinguish between oxygen and carbon dioxide very well, so it can accidentally add O2 instead of CO2 to RuBP. This process reduces the efficiency of photosynthesis\u2014it consumes ATP and oxygen, releases CO2, and produces no sugar. It can waste up to half the carbon fixed by the Calvin cycle. Several mechanisms have evolved in different lineages that raise the carbon dioxide concentration relative to oxygen within the chloroplast, increasing the efficiency of photosynthesis. These mechanisms are called carbon dioxide concentrating mechanisms, or CCMs. These include Crassulacean acid metabolism, C4 carbon fixation, and pyrenoids. Chloroplasts in C4 plants are notable as they exhibit a distinct chloroplast dimorphism.\npH.\nBecause of the H+ gradient across the thylakoid membrane, the interior of the thylakoid is acidic, with a pH around 4, while the stroma is slightly basic, with a pH of around 8.\nThe optimal stroma pH for the Calvin cycle is 8.1, with the reaction nearly stopping when the pH falls below 7.3.\nCO2 in water can form carbonic acid, which can disturb the pH of isolated chloroplasts, interfering with photosynthesis, even though CO2 is used in photosynthesis. However, chloroplasts in living plant cells are not affected by this as much.\nChloroplasts can pump K+ and H+ ions in and out of themselves using a poorly understood light-driven transport system.\nIn the presence of light, the pH of the thylakoid lumen can drop up to 1.5 pH units, while the pH of the stroma can rise by nearly one pH unit.\nAmino acid synthesis.\nChloroplasts alone make almost all of a plant cell's amino acids in their stroma except the sulfur-containing ones like cysteine and methionine. Cysteine is made in the chloroplast (the proplastid too) but it is also synthesized in the cytosol and mitochondria, probably because it has trouble crossing membranes to get to where it is needed. The chloroplast is known to make the precursors to methionine but it is unclear whether the organelle carries out the last leg of the pathway or if it happens in the cytosol.\nOther nitrogen compounds.\nChloroplasts make all of a cell's purines and pyrimidines\u2014the nitrogenous bases found in DNA and RNA. They also convert nitrite (NO2\u2212) into ammonia (NH3) which supplies the plant with nitrogen to make its amino acids and nucleotides.\nOther chemical products.\nThe plastid is the site of diverse and complex lipid synthesis in plants. The carbon used to form the majority of the lipid is from acetyl-CoA, which is the decarboxylation product of pyruvate. Pyruvate may enter the plastid from the cytosol by passive diffusion through the membrane after production in glycolysis. Pyruvate is also made in the plastid from phosphoenolpyruvate, a metabolite made in the cytosol from pyruvate or PGA. Acetate in the cytosol is unavailable for lipid biosynthesis in the plastid. The typical length of fatty acids produced in the plastid are 16 or 18 carbons, with 0-3 cis double bonds.\nThe biosynthesis of fatty acids from acetyl-CoA primarily requires two enzymes. Acetyl-CoA carboxylase creates malonyl-CoA, used in both the first step and the extension steps of synthesis. Fatty acid synthase (FAS) is a large complex of enzymes and cofactors including acyl carrier protein (ACP) which holds the acyl chain as it is synthesized. The initiation of synthesis begins with the condensation of malonyl-ACP with acetyl-CoA to produce ketobutyryl-ACP. 2 reductions involving the use of NADPH and one dehydration creates butyryl-ACP. Extension of the fatty acid comes from repeated cycles of malonyl-ACP condensation, reduction, and dehydration.\nOther lipids are derived from the methyl-erythritol phosphate (MEP) pathway and consist of gibberelins, sterols, abscisic acid, phytol, and innumerable secondary metabolites.\nDifferentiation, replication, and inheritance.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \n300px\ncircle 315 89 36 Proplastid\ncircle 161 147 36 Etioplast\ncircle 407 241 36 Leucoplast\ncircle 83 281 36 Chromoplast\ncircle 202 426 36 Amyloplast\ncircle 350 425 36 Elaioplast\ncircle 512 428 36 Proteinoplast\nrect 357 65 468 88 Proplastid\nrect 430 182 544 210 Leucoplast\nrect 113 82 208 104 Etioplast\nrect 12 320 148 345 Chromoplast\nrect 141 466 259 490 Amyloplast\nrect 300 465 405 488 Elaioplast\nrect 447 466 594 491 Proteinoplast\npoly 207 257 199 252 197 241 202 227 213 213 226 205 240 201 253 201 266 203 279 208 287 218 288 229 285 236 270 241 256 241 243 241 230 246 220 255 212 257 Chloroplast\nrect 179 265 301 289 Chloroplast\nrect 0 0 600 500 \ndesc none\n&lt;/imagemap&gt;Plastid types \"(Interactive diagram)\" Plants contain many different kinds of plastids in their cells. \nChloroplasts are a special type of a plant cell organelle called a plastid, though the two terms are sometimes used interchangeably. There are many other types of plastids, which carry out various functions. All chloroplasts in a plant are descended from undifferentiated proplastids found in the zygote, or fertilized egg. Proplastids are commonly found in an adult plant's apical meristems. Chloroplasts do not normally develop from proplastids in root tip meristems\u2014instead, the formation of starch-storing amyloplasts is more common.\nIn shoots, proplastids from shoot apical meristems can gradually develop into chloroplasts in photosynthetic leaf tissues as the leaf matures, if exposed to the required light. This process involves invaginations of the inner plastid membrane, forming sheets of membrane that project into the internal stroma. These membrane sheets then fold to form thylakoids and grana.\nIf angiosperm shoots are not exposed to the required light for chloroplast formation, proplastids may develop into an etioplast stage before becoming chloroplasts. An etioplast is a plastid that lacks chlorophyll, and has inner membrane invaginations that form a lattice of tubes in their stroma, called a prolamellar body. While etioplasts lack chlorophyll, they have a yellow chlorophyll precursor stocked. Within a few minutes of light exposure, the prolamellar body begins to reorganize into stacks of thylakoids, and chlorophyll starts to be produced. This process, where the etioplast becomes a chloroplast, takes several hours. Gymnosperms do not require light to form chloroplasts.\nLight, however, does not guarantee that a proplastid will develop into a chloroplast. Whether a proplastid develops into a chloroplast some other kind of plastid is mostly controlled by the nucleus and is largely influenced by the kind of cell it resides in.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nMany plastid interconversions are possible. \nPlastid interconversion.\nPlastid differentiation is not permanent, in fact many interconversions are possible. Chloroplasts may be converted to chromoplasts, which are pigment-filled plastids responsible for the bright colors seen in flowers and ripe fruit. Starch storing amyloplasts can also be converted to chromoplasts, and it is possible for proplastids to develop straight into chromoplasts. Chromoplasts and amyloplasts can also become chloroplasts, like what happens when a carrot or a potato is illuminated. If a plant is injured, or something else causes a plant cell to revert to a meristematic state, chloroplasts and other plastids can turn back into proplastids. Chloroplast, amyloplast, chromoplast, proplastid are not absolute; state\u2014intermediate forms are common.\nDivision.\nMost chloroplasts in a photosynthetic cell do not develop directly from proplastids or etioplasts. In fact, a typical shoot meristematic plant cell contains only 7\u201320 proplastids. These proplastids differentiate into chloroplasts, which divide to create the 30\u201370 chloroplasts found in a mature photosynthetic plant cell. If the cell divides, chloroplast division provides the additional chloroplasts to partition between the two daughter cells.\nIn single-celled algae, chloroplast division is the only way new chloroplasts are formed. There is no proplastid differentiation\u2014when an algal cell divides, its chloroplast divides along with it, and each daughter cell receives a mature chloroplast.\nAlmost all chloroplasts in a cell divide, rather than a small group of rapidly dividing chloroplasts. Chloroplasts have no definite S-phase\u2014their DNA replication is not synchronized or limited to that of their host cells.\nMuch of what we know about chloroplast division comes from studying organisms like \"Arabidopsis\" and the red alga \"Cyanidioschyzon merol\u00e6\".\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nThe division process starts when the proteins FtsZ1 and FtsZ2 assemble into filaments, and with the help of a protein ARC6, form a structure called a Z-ring within the chloroplast's stroma. The Min system manages the placement of the Z-ring, ensuring that the chloroplast is cleaved more or less evenly. The protein MinD prevents FtsZ from linking up and forming filaments. Another protein ARC3 may also be involved, but it is not very well understood. These proteins are active at the poles of the chloroplast, preventing Z-ring formation there, but near the center of the chloroplast, MinE inhibits them, allowing the Z-ring to form.\nNext, the two plastid-dividing rings, or PD rings form. The inner plastid-dividing ring is located in the inner side of the chloroplast's inner membrane, and is formed first. The outer plastid-dividing ring is found wrapped around the outer chloroplast membrane. It consists of filaments about 5 nanometers across, arranged in rows 6.4 nanometers apart, and shrinks to squeeze the chloroplast. This is when chloroplast constriction begins. In a few species like \"Cyanidioschyzon merol\u00e6\", chloroplasts have a third plastid-dividing ring located in the chloroplast's intermembrane space.\nLate into the constriction phase, dynamin proteins assemble around the outer plastid-dividing ring, helping provide force to squeeze the chloroplast. Meanwhile, the Z-ring and the inner plastid-dividing ring break down. During this stage, the many chloroplast DNA plasmids floating around in the stroma are partitioned and distributed to the two forming daughter chloroplasts.\nLater, the dynamins migrate under the outer plastid dividing ring, into direct contact with the chloroplast's outer membrane, to cleave the chloroplast in two daughter chloroplasts.\nA remnant of the outer plastid dividing ring remains floating between the two daughter chloroplasts, and a remnant of the dynamin ring remains attached to one of the daughter chloroplasts.\nOf the five or six rings involved in chloroplast division, only the outer plastid-dividing ring is present for the entire constriction and division phase\u2014while the Z-ring forms first, constriction does not begin until the outer plastid-dividing ring forms.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nChloroplast division In this light micrograph of some moss chloroplasts, many dumbbell-shaped chloroplasts can be seen dividing. Grana are also just barely visible as small granules. \nRegulation.\nIn species of algae that contain a single chloroplast, regulation of chloroplast division is extremely important to ensure that each daughter cell receives a chloroplast\u2014chloroplasts can't be made from scratch. In organisms like plants, whose cells contain multiple chloroplasts, coordination is looser and less important. It is likely that chloroplast and cell division are somewhat synchronized, though the mechanisms for it are mostly unknown.\nLight has been shown to be a requirement for chloroplast division. Chloroplasts can grow and progress through some of the constriction stages under poor quality green light, but are slow to complete division\u2014they require exposure to bright white light to complete division. Spinach leaves grown under green light have been observed to contain many large dumbbell-shaped chloroplasts. Exposure to white light can stimulate these chloroplasts to divide and reduce the population of dumbbell-shaped chloroplasts.\nChloroplast inheritance.\nLike mitochondria, chloroplasts are usually inherited from a single parent. Biparental chloroplast inheritance\u2014where plastid genes are inherited from both parent plants\u2014occurs in very low levels in some flowering plants.\nMany mechanisms prevent biparental chloroplast DNA inheritance, including selective destruction of chloroplasts or their genes within the gamete or zygote, and chloroplasts from one parent being excluded from the embryo. Parental chloroplasts can be sorted so that only one type is present in each offspring.\nGymnosperms, such as pine trees, mostly pass on chloroplasts paternally, while flowering plants often inherit chloroplasts maternally. Flowering plants were once thought to only inherit chloroplasts maternally. However, there are now many documented cases of angiosperms inheriting chloroplasts paternally.\nAngiosperms, which pass on chloroplasts maternally, have many ways to prevent paternal inheritance. Most of them produce sperm cells that do not contain any plastids. There are many other documented mechanisms that prevent paternal inheritance in these flowering plants, such as different rates of chloroplast replication within the embryo.\nAmong angiosperms, paternal chloroplast inheritance is observed more often in hybrids than in offspring from parents of the same species. This suggests that incompatible hybrid genes might interfere with the mechanisms that prevent paternal inheritance.\nTransplastomic plants.\nRecently, chloroplasts have caught attention by developers of genetically modified crops. Since, in most flowering plants, chloroplasts are not inherited from the male parent, transgenes in these plastids cannot be disseminated by pollen. This makes plastid transformation a valuable tool for the creation and cultivation of genetically modified plants that are biologically contained, thus posing significantly lower environmental risks. This biological containment strategy is therefore suitable for establishing the coexistence of conventional and organic agriculture. While the reliability of this mechanism has not yet been studied for all relevant crop species, recent results in tobacco plants are promising, showing a failed containment rate of transplastomic plants at 3 in 1,000,000.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6357", "revid": "1157118146", "url": "https://en.wikipedia.org/wiki?curid=6357", "title": "Camp David", "text": "Country retreat of the US president\nCamp David is the country retreat for the President of the United States. It is located in the wooded hills of Catoctin Mountain Park, in Frederick County, Maryland, near the towns of Thurmont and Emmitsburg, about north-northwest of the national capital city of Washington, D.C. It is code named Naval Support Facility Thurmont. Technically a military installation, the staffing is primarily provided by the Seabees, Civil Engineer Corps (CEC), the United States Navy and the United States Marine Corps. Naval construction battalions are tasked with Camp David construction and send detachments as needed.\nOriginally known as Hi-Catoctin, Camp David was built as a retreat for federal government agents and their families by the Works Progress Administration. Construction started in 1935 and was completed in 1938. In 1942, President Franklin D. Roosevelt converted it to a presidential retreat and renamed it \"Shangri-La\", after the fictional Himalayan paradise. Camp David received its present name in 1953 from President Dwight D. Eisenhower, in honor of his father and his grandson, both named David.\nThe Catoctin Mountain Park does not indicate the location of Camp David on park maps due to privacy and security concerns, although it can be seen through the use of publicly accessible satellite images.\nPresidential use.\nFranklin D. Roosevelt hosted Sir Winston Churchill at Shangri-La in May 1943, during World War II. Dwight Eisenhower held his first cabinet meeting there on November 22, 1955, following hospitalization and convalescence he required after a heart attack suffered in Denver, Colorado, on September 24. Eisenhower met Nikita Khrushchev there for two days of discussions in September 1959.\nJohn F. Kennedy and his family often enjoyed riding and other recreational activities there, and Kennedy often allowed White House staff and Cabinet members to use the retreat when he or his family were not there. Lyndon B. Johnson met with advisors in this setting and hosted both Australian prime minister Harold Holt and Canadian prime minister Lester B. Pearson there. Richard Nixon was a frequent visitor. He personally directed the construction of a swimming pool and other improvements to Aspen Lodge. Gerald Ford hosted Indonesian president Suharto at Camp David.\nJimmy Carter initially favored closing Camp David in order to save money, but once he visited the retreat, he decided to keep it. Carter brokered the Camp David Accords there in September 1978 between Egyptian president Anwar al-Sadat and Israeli prime minister Menachem Begin. Ronald Reagan visited the retreat more than any other president. In 1984, Reagan hosted British prime minister Margaret Thatcher. Reagan restored the nature trails that Nixon paved over so he could horseback ride at Camp David. George H. W. Bush's daughter, Dorothy Bush Koch, was married there in 1992, in the first wedding held at Camp David. During his tenure as president, Bill Clinton spent every Thanksgiving at Camp David with his family. In July 2000, he hosted the 2000 Camp David Summit negotiations between Israeli prime minister Ehud Barak and Palestinian Authority chairman Yasser Arafat there.\nIn February 2001, George W. Bush held his first meeting with a European leader, UK prime minister Tony Blair, at Camp David, to discuss missile defense, Iraq, and NATO. After the September 11 attacks, Bush held a Cabinet meeting at Camp David to prepare the United States invasion of Afghanistan. During his two terms in office, Bush visited Camp David 149 times, for a total of 487 days, for hosting foreign visitors as well as a personal retreat. He met Blair there four times. Among the numerous other foreign leaders he hosted at Camp David were Russian president Vladimir Putin and President Musharraf of Pakistan in 2003, Danish prime minister Anders Fogh Rasmussen in June 2006, and British prime minister Gordon Brown in 2007.\nBarack Obama chose Camp David to host the 38th G8 summit in 2012. President Obama also hosted Russian prime minister Dmitry Medvedev at Camp David, as well as the GCC Summit there in 2015.\nDonald Trump hosted Senate majority leader Mitch McConnell and Speaker of the House Paul Ryan at Camp David while the Republican Party prepared to defend both houses of Congress in the 2018 midterm elections. The 46th G7 summit was to be held at Camp David on June 10\u201312, 2020, but was cancelled due to health concerns during the ongoing COVID-19 pandemic.\nPractice golf facility.\nTo be able to play his favorite sport, President Eisenhower had golf course architect Robert Trent Jones design a practice golf facility at Camp David. Around 1954, Jones built one golf hole\u2014a par 3\u2014with four different tees; Eisenhower added a driving range near the helicopter landing zone.\nSecurity incidents.\nOn July 2, 2011, an F-15 intercepted a civilian aircraft approximately from Camp David, when President Obama was in the residence. The two-seater, which was out of radio communication, was escorted to nearby Hagerstown, Maryland, without incident.\nOn July 10, 2011, a F-15 intercepted another small plane near Camp David when Obama was again in the residence; a total of three were intercepted that weekend.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "6359", "revid": "10938973", "url": "https://en.wikipedia.org/wiki?curid=6359", "title": "Crux", "text": "Constellation in the southern celestial hemisphere\nCrux () is a constellation of the southern sky that is centred on four bright stars in a cross-shaped asterism commonly known as the Southern Cross. It lies on the southern end of the Milky Way's visible band. The name \"Crux\" is Latin for cross. Even though it is the smallest of all 88 modern constellations, Crux is among the most easily distinguished as its four main stars each have an apparent visual magnitude brighter than +2.8. It has attained a high level of cultural significance in many Southern Hemisphere states and nations.\nBlue-white \u03b1 Crucis (Acrux) is the most southerly member of the constellation and, at magnitude 0.8, the brightest. The three other stars of the cross appear clockwise and in order of lessening magnitude: \u03b2 Crucis (Mimosa), \u03b3 Crucis (Gacrux), and \u03b4 Crucis (Imai). \u03b5 Crucis (Ginan) also lies within the cross asterism. Many of these brighter stars are members of the Scorpius\u2013Centaurus association, a large but loose group of hot blue-white stars that appear to share common origins and motion across the southern Milky Way.\nCrux contains four Cepheid variables, each visible to the naked eye under optimum conditions. Crux also contains the bright and colourful open cluster known as the Jewel Box (NGC 4755) on its eastern border. Nearby to the southeast is a large dark nebula spanning 7\u00b0 by 5\u00b0 known as the Coalsack Nebula, portions of which are mapped in the neighbouring constellations of Centaurus and Musca.\nHistory.\nThe bright stars in Crux were known to the Ancient Greeks, where Ptolemy regarded them as part of the constellation Centaurus. They were entirely visible as far north as Britain in the fourth millennium BC. However, the precession of the equinoxes gradually lowered the stars below the European horizon, and they were eventually forgotten by the inhabitants of northern latitudes. By 400\u00a0CE, the stars in the constellation now called Crux never rose above the horizon throughout most of Europe. Dante may have known about the constellation in the 14th century, as he describes an asterism of four bright stars in the southern sky in his \"Divine Comedy\". His description, however, may be allegorical, and the similarity to the constellation a coincidence.\nThe 15th\u00a0century Venetian navigator Alvise Cadamosto made note of what was probably the Southern Cross on exiting the Gambia River in 1455, calling it the \"carro dell'ostro\" (\"southern chariot\"). However, Cadamosto's accompanying diagram was inaccurate. Historians generally credit Jo\u00e3o Faras for being the first European to depict it correctly. Faras sketched and described the constellation (calling it \"las guardas\") in a letter written on the beaches of Brazil on 1\u00a0May 1500 to the Portuguese monarch.\nExplorer Amerigo Vespucci seems to have observed not only the Southern Cross but also the neighboring Coalsack Nebula on his second voyage in 1501\u20131502.\nAnother early modern description clearly describing Crux as a separate constellation is attributed to Andrea Corsali, an Italian navigator who from 1515\u20131517 sailed to China and the East Indies in an expedition sponsored by King Manuel\u00a0I. In 1516, Corsali wrote a letter to the monarch describing his observations of the southern sky, which included a rather crude map of the stars around the south celestial pole including the Southern Cross and the two Magellanic Clouds seen in an external orientation, as on a globe.\nEmery Molyneux and Petrus Plancius have also been cited as the first uranographers (sky mappers) to distinguish Crux as a separate constellation; their representations date from 1592, the former depicting it on his celestial globe and the latter in one of the small celestial maps on his large wall map. Both authors, however, depended on unreliable sources and placed Crux in the wrong position. Crux was first shown in its correct position on the celestial globes of Petrus Plancius and Jodocus Hondius in 1598 and 1600. Its stars were first catalogued separately from Centaurus by Frederick de Houtman in 1603. The constellation was later adopted by Jakob Bartsch in 1624 and Augustin Royer in 1679. Royer is sometimes wrongly cited as initially distinguishing Crux.\nCharacteristics.\nCrux is bordered by the constellations Centaurus (which surrounds it on three sides) on the east, north and west, and Musca to the south. Covering 68\u00a0square degrees and 0.165% of the night sky, it is the smallest of the 88 constellations. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"Cru\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of four segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 11h 56.13m and 12h 57.45m, while the declination coordinates are between \u221255.68\u00b0 and \u221264.70\u00b0. Its totality figures at least part of the year south of the 25th parallel north.\nIn tropical regions Crux can be seen in the sky from April to June. Crux is exactly opposite to Cassiopeia on the celestial sphere, and therefore it cannot appear in the sky with the latter at the same time. In this era, south of Cape Town, Adelaide, and Buenos Aires (the 34th parallel south), Crux is circumpolar and thus always appears in the sky.\nCrux is sometimes confused with the nearby False Cross asterism by stargazers. The False Cross consists of stars in Carina and Vela, is larger and dimmer, does not have a fifth star, and lacks the two prominent nearby \"Pointer Stars\". Between the two is the even larger and dimmer Diamond Cross.\nVisibility.\nCrux is easily visible from the southern hemisphere, south of 35th parallel at practically any time of year as circumpolar. It is also visible near the horizon from tropical latitudes of the northern hemisphere for a few hours every night during the northern winter and spring. For instance, it is visible from Cancun or any other place at latitude 25\u00b0 N or less at around 10 pm at the end of April. There are 5 main stars.\nDue to precession, Crux will move closer to the South Pole in the next millennia, up to 67 degrees south declination for the middle of the constellation. However, by the year 14,000 Crux will be visible for most parts of Europe and continental United States which will extend to North Europe by the year 18,000 as it will be less than 30 degrees south declination.\nUse in navigation.\nIn the Southern Hemisphere, the Southern Cross is frequently used for navigation in much the same way that Polaris is used in the Northern Hemisphere. Projecting a line from \u03b3 to \u03b1 Crucis (the foot of the crucifix) approximately &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4+1\u20442 times beyond gives a point close to the Southern Celestial Pole which is also, coincidentally, where intersects a perpendicular line taken southwards from the east-west axis of Alpha Centauri to Beta Centauri, which are stars at an alike declination to Crux and of a similar width as the cross, but higher magnitude. Argentine gauchos are documented as using Crux for night orientation in the Pampas and Patagonia.\nAlpha and Beta Centauri are of similar declinations (thus distance from the pole) and are often referred as the \"Southern Pointers\" or just \"The Pointers\", allowing people to easily identify the Southern Cross, the constellation of Crux. Very few bright stars lie between Crux and the pole itself, although the constellation Musca is fairly easily recognised immediately south of Crux.\nBright stars.\nDown to apparent magnitude +2.5 are 92 stars that shine the brightest as viewed from the Earth. Three of these stars are in Crux making it the most densely populated as to those stars (this being 3.26% of these 92 stars, and in turn being 19.2 times more than the expected 0.17% that would result on a homogenous distribution of all bright stars and a randomised drawing of all 88 constellations, given its area, 0.17% of the sky).\nFeatures.\nStars.\nWithin the constellation's borders, there are 49 stars brighter than or equal to apparent magnitude 6.5. The four main stars that form the asterism are Alpha, Beta, Gamma, and Delta Crucis.\nThere is also a fifth star, that is often included with the Southern Cross.\nThere are several other naked-eye stars within the borders of Crux, especially:\nScorpius\u2013Centaurus association.\nUnusually, a total of 15 of the 23 brightest stars in Crux are spectrally blue-white B-type stars. Among the five main bright stars, Delta, and probably Alpha and Beta, are likely co-moving B-type members of the Scorpius\u2013Centaurus association, the nearest OB association to the Sun. They are among the highest-mass stellar members of the Lower Centaurus\u2013Crux subgroup of the association, with ages of roughly 10 to 20\u00a0million years. Other members include the blue-white stars Zeta, Lambda and both the components of the visual double star, Mu.\nVariable stars.\nCrux contains many variable stars. It boasts four Cepheid variables that may all reach naked eye visibility.\nOther well studied variable stars includes:\nHost star exoplanets in Crux.\nThe star HD 106906 has been found to have a planet\u2014HD 106906 b\u2014that has one of the widest orbits of any currently known planetary-mass companions.\nObjects beyond the Local Arm.\nCrux is backlit by the multitude of stars of the Scutum-Crux Arm (more commonly called the Scutum-Centaurus Arm) of the Milky Way. This is the main inner arm in the local radial quarter of the galaxy. Part-obscuring this is:\nA key feature of the Scutum-Crux Arm is:\nCultural significance.\nThe most prominent feature of Crux is the distinctive asterism known as the Southern Cross. It has great significance in the cultures of the southern hemisphere, particularly of Australia, Brazil, and New Zealand.\nFlags and symbols.\nSeveral southern countries and organisations have traditionally used Crux as a national or distinctive symbol. The four or five brightest stars of Crux appear, heraldically standardised in various ways, on the flags of Australia, Brazil, New Zealand, Papua New Guinea and Samoa. They also appear on the flags of the Australian state of Victoria, the Australian Capital Territory, the Northern Territory, as well as the flag of Magallanes Region of Chile, the flag of Londrina (Brazil) and several Argentine provincial flags and emblems (for example, \"Tierra del Fuego\" and \"Santa Cruz\"). The flag of the Mercosur trading zone displays the four brightest stars. Crux also appears on the Brazilian coat of arms and, as of July 2015[ [update]], on the cover of Brazilian passports.\nFive stars appear in the logo of the Brazilian football team Cruzeiro Esporte Clube and in the insignia of the Order of the Southern Cross, and the cross has featured as name of the Brazilian currency (the \"cruzeiro\" from 1942 to 1986 and again from 1990 to 1994). All coins of the current[ [update]] (1998) series of the Brazilian real display the constellation.\nSongs and literature reference the Southern Cross, including the Argentine epic poem \"Mart\u00edn Fierro\". The Argentinian singer Charly Garc\u00eda says that he is \"from the Southern Cross\" in the song \"No voy en tren\".\nThe Cross gets a mention in the lyrics of the Brazilian National Anthem (1909): \"A imagem do Cruzeiro resplandece\" (\"the image of the Cross shines\").\nThe Southern Cross is mentioned in the Australian National Anthem, \"\"Beneath our radiant Southern Cross we'll toil with hearts and hands\"\nThe Southern Cross features in the coat of arms of William Birdwood, 1st Baron Birdwood, the British officer who commanded the Australian and New Zealand Army Corps during the Gallipoli Campaign of the First World War.\nThe Southern Cross is also mentioned in the Samoan\nNational Anthem.\n\"Vaai 'i na fetu o lo'u a agiagia ai: Le faailoga lea o Iesu, na maliu ai mo Samoa.\"\" (\"Look at those stars that are waving on it: This is the symbol of Jesus, who died on it for Samoa.\")\nThe 1952-53 NBC Television Series \"Victory At Sea\" contained a musical number entitled \"Beneath the Southern Cross\".\n\"Southern Cross\" is a single released by Crosby, Stills and Nash in 1981. It reached #18 on Billboard Hot 100 in late 1982.\n\"The Sign of the Southern Cross\" is a song released by Black Sabbath in 1981. The song was released on the album \"Mob Rules\".\nThe Order of the Southern Cross is a Brazilian order of chivalry awarded to \"those who have rendered significant service to the Brazilian nation\".\nIn \"O Sweet Saint Martin's Land\", the lyrics mention the Southern Cross: \"Thy Southern Cross the night\".\nA stylized version of Crux appears on the Australian Eureka Flag. The constellation was also used on the dark blue, shield-like patch worn by personnel of the U.S. Army's Americal Division, which was organized in the Southern Hemisphere, on the island of New Caledonia, and also on the blue diamond of the U.S. 1st Marine Division, which fought on the Southern Hemisphere islands of Guadalcanal and New Britain.\nThe \"Petersflagge\" flag of the German East Africa Company of 1885\u20131920, which included a constellation of five white five-pointed Crux \"stars\" on a red ground, later served as the model for symbolism associated with generic German colonial-oriented organisations: the Reichskolonialbund of 1936\u20131943 and the Friends of the former German Protectorates (1956/1983 to the present).\nSouthern Cross station is a major rail terminal in Melbourne, Australia.\nThe Personal Ordinariate of Our Lady of the Southern Cross is a personal ordinariate of the Roman Catholic Church primarily within the territory of the Australian Catholic Bishops Conference for groups of Anglicans who desire full communion with the Catholic Church in Australia and Asia.\nThe Knights of the Southern Cross (KSC) is a Catholic fraternal order throughout Australia.\nVarious cultures.\nIn India, there is a story related to the creation of Trishanku Swarga (\u0924\u094d\u0930\u093f\u0936\u0902\u0915\u0941), meaning \"Cross\" (Crux), created by Sage Vishwamitra.\nIn Chinese, (), meaning \"Cross\", refers to an asterism consisting of \u03b3 Crucis, \u03b1 Crucis, \u03b2 Crucis and \u03b4 Crucis.\nIn Australian Aboriginal astronomy, Crux and the Coalsack mark the head of the 'Emu in the Sky' (which is seen in the dark spaces rather than in the patterns of stars) in several Aboriginal cultures, while Crux itself is said to be a possum sitting in a tree (Boorong people of the Wimmera region of northwestern Victoria), a representation of the sky deity Mirrabooka (Quandamooka people of Stradbroke Island), a stingray (Yolngu people of Arnhem Land), or an eagle (Kaurna people of the Adelaide Plains). Two Pacific constellations also included Gamma Centauri. Torres Strait Islanders in modern-day Australia saw Gamma Centauri as the handle and the four stars as the trident of Tagai's Fishing Spear. The Aranda people of central Australia saw the four Cross stars as the talon of an eagle and Gamma Centauri as its leg.\nVarious peoples in the East Indies and Brazil viewed the four main stars as the body of a ray. In both Indonesia and Malaysia, it is known as \"Bintang Pari\" and \"Buruj Pari\", respectively (\"ray stars\"). This aquatic theme is also shared by an archaic name of the constellation in Vietnam, where it was once known as \"sao C\u00e1 Li\u1ec7t\" (the ponyfish star).\nAmong Filipino people, the southern cross have various names pertaining to tops, including \"kasing\" (Visayan languages), \"paglong\" (Bikol), and \"pasil\" (Tagalog). It is also called \"butiti\" (puffer fish) in Waray.\nThe Javanese people of Indonesia called this constellation \"Gubug p\u00e8nc\u00e8ng\" (\"raking hut\") or \"lumbung\" (\"the granary\"), because the shape of the constellation was like that of a raking hut.\nThe Southern Cross (\u03b1, \u03b2, \u03b3 and \u03b4 Crucis) together with \u03bc Crucis is one of the asterisms used by Bugis sailors for navigation, called \"binto\u00e9ng bola k\u00e9ppang\", meaning \"incomplete house star\"\nThe M\u0101ori name for the Southern Cross is \"M\u0101hutonga\" and it is thought of as the anchor (\"Te Punga\") of Tama-rereti's \"waka\" (the Milky Way), while the Pointers are its rope. In Tonga it is known as \"Toloa\" (\"duck\"); it is depicted as a duck flying south, with one of his wings (\u03b4 Crucis) wounded because \"Ongo tangata\" (\"two men\", \u03b1 and \u03b2 Centauri) threw a stone at it. The Coalsack is known as \"Humu\" (the \"triggerfish\"), because of its shape. In Samoa the constellation is called \"Sumu\" (\"triggerfish\") because of its rhomboid shape, while \u03b1 and \u03b2 Centauri are called \"Luatagata\" (Two Men), just as they are in Tonga. The peoples of the Solomon Islands saw several figures in the Southern Cross. These included a knee protector and a net used to catch Palolo worms. Neighboring peoples in the Marshall Islands saw these stars as a fish. Peninsular Malays also see the likeness of a fish in the Crux, particularly the Scomberomorus or its local name \"Tohok\".\nIn Mapudungun, the language of Patagonian Mapuches, the name of the Southern Cross is \"Melipal\", which means \"four stars\". In Quechua, the language of the Inca civilization, Crux is known as \"Chakana\", which means literally \"stair\" (\"chaka\", bridge, link; \"hanan\", high, above), but carries a deep symbolism within Quechua mysticism. Alpha and Beta Crucis make up one foot of the Great Rhea, a constellation encompassing Centaurus and Circinus along with the two bright stars. The Great Rhea was a constellation of the Bororo of Brazil. The Mocov\u00ed people of Argentina also saw a rhea including the stars of Crux. Their rhea is attacked by two dogs, represented by bright stars in Centaurus and Circinus. The dogs' heads are marked by Alpha and Beta Centauri. The rhea's body is marked by the four main stars of Crux, while its head is Gamma Centauri and its feet are the bright stars of Musca. The Bakairi people of Brazil had a sprawling constellation representing a bird snare. It included the bright stars of Crux, the southern part of Centaurus, Circinus, at least one star in Lupus, the bright stars of Musca, Beta and the optical double star Delta1,2 Chamaeleontis: and some of the stars of Volans, and Mensa. The Kalapalo people of Mato Grosso state in Brazil saw the stars of Crux as \"Aganagi\" angry bees having emerged from the Coalsack, which they saw as the beehive.\nAmong Tuaregs, the four most visible stars of Crux are considered \"iggaren\", i.e. four \"Maerua crassifolia\" trees. The Tswana people of Botswana saw the constellation as \"Dithutlwa\", two giraffes \u2013 Alpha and Beta Crucis forming a male, and Gamma and Delta forming the female.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 12h 30m 00s, \u221260\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6360", "revid": "8390765", "url": "https://en.wikipedia.org/wiki?curid=6360", "title": "Cepheus", "text": "&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nCepheus (Ancient Greek: \u039a\u03b7\u03c6\u03b5\u03cd\u03c2 \"Kephe\u00fas\") may refer to:\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "6361", "revid": "27335766", "url": "https://en.wikipedia.org/wiki?curid=6361", "title": "Cassiopeia", "text": "Cassiopeia or Cassiopea may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "6362", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6362", "title": "Cetus", "text": "Constellation straddling the celestial equator\nCetus () is a constellation, sometimes called 'the whale' in English. The Cetus was a sea monster in Greek mythology which both Perseus and Heracles needed to slay. Cetus is in the region of the sky that contains other water-related constellations: Aquarius, Pisces and Eridanus.\nFeatures.\nEcliptic.\nCetus is not among the 12 true zodiac constellations in the J2000 epoch, nor classical 12-part zodiac. The ecliptic passes less than 0.25\u00b0 from one of its corners. Thus the moon and planets will enter Cetus (occulting any stars as a foreground object) in 50% of their successive orbits briefly and the southern part of the sun appears in Cetus for about one day each year. Many asteroids in belts have longer phases occulting the north-western part of Cetus, those with a slightly greater inclination to the ecliptic than the moon and planets.\nAs seen from Mars, the ecliptic (apparent plane of the sun and also the average plane of the planets which is almost the same) passes into it.\nStars.\nMira (\"wonderful\", named by Bayer: Omicron Ceti, a star of the neck of the asterism) was the first variable star to be discovered and the prototype of its class, Mira variables. Over a period of 332 days, it reaches a maximum apparent magnitude of 3 - visible to the naked eye - and dips to a minimum magnitude of 10, invisible to the unaided eye. Its seeming appearance and disappearance gave it its name. Mira pulsates with a minimum size of 400 solar diameters and a maximum size of 500 solar diameters. 420 light-years from Earth, it was discovered by David Fabricius in 1596.\n\u03b1 Ceti, traditionally called Menkar (\"the nose\"), is a red-hued giant star of magnitude 2.5, 220 light-years from Earth. It is a wide double star; the secondary is 93 Ceti, a blue-white hued star of magnitude 5.6, 440 light-years away. \u03b2 Ceti, also called Deneb Kaitos and Diphda is the brightest star in Cetus. It is an orange-hued giant star of magnitude 2.0, 96 light-years from Earth. The traditional name \"Deneb Kaitos\" means \"the whale's tail\". \u03b3 Ceti, Kaffaljidhma (\"head of the whale\") is a very close double star. The primary is a yellow-hued star of magnitude 3.5, 82 light-years from Earth, and the secondary is a blue-hued star of magnitude 6.6. Tau Ceti is noted for being a near Sun-like star at a distance of 11.9 light-years. It is a yellow-hued main-sequence star of magnitude 3.5.\nAA Ceti is a triple star system; the brightest member has a magnitude of 6.2. The primary and secondary are separated by 8.4 arcseconds at an angle of 304 degrees. The tertiary is not visible in telescopes. AA Ceti is an eclipsing variable star; the tertiary star passes in front of the primary and causes the system's apparent magnitude to decrease by 0.5 magnitudes. UV Ceti is an unusual binary variable star. 8.7 light-years from Earth, the system consists of two red dwarfs. Both of magnitude 13. One of the stars is a flare star, which are prone to sudden, random outbursts that last several minutes; these increase the pair's apparent brightness significantly - as high as magnitude 7.\nDeep-sky objects.\nCetus lies far from the galactic plane, so that many distant galaxies are visible, unobscured by dust from the Milky Way. Of these, the brightest is Messier 77 (NGC 1068), a 9th magnitude spiral galaxy near Delta Ceti. It appears face-on and has a clearly visible nucleus of magnitude 10. About 50 million light-years from Earth, M77 is also a Seyfert galaxy and thus a bright object in the radio spectrum. Recently, the galactic cluster JKCS\u00a0041 was confirmed to be the most distant cluster of galaxies yet discovered.\nThe massive cD galaxy Holmberg 15A is also found in Cetus. As is spiral galaxy NGC 1042 and ultra-diffuse galaxy NGC 1052-DF2.\nIC 1613 (Caldwell 51) is an irregular dwarf galaxy near the star 26 Ceti and is a member of the Local Group.\nNGC 246 (Caldwell 56), also called the Cetus Ring, is a planetary nebula with a magnitude of 8.0, 1600 light-years from Earth. Among some amateur astronomers, NGC 246 has garnered the nickname \"Pac-Man Nebula\" because of the arrangement of its central stars and the surrounding star field.\nThe Wolf\u2013Lundmark\u2013Melotte (WLM) is a barred irregular galaxy discovered in 1909 by Max Wolf, located on the outer edges of the Local Group. The discovery of the nature of the galaxy was accredited to Knut Lundmark and Philibert Jacques Melotte in 1926. It is in the constellation Cetus.\nHistory and mythology.\nCetus may have originally been associated with a whale, which would have had mythic status amongst Mesopotamian cultures. It is often now called the Whale, though it is most strongly associated with Cetus the sea-monster, who was slain by Perseus as he saved the princess Andromeda from Poseidon's wrath. It is in the middle of \"The Sea\" recognised by mythologists, a set of water-associated constellations, its other members being Eridanus, Pisces, Piscis Austrinus and Aquarius.\nCetus has been depicted in many ways throughout its history. In the 17th century, Cetus was depicted as a \"dragon fish\" by Johann Bayer. Both Willem Blaeu and Andreas Cellarius depicted Cetus as a whale-like creature in the same century. However, Cetus has also been variously depicted with animal heads attached to a piscine body.\nIn global astronomy.\nIn Chinese astronomy, the stars of Cetus are found among two areas: the Black Tortoise of the North (\u5317\u65b9\u7384\u6b66, \"B\u011bi F\u0101ng Xu\u00e1n W\u01d4\") and the White Tiger of the West (\u897f\u65b9\u767d\u864e, \"X\u012b F\u0101ng B\u00e1i H\u01d4\").\nThe Tukano and Kobeua people of the Amazon used the stars of Cetus to create a jaguar, representing the god of hurricanes and other violent storms. Lambda, Mu, Xi, Nu, Gamma, and Alpha Ceti represented its head; Omicron, Zeta, and Chi Ceti represented its body; Eta Eri, Tau Cet, and Upsilon Cet marked its legs and feet; and Theta, Eta, and Beta Ceti delineated its tail.\nIn Hawaii, the constellation was called \"Na Kuhi\", and Mira (Omicron Ceti) may have been called \"Kane\".\nNamesakes.\nUSS Cetus (AK-77) was a United States Navy Crater class cargo ship named after the constellation.\n\"Cetus\" is the title of a ragtime piano composition by Tom Brier on the album \"Constellations\" and a 1967 electronic composition by Olly Wilson.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;de=-11.35&amp;zoom=&amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 01h 25m 12s, \u221211\u00b0 21\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6363", "revid": "45714998", "url": "https://en.wikipedia.org/wiki?curid=6363", "title": "Carina (constellation)", "text": "Constellation in the southern celestial hemisphere\nCarina ( ) is a constellation in the southern sky. Its name is Latin for the keel of a ship, and it was the southern foundation of the larger constellation of Argo Navis (the ship \"Argo\") until it was divided into three pieces, the other two being Puppis (the poop deck), and Vela (the sails of the ship).\nHistory and mythology.\nCarina was once a part of Argo Navis, the great ship of Jason and the Argonauts who searched for the Golden Fleece. The constellation of Argo was introduced in ancient Greece. However, due to the massive size of Argo Navis and the sheer number of stars that required separate designation, Nicolas-Louis de Lacaille divided Argo into three sections in 1763, including Carina (the hull or keel). In the 19th century, these three became established as separate constellations, and were formally included in the list of 88 modern IAU constellations in 1930. Lacaille kept a single set of Greek letters for the whole of Argo, and separate sets of Latin letter designations for each of the three sections. Therefore, Carina has the \u03b1, \u03b2 and \u03b5, Vela has \u03b3 and \u03b4, Puppis has \u03b6, and so on.\nNotable features.\nStars.\nCarina contains Canopus, a white-hued supergiant that is the second-brightest star in the night sky at magnitude \u22120.72. Alpha Carinae, as Canopus is formally designated, is 313 light-years from Earth. Its traditional name comes from the mythological Canopus, who was a navigator for Menelaus, king of Sparta.\nThere are several other stars above magnitude 3 in Carina. Beta Carinae, traditionally called Miaplacidus, is a blue-white-hued star of magnitude 1.7, 111 light-years from Earth. Epsilon Carinae is an orange-hued giant star similarly bright to Miaplacidus at magnitude 1.9; it is 630 light-years from Earth. Another fairly bright star is the blue-white-hued Theta Carinae; it is a magnitude 2.7 star 440 light-years from Earth. Theta Carinae is also the most prominent member of the cluster IC 2602. Iota Carinae is a white-hued supergiant star of magnitude 2.2, 690 light-years from Earth.\nEta Carinae is the most prominent variable star in Carina, with a mass of approximately 100 solar masses and 4 million times as bright as the Sun. It was first discovered to be unusual in 1677, when its magnitude suddenly rose to 4, attracting the attention of Edmond Halley. Eta Carinae is inside NGC 3372, commonly called the Carina Nebula. It had a long outburst in 1827, when it brightened to magnitude 1, only fading to magnitude 1.5 in 1828. Its most prominent outburst made Eta Carinae the equal of Sirius; it brightened to magnitude \u22121.5 in 1843. In the decades following 1843 it appeared relatively placid, having a magnitude between 6.5 and 7.9. However, in 1998, it brightened again, though only to magnitude 5.0, a far less drastic outburst. Eta Carinae is a binary star, with a companion that has a period of 5.5 years; the two stars are surrounded by the Homunculus Nebula, which is composed of gas that was ejected in 1843.\nThere are several less prominent variable stars in Carina. l Carinae is a Cepheid variable noted for its brightness; it is the brightest Cepheid that is variable to the unaided eye. It is a yellow-hued supergiant star with a minimum magnitude of 4.2 and a maximum magnitude of 3.3; it has a period of 35.5 days.\nTwo bright Mira variable stars are in Carina: R Carinae and S Carinae; both stars are red giants. R Carinae has a minimum magnitude of 10.0 and a maximum magnitude of 4.0. Its period is 309 days and it is 416 light-years from Earth. S Carinae is similar, with a minimum magnitude of 10.0 and a maximum magnitude of 5.0. However, S Carinae has a shorter period\u2014150 days, though it is much more distant at 1,300 light-years from Earth.\nCarina is home to several double stars and binary stars. Upsilon Carinae is a binary star with two blue-white-hued giant components, 1,600 light-years from Earth. The primary is of magnitude 3.0 and the secondary is of magnitude 6.0; the two components are distinguishable in a small amateur telescope.\nTwo asterisms are prominent in Carina. The 'Diamond Cross' is composed of the stars Beta, Theta, Upsilon and Omega Carinae. The Diamond Cross is visible south of 20\u00baN latitude, and is larger but fainter than the Southern Cross in Crux. Flanking the Diamond Cross is the False cross, composed of four stars - two stars in Carina, Iota Carinae and Epsilon Carinae, and two stars in Vela, Kappa Velorum and Delta Velorum - and is often mistaken for the Southern Cross, causing errors in astronavigation.\nDeep-sky objects.\nCarina is known for its namesake nebula, NGC 3372, discovered by French astronomer Nicolas-Louis de Lacaille in 1751, which contains several nebulae. The Carina Nebula overall is an extended emission nebula approximately 8,000 light-years away and 300 light-years wide that includes vast star-forming regions. It has an overall magnitude of 8.0 and an apparent diameter of over 2 degrees. Its central region is called the Keyhole, or the Keyhole Nebula. This was described in 1847 by John Herschel, and likened to a keyhole by Emma Converse in 1873. The Keyhole is about seven light-years wide and is composed mostly of ionized hydrogen, with two major star-forming regions. The Homunculus Nebula is a planetary nebula visible to the naked eye that is being ejected by the erratic luminous blue variable star Eta Carinae, the most massive visible star known. Eta Carinae is so massive that it has reached the theoretical upper limit for the mass of a star and is therefore unstable. It is known for its outbursts; in 1840 it briefly became one of the brightest stars in the sky due to a particularly massive outburst, which largely created the Homunculus Nebula. Because of this instability and history of outbursts, Eta Carinae is considered a prime supernova candidate for the next several hundred thousand years because it has reached the end of its estimated million-year life span.\nNGC 2516 is an open cluster that is both quite large (approximately half a degree square) and bright, visible to the unaided eye. It is located 1,100 light-years from Earth and has approximately 80 stars, the brightest of which is a red giant star of magnitude 5.2. NGC 3114 is another open cluster approximately of the same size, though it is more distant at 3,000 light-years from Earth. It is more loose and dim than NGC 2516, as its brightest stars are only 6th magnitude. The most prominent open cluster in Carina is IC 2602, also called the \"Southern Pleiades\". It contains Theta Carinae, along with several other stars visible to the unaided eye. In total, the cluster possesses approximately 60 stars. The Southern Pleiades is particularly large for an open cluster, with a diameter of approximately one degree. Like IC 2602, NGC 3532 is visible to the unaided eye and is of comparable size. It possesses approximately 150 stars that are arranged in an unusual shape, approximating an ellipse with a dark central area. Several prominent orange giants are among the cluster's bright stars, of the 7th magnitude. Superimposed on the cluster is Chi Carinae, a yellow-white-hued star of magnitude 3.9, far more distant than NGC 3532.\nCarina also contains the naked-eye globular cluster NGC 2808. Epsilon Carinae and Upsilon Carinae are double stars visible in small telescopes.\nOne noted galaxy cluster is 1E 0657-56, the Bullet Cluster. At a distance of 4 billion light-years (redshift 0.296), this galaxy cluster is named for the shock wave seen in the intracluster medium, which resembles the shock wave of a supersonic bullet. The bow shock visible is thought to be due to the smaller galaxy cluster moving through the intracluster medium at a relative speed of 3,000\u20134,000 kilometers per second to the larger cluster. Because this gravitational interaction has been ongoing for hundreds of millions of years, the smaller cluster is being destroyed and will eventually merge with the larger cluster.\nMeteors.\nCarina contains the radiant of the Eta Carinids meteor shower, which peaks around January 21 each year.\nEquivalents.\nFrom China (especially northern China), the stars of Carina can barely be seen. The star Canopus (the south polar star in Chinese astronomy) was located by Chinese astronomers in the Vermilion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"). The rest of the stars were first classified by Xu Guanggi during the Ming dynasty, based on the knowledge acquired from western star charts, and placed among The Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\").\nPolynesian peoples had no name for the constellation in particular, though they had many names for Canopus.\nThe M\u0101ori name \"Ariki\" (\"High-born\"), and the Hawaiian \"Ke Alii-o-kona-i-ka-lewa\", \"The Chief of the southern expanse\" both attest to the star's prominence in the southern sky, while the M\u0101ori \"Atutahi\", \"First-light\" or \"Single-light\", and the Tuamotu \"Te Tau-rari\" and \"Marere-te-tavahi\", \"He who stands alone\". refer to the star's solitary nature.\nIt was also called \"Kapae-poto\" (\"Short horizon\"), because it rarely sets from the vantage point of New Zealand, and \"Kauanga\" (\"Solitary\"), when it was the last star visible before sunrise.\nFuture.\nCarina is in the southern sky quite near the south celestial pole, making it never set (circumpolar) for most of the southern hemisphere. Due to precession of Earth's axis, by the year 4700 the south celestial pole will be in Carina. Three bright stars in Carina will come within 1 degree of the southern celestial pole and take turns as the southern pole star: Omega Carinae (mag 3.29) in 5600, Upsilon Carinae (mag 2.97) in 6700, and Iota Carinae (mag 2.21) in 7900. About 13,860 CE, the bright Canopus (\u22120.7) will have a greater declination than \u221282\u00b0.\nNamesakes.\n was a United States Navy \"Crater\"-class cargo ship named after the constellation.\nthe Toyota Carina was named after it.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n Media related to at Wikimedia Commons\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 9h 00m 00s, \u221260\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6364", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=6364", "title": "Camelopardalis", "text": "Constellation in the northern celestial hemisphere\nCamelopardalis is a large but faint constellation of the northern sky representing a giraffe. The constellation was introduced in 1612 or 1613 by Petrus Plancius. Some older astronomy books give Camelopardalus or Camelopardus as alternative forms of the name, but the version recognized by the International Astronomical Union matches the genitive form, seen suffixed to most of its key stars.\nEtymology.\nFirst attested in English in 1785, the word \"camelopardalis\" comes from Latin, and it is the romanization of the Greek \"\u03ba\u03b1\u03bc\u03b7\u03bb\u03bf\u03c0\u03ac\u03c1\u03b4\u03b1\u03bb\u03b9\u03c2\" meaning \"giraffe\", from \"\u03ba\u03ac\u03bc\u03b7\u03bb\u03bf\u03c2\" (\"kam\u0113los\"), \"camel\" + \"\u03c0\u03ac\u03c1\u03b4\u03b1\u03bb\u03b9\u03c2\" (\"pardalis\"), \"spotted\", because it has a long neck like a camel and spots.\nFeatures.\nStars.\nAlthough Camelopardalis is the 18th largest constellation, it is not a particularly bright constellation, as the brightest stars are only of fourth magnitude. In fact, it only contains four stars brighter than magnitude 5.0.\nOther variable stars are U Camelopardalis, VZ Camelopardalis, and Mira variables T Camelopardalis, X Camelopardalis, and R Camelopardalis. RU Camelopardalis is one of the brighter Type II Cepheids visible in the night sky.\nIn 2011 a supernova was discovered in the constellation.\nDeep-sky objects.\nCamelopardalis is in the part of the celestial sphere facing away from the galactic plane. Accordingly, many distant galaxies are visible within its borders. \nMeteor showers.\nThe annual May meteor shower Camelopardalids from comet 209P/LINEAR have a radiant in Camelopardalis.\nHistory.\nCamelopardalis is not one of Ptolemy's 48 constellations in the \"Almagest\". It was created by Petrus Plancius in 1613. It first appeared in a globe designed by him and produced by Pieter van den Keere. One year later, Jakob Bartsch featured it in his atlas. Johannes Hevelius depicted this constellation in his works which were so influential that it was referred to as Camelopardali Hevelii or abbreviated as Camelopard. Hevel.\nPart of the constellation was hived off to form the constellation Sciurus Volans, the Flying Squirrel, by William Croswell in 1810. However this was not taken up by later cartographers.\nEquivalents.\nIn Chinese astronomy, the stars of Camelopardalis are located within a group of circumpolar stars called the Purple Forbidden Enclosure (\u7d2b\u5fae\u57a3 \"Z\u01d0 W\u0113i Yu\u00e1n\").\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;de=70.0&amp;zoom=&amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 06h 00m 00s, +70\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6365", "revid": "26187513", "url": "https://en.wikipedia.org/wiki?curid=6365", "title": "Convention of Kanagawa", "text": "1854 treaty between Japan and the US\nThe Convention of Kanagawa, also known as the Kanagawa Treaty (, \"Kanagawa J\u014dyaku\") or the Japan\u2013US Treaty of Peace and Amity (, \"Nichibei Washin J\u014dyaku\"), was a treaty signed between the United States and the Tokugawa Shogunate on March 31, 1854. Signed under threat of force, it effectively meant the end of Japan's 220-year-old policy of national seclusion (\"sakoku\") by opening the ports of Shimoda and Hakodate to American vessels. It also ensured the safety of American castaways and established the position of an American consul in Japan. The treaty precipitated the signing of similar treaties establishing diplomatic relations with other Western powers.\nIsolation of Japan.\nSince the beginning of the 17th century, the Tokugawa Shogunate pursued a policy of isolating the country from outside influences. Foreign trade was maintained only with the Dutch and the Chinese and was conducted exclusively at Nagasaki under a strict government monopoly. This \"Pax Tokugawa\" period is largely associated with domestic peace, social stability, commercial development, and expanded literacy. This policy had two main objectives:\nBy the early 19th century, this policy of isolation was increasingly under challenge. In 1844, King William II of the Netherlands sent a letter urging Japan to end the isolation policy on its own before change would be forced from the outside. In 1846, an official American expedition led by Commodore James Biddle arrived in Japan asking for ports to be opened for trade but was sent away.\nPerry expedition.\nIn 1853, United States Navy Commodore Matthew C. Perry was sent with a fleet of warships by U.S. President Millard Fillmore to force the opening of Japanese ports to American trade, through the use of gunboat diplomacy if necessary. The growing commerce between America and China, the presence of American whalers in waters offshore Japan, and the increasing monopolization of potential coaling stations by the British and French in Asia were all contributing factors. The Americans were also driven by concepts of manifest destiny and the desire to impose the \"benefits\" of western civilization and the Christian religion on what they perceived as backward Asian nations. From the Japanese perspective, increasing contacts with foreign warships and the increasing disparity between western military technology and the Japanese feudal armies created growing concern. The Japanese had been keeping abreast of world events via information gathered from Dutch traders in Dejima and had been forewarned by the Dutch of Perry's voyage. There was a considerable internal debate in Japan on how best to meet this potential threat to Japan's economic and political sovereignty in light of events occurring in China with the Opium Wars.\nPerry arrived with four warships at Uraga, at the mouth of Edo Bay on July 8, 1853. He blatantly refused Japanese demands that he proceed to Nagasaki, which was the designated port for foreign contact. After threatening to continue directly on to Edo, the nation's capital, and to burn it to the ground if necessary, he was allowed to land at nearby Kurihama on July 14 and to deliver his letter. Such refusal was intentional, as Perry wrote in his journal: \u201cTo show these princes how little I regarded their order for me to depart, on getting on board I immediately ordered the whole squadron underway, not to leave the bay\u2026 but to go higher up\u2026 would produce a decided influence upon the pride and conceit of the government, and cause a more favorable consideration of the President\u2019s letter.\" Perry\u2019s power front did not stop with refusing to land in Uraga, but he continued to push the boundaries of the Japanese. He ordered the squadron to survey Edo bay, which led to a stand-off between Japanese officers with swords and Americans with guns. By firing the guns into the water, Perry demonstrated their military might, which greatly affected Japanese perceptions of Perry and the United States. Namely, a perception of fear and disrespect.\nDespite years of debate on the isolation policy, Perry's letter created great controversy within the highest levels of the Tokugawa shogunate. The \"sh\u014dgun\" himself, Tokugawa Ieyoshi, died days after Perry's departure and was succeeded by his sickly young son, Tokugawa Iesada, leaving effective administration in the hands of the Council of Elders (\"r\u014dj\u016b\") led by Abe Masahiro. Abe felt that it was impossible for Japan to resist the American demands by military force and yet was reluctant to take any action on his own authority for such an unprecedented situation. Attempting to legitimize any decision taken, Abe polled all of the \"daimy\u014d\" for their opinions. This was the first time that the Tokugawa shogunate had allowed its decision-making to be a matter of public debate and had the unforeseen consequence of portraying the shogunate as weak and indecisive. The results of the poll also failed to provide Abe with an answer; of the 61 known responses, 19 were in favour of accepting the American demands and 19 were equally opposed. Of the remainder, 14 gave vague responses expressing concern of possible war, 7 suggested making temporary concessions and 2 advised that they would simply go along with whatever was decided.\nPerry returned again on February 11, 1854, with an even larger force of eight warships and made it clear that he would not be leaving until a treaty was signed. Perry continued his manipulation of the setting, such as keeping himself aloof from lower-ranking officials, implying the use of force, surveying the harbor, and refusing to meet in the designated negotiation sites. Negotiations began on March 8 and proceeded for around one month. Each party shared a performance when Perry arrived. The Americans had a technology demonstration, and the Japanese had a sumo wrestling show. While the new technology awed the Japanese people, Perry was unimpressed by the sumo wrestlers and perceived such performance as foolish and degrading: \u201cThis disgusting exhibition did not terminate until the whole twenty-five had, successively, in pairs, displayed their immense powers and savage qualities.\" The Japanese side gave in to almost all of Perry's demands, with the exception of a commercial agreement modelled after previous American treaties with China, which Perry agreed to defer to a later time. The main controversy centered on the selection of the ports to open, with Perry adamantly rejecting Nagasaki. The treaty, written in English, Dutch, Chinese and Japanese, was signed on March 31, 1854, at what is now Kaik\u014d Hiroba (Port Opening Square) Yokohama, a site adjacent to the current Yokohama Archives of History.\nTreaty of Peace and Amity (1854).\nThe \"Japan-US Treaty of Peace and Amity\" has twelve articles: \nAt the time, \"sh\u014dgun\" Tokugawa Iesada was the de facto ruler of Japan; for the Emperor of Japan to interact in any way with foreigners was out of the question. Perry concluded the treaty with representatives of the shogun, led by plenipotentiary and the text was endorsed subsequently, albeit reluctantly, by Emperor K\u014dmei.\nThe treaty was ratified on February 21, 1855.\nConsequences of the treaty.\nIn the short term, the U.S. was content with the agreement since Perry had achieved his primary objective of breaking Japan's \"sakoku\" policy and setting the grounds for protection of American citizens and an eventual commercial agreement. On the other hand, the Japanese were forced into this trade, and many saw it as a sign of weakness. The Tokugawa shogunate could point out that the treaty was not actually signed by the shogun, or indeed any of his \"r\u014dj\u016b\", and that it had at least temporarily averted the possibility of immediate military confrontation.\nExternally, the treaty led to the United States-Japan Treaty of Amity and Commerce, the \"Harris Treaty\" of 1858, which allowed the establishment of foreign concessions, extraterritoriality for foreigners, and minimal import taxes for foreign goods. The Japanese chafed under the \"unequal treaty system\" which characterized Asian and western relations during this period. The Kanagawa treaty was also followed by similar agreements with the United Kingdom (Anglo-Japanese Friendship Treaty, October 1854), Russia (Treaty of Shimoda, February 7, 1855), and France (Treaty of Amity and Commerce between France and Japan, October 9, 1858).\nInternally, the treaty had far-reaching consequences. Decisions to suspend previous restrictions on military activities led to re-armament by many domains and further weakened the position of the shogun. Debate over foreign policy and popular outrage over perceived appeasement to the foreign powers was a catalyst for the \"sonn\u014d j\u014di\" movement and a shift in political power from Edo back to the Imperial Court in Kyoto. The opposition of Emperor K\u014dmei to the treaties further lent support to the \"t\u014dbaku\" (overthrow the shogunate) movement, and eventually to the Meiji Restoration, which affected all realms of Japanese life. Following this period came an increase in foreign trade, the rise of Japanese military might, and the later rise of Japanese economic and technological advancement. Westernization at the time was a defense mechanism, but Japan has since found a balance between Western modernity and Japanese tradition. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6366", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6366", "title": "Canis Major", "text": "Constellation in the southern celestial hemisphere\nCanis Major is a constellation in the southern celestial hemisphere. In the second century, it was included in Ptolemy's 48 constellations, and is counted among the 88 modern constellations. Its name is Latin for \"greater dog\" in contrast to Canis Minor, the \"lesser dog\"; both figures are commonly represented as following the constellation of Orion the hunter through the sky. The Milky Way passes through Canis Major and several open clusters lie within its borders, most notably M41.\nCanis Major contains Sirius, the brightest star in the night sky, known as the \"dog star\". It is bright because of its proximity to the Solar System. In contrast, the other bright stars of the constellation are stars of great distance and high luminosity. At magnitude 1.5, Epsilon Canis Majoris (Adhara) is the second-brightest star of the constellation and the brightest source of extreme ultraviolet radiation in the night sky. Next in brightness are the yellow-white supergiant Delta (Wezen) at 1.8, the blue-white giant Beta (Mirzam) at 2.0, blue-white supergiants Eta (Aludra) at 2.4 and Omicron2 at 3.0, and white spectroscopic binary Zeta (Furud), also at 3.0. The red hypergiant VY Canis Majoris is one of the largest stars known, while the neutron star RX J0720.4-3125 has a radius of a mere 5\u00a0km.\nHistory and mythology.\nIn western astronomy.\nIn ancient Mesopotamia, Sirius, named KAK.SI.SA2 by the Babylonians, was seen as an arrow aiming towards Orion, while the southern stars of Canis Major and a part of Puppis were viewed as a bow, named BAN in the \"Three Stars Each\" tablets, dating to around 1100 BC. In the later compendium of Babylonian astronomy and astrology titled \"MUL.APIN\", the arrow, Sirius, was also linked with the warrior Ninurta, and the bow with Ishtar, daughter of Enlil. Ninurta was linked to the later deity Marduk, who was said to have slain the ocean goddess Tiamat with a great bow, and worshipped as the principal deity in Babylon. The Ancient Greeks replaced the bow and arrow depiction with that of a dog.\nIn Greek Mythology, Canis Major represented the dog Laelaps, a gift from Zeus to Europa; or sometimes the hound of Procris, Diana's nymph; or the one given by Aurora to Cephalus, so famed for its speed that Zeus elevated it to the sky. It was also considered to represent one of Orion's hunting dogs, pursuing Lepus the Hare or helping Orion fight Taurus the Bull; and is referred to in this way by Aratos, Homer and Hesiod. The ancient Greeks refer only to one dog, but by Roman times, Canis Minor appears as Orion's second dog. Alternative names include Canis Sequens and Canis Alter. Canis Syrius was the name used in the 1521 \"Alfonsine tables\".\nThe Roman myth refers to Canis Major as \"Custos Europae\", the dog guarding Europa but failing to prevent her abduction by Jupiter in the form of a bull, and as \"Janitor Lethaeus\", \"the watchdog\". In medieval Arab astronomy, the constellation became \"al-Kalb al-Akbar\", \"the Greater Dog\", transcribed as \"Alcheleb Alachbar\" by 17th century writer Edmund Chilmead. Islamic scholar Ab\u016b Ray\u1e25\u0101n al-B\u012br\u016bn\u012b referred to Orion as \"Kalb al-Jabb\u0101r\", \"the Dog of the Giant\". Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called \"Merzem\", includes the stars of Canis Major and Canis Minor and is the herald of two weeks of hot weather.\nIn non-western astronomy.\nIn Chinese astronomy, the modern constellation of Canis Major is located in the Vermilion Bird (), where the stars were classified in several separate asterisms of stars. The Military Market () was a circular pattern of stars containing Nu3, Beta, Xi1 and Xi2, and some stars from Lepus. The Wild Cockerel () was at the centre of the Military Market, although it is uncertain which stars depicted what. Schlegel reported that the stars Omicron and Pi Canis Majoris might have been them, while Beta or Nu2 have also been proposed. Sirius was ' (), the Celestial Wolf, denoting invasion and plunder. Southeast of the Wolf was the asterism ' (), the celestial Bow and Arrow, which was interpreted as containing Delta, Epsilon, Eta and Kappa Canis Majoris and Delta Velorum. Alternatively, the arrow was depicted by Omicron2 and Eta and aiming at Sirius (the Wolf), while the bow comprised Kappa, Epsilon, Sigma, Delta and 164 Canis Majoris, and Pi and Omicron Puppis.\nBoth the M\u0101ori people and the people of the Tuamotus recognized the figure of Canis Major as a distinct entity, though it was sometimes absorbed into other constellations. ', also called ' and ', (\"The Assembly of \" or \"The Assembly of Sirius\") was a M\u0101ori constellation that included both Canis Minor and Canis Major, along with some surrounding stars. Related was ', also called ', the Mirror of , formed from an undefined group of stars in Canis Major. They called Sirius ' and ', corresponding to two of the names for the constellation, though ' was a name applied to other stars in various M\u0101ori groups and other Polynesian cosmologies. The Tuamotu people called Canis Major \"\", \"the abiding assemblage of \".\nThe Tharumba people of the Shoalhaven River saw three stars of Canis Major as ' (Bat) and his two wives ' (Mrs Brown Snake) and ' (Mrs Black Snake); bored of following their husband around, the women try to bury him while he is hunting a wombat down its hole. He spears them and all three are placed in the sky as the constellation '. To the Boorong people of Victoria, Sigma Canis Majoris was ' (which has become the official name of this star), and its flanking stars Delta and Epsilon were his two wives. The moon (', \"native cat\") sought to lure the further wife (Epsilon) away, but assaulted him and he has been wandering the sky ever since.\nCharacteristics.\nCanis Major is a constellation in the Southern Hemisphere's summer (or northern hemisphere's winter) sky, bordered by Monoceros (which lies between it and Canis Minor) to the north, Puppis to the east and southeast, Columba to the southwest, and Lepus to the west. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CMa\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a quadrilateral; in the equatorial coordinate system, the right ascension coordinates of these borders lie between 06h 12.5m and 07h 27.5m, while the declination coordinates are between \u221211.03\u00b0 and \u221233.25\u00b0. Covering 380 square degrees or 0.921% of the sky, it ranks 43rd of the 88 currently-recognized constellations in size.\nFeatures.\nStars.\nCanis Major is a prominent constellation because of its many bright stars. These include Sirius (Alpha Canis Majoris), the brightest star in the night sky, as well as three other stars above magnitude 2.0. Furthermore, two other stars are thought to have previously outshone all others in the night sky\u2014Adhara (Epsilon Canis Majoris) shone at \u22123.99 around 4.7\u00a0million years ago, and Mirzam (Beta Canis Majoris) peaked at \u22123.65 around 4.42\u00a0million years ago. Another, NR Canis Majoris, will be brightest at magnitude \u22120.88 in about 2.87\u00a0million years' time.\nThe German cartographer Johann Bayer used the Greek letters Alpha through Omicron to label the most prominent stars in the constellation, including three adjacent stars as Nu and two further pairs as Xi and Omicron, while subsequent observers designated further stars in the southern parts of the constellation that were hard to discern from Central Europe. Bayer's countryman Johann Elert Bode later added Sigma, Tau and Omega; the French astronomer Nicolas Louis de Lacaille added lettered stars a to k (though none are in use today). John Flamsteed numbered 31 stars, with 3 Canis Majoris being placed by Lacaille into Columba as Delta Columbae (Flamsteed had not recognised Columba as a distinct constellation). He also labelled two stars\u2014his 10 and 13 Canis Majoris\u2014as Kappa1 and Kappa2 respectively, but subsequent cartographers such as Francis Baily and John Bevis dropped the fainter former star, leaving Kappa2 as the sole Kappa. Flamsteed's listing of Nu1, Nu2, Nu3, Xi1, Xi2, Omicron1 and Omicron2 have all remained in use.\nSirius is the brightest star in the night sky at apparent magnitude \u22121.46 and one of the closest stars to Earth at a distance of 8.6 light-years. Its name comes from the Greek word for \"scorching\" or \"searing\". Sirius is also a binary star; its companion Sirius B is a white dwarf with a magnitude of 8.4\u201310,000 times fainter than Sirius A to observers on Earth. The two orbit each other every 50 years. Their closest approach last occurred in 1993 and they will be at their greatest separation between 2020 and 2025. Sirius was the basis for the ancient Egyptian calendar. The star marked the Great Dog's mouth on Bayer's star atlas.\nFlanking Sirius are Beta and Gamma Canis Majoris. Also called Mirzam or Murzim, Beta is a blue-white Beta Cephei variable star of magnitude 2.0, which varies by a few hundredths of a magnitude over a period of six hours. Mirzam is 500 light-years from Earth, and its traditional name means \"the announcer\", referring to its position as the \"announcer\" of Sirius, as it rises a few minutes before Sirius does. Gamma, also known as Muliphein, is a fainter star of magnitude 4.12, in reality a blue-white bright giant of spectral type B8IIe located 441 light-years from earth. Iota Canis Majoris, lying between Sirius and Gamma, is another star that has been classified as a Beta Cephei variable, varying from magnitude 4.36 to 4.40 over a period of 1.92 hours. It is a remote blue-white supergiant star of spectral type B3Ib, around 46,000 times as luminous as the sun and, at 2500 light-years distant, 300 times further away than Sirius.\nEpsilon, Omicron2, Delta, and Eta Canis Majoris were called \"Al Adzari\" \"the virgins\" in medieval Arabic tradition. Marking the dog's right thigh on Bayer's atlas is Epsilon Canis Majoris, also known as Adhara. At magnitude 1.5, it is the second-brightest star in Canis Major and the 23rd-brightest star in the sky. It is a blue-white supergiant of spectral type B2Iab, around 404 light-years from Earth. This star is one of the brightest known extreme ultraviolet sources in the sky. It is a binary star; the secondary is of magnitude 7.4. Its traditional name means \"the virgins\", having been transferred from the group of stars to Epsilon alone. Nearby is Delta Canis Majoris, also called Wezen. It is a yellow-white supergiant of spectral type F8Iab and magnitude 1.84, around 1605 light-years from Earth. With a traditional name meaning \"the weight\", Wezen is 17 times as massive and 50,000 times as luminous as the Sun. If located in the centre of the Solar System, it would extend out to Earth as its diameter is 200 times that of the Sun. Only around 10\u00a0million years old, Wezen has stopped fusing hydrogen in its core. Its outer envelope is beginning to expand and cool, and in the next 100,000 years it will become a red supergiant as its core fuses heavier and heavier elements. Once it has a core of iron, it will collapse and explode as a supernova. Nestled between Adhara and Wezen lies Sigma Canis Majoris, known as Unurgunite to the Boorong and Wotjobaluk people, a red supergiant of spectral type K7Ib that varies irregularly between magnitudes 3.43 and 3.51.\nAlso called Aludra, Eta Canis Majoris is a blue-white supergiant of spectral type B5Ia with a luminosity 176,000 times and diameter around 80 times that of the Sun. Classified as an Alpha Cygni type variable star, Aludra varies in brightness from magnitude 2.38 to 2.48 over a period of 4.7 days. It is located 1120 light-years away. To the west of Adhara lies 3.0-magnitude Zeta Canis Majoris or Furud, around 362 light-years distant from Earth. It is a spectroscopic binary, whose components orbit each other every 1.85 years, the combined spectrum indicating a main star of spectral type B2.5V.\nBetween these stars and Sirius lie Omicron1, Omicron2, and Pi Canis Majoris. Omicron2 is a massive supergiant star about 21 times as massive as the Sun. Only 7\u00a0million years old, it has exhausted the supply of hydrogen at its core and is now processing helium. It is an Alpha Cygni variable that undergoes periodic non-radial pulsations, which cause its brightness to cycle from magnitude 2.93 to 3.08 over a 24.44-day interval. Omicron1 is an orange K-type supergiant of spectral type K2.5Iab that is an irregular variable star, varying between apparent magnitudes 3.78 and 3.99. Around 18 times as massive as the Sun, it shines with 65,000 times its luminosity.\nNorth of Sirius lie Theta and Mu Canis Majoris, Theta being the most northerly star with a Bayer designation in the constellation. Around 8\u00a0billion years old, it is an orange giant of spectral type K4III that is around as massive as the Sun but has expanded to 30 times the Sun's diameter. Mu is a multiple star system located around 1244 light-years distant, its components discernible in a small telescope as a 5.3-magnitude yellow-hued and 7.1-magnitude bluish star. The brighter star is a giant of spectral type K2III, while the companion is a main sequence star of spectral type B9.5V. Nu1 Canis Majoris is a yellow-hued giant star of magnitude 5.7, 278 light-years away; it is at the threshold of naked-eye visibility. It has a companion of magnitude 8.1.\nAt the southern limits of the constellation lie Kappa and Lambda Canis Majoris. Although of similar spectra and nearby each other as viewed from Earth, they are unrelated. Kappa is a Gamma Cassiopeiae variable of spectral type B2Vne, which brightened by 50% between 1963 and 1978, from magnitude 3.96 or so to 3.52. It is around 659 light-years distant. Lambda is a blue-white B-type main sequence dwarf with an apparent magnitude of 4.48 located around 423 light-years from Earth. It is 3.7 times as wide as and 5.5 times as massive as the Sun, and shines with 940 times its luminosity.\nCanis Major is also home to many variable stars. EZ Canis Majoris is a Wolf\u2013Rayet star of spectral type WN4 that varies between magnitudes 6.71 and 6.95 over a period of 3.766 days; the cause of its variability is unknown but thought to be related to its stellar wind and rotation. VY Canis Majoris is a remote red hypergiant located approximately 3,800 light-years away from Earth. It is one of largest stars known (sometimes described as the largest known) and is also one of the most luminous with a radius varying from 1,420 to 2,200 times the Sun's radius, and a luminosity around 300,000 times greater than the Sun. Its current mass is about 17 \u00b1 8 solar masses, having shed material from an initial mass of 25\u201332 solar masses. VY CMa is also surrounded by a red reflection nebula that has been made by the material expelled by the strong stellar winds of its central star. W Canis Majoris is a type of red giant known as a carbon star\u2014a semiregular variable, it ranges between magnitudes 6.27 and 7.09 over a period of 160 days. A cool star, it has a surface temperature of around 2,900 K and a radius 234 times that of the Sun, its distance estimated at 1,444\u20131,450 light-years from Earth. At the other extreme in size is RX J0720.4-3125, a neutron star with a radius of around 5\u00a0km. Exceedingly faint, it has an apparent magnitude of 26.6. Its spectrum and temperature appear to be mysteriously changing over several years. The nature of the changes are unclear, but it is possible they were caused by an event such as the star's absorption of an accretion disc.\nTau Canis Majoris is a Beta Lyrae-type eclipsing multiple star system that varies from magnitude 4.32 to 4.37 over 1.28 days. Its four main component stars are hot O-type stars, with a combined mass 80 times that of the Sun and shining with 500,000 times its luminosity, but little is known of their individual properties. A fifth component, a magnitude 10 star, lies at a distance of . The system is only 5\u00a0million years old. UW Canis Majoris is another Beta Lyrae-type star 3000 light-years from Earth; it is an eclipsing binary that ranges in magnitude from a minimum of 5.3 to a maximum of 4.8. It has a period of 4.4 days; its components are two massive hot blue stars, one a blue supergiant of spectral type O7.5\u20138 Iab, while its companion is a slightly cooler, less evolved and less luminous supergiant of spectral type O9.7Ib. The stars are 200,000 and 63,000 times as luminous as the Sun. However the fainter star is the more massive at 19 solar masses to the primary's 16. R Canis Majoris is another eclipsing binary that varies from magnitude 5.7 to 6.34 over 1.13 days, with a third star orbiting these two every 93 years. The shortness of the orbital period and the low ratio between the two main components make this an unusual Algol-type system.\nSeven star systems have been found to have planets. Nu2 Canis Majoris is an ageing orange giant of spectral type K1III of apparent magnitude 3.91 located around 64 light-years distant. Around 1.5 times as massive and 11 times as luminous as the Sun, it is orbited over a period of 763 days by a planet 2.6 times as massive as Jupiter. HD 47536 is likewise an ageing orange giant found to have a planetary system\u2014echoing the fate of the Solar System in a few billion years as the Sun ages and becomes a giant. Conversely, HD 45364 is a star 107 light-years distant that is a little smaller and cooler than the Sun, of spectral type G8V, which has two planets discovered in 2008. With orbital periods of 228 and 342 days, the planets have a 3:2 orbital resonance, which helps stabilise the system. HD 47186 is another sunlike star with two planets; the inner\u2014HD 47186 b\u2014takes four days to complete an orbit and has been classified as a Hot Neptune, while the outer\u2014HD 47186 c\u2014has an eccentric 3.7-year period orbit and has a similar mass to Saturn. HD 43197 is a sunlike star around 183 light-years distant that has two planets: a hot Jupiter-size planet with an eccentric orbit. The other planet, HD 43197 c, is another massive Jovian planet with a slightly oblong orbit outside of its habitable zone. \nZ Canis Majoris is a star system a mere 300,000 years old composed of two pre-main-sequence stars\u2014a FU Orionis star and a Herbig Ae/Be star, which has brightened episodically by two magnitudes to magnitude 8 in 1987, 2000, 2004 and 2008. The more massive Herbig Ae/Be star is enveloped in an irregular roughly spherical cocoon of dust that has an inner diameter of and outer diameter of . The cocoon has a hole in it through which light shines that covers an angle of 5 to 10 degrees of its circumference. Both stars are surrounded by a large envelope of in-falling material left over from the original cloud that formed the system. Both stars are emitting jets of material, that of the Herbig Ae/Be star being much larger\u201411.7 light-years long. Meanwhile, FS Canis Majoris is another star with infra-red emissions indicating a compact shell of dust, but it appears to be a main-sequence star that has absorbed material from a companion. These stars are thought to be significant contributors to interstellar dust.\nDeep-sky objects.\nThe band of the Milky Way goes through Canis Major, with only patchy obscurement by interstellar dust clouds. It is bright in the northeastern corner of the constellation, as well as in a triangular area between Adhara, Wezen and Aludra, with many stars visible in binoculars. Canis Major boasts several open clusters. The only Messier object is M41 (NGC 2287), an open cluster with a combined visual magnitude of 4.5, around 2300 light-years from Earth. Located 4 degrees south of Sirius, it contains contrasting blue, yellow and orange stars and covers an area the apparent size of the full moon\u2014in reality around 25 light-years in diameter. Its most luminous stars have already evolved into giants. The brightest is a 6.3-magnitude star of spectral type K3. Located in the field is 12 Canis Majoris, though this star is only 670 light-years distant. NGC 2360, known as Caroline's Cluster after its discoverer Caroline Herschel, is an open cluster located 3.5 degrees west of Muliphein and has a combined apparent magnitude of 7.2. Around 15 light-years in diameter, it is located 3700 light-years away from Earth, and has been dated to around 2.2\u00a0billion years old. NGC 2362 is a small, compact open cluster, 5200 light-years from Earth. It contains about 60 stars, of which Tau Canis Majoris is the brightest member. Located around 3 degrees northeast of Wezen, it covers an area around 12 light-years in diameter, though the stars appear huddled around Tau when seen through binoculars. It is a very young open cluster as its member stars are only a few million years old. Lying 2 degrees southwest of NGC 2362 is NGC 2354 a fainter open cluster of magnitude 6.5, with around 15 member stars visible with binoculars. Located around 30' northeast of NGC 2360, NGC 2359 (Thor's Helmet or the Duck Nebula) is a relatively bright emission nebula in Canis Major, with an approximate magnitude of 10, which is 10,000 light-years from Earth. The nebula is shaped by HD 56925, an unstable Wolf\u2013Rayet star embedded within it.\nIn 2003, an overdensity of stars in the region was announced to be the Canis Major Dwarf, the closest satellite galaxy to Earth. However, there remains debate over whether it represents a disrupted dwarf galaxy or in fact a variation in the thin and thick disk and spiral arm populations of the Milky Way. Investigation of the area yielded only ten RR Lyrae variables\u2014consistent with the Milky Way's halo and thick disk populations rather than a separate dwarf spheroidal galaxy. On the other hand, a globular cluster in Puppis, NGC 2298\u2014which appears to be part of the Canis Major dwarf system\u2014is extremely metal-poor, suggesting it did not arise from the Milky Way's thick disk, and instead is of extragalactic origin.\nNGC 2207 and IC 2163 are a pair of face-on interacting spiral galaxies located 125\u00a0million light-years from Earth. About 40\u00a0million years ago, the two galaxies had a close encounter and are now moving farther apart; nevertheless, the smaller IC 2163 will eventually be incorporated into NGC 2207. As the interaction continues, gas and dust will be perturbed, sparking extensive star formation in both galaxies. Supernovae have been observed in NGC 2207 in 1975 (type Ia SN 1975a), 1999 (the type Ib SN 1999ec), 2003 (type 1b supernova SN 2003H), and 2013 (type II supernova SN 2013ai). Located 16\u00a0million light-years distant, ESO 489-056 is an irregular dwarf- and low-surface-brightness galaxy that has one of the lowest metallicities known.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;de=-20.0&amp;zoom=&amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 07h 00m 00s, \u221220\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6367", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6367", "title": "Canis Minor", "text": "Constellation in the northern celestial hemisphere\nCanis Minor is a small constellation in the northern celestial hemisphere. In the second century, it was included as an asterism, or pattern, of two stars in Ptolemy's 48 constellations, and it is counted among the 88 modern constellations. Its name is Latin for \"lesser dog\", in contrast to Canis Major, the \"greater dog\"; both figures are commonly represented as following the constellation of Orion the hunter.\nCanis Minor contains only two stars brighter than the fourth magnitude, Procyon (Alpha Canis Minoris), with a magnitude of 0.34, and Gomeisa (Beta Canis Minoris), with a magnitude of 2.9. The constellation's dimmer stars were noted by Johann Bayer, who named eight stars including Alpha and Beta, and John Flamsteed, who numbered fourteen. Procyon is the eighth-brightest star in the night sky, as well as one of the closest. A yellow-white main-sequence star, it has a white dwarf companion. Gomeisa is a blue-white main-sequence star. Luyten's Star is a ninth-magnitude red dwarf and the Solar System's next closest stellar neighbour in the constellation after Procyon. Additionally, Procyon and Luyten's Star are only 1.12 light-years away from each other, and Procyon would be the brightest star in Luyten's Star's sky. The fourth-magnitude HD 66141, which has evolved into an orange giant towards the end of its life cycle, was discovered to have a planet in 2012. There are two faint deep-sky objects within the constellation's borders. The 11 Canis-Minorids are a meteor shower that can be seen in early December.\nHistory and mythology.\nThough strongly associated with the Classical Greek uranographic tradition, Canis Minor originates from ancient Mesopotamia. Procyon and Gomeisa were called \"MASH.TAB.BA\" or \"twins\" in the \"Three Stars Each\" tablets, dating to around 1100 BC. In the later \"MUL.APIN\", this name was also applied to the pairs of Pi3 and Pi4 Orionis and Zeta and Xi Orionis. The meaning of \"MASH.TAB.BA\" evolved as well, becoming the twin deities Lulal and Latarak, who are on the opposite side of the sky from \"Papsukkal\", the True Shepherd of Heaven in Babylonian mythology. Canis Minor was also given the name \"DAR.LUGAL\", its position defined as \"the star which stands behind it [Orion]\", in the \"MUL.APIN\"; the constellation represents a rooster. This name may have also referred to the constellation Lepus. \"DAR.LUGAL\" was also denoted \"DAR.MU\u0160EN\" and \"DAR.LUGAL.MU\u0160EN\" in Babylonia. Canis Minor was then called \"tarlugallu\" in Akkadian astronomy.\nCanis Minor was one of the original 48 constellations formulated by Ptolemy in his second-century Almagest, in which it was defined as a specific pattern (asterism) of stars; Ptolemy identified only two stars and hence no depiction was possible. The Ancient Greeks called the constellation \u03c0\u03c1\u03bf\u03ba\u03c5\u03c9\u03bd/\"Procyon\", \"coming before the dog\", transliterated into Latin as \"Antecanis\", \"Praecanis\", or variations thereof, by Cicero and others. Roman writers also appended the descriptors \"parvus\", \"minor\" or \"minusculus\" (\"small\" or \"lesser\", for its faintness), \"septentrionalis\" (\"northerly\", for its position in relation to Canis Major), \"primus\" (rising \"first\") or \"sinister\" (rising to the \"left\") to its name \"Canis\".\nIn Greek mythology, Canis Minor was sometimes connected with the Teumessian Fox, a beast turned into stone with its hunter, Laelaps, by Zeus, who placed them in heaven as Canis Major (Laelaps) and Canis Minor (Teumessian Fox). Eratosthenes accompanied the Little Dog with Orion, while Hyginus linked the constellation with Maera, a dog owned by Icarius of Athens. On discovering the latter's death, the dog and Icarius' daughter Erigone took their lives and all three were placed in the sky\u2014Erigone as Virgo and Icarius as Bo\u00f6tes. As a reward for his faithfulness, the dog was placed along the \"banks\" of the Milky Way, which the ancients believed to be a heavenly river, where he would never suffer from thirst.\nThe medieval Arabic astronomers maintained the depiction of Canis Minor (\"al-Kalb al-Asghar\" in Arabic) as a dog; in his Book of the Fixed Stars, Abd al-Rahman al-Sufi included a diagram of the constellation with a canine figure superimposed. There was one slight difference between the Ptolemaic vision of Canis Minor and the Arabic; al-Sufi claims Mirzam, now assigned to Orion, as part of both Canis Minor\u2014the collar of the dog\u2014and its modern home. The Arabic names for both Procyon and Gomeisa alluded to their proximity and resemblance to Sirius, though they were not direct translations of the Greek; Procyon was called \"ash-Shi'ra ash-Shamiya\", the \"Syrian Sirius\" and Gomeisa was called \"ash-Shira al-Ghamisa\", the Sirius with bleary eyes. Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called \"Merzem\", includes the stars of Canis Minor and Canis Major and is the herald of two weeks of hot weather.\nThe ancient Egyptians thought of this constellation as Anubis, the jackal god.\nAlternative names have been proposed: Johann Bayer in the early 17th century termed the constellation \"Fovea\" \"The Pit\", and \"Morus\" \"Sycamine Tree\". Seventeenth-century German poet and author Philippus Caesius linked it to the dog of Tobias from the Apocrypha. Richard A. Proctor gave the constellation the name \"Felis\" \"the Cat\" in 1870 (contrasting with Canis Major, which he had abbreviated to \"Canis\" \"the Dog\"), explaining that he sought to shorten the constellation names to make them more manageable on celestial charts. Occasionally, Canis Minor is confused with Canis Major and given the name \"Canis Orionis\" (\"Orion's Dog\").\nIn non-Western astronomy.\nIn Chinese astronomy, the stars corresponding to Canis Minor lie in the Vermilion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"). Procyon, Gomeisa and Eta Canis Minoris form an asterism known as N\u00e1nh\u00e9, the Southern River. With its counterpart, the Northern River Beihe (Castor and Pollux), N\u00e1nh\u00e9 was also associated with a gate or sentry. Along with Zeta and 8 Cancri, 6 Canis Minoris and 11 Canis Minoris formed the asterism \"Shuiwei\", which literally means \"water level\". Combined with additional stars in Gemini, Shuiwei represented an official who managed floodwaters or a marker of the water level. Neighboring Korea recognized four stars in Canis Minor as part of a different constellation, \"the position of the water\". This constellation was located in the Red Bird, the southern portion of the sky.\nPolynesian peoples often did not recognize Canis Minor as a constellation, but they saw Procyon as significant and often named it; in the Tuamotu Archipelago it was known as \"Hiro\", meaning \"twist as a thread of coconut fiber\", and \"Kopu-nui-o-Hiro\" (\"great paunch of Hiro\"), which was either a name for the modern figure of Canis Minor or an alternative name for Procyon. Other names included \"Vena\" (after a goddess), on Mangaia and \"Puanga-hori\" (false \"Puanga\", the name for Rigel), in New Zealand. In the Society Islands, Procyon was called \"Ana-tahua-vahine-o-toa-te-manava\", literally \"Aster the priestess of brave heart\", figuratively the \"pillar for elocution\". The Wardaman people of the Northern Territory in Australia gave Procyon and Gomeisa the names \"Magum\" and \"Gurumana\", describing them as humans who were transformed into gum trees in the dreamtime. Although their skin had turned to bark, they were able to speak with a human voice by rustling their leaves.\nThe Aztec calendar was related to their cosmology. The stars of Canis Minor were incorporated along with some stars of Orion and Gemini into an asterism associated with the day called \"Water\".\nCharacteristics.\nLying directly south of Gemini's bright stars Castor and Pollux, Canis Minor is a small constellation bordered by Monoceros to the south, Gemini to the north, Cancer to the northeast, and Hydra to the east. It does not border Canis Major; Monoceros is in between the two. Covering 183 square degrees, Canis Minor ranks seventy-first of the 88 constellations in size. It appears prominently in the southern sky during the Northern Hemisphere's winter. The constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of 14 sides. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 07h 06.4m and 08h 11.4m, while the declination coordinates are between \u00b0 and \u00b0. Most visible in the evening sky from January to March, Canis Minor is most prominent at 10 p.m. during mid-February. It is then seen earlier in the evening until July, when it is only visible after sunset before setting itself, and rising in the morning sky before dawn. The constellation's three-letter abbreviation, as adopted by the International Astronomical Union in 1922, is \"CMi\".\nFeatures.\nStars.\nCanis Minor contains only two stars brighter than fourth magnitude. At magnitude 0.34, Procyon, or Alpha Canis Minoris, is the eighth-brightest star in the night sky, as well as one of the closest. Its name means \"before the dog\" or \"preceding the dog\" in Greek, as it rises an hour before the \"Dog Star\", Sirius, of Canis Major. It is a binary star system, consisting of a yellow-white main-sequence star of spectral type F5\u00a0IV-V, named Procyon\u00a0A, and a faint white dwarf companion of spectral type DA, named Procyon\u00a0B. Procyon\u00a0B, which orbits the more massive star every 41 years, is of magnitude 10.7. Procyon\u00a0A is 1.4 times the Sun's mass, while its smaller companion is 0.6 times as massive as the Sun. The system is from Earth, the shortest distance to a northern-hemisphere star of the first magnitude. Gomeisa, or Beta Canis Minoris, with a magnitude of 2.89, is the second-brightest star in Canis Minor. Lying from the Solar System, it is a blue-white main-sequence star of spectral class B8\u00a0Ve. Although fainter to Earth observers, it is much brighter than Procyon, and is 250 times as luminous and three times as massive as the Sun. Although its variations are slight, Gomeisa is classified as a shell star (Gamma Cassiopeiae variable), with a maximum magnitude of 2.84 and a minimum magnitude of 2.92. It is surrounded by a disk of gas which it heats and causes to emit radiation.\nJohann Bayer used the Greek letters Alpha to Eta to label the most prominent eight stars in the constellation, designating two stars as Delta (named Delta1 and Delta2). John Flamsteed numbered fourteen stars, discerning a third star he named Delta3; his star 12 Canis Minoris was not found subsequently. In Bayer's 1603 work \"Uranometria\", Procyon is located on the dog's belly, and Gomeisa on its neck. Gamma, Epsilon and Eta Canis Minoris lie nearby, marking the dog's neck, crown and chest, respectively. Although it has an apparent magnitude of 4.34, Gamma Canis Minoris is an orange K-type giant of spectral class K3-III C, which lies away. Its colour is obvious when seen through binoculars. It is a multiple system, consisting of the spectroscopic binary Gamma A and three optical companions, Gamma B, magnitude 13; Gamma C, magnitude 12; and Gamma D, magnitude 10. The two components of Gamma A orbit each other every 389.2 days, with an eccentric orbit that takes their separation between 2.3 and 1.4 astronomical units (AU). Epsilon Canis Minoris is a yellow bright giant of spectral class G6.5IIb of magnitude of 4.99. It lies from Earth, with 13 times the diameter and 750 times the luminosity of the Sun. Eta Canis Minoris is a giant of spectral class F0III of magnitude 5.24, which has a yellowish hue when viewed through binoculars as well as a faint companion of magnitude 11.1. Located 4 arcseconds from the primary, the companion star is actually around 440 AU from the main star and takes around 5,000 years to orbit it.\nNear Procyon, three stars share the name Delta Canis Minoris. Delta1 is a yellow-white F-type giant of magnitude 5.25 located around from Earth. About 360 times as luminous and 3.75 times as massive as the Sun, it is expanding and cooling as it ages, having spent much of its life as a main sequence star of spectrum B6V. Also known as 8 Canis Minoris, Delta2 is an F-type main-sequence star of spectral type F2V and magnitude 5.59 which is distant. The last of the trio, Delta3 (also known as 9 Canis Minoris), is a white main sequence star of spectral type A0Vnn and magnitude 5.83 which is distant. These stars mark the paws of the Lesser Dog's left hind leg, while magnitude 5.13 Zeta marks the right. A blue-white bright giant of spectral type B8II, Zeta lies around away from the Solar System.\nLying 222 \u00b1 7 light-years away with an apparent magnitude of 4.39, HD 66141 is 6.8\u00a0billion years old and has evolved into an orange giant of spectral type K2III with a diameter around 22 times that of the Sun, and weighing 1.1 solar masses. It is 174 times as luminous as the Sun, with an absolute magnitude of \u22120.15. HD 66141 was mistakenly named 13 Puppis, as its celestial coordinates were recorded incorrectly when catalogued and hence mistakenly thought to be in the constellation of Puppis; Bode gave it the name Lambda Canis Minoris, which is now obsolete. The orange giant is orbited by a planet, HD 66141b, which was detected in 2012 by measuring the star's radial velocity. The planet has a mass around 6 times that of Jupiter and a period of 480 days.\nA red giant of spectral type M4III, BC Canis Minoris lies around distant from the Solar System. It is a semiregular variable star that varies between a maximum magnitude of 6.14 and minimum magnitude of 6.42. Periods of 27.7, 143.3 and 208.3 days have been recorded in its pulsations. AZ, AD and BI Canis Minoris are Delta Scuti variables\u2014short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. AZ is of spectral type A5IV, and ranges between magnitudes 6.44 and 6.51 over a period of 2.3 hours. AD has a spectral type of F2III, and has a maximum magnitude of 9.21 and minimum of 9.51, with a period of approximately 2.95 hours. BI is of spectral type F2 with an apparent magnitude varying around 9.19 and a period of approximately 2.91 hours.\nAt least three red giants are Mira variables in Canis Minor. S Canis Minoris, of spectral type M7e, is the brightest, ranging from magnitude 6.6 to 13.2 over a period of 332.94 days. V Canis Minoris ranges from magnitude 7.4 to 15.1 over a period of 366.1 days. Similar in magnitude is R Canis Minoris, which has a maximum of 7.3, but a significantly brighter minimum of 11.6. An S-type star, it has a period of 337.8 days.\nYZ Canis Minoris is a red dwarf of spectral type M4.5V and magnitude 11.2, roughly three times the size of Jupiter and from Earth. It is a flare star, emitting unpredictable outbursts of energy for mere minutes, which might be much more powerful analogues of solar flares. Luyten's Star (GJ 273) is a red dwarf star of spectral type M3.5V and close neighbour of the Solar System. Its visual magnitude of 9.9 renders it too faint to be seen with the naked eye, even though it is only away. Fainter still is PSS 544-7, an eighteenth-magnitude red dwarf around 20 percent the mass of the Sun, located from Earth. First noticed in 1991, it is thought to be a cannonball star, shot out of a star cluster and now moving rapidly through space directly away from the galactic disc.\nThe WZ Sagittae-type dwarf nova DY Canis Minoris (also known as VSX J074727.6+065050) flared up to magnitude 11.4 over January and February 2008 before dropping eight magnitudes to around 19.5 over approximately 80 days. It is a remote binary star system where a white dwarf and low-mass star orbit each other close enough for the former star to draw material off the latter and form an accretion disc. This material builds up until it erupts dramatically.\nDeep-sky objects.\nThe Milky Way passes through much of Canis Minor, yet it has few deep-sky objects. William Herschel recorded four objects in his 1786 work \"Catalogue of Nebulae and Clusters of Stars\", including two he mistakenly believed were star clusters. NGC 2459 is a group of five thirteenth- and fourteenth-magnitude stars that appear to lie close together in the sky but are not related. A similar situation has occurred with NGC 2394, also in Canis Minor. This is a collection of fifteen unrelated stars of ninth magnitude and fainter.\nHerschel also observed three faint galaxies, two of which are interacting with each other. NGC 2508 is a lenticular galaxy of thirteenth magnitude, estimated at 205 million light-years' distance (63 million parsecs) with a diameter of . Named as a single object by Herschel, NGC 2402 is actually a pair of near-adjacent galaxies that appear to be interacting with each other. Only of fourteenth and fifteenth magnitudes, respectively, the elliptical and spiral galaxy are thought to be approximately 245\u00a0million light-years distant, and each measure 55,000 light-years in diameter.\nMeteor showers.\nThe 11 Canis-Minorids, also called the Beta Canis Minorids, are a meteor shower that arise near the fifth-magnitude star 11 Canis Minoris and were discovered in 1964 by Keith Hindley, who investigated their trajectory and proposed a common origin with the comet D/1917 F1 Mellish. However, this conclusion has been refuted subsequently as the number of orbits analysed was low and their trajectories too disparate to confirm a link. They last from 4 to 15 December, peaking over 10 and 11 December.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;de=&amp;zoom=&amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 08h 00m 00s, +05\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6368", "revid": "22041646", "url": "https://en.wikipedia.org/wiki?curid=6368", "title": "Choshu", "text": ""}
{"id": "6371", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6371", "title": "Centaurus", "text": "Constellation in the southern celestial hemisphere\nCentaurus is a bright constellation in the southern sky. One of the largest constellations, Centaurus was included among the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations. In Greek mythology, Centaurus represents a centaur; a creature that is half human, half horse (another constellation named after a centaur is one from the zodiac: Sagittarius). Notable stars include Alpha Centauri, the nearest star system to the Solar System, its neighbour in the sky Beta Centauri, and V766 Centauri, one of the largest stars yet discovered. The constellation also contains Omega Centauri, the brightest globular cluster as visible from Earth and the largest identified in the Milky Way, possibly a remnant of a dwarf galaxy.\nNotable features.\nStars.\nCentaurus contains several very bright stars. Its alpha and beta stars are used as \"pointer stars\" to help observers find the constellation Crux. Centaurus has 281 stars above magnitude 6.5, meaning that they are visible to the unaided eye, the most of any constellation. Alpha Centauri, the closest star system to the Sun, has a high proper motion; it will be a mere half-degree from Beta Centauri in approximately 4000 years.\nAlpha Centauri is a triple star system composed of a binary system orbited by Proxima Centauri, currently the nearest star to the Sun. Traditionally called Rigil Kentaurus (from Arabic \u0631\u062c\u0644 \u0642\u0646\u0637\u0648\u0631\u0633, meaning \"foot of the centaur\") or Toliman (from Arabic \u0627\u0644\u0638\u0644\u064a\u0645\u064a\u0646 meaning \"two male ostriches\"), the system has an overall magnitude of \u22120.28 and is 4.4 light-years from Earth. The primary and secondary are both yellow-hued stars; the first is of magnitude \u22120.01 and the second: 1.35. Proxima, the tertiary star, is a red dwarf of magnitude 11.0; it appears almost 2 degrees away from the close pairing of Alpha and has a period of approximately one million years. Also a flare star, Proxima has minutes-long outbursts where it brightens by over a magnitude. The Alpha couple revolve in 80-year periodicity and will next appear closest as seen from Earth's telescopes in 2037 and 2038, together as they appear to the naked eye they present the third-brightest \"star\" in the night sky.\nOne other first magnitude star Beta Centauri is in the constellation in a position beyond Proxima and toward the narrow axis of Crux, thus with Alpha forming a far-south limb of the constellation. Also called Hadar and Agena, it is a double star; the primary is a blue-hued giant star of magnitude 0.6, 525 light-years from Earth. The secondary is of magnitude 4.0 and has a modest separation, appearing only under intense magnification due to its distance.\nThe northerly star Theta Centauri, officially named Menkent, is an orange giant star of magnitude 2.06. It is the only bright star of Centaurus that is easily visible from mid-northern latitudes.\nThe next bright object is Gamma Centauri, a binary star which appears to the naked eye at magnitude 2.2. The primary and secondary are both blue-white hued stars of magnitude 2.9; their period is 84 years.\nCentaurus also has many dimmer double stars and binary stars. 3 Centauri is a double star with a blue-white hued primary of magnitude 4.5 and a secondary of magnitude 6.0. The primary is 344 light-years away.\nCentaurus is home to many variable stars. R Centauri is a Mira variable star with a minimum magnitude of 11.8 and a maximum magnitude of 5.3; it is about 1,250 light-years from Earth and has a period of 18 months. V810 Centauri is a semiregular variable.\nBPM 37093 is a white dwarf star whose carbon atoms are thought to have formed a crystalline structure. Since diamond also consists of carbon arranged in a crystalline lattice (though of a different configuration), scientists have nicknamed this star \"Lucy\" after the Beatles song \"\"Lucy in the Sky with Diamonds\".\"\nPDS 70, (V1032 Centauri) a low mass T Tauri star is found in the constellation Centaurus. In July 2018 astronomers captured the first conclusive image of a protoplanetary disk containing a nascent exoplanet, named PDS 70b.\nDeep-sky objects.\n\u03c9 Centauri (NGC 5139), despite being listed as the constellation's \"omega\" star, is in fact a naked-eye globular cluster, 17,000 light-years away with a diameter of 150 light-years. It is the largest and brightest globular cluster in the Milky Way; at ten times the size of the next-largest cluster, it has a magnitude of 3.7. It is also the most luminous globular cluster in the Milky Way, at over one million solar luminosities. Omega Centauri is classified as a Shapley class VIII cluster, which means that its center is loosely concentrated. It is also the only globular cluster to be designated with a Bayer letter; the globular cluster 47 Tucanae is the only one designated with a Flamsteed number. It contains several million stars, most of which are yellow dwarf stars, but also possesses red giants and blue-white stars; the stars have an average age of 12 billion years. This has prompted suspicion that Omega Centauri was the core of a dwarf galaxy that had been absorbed by the Milky Way. Omega Centauri was determined to be nonstellar in 1677 by the English astronomer Edmond Halley, though it was visible as a star to the ancients. Its status as a globular cluster was determined by James Dunlop in 1827. To the unaided eye, Omega Centauri appears fuzzy and is obviously non-circular; it is approximately half a degree in diameter, the same size as the full Moon.\nCentaurus is also home to open clusters. NGC 3766 is an open cluster 6,300 light-years from Earth that is visible to the unaided eye. It contains approximately 100 stars, the brightest of which are 7th magnitude. NGC 5460 is another naked-eye open cluster, 2,300 light-years from Earth, that has an overall magnitude of 6 and contains approximately 40 stars.\nThere is one bright planetary nebula in Centaurus, NGC 3918, also known as the Blue Planetary. It has an overall magnitude of 8.0 and a central star of magnitude 11.0; it is 2600 light-years from Earth. The Blue Planetary was discovered by John Herschel and named for its color's similarity to Uranus, though the nebula is apparently three times larger than the planet.\nCentaurus is rich in galaxies as well. NGC 4622 is a face-on spiral galaxy located 200 million light-years from Earth (redshift 0.0146). Its spiral arms wind in both directions, which makes it nearly impossible for astronomers to determine the rotation of the galaxy. Astronomers theorize that a collision with a smaller companion galaxy near the core of the main galaxy could have led to the unusual spiral structure. NGC 5253, a peculiar irregular galaxy, is located near the border with Hydra and M83, with which it likely had a close gravitational interaction 1\u20132 billion years ago. This may have sparked the galaxy's high rate of star formation, which continues today and contributes to its high surface brightness. NGC 5253 includes a large nebula and at least 12 large star clusters. In the eyepiece, it is a small galaxy of magnitude 10 with dimensions of 5 arcminutes by 2 arcminutes and a bright nucleus. NGC 4945 is a spiral galaxy seen edge-on from Earth, 13 million light-years away. It is visible with any amateur telescope, as well as binoculars under good conditions; it has been described as \"shaped like a candle flame\", being long and thin (16' by 3'). In the eyepiece of a large telescope, its southeastern dust lane becomes visible. Another galaxy is NGC 5102, found by star-hopping from Iota Centauri. In the eyepiece, it appears as an elliptical object 9 arcminutes by 2.5 arcminutes tilted on a southwest-northeast axis.\nOne of the closest active galaxies to Earth is the Centaurus A galaxy, NGC 5128, at 11 million light-years away (redshift 0.00183). It has a supermassive black hole at its core, which expels massive jets of matter that emit radio waves due to synchrotron radiation. Astronomers posit that its dust lanes, not common in elliptical galaxies, are due to a previous merger with another galaxy, probably a spiral galaxy. NGC 5128 appears in the optical spectrum as a fairly large elliptical galaxy with a prominent dust lane. Its overall magnitude is 7.0 and it has been seen under perfect conditions with the naked eye, making it one of the most distant objects visible to the unaided observer. In equatorial and southern latitudes, it is easily found by star hopping from Omega Centauri. In small telescopes, the dust lane is not visible; it begins to appear with about 4 inches of aperture under good conditions. In large amateur instruments, above about 12 inches in aperture, the dust lane's west-northwest to east-southeast direction is easily discerned. Another dim dust lane on the east side of the 12-arcminute-by-15-arcminute galaxy is also visible. ESO 270-17, also called the Fourcade-Figueroa Object, is a low-surface brightness object believed to be the remnants of a galaxy; it does not have a core and is very difficult to observe with an amateur telescope. It measures 7 arcminutes by 1 arcminute. It likely originated as a spiral galaxy and underwent a catastrophic gravitational interaction with Centaurus A around 500 million years ago, stopping its rotation and destroying its structure.\nNGC 4650A is a polar-ring galaxy 136 million light-years from Earth (redshift 0.01). It has a central core made of older stars that resembles an elliptical galaxy, and an outer ring of young stars that orbits around the core. The plane of the outer ring is distorted, which suggests that NGC 4650A is the result of a galaxy collision about a billion years ago. This galaxy has also been cited in studies of dark matter, because the stars in the outer ring orbit too quickly for their collective mass. This suggests that the galaxy is surrounded by a dark matter halo, which provides the necessary mass.\nOne of the closest galaxy clusters to Earth is the Centaurus Cluster at c. 160 million light-years away, having redshift 0.0114. It has a cooler, denser central region of gas and a hotter, more diffuse outer region. The intracluster medium in the Centaurus Cluster has a high concentration of metals (elements heavier than helium) due to a large number of supernovae. This cluster also possesses a plume of gas whose origin is unknown.\nHistory.\nWhile Centaurus now has a high southern latitude, at the dawn of civilization it was an equatorial constellation. Precession has been slowly shifting it southward for millennia, and it is now close to its maximal southern declination. In a little over 7000 years it will be at maximum visibility for those in the northern hemisphere, visible at times in the year up to quite a high northern latitude.\nThe figure of Centaurus can be traced back to a Babylonian constellation known as the Bison-man (MUL.GUD.ALIM). This being was depicted in two major forms: firstly, as a 4-legged bison with a human head, and secondly, as a being with a man's head and torso attached to the rear legs and tail of a bull or bison. It has been closely associated with the Sun god Utu-Shamash from very early times.\nThe Greeks depicted the constellation as a centaur and gave it its current name. It was mentioned by Eudoxus in the 4th century BC and Aratus in the 3rd century BC. In the 2nd century AD, Claudius Ptolemy catalogued 37 stars in Centaurus, including Alpha Centauri. Large as it is now, in earlier times it was even larger, as the constellation Lupus was treated as an asterism within Centaurus, portrayed in illustrations as an unspecified animal either in the centaur's grasp or impaled on its spear. The Southern Cross, which is now regarded as a separate constellation, was treated by the ancients as a mere asterism formed of the stars composing the centaur's legs. Additionally, what is now the minor constellation Circinus was treated as undefined stars under the centaur's front hooves.\nAccording to the Roman poet Ovid (\"Fasti\" v.379), the constellation honors the centaur Chiron, who was tutor to many of the earlier Greek heroes including Heracles (Hercules), Theseus, and Jason, the leader of the Argonauts. It is not to be confused with the more warlike centaur represented by the zodiacal constellation Sagittarius. The legend associated with Chiron says that he was accidentally poisoned with an arrow shot by Hercules, and was subsequently placed in the heavens.\nEquivalents.\nIn Chinese astronomy, the stars of Centaurus are found in three areas: the Azure Dragon of the East (\u6771\u65b9\u9752\u9f8d, \"D\u014dng F\u0101ng Q\u012bng L\u00f3ng\"), the Vermillion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"), and the Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\"). Not all of the stars of Centaurus can be seen from China, and the unseen stars were classified among the Southern Asterisms by Xu Guangqi, based on his study of western star charts. However, most of the brightest stars of Centaurus, including \u03b1 Centauri, \u03b8 Centauri (or Menkent), \u03b5 Centauri and \u03b7 Centauri, can be seen in the Chinese sky.\nSome Polynesian peoples considered the stars of Centaurus to be a constellation as well. On Pukapuka, Centaurus had two names: \"Na Mata-o-te-tokolua\" and \"Na Lua-mata-o-Wua-ma-Velo\". In Tonga, the constellation was called by four names: \"O-nga-tangata\", \"Tautanga-ufi\", \"Mamangi-Halahu\", and \"Mau-kuo-mau\". Alpha and Beta Centauri were not named specifically by the people of Pukapuka or Tonga, but they were named by the people of Hawaii and the Tuamotus. In Hawaii, the name for Alpha Centauri was either \"Melemele\" or \"Ka Maile-hope\" and the name for Beta Centauri was either \"Polapola\" or \"Ka Maile-mua\". In the Tuamotu islands, Alpha was called \"Na Kuhi\" and Beta was called \"Tere\".\nThe Pointer (\u03b1 Centauri and \u03b2 Centauri) is one of the asterisms used by Bugis sailors for navigation, called \"binto\u00e9ng balu\u00e9\", meaning \"the widowed-before-marriage\". It is also called \"binto\u00e9ng sallatang\" meaning \"southern star\".\nNamesakes.\nTwo United States Navy ships, and , were named after Centaurus, the constellation.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 13h 00m 00s, \u221250\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6416", "revid": "1154172615", "url": "https://en.wikipedia.org/wiki?curid=6416", "title": "Impact crater", "text": "Circular depression in a solid astronomical body formed by the impact of a smaller object\nAn impact crater is a circular depression in the surface of a solid astronomical object formed by the hypervelocity impact of a smaller object. In contrast to volcanic craters, which result from explosion or internal collapse, impact craters typically have raised rims and floors that are lower in elevation than the surrounding terrain. Lunar impact craters range from microscopic craters on lunar rocks returned by the Apollo program and small, simple, bowl-shaped depressions in the lunar regolith to large, complex, multi-ringed impact basins. Meteor Crater is a well-known example of a small impact crater on Earth.\nImpact craters are the dominant geographic features on many solid Solar System objects including the Moon, Mercury, Callisto, Ganymede and most small moons and asteroids. On other planets and moons that experience more active surface geological processes, such as Earth, Venus, Europa, Io and Titan, visible impact craters are less common because they become eroded, buried or transformed by tectonics over time. Where such processes have destroyed most of the original crater topography, the terms impact structure or astrobleme are more commonly used. In early literature, before the significance of impact cratering was widely recognised, the terms cryptoexplosion or cryptovolcanic structure were often used to describe what are now recognised as impact-related features on Earth.\nThe cratering records of very old surfaces, such as Mercury, the Moon, and the southern highlands of Mars, record a period of intense early bombardment in the inner Solar System around 3.9 billion years ago. The rate of crater production on Earth has since been considerably lower, but it is appreciable nonetheless. Earth experiences, on average, from one to three impacts large enough to produce a crater every million years. This indicates that there should be far more relatively young craters on the planet than have been discovered so far. The cratering rate in the inner solar system fluctuates as a consequence of collisions in the asteroid belt that create a family of fragments that are often sent cascading into the inner solar system. Formed in a collision 80 million years ago, the Baptistina family of asteroids is thought to have caused a large spike in the impact rate. The rate of impact cratering in the outer Solar System could be different from the inner Solar System.\nAlthough Earth's active surface processes quickly destroy the impact record, about 190 terrestrial impact craters have been identified. These range in diameter from a few tens of meters up to about , and they range in age from recent times (e.g. the Sikhote-Alin craters in Russia whose creation was witnessed in 1947) to more than two billion years, though most are less than 500 million years old because geological processes tend to obliterate older craters. They are also selectively found in the stable interior regions of continents. Few undersea craters have been discovered because of the difficulty of surveying the sea floor, the rapid rate of change of the ocean bottom, and the subduction of the ocean floor into Earth's interior by processes of plate tectonics.\nImpact craters are not to be confused with landforms that may appear similar, including calderas, sinkholes, glacial cirques, ring dikes, salt domes, and others.\nHistory.\nDaniel M. Barringer, a mining engineer, was convinced already in 1903 that the crater he owned, Meteor Crater, was of cosmic origin. Most geologists at the time assumed it formed as the result of a volcanic steam eruption.\nIn the 1920s, the American geologist Walter H. Bucher studied a number of sites now recognized as impact craters in the United States. He concluded they had been created by some great explosive event, but believed that this force was probably volcanic in origin. However, in 1936, the geologists John D. Boon and Claude C. Albritton Jr. revisited Bucher's studies and concluded that the craters that he studied were probably formed by impacts.\nGrove Karl Gilbert suggested in 1893 that the Moon's craters were formed by large asteroid impacts. Ralph Baldwin in 1949 wrote that the Moon's craters were mostly of impact origin. Around 1960, Gene Shoemaker revived the idea. According to David H. Levy, Shoemaker \"saw the craters on the Moon as logical impact sites that were formed not gradually, in eons, but explosively, in seconds.\" For his Ph.D. degree at Princeton University (1960), under the guidance of Harry Hammond Hess, Shoemaker studied the impact dynamics of Meteor Crater. Shoemaker noted that Meteor Crater had the same form and structure as two explosion craters created from atomic bomb tests at the Nevada Test Site, notably Jangle U in 1951 and Teapot Ess in 1955. In 1960, Edward C. T. Chao and Shoemaker identified coesite (a form of silicon dioxide) at Meteor Crater, proving the crater was formed from an impact generating extremely high temperatures and pressures. They followed this discovery with the identification of coesite within suevite at N\u00f6rdlinger Ries, proving its impact origin.\nArmed with the knowledge of shock-metamorphic features, Carlyle S. Beals and colleagues at the Dominion Astrophysical Observatory in Victoria, British Columbia, Canada and Wolf von Engelhardt of the University of T\u00fcbingen in Germany began a methodical search for impact craters. By 1970, they had tentatively identified more than 50. Although their work was controversial, the American Apollo Moon landings, which were in progress at the time, provided supportive evidence by recognizing the rate of impact cratering on the Moon. Because the processes of erosion on the Moon are minimal, craters persist. Since the Earth could be expected to have roughly the same cratering rate as the Moon, it became clear that the Earth had suffered far more impacts than could be seen by counting evident craters.\nCrater formation.\nImpact cratering involves high velocity collisions between solid objects, typically much greater than the speed of sound in those objects. Such hyper-velocity impacts produce physical effects such as melting and vaporization that do not occur in familiar sub-sonic collisions. On Earth, ignoring the slowing effects of travel through the atmosphere, the lowest impact velocity with an object from space is equal to the gravitational escape velocity of about 11\u00a0km/s. The fastest impacts occur at about 72\u00a0km/s in the \"worst case\" scenario in which an object in a retrograde near-parabolic orbit hits Earth. The median impact velocity on Earth is about 20\u00a0km/s.\nHowever, the slowing effects of travel through the atmosphere rapidly decelerate any potential impactor, especially in the lowest 12 kilometres where 90% of the earth's atmospheric mass lies. Meteorites of up to 7,000\u00a0kg lose all their cosmic velocity due to atmospheric drag at a certain altitude (retardation point), and start to accelerate again due to Earth's gravity until the body reaches its terminal velocity of 0.09 to 0.16\u00a0km/s. The larger the meteoroid (i.e. asteroids and comets) the more of its initial cosmic velocity it preserves. While an object of 9,000\u00a0kg maintains about 6% of its original velocity, one of 900,000\u00a0kg already preserves about 70%. Extremely large bodies (about 100,000 tonnes) are not slowed by the atmosphere at all, and impact with their initial cosmic velocity if no prior disintegration occurs.\nImpacts at these high speeds produce shock waves in solid materials, and both impactor and the material impacted are rapidly compressed to high density. Following initial compression, the high-density, over-compressed region rapidly depressurizes, exploding violently, to set in train the sequence of events that produces the impact crater. Impact-crater formation is therefore more closely analogous to cratering by high explosives than by mechanical displacement. Indeed, the energy density of some material involved in the formation of impact craters is many times higher than that generated by high explosives. Since craters are caused by explosions, they are nearly always circular \u2013 only very low-angle impacts cause significantly elliptical craters.\nThis describes impacts on solid surfaces. Impacts on porous surfaces, such as that of Hyperion, may produce internal compression without ejecta, punching a hole in the surface without filling in nearby craters. This may explain the 'sponge-like' appearance of that moon.\nIt is convenient to divide the impact process conceptually into three distinct stages: (1) initial contact and compression, (2) excavation, (3) modification and collapse. In practice, there is overlap between the three processes with, for example, the excavation of the crater continuing in some regions while modification and collapse is already underway in others.\nContact and compression.\nIn the absence of atmosphere, the impact process begins when the impactor first touches the target surface. This contact accelerates the target and decelerates the impactor. Because the impactor is moving so rapidly, the rear of the object moves a significant distance during the short-but-finite time taken for the deceleration to propagate across the impactor. As a result, the impactor is compressed, its density rises, and the pressure within it increases dramatically. Peak pressures in large impacts exceed 1 TPa to reach values more usually found deep in the interiors of planets, or generated artificially in nuclear explosions.\nIn physical terms, a shock wave originates from the point of contact. As this shock wave expands, it decelerates and compresses the impactor, and it accelerates and compresses the target. Stress levels within the shock wave far exceed the strength of solid materials; consequently, both the impactor and the target close to the impact site are irreversibly damaged. Many crystalline minerals can be transformed into higher-density phases by shock waves; for example, the common mineral quartz can be transformed into the higher-pressure forms coesite and stishovite. Many other shock-related changes take place within both impactor and target as the shock wave passes through, and some of these changes can be used as diagnostic tools to determine whether particular geological features were produced by impact cratering.\nAs the shock wave decays, the shocked region decompresses towards more usual pressures and densities. The damage produced by the shock wave raises the temperature of the material. In all but the smallest impacts this increase in temperature is sufficient to melt the impactor, and in larger impacts to vaporize most of it and to melt large volumes of the target. As well as being heated, the target near the impact is accelerated by the shock wave, and it continues moving away from the impact behind the decaying shock wave.\nExcavation.\nContact, compression, decompression, and the passage of the shock wave all occur within a few tenths of a second for a large impact. The subsequent excavation of the crater occurs more slowly, and during this stage the flow of material is largely subsonic. During excavation, the crater grows as the accelerated target material moves away from the point of impact. The target's motion is initially downwards and outwards, but it becomes outwards and upwards. The flow initially produces an approximately hemispherical cavity that continues to grow, eventually producing a paraboloid (bowl-shaped) crater in which the centre has been pushed down, a significant volume of material has been ejected, and a topographically elevated crater rim has been pushed up. When this cavity has reached its maximum size, it is called the transient cavity.\nThe depth of the transient cavity is typically a quarter to a third of its diameter. Ejecta thrown out of the crater do not include material excavated from the full depth of the transient cavity; typically the depth of maximum excavation is only about a third of the total depth. As a result, about one third of the volume of the transient crater is formed by the ejection of material, and the remaining two thirds is formed by the displacement of material downwards, outwards and upwards, to form the elevated rim. For impacts into highly porous materials, a significant crater volume may also be formed by the permanent compaction of the pore space. Such compaction craters may be important on many asteroids, comets and small moons.\nIn large impacts, as well as material displaced and ejected to form the crater, significant volumes of target material may be melted and vaporized together with the original impactor. Some of this impact melt rock may be ejected, but most of it remains within the transient crater, initially forming a layer of impact melt coating the interior of the transient cavity. In contrast, the hot dense vaporized material expands rapidly out of the growing cavity, carrying some solid and molten material within it as it does so. As this hot vapor cloud expands, it rises and cools much like the archetypal mushroom cloud generated by large nuclear explosions. In large impacts, the expanding vapor cloud may rise to many times the scale height of the atmosphere, effectively expanding into free space.\nMost material ejected from the crater is deposited within a few crater radii, but a small fraction may travel large distances at high velocity, and in large impacts it may exceed escape velocity and leave the impacted planet or moon entirely. The majority of the fastest material is ejected from close to the center of impact, and the slowest material is ejected close to the rim at low velocities to form an overturned coherent flap of ejecta immediately outside the rim. As ejecta escapes from the growing crater, it forms an expanding curtain in the shape of an inverted cone. The trajectory of individual particles within the curtain is thought to be largely ballistic.\nSmall volumes of un-melted and relatively un-shocked material may be spalled at very high relative velocities from the surface of the target and from the rear of the impactor. Spalling provides a potential mechanism whereby material may be ejected into inter-planetary space largely undamaged, and whereby small volumes of the impactor may be preserved undamaged even in large impacts. Small volumes of high-speed material may also be generated early in the impact by jetting. This occurs when two surfaces converge rapidly and obliquely at a small angle, and high-temperature highly shocked material is expelled from the convergence zone with velocities that may be several times larger than the impact velocity.\nModification and collapse.\nIn most circumstances, the transient cavity is not stable and collapses under gravity. In small craters, less than about 4\u00a0km diameter on Earth, there is some limited collapse of the crater rim coupled with debris sliding down the crater walls and drainage of impact melts into the deeper cavity. The resultant structure is called a simple crater, and it remains bowl-shaped and superficially similar to the transient crater. In simple craters, the original excavation cavity is overlain by a lens of collapse breccia, ejecta and melt rock, and a portion of the central crater floor may sometimes be flat.\nAbove a certain threshold size, which varies with planetary gravity, the collapse and modification of the transient cavity is much more extensive, and the resulting structure is called a complex crater. The collapse of the transient cavity is driven by gravity, and involves both the uplift of the central region and the inward collapse of the rim. The central uplift is not the result of elastic rebound, which is a process in which a material with elastic strength attempts to return to its original geometry; rather the collapse is a process in which a material with little or no strength attempts to return to a state of gravitational equilibrium.\nComplex craters have uplifted centers, and they have typically broad flat shallow crater floors, and terraced walls. At the largest sizes, one or more exterior or interior rings may appear, and the structure may be labeled an impact basin rather than an impact crater. Complex-crater morphology on rocky planets appears to follow a regular sequence with increasing size: small complex craters with a central topographic peak are called central peak craters, for example Tycho; intermediate-sized craters, in which the central peak is replaced by a ring of peaks, are called peak-ring craters, for example Schr\u00f6dinger; and the largest craters contain multiple concentric topographic rings, and are called multi-ringed basins, for example Orientale. On icy (as opposed to rocky) bodies, other morphological forms appear that may have central pits rather than central peaks, and at the largest sizes may contain many concentric rings. Valhalla on Callisto is an example of this type.\nIdentifying impact craters.\nNon-explosive volcanic craters can usually be distinguished from impact craters by their irregular shape and the association of volcanic flows and other volcanic materials. Impact craters produce melted rocks as well, but usually in smaller volumes with different characteristics.\nThe distinctive mark of an impact crater is the presence of rock that has undergone shock-metamorphic effects, such as shatter cones, melted rocks, and crystal deformations. The problem is that these materials tend to be deeply buried, at least for simple craters. They tend to be revealed in the uplifted center of a complex crater, however.\nImpacts produce distinctive shock-metamorphic effects that allow impact sites to be distinctively identified. Such shock-metamorphic effects can include:\nEconomic importance of impacts.\nOn Earth impact craters have resulted in useful minerals. Some of the ores produced from impact related effects on Earth include ores of iron, uranium, gold, copper, and nickel. It is estimated that the value of materials mined from impact structures is five billion dollars/year just for North America. The eventual usefulness of impact craters depends on several factors especially the nature of the materials that were impacted and when the materials were affected. In some cases the deposits were already in place and the impact brought them to the surface. These are called \"progenetic economic deposits.\" Others were created during the actual impact. The great energy involved caused melting. Useful minerals formed as a result of this energy are classified as \"syngenetic deposits.\" The third type, called \"epigenetic deposits,\" is caused by the creation of a basin from the impact. Many of the minerals that our modern lives depend on are associated with impacts in the past. The Vredeford Dome in the center of the Witwatersrand Basin is the largest goldfield in the world which has supplied about 40% of all the gold ever mined in an impact structure (though the gold did not come from the bolide). The asteroid that struck the region was wide. The Sudbury Basin was caused by an impacting body over in diameter. This basin is famous for its deposits of nickel, copper, and platinum group elements. An impact was involved in making the Carswell structure in Saskatchewan, Canada; it contains uranium deposits.\nHydrocarbons are common around impact structures. Fifty percent of impact structures in North America in hydrocarbon-bearing sedimentary basins contain oil/gas fields.\nMartian craters.\nBecause of the many missions studying Mars since the 1960s, there is good coverage of its surface which contains large numbers of craters. Many of the craters on Mars differ from those on the Moon and other moons since Mars contains ice under the ground, especially in the higher latitudes. Some of the types of craters that have special shapes due to impact into ice-rich ground are pedestal craters, rampart craters, expanded craters, and LARLE craters.\nLists of craters.\nImpact craters on Earth.\nOn Earth, the recognition of impact craters is a branch of geology, and is related to planetary geology in the study of other worlds. Out of many proposed craters, relatively few are confirmed. The following twenty are a sample of articles of confirmed and well-documented impact sites.\nSee the Earth Impact Database, a website concerned with 190 (as of \u00a02019[ [update]]) scientifically-confirmed impact craters on Earth.\nLargest named craters in the Solar System.\nThere are approximately twelve more impact craters/basins larger than 300\u00a0km on the Moon, five on Mercury, and four on Mars. Large basins, some unnamed but mostly smaller than 300\u00a0km, can also be found on Saturn's moons Dione, Rhea and Iapetus.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6417", "revid": "29278485", "url": "https://en.wikipedia.org/wiki?curid=6417", "title": "Corvus (disambiguation)", "text": "Corvus is a genus of birds commonly known as crows and ravens.\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nCorvus may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "6420", "revid": "15885572", "url": "https://en.wikipedia.org/wiki?curid=6420", "title": "Corona Borealis", "text": "Constellation in the northern celestial hemisphere\nCorona Borealis is a small constellation in the Northern Celestial Hemisphere. It is one of the 48\u00a0constellations listed by the 2nd-century astronomer Ptolemy, and remains one of the 88 modern constellations. Its brightest stars form a semicircular arc. Its Latin name, inspired by its shape, means \"northern crown\". In classical mythology Corona Borealis generally represented the crown given by the god Dionysus to the Cretan princess Ariadne and set by her in the heavens. Other cultures likened the pattern to a circle of elders, an eagle's nest, a bear's den or a smokehole. Ptolemy also listed a southern counterpart, Corona Australis, with a similar pattern.\nThe brightest star is the magnitude\u00a02.2 Alpha Coronae Borealis. The yellow supergiant R Coronae Borealis is the prototype of a rare class of giant stars\u2014the R Coronae Borealis variables\u2014that are extremely hydrogen deficient, and thought to result from the merger of two white dwarfs. T Coronae Borealis, also known as the Blaze Star, is another unusual type of variable star known as a recurrent nova. Normally of magnitude\u00a010, it last flared up to magnitude\u00a02 in 1946. ADS 9731 and Sigma Coronae Borealis are multiple star systems with six and five components respectively. Five star systems have been found to have Jupiter-sized exoplanets. Abell 2065 is a highly concentrated galaxy cluster one billion light-years from the Solar System containing more than 400 members, and is itself part of the larger Corona Borealis Supercluster.\nCharacteristics.\nCovering 179 square degrees and hence 0.433% of the sky, Corona Borealis ranks 73rd of the 88 modern constellations by area. Its position in the Northern Celestial Hemisphere means that the whole constellation is visible to observers north of 50\u00b0S. It is bordered by Bo\u00f6tes to the north and west, Serpens Caput to the south, and Hercules to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CrB\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of eight segments (\"illustrated in infobox\"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between 15h 16.0m and 16h 25.1m, while the declination coordinates are between 39.71\u00b0 and 25.54\u00b0. It has a counterpart\u2014Corona Australis\u2014in the Southern Celestial Hemisphere.\nFeatures.\nStars.\nThe seven stars that make up the constellation's distinctive crown-shaped pattern are all 4th-magnitude stars except for the brightest of them, Alpha Coronae Borealis. The other six stars are Theta, Beta, Gamma, Delta, Epsilon and Iota Coronae Borealis. The German cartographer Johann Bayer gave twenty stars in Corona Borealis Bayer designations from Alpha to Upsilon in his 1603 star atlas \"Uranometria\". Zeta Coronae Borealis was noted to be a double star by later astronomers and its components designated Zeta1 and Zeta2. John Flamsteed did likewise with Nu Coronae Borealis; classed by Bayer as a single star, it was noted to be two close stars by Flamsteed. He named them 20 and 21 Coronae Borealis in his catalogue, alongside the designations Nu1 and Nu2 respectively. Chinese astronomers deemed nine stars to make up the asterism, adding Pi and Rho Coronae Borealis. Within the constellation's borders, there are 37 stars brighter than or equal to apparent magnitude\u00a06.5.\nAlpha Coronae Borealis (officially named Alphecca by the IAU, but sometimes also known as Gemma) appears as a blue-white star of magnitude\u00a02.2. In fact, it is an Algol-type eclipsing binary that varies by 0.1\u00a0magnitude with a period of 17.4\u00a0days. The primary is a white main-sequence star of spectral type A0V that is 2.91\u00a0times the mass of the Sun (M\u2609) and 57 times as luminous (L\u2609), and is surrounded by a debris disk out to a radius of around 60\u00a0astronomical units (AU). The secondary companion is a yellow main-sequence star of spectral type G5V that is a little smaller (0.9 times) the diameter of the Sun. Lying 75\u00b10.5\u00a0light-years from Earth, Alphecca is believed to be a member of the Ursa Major Moving Group of stars that have a common motion through space.\nLocated 112\u00b13\u00a0light-years away, Beta Coronae Borealis or Nusakan is a spectroscopic binary system whose two components are separated by 10\u00a0AU and orbit each other every 10.5 years. The brighter component is a rapidly oscillating Ap star, pulsating with a period of 16.2\u00a0minutes. Of spectral type A5V with a surface temperature of around 7980\u00a0K, it has around 2.1\u00a0M\u2609, 2.6\u00a0solar radii (R\u2609), and 25.3\u00a0L\u2609. The smaller star is of spectral type F2V with a surface temperature of around 6750\u00a0K, and has around 1.4\u00a0M\u2609, 1.56\u00a0R\u2609, and between 4 and 5\u00a0L\u2609. Near Nusakan is Theta Coronae Borealis, a binary system that shines with a combined magnitude of 4.13 located 380\u00b120 light-years distant. The brighter component, Theta Coronae Borealis A, is a blue-white star that spins extremely rapidly\u2014at a rate of around 393\u00a0km per second. A Be star, it is surrounded by a debris disk.\nFlanking Alpha to the east is Gamma Coronae Borealis, yet another binary star system, whose components orbit each other every 92.94\u00a0years and are roughly as far apart from each other as the Sun and Neptune. The brighter component has been classed as a Delta Scuti variable star, though this view is not universal. The components are main sequence stars of spectral types B9V and A3V. Located 170\u00b12\u00a0light-years away, 4.06-magnitude Delta Coronae Borealis is a yellow giant star of spectral type G3.5III that is around 2.4\u00a0M\u2609 and has swollen to 7.4\u00a0R\u2609. It has a surface temperature of 5180\u00a0K. For most of its existence, Delta Coronae Borealis was a blue-white main-sequence star of spectral type B before it ran out of hydrogen fuel in its core. Its luminosity and spectrum suggest it has just crossed the Hertzsprung gap, having finished burning core hydrogen and just begun burning hydrogen in a shell that surrounds the core.\nZeta Coronae Borealis is a double star with two blue-white components 6.3\u00a0arcseconds apart that can be readily separated at 100x\u00a0magnification. The primary is of magnitude\u00a05.1 and the secondary is of magnitude\u00a06.0. Nu Coronae Borealis is an optical double, whose components are a similar distance from Earth but have different radial velocities, hence are assumed to be unrelated. The primary, Nu1 Coronae Borealis, is a red giant of spectral type M2III and magnitude 5.2, lying 640\u00b130 light-years distant, and the secondary, Nu2 Coronae Borealis, is an orange-hued giant star of spectral type K5III and magnitude 5.4, estimated to be 590\u00b130\u00a0light-years away. Sigma Coronae Borealis, on the other hand, is a true multiple star system divisible by small amateur telescopes. It is actually a complex system composed of two stars around as massive as the Sun that orbit each other every 1.14\u00a0days, orbited by a third Sun-like star every 726\u00a0years. The fourth and fifth components are a binary red dwarf system that is 14,000\u00a0AU distant from the other three stars. ADS 9731 is an even rarer multiple system in the constellation, composed of six stars, two of which are spectroscopic binaries.\nCorona Borealis is home to two remarkable variable stars. T Coronae Borealis is a cataclysmic variable star also known as the Blaze Star. Normally placid around magnitude 10\u2014it has a minimum of 10.2 and maximum of 9.9\u2014it brightens to magnitude 2 in a period of hours, caused by a nuclear chain reaction and the subsequent explosion. T Coronae Borealis is one of a handful of stars called recurrent novae, which include T Pyxidis and U Scorpii. An outburst of T Coronae Borealis was first recorded in 1866; its second recorded outburst was in February 1946. T Coronae Borealis is a binary star with a red-hued giant primary and a white dwarf secondary, the two stars orbiting each other over a period of approximately 8 months. R Coronae Borealis is a yellow-hued variable supergiant star, over 7000 light-years from Earth, and prototype of a class of stars known as R Coronae Borealis variables. Normally of magnitude 6, its brightness periodically drops as low as magnitude 15 and then slowly increases over the next several months. These declines in magnitude come about as dust that has been ejected from the star obscures it. Direct imaging with the Hubble Space Telescope shows extensive dust clouds out to a radius of around 2000\u00a0AU from the star, corresponding with a stream of fine dust (composed of grains 5\u00a0nm in diameter) associated with the star's stellar wind and coarser dust (composed of grains with a diameter of around 0.14\u00a0\u00b5m) ejected periodically.\nThere are several other variables of reasonable brightness for amateur astronomer to observe, including three Mira-type long period variables: S Coronae Borealis ranges between magnitudes 5.8 and 14.1 over a period of 360\u00a0days. Located around 1946\u00a0light-years distant, it shines with a luminosity 16,643\u00a0times that of the Sun and has a surface temperature of 3033 K. One of the reddest stars in the sky, V Coronae Borealis is a cool star with a surface temperature of 2877\u00a0K that shines with a luminosity 102,831 times that of the Sun and is a remote 8810\u00a0light-years distant from Earth. Varying between magnitudes 6.9 and 12.6 over a period of 357\u00a0days, it is located near the junction of the border of Corona Borealis with Hercules and Bootes. Located 1.5\u00b0 northeast of Tau Coronae Borealis, W Coronae Borealis ranges between magnitudes 7.8 and 14.3 over a period of 238\u00a0days. Another red giant, RR Coronae Borealis is a M3-type semiregular variable star that varies between magnitudes 7.3 and 8.2 over 60.8 days. RS Coronae Borealis is yet another semiregular variable red giant, which ranges between magnitudes 8.7 to 11.6 over 332 days. It is unusual in that it is a red star with a high proper motion (greater than 50 milliarcseconds a year). Meanwhile, U Coronae Borealis is an Algol-type eclipsing binary star system whose magnitude varies between 7.66 and 8.79 over a period of 3.45 days\nTY Coronae Borealis is a pulsating white dwarf (of ZZ Ceti) type, which is around 70% as massive as the Sun, yet has only 1.1% of its diameter. Discovered in 1990, UW Coronae Borealis is a low-mass X-ray binary system composed of a star less massive than the Sun and a neutron star surrounded by an accretion disk that draws material from the companion star. It varies in brightness in an unusually complex manner: the two stars orbit each other every 111 minutes, yet there is another cycle of 112.6 minutes, which corresponds to the orbit of the disk around the degenerate star. The beat period of 5.5 days indicates the time the accretion disk\u2014which is asymmetrical\u2014takes to precess around the star.\nExtrasolar planetary systems.\nExtrasolar planets have been confirmed in five star systems, four of which were found by the radial velocity method. The spectrum of Epsilon Coronae Borealis was analysed for seven years from 2005 to 2012, revealing a planet around 6.7\u00a0times as massive as Jupiter (MJ) orbiting every 418\u00a0days at an average distance of around 1.3\u00a0AU. Epsilon itself is a 1.7\u00a0M\u2609 orange giant of spectral type K2III that has swollen to 21\u00a0R\u2609 and 151\u00a0L\u2609. Kappa Coronae Borealis is a spectral type K1IV orange subgiant nearly twice as massive as the Sun; around it lies a dust debris disk, and one planet with a period of 3.4\u00a0years. This planet's mass is estimated at 2.5\u00a0MJ. The dimensions of the debris disk indicate it is likely there is a second substellar companion. Omicron Coronae Borealis is a K-type clump giant with one confirmed planet with a mass of 0.83\u00a0MJ that orbits every 187\u00a0days\u2014one of the two least massive planets known around clump giants. HD 145457 is an orange giant of spectral type K0III found to have one planet of 2.9\u00a0MJ. Discovered by the Doppler method in 2010, it takes 176\u00a0days to complete an orbit. XO-1 is a magnitude 11 yellow main-sequence star located approximately light-years away, of spectral type G1V with a mass and radius similar to the Sun. In 2006 the hot Jupiter exoplanet XO-1b was discovered orbiting XO-1 by the transit method using the XO Telescope. Roughly the size of Jupiter, it completes an orbit around its star every three days.\nThe discovery of a Jupiter-sized planetary companion was announced in 1997 via analysis of the radial velocity of Rho Coronae Borealis, a yellow main sequence star and Solar analog of spectral type G0V, around 57 light-years distant from Earth. More accurate measurement of data from the Hipparcos satellite subsequently showed it instead to be a low-mass star somewhere between 100 and 200 times the mass of Jupiter. Possible stable planetary orbits in the habitable zone were calculated for the binary star Eta Coronae Borealis, which is composed of two stars\u2014yellow main sequence stars of spectral type G1V and G3V respectively\u2014similar in mass and spectrum to the Sun. No planet has been found, but a brown dwarf companion about 63 times as massive as Jupiter with a spectral type of L8 was discovered at a distance of 3640\u00a0AU from the pair in 2001.\nDeep-sky objects.\nCorona Borealis contains few galaxies observable with amateur telescopes. NGC 6085 and 6086 are a faint spiral and elliptical galaxy respectively close enough to each other to be seen in the same visual field through a telescope. Abell 2142 is a huge (six million light-year diameter), X-ray luminous galaxy cluster that is the result of an ongoing merger between two galaxy clusters. It has a redshift of 0.0909 (meaning it is moving away from us at 27,250\u00a0km/s) and a visual magnitude of 16.0. It is about 1.2 billion light-years away. Another galaxy cluster in the constellation, RX\u00a0J1532.9+3021, is approximately 3.9 billion light-years from Earth. At the cluster's center is a large elliptical galaxy containing one of the most massive and most powerful supermassive black holes yet discovered. Abell 2065 is a highly concentrated galaxy cluster containing more than 400 members, the brightest of which are 16th magnitude; the cluster is more than one billion light-years from Earth. On a larger scale still, Abell\u00a02065, along with Abell 2061, Abell 2067, Abell 2079, Abell 2089, and Abell 2092, make up the Corona Borealis Supercluster. Another galaxy cluster, Abell 2162, is a member of the Hercules Superclusters.\nMythology.\nIn Greek mythology, Corona Borealis was linked to the legend of Theseus and the minotaur. It was generally considered to represent a crown given by Dionysus to Ariadne, the daughter of Minos of Crete, after she had been abandoned by the Athenian prince Theseus. When she wore the crown at her marriage to Dionysus, he placed it in the heavens to commemorate their wedding. An alternate version has the besotted Dionysus give the crown to Ariadne, who in turn gives it to Theseus after he arrives in Crete to kill the minotaur that the Cretans have demanded tribute from Athens to feed. The hero uses the crown's light to escape the labyrinth after disposing of the creature, and Dionysus later sets it in the heavens. The Latin author Hyginus linked it to a crown or wreath worn by Bacchus (Dionysus) to disguise his appearance when first approaching Mount Olympus and revealing himself to the gods, having been previously hidden as yet another child of Jupiter's trysts with a mortal, in this case Semele. Corona Borealis was one of the 48 constellations mentioned in the \"Almagest\" of classical astronomer Ptolemy.\nIn Mesopotamia, Corona Borealis was associated with the goddess Nanaya.\nIn Welsh mythology, it was called Caer Arianrhod, \"the Castle of the Silver Circle\", and was the heavenly abode of the Lady Arianrhod. To the ancient Balts, Corona Borealis was known as \"Dar\u017eelis\", the \"flower garden.\"\nThe Arabs called the constellation Alphecca (a name later given to Alpha Coronae Borealis), which means \"separated\" or \"broken up\" ( '), a reference to the resemblance of the stars of Corona Borealis to a loose string of jewels. This was also interpreted as a broken dish. Among the Bedouins, the constellation was known as ' (), or \"the dish/bowl of the poor people\".\nThe Skidi people of Native Americans saw the stars of Corona Borealis representing a council of stars whose chief was Polaris. The constellation also symbolised the smokehole over a fireplace, which conveyed their messages to the gods, as well as how chiefs should come together to consider matters of importance. The Shawnee people saw the stars as the \"Heavenly Sisters\", who descended from the sky every night to dance on earth. Alphecca signifies the youngest and most comely sister, who was seized by a hunter who transformed into a field mouse to get close to her. They married though she later returned to the sky, with her heartbroken husband and son following later. The Mi'kmaq of eastern Canada saw Corona Borealis as \"Mskegw\u01d2m\", the den of the celestial bear (Alpha, Beta, Gamma and Delta Ursae Majoris).\nPolynesian peoples often recognized Corona Borealis; the people of the Tuamotus named it \"Na Kaua-ki-tokerau\" and probably \"Te Hetu\". The constellation was likely called \"Kaua-mea\" in Hawaii, \"Rangawhenua\" in New Zealand, and \"Te Wale-o-Awitu\" in the Cook Islands atoll of Pukapuka. Its name in Tonga was uncertain; it was either called \"Ao-o-Uvea\" or \"Kau-kupenga\".\nIn Australian Aboriginal astronomy, the constellation is called \"womera\" (\"the boomerang\") due to the shape of the stars. The Wailwun people of northwestern New South Wales saw Corona Borealis as \"mullion wollai\" \"eagle's nest\", with Altair and Vega\u2014each called \"mullion\"\u2014the pair of eagles accompanying it. The Wardaman people of northern Australia held the constellation to be a gathering point for Men's Law, Women's Law and Law of both sexes come together and consider matters of existence.\nLater references.\nCorona Borealis was renamed Corona Firmiana in honour of the Archbishop of Salzburg in the 1730 Atlas \"Mercurii Philosophicii Firmamentum Firminianum Descriptionem\" by Corbinianus Thomas, but this was not taken up by subsequent cartographers. The constellation was featured as a main plot ingredient in the short story \"Hypnos\" by H. P. Lovecraft, published in 1923; it is the object of fear of one of the protagonists in the short story. Finnish band Cadacross released an album titled \"Corona Borealis\" in 2002.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 16h 00m 00s, +30\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6421", "revid": "1160711117", "url": "https://en.wikipedia.org/wiki?curid=6421", "title": "Cygnus (constellation)", "text": "Constellation in the northern celestial hemisphere\nCygnus is a northern constellation on the plane of the Milky Way, deriving its name from the Latinized Greek word for swan. Cygnus is one of the most recognizable constellations of the northern summer and autumn, and it features a prominent asterism known as the Northern Cross (in contrast to the Southern Cross). Cygnus was among the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations.\nCygnus contains Deneb (\u0630\u0646\u0628, translit. \"\u1e0fanab,\" tail)\u00a0\u2013 one of the brightest stars in the night sky and the most distant first-magnitude star\u00a0\u2013 as its \"tail star\" and one corner of the Summer Triangle the constellation forming an east pointing altitude of the triangle. It also has some notable X-ray sources and the giant stellar association of Cygnus OB2. Cygnus is also known as the Northern Cross. One of the stars of this association, NML Cygni, is one of the largest stars currently known. The constellation is also home to Cygnus X-1, a distant X-ray binary containing a supergiant and unseen massive companion that was the first object widely held to be a black hole. Many star systems in Cygnus have known planets as a result of the Kepler Mission observing one patch of the sky, an area around Cygnus.\nMost of the east has part of the Hercules\u2013Corona Borealis Great Wall in the deep sky, a giant galaxy filament that is the largest known structure in the observable universe, covering most of the northern sky.\nHistory and mythology.\nIn Eastern and World Astronomy.\nIn Hinduism, the period of time (or Muhurta) between 4:24 AM to 5:12 AM is called the Brahmamuhurtha, which means \"the moment of the Universe\"; the star system in correlation is the Cygnus constellation. This is believed to be a highly auspicious time to meditate, do any task, or start the day.\nIn Polynesia, Cygnus was often recognized as a separate constellation. In Tonga it was called \"Tuula-lupe\", and in the Tuamotus it was called \"Fanui-tai\". In New Zealand it was called \"Mara-tea\", in the Society Islands it was called \"Pirae-tea\" or \"Taurua-i-te-haapa-raa-manu\", and in the Tuamotus it was called \"Fanui-raro\". Beta Cygni was named in New Zealand; it was likely called \"Whetu-kaupo\". Gamma Cygni was called \"Fanui-runga\" in the Tuamotus.\nDeneb was also often a given name, in the Islamic world of astronomy. The name \"Deneb\" comes from the Arabic name \"dhaneb\", meaning \"tail\", from the phrase \"Dhanab ad-Daj\u0101jah\", which means \"the tail of the hen\".\nIn Western astronomy.\nIn Greek mythology, Cygnus has been identified with several different legendary swans. Zeus disguised himself as a swan to seduce Leda, Spartan king Tyndareus's wife, who gave birth to the Gemini, Helen of Troy, and Clytemnestra; Orpheus was transformed into a swan after his murder, and was said to have been placed in the sky next to his lyre (Lyra); and the King Cygnus was transformed into a swan.\nLater Romans also associated this constellation with the tragic story of Phaethon, the son of Helios the sun god, who demanded to ride his father's sun chariot for a day. Phaethon, however, was unable to control the reins, forcing Zeus to destroy the chariot (and Phaethon) with a thunderbolt, causing it to plummet to the earth into the river Eridanus. According to the myth, Phaethon's close friend or lover, Cygnus, grieved bitterly and spent many days diving into the river to collect Phaethon's bones to give him a proper burial. The gods were so touched by Cygnus's devotion that they turned him into a swan and placed him among the stars.\nIn Ovid's \"Metamorphoses\", there are three people named Cygnus, all of whom are transformed into swans. Alongside Cygnus, noted above, he mentions a boy from Tempe who commits suicide when Phyllius refuses to give him a tamed bull that he demands, but is transformed into a swan and flies away. He also mentions a son of Neptune who is an invulnerable warrior in the Trojan War who is eventually defeated by Achilles, but Neptune saves him by transforming him into a swan.\nTogether with other avian constellations near the summer solstice, Vultur cadens and Aquila, Cygnus may be a significant part of the origin of the myth of the Stymphalian Birds, one of The Twelve Labours of Hercules.\nCharacteristics.\nA very large constellation, Cygnus is bordered by Cepheus to the north and east, Draco to the north and west, Lyra to the west, Vulpecula to the south, Pegasus to the southeast and Lacerta to the east. The three-letter abbreviation for the constellation, as adopted by the IAU in 1922, is \"Cyg\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined as a polygon of 28 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 19h 07.3m and 22h 02.3m, while the declination coordinates are between 27.73\u00b0 and 61.36\u00b0. Covering 804 square degrees and around 1.9% of the night sky, Cygnus ranks 16th of the 88 constellations in size.\nCygnus culminates at midnight on 29 June, and is most visible in the evening from the early summer to mid-autumn in the Northern Hemisphere.\nNormally, Cygnus is depicted with Delta and Epsilon Cygni as its wings. Deneb, the brightest in the constellation is at its tail, and Albireo as the tip of its beak.\nThere are several asterisms in Cygnus. In the 17th-century German celestial cartographer Johann Bayer's star atlas the \"Uranometria\", Alpha, Beta and Gamma Cygni form the pole of a cross, while Delta and Epsilon form the cross beam. The nova P Cygni was then considered to be the body of Christ.\nFeatures.\nThere is an abundance of deep-sky objects, with many open clusters, nebulae of various types and supernova remnants found in Cygnus due to its position on the Milky Way.\nIts molecular clouds form the apparent Cygnus Rift dark nebula constellation, which is one end of the apparent part of the apparent Great Rift along the Milky Way's galactic plane. The rift begins with features like the Northern Coalsack which obscures the further away and large in apparent size Cygnus\u00a0molecular cloud complex which the North America Nebula is part of.\nStars.\nBayer catalogued many stars in the constellation, giving them the Bayer designations from Alpha to Omega and then using lowercase Roman letters to g. John Flamsteed added the Roman letters h, i, k, l and m (these stars were considered \"informes\" by Bayer as they lay outside the asterism of Cygnus), but were dropped by Francis Baily.\nThere are several bright stars in Cygnus. Alpha Cygni, called Deneb, is the brightest star in Cygnus. It is a white supergiant star of spectral type A2Iae that varies between magnitudes 1.21 and 1.29, one of the largest and most luminous A-class stars known. It is located about 2600 light-years away. Its traditional name means \"tail\" and refers to its position in the constellation. Albireo, designated Beta Cygni, is a celebrated binary star among amateur astronomers for its contrasting hues. The primary is an orange-hued giant star of magnitude 3.1 and the secondary is a blue-green hued star of magnitude 5.1. The system is 430 light-years away and is visible in large binoculars and all amateur telescopes. Gamma Cygni, traditionally named Sadr, is a yellow-tinged supergiant star of magnitude 2.2, 1800 light-years away. Its traditional name means \"breast\" and refers to its position in the constellation. Delta Cygni (the proper name is Fawaris) is another bright binary star in Cygnus, 166 light-years with a period of 800 years. The primary is a blue-white hued giant star of magnitude 2.9, and the secondary is a star of magnitude 6.6. The two components are visible in a medium-sized amateur telescope. The fifth star in Cygnus above magnitude 3 is Aljanah, designated Epsilon Cygni. It is an orange-hued giant star of magnitude 2.5, 72 light-years from Earth.\nThere are several other dimmer double and binary stars in Cygnus. Mu Cygni is a binary star with an optical tertiary component. The binary system has a period of 790 years and is 73 light-years from Earth. The primary and secondary, both white stars, are of magnitude 4.8 and 6.2, respectively. The unrelated tertiary component is of magnitude 6.9. Though the tertiary component is visible in binoculars, the primary and secondary currently require a medium-sized amateur telescope to split, as they will through the year 2020. The two stars will be closest between 2043 and 2050, when they will require a telescope with larger aperture to split. The stars 30 and 31 Cygni form a contrasting double star similar to the brighter Albireo. The two are visible in binoculars. The primary, 31 Cygni, is an orange-hued star of magnitude 3.8, 1400 light-years from Earth. The secondary, 30 Cygni, appears blue-green. It is of spectral type A5IIIn and magnitude 4.83, and is around 610 light-years from Earth. 31 Cygni itself is a binary star; the tertiary component is a blue star of magnitude 7.0. Psi Cygni is a binary star visible in small amateur telescopes, with two white components. The primary is of magnitude 5.0 and the secondary is of magnitude 7.5. 61 Cygni is a binary star visible in large binoculars or a small amateur telescope. It is 11.4 light-years from Earth and has a period of 750 years. Both components are orange-hued dwarf (main sequence) stars; the primary is of magnitude 5.2 and the secondary is of magnitude 6.1. 61 Cygni is significant because Friedrich Wilhelm Bessel determined its parallax in 1838, the first star to have a known parallax.\nLocated near Eta Cygni is the X-ray source Cygnus X-1, which is now thought to be caused by a black hole accreting matter in a binary star system. This was the first X-ray source widely believed to be a black hole. It is located approximately 2.2 kiloparsecs from the Sun. There is also supergiant variable star in the system which is known as HDE 226868.\nCygnus also contains several other noteworthy X-ray sources. Cygnus X-3 is a microquasar containing a Wolf\u2013Rayet star in orbit around a very compact object, with a period of only 4.8 hours. The system is one of the most intrinsically luminous X-ray sources observed. The system undergoes periodic outbursts of unknown nature, and during one such outburst, the system was found to be emitting muons, likely caused by neutrinos. While the compact object is thought to be a neutron star or possibly a black hole, it is possible that the object is instead a more exotic stellar remnant, possibly the first discovered quark star, hypothesized due to its production of cosmic rays that cannot be explained if the object is a normal neutron star. The system also emits cosmic rays and gamma rays, and has helped shed insight on to the formation of such rays. Cygnus X-2 is another X-ray binary, containing an A-type giant in orbit around a neutron star with a 9.8-day period. The system is interesting due to the rather small mass of the companion star, as most millisecond pulsars have much more massive companions. Another black hole in Cygnus is V404 Cygni, which consists of a K-type star orbiting around a black hole of around 12 solar masses. The black hole, similar to that of Cygnus X-3, has been hypothesized to be a quark star. 4U 2129+ 47 is another X-ray binary containing a neutron star which undergoes outbursts, as is EXO 2030+ 375.\nCygnus is also home to several variable stars. SS Cygni is a dwarf nova which undergoes outbursts every 7\u20138 weeks. The system's total magnitude varies from 12th magnitude at its dimmest to 8th magnitude at its brightest. The two objects in the system are incredibly close together, with an orbital period of less than 0.28 days. Chi Cygni is a red giant and the second-brightest Mira variable star at its maximum. It ranges between magnitudes 3.3 and 14.2, and spectral types S6,2e to S10,4e (MSe) over a period of 408 days; it has a diameter of 300 solar diameters and is 350 light-years from Earth. P Cygni is a luminous blue variable that brightened suddenly to 3rd magnitude in 1600 AD. Since 1715, the star has been of 5th magnitude, despite being more than 5000 light-years from Earth. The star's spectrum is unusual in that it contains very strong emission lines resulting from surrounding nebulosity. W Cygni is a semi-regular variable red giant star, 618 light-years from Earth.It has a maximum magnitude of 5.10 and a minimum magnitude 6.83; its period of 131 days. It is a red giant ranging between spectral types M4e-M6e(Tc:)III, NML Cygni is a red hypergiant semi-regular variable star located at 5,300 light-years away from Earth. It is one of largest stars currently known in the galaxy with a radius exceeding 1,000 solar radii. Its magnitude is around 16.6, its period is about 940 days.\nThe star KIC 8462852 (Tabby's Star) has received widespread press coverage because of unusual light fluctuations.\nCygnus is one of the constellations that the Kepler satellite surveyed in its search for exoplanets, and as a result, there are about a hundred stars in Cygnus with known planets, the most of any constellation. One of the most notable systems is the Kepler-11 system, containing six transiting planets, all within a plane of approximately one degree. It was the system with six exoplanets to be discovered. With a spectral type of G6V, the star is somewhat cooler than the Sun. The planets are very close to the star; all but the last planet are closer to Kepler-11 than Mercury is to the Sun, and all the planets are more massive than Earth, and have low densities. The planets have low densities. The naked-eye star 16 Cygni, a triple star approximately 70 light-years from Earth composed two Sun-like stars and a red dwarf, contains a planet orbiting one of the sun-like stars, found due to variations in the star's radial velocity. Gliese 777, another naked-eye multiple star system containing a yellow star and a red dwarf, also contains a planet. The planet is somewhat similar to Jupiter, but with slightly more mass and a more eccentric orbit. The Kepler-22 system is also notable for having the most Earth-like exoplanet when it was discovered in 2011.\nStar clusters.\nThe rich background of stars of Cygnus can make it difficult to make out open cluster.\nM39 (NGC 7092) is an open cluster 950 light-years from Earth that are visible to the unaided eye under dark skies. It is loose, with about 30 stars arranged over a wide area; their conformation appears triangular. The brightest stars of M39 are of the 7th magnitude. Another open cluster in Cygnus is NGC 6910, also called the Rocking Horse Cluster, possessing 16 stars with a diameter of 5 arcminutes visible in a small amateur instrument; it is of magnitude 7.4. The brightest of these are two gold-hued stars, which represent the bottom of the toy it is named for. A larger amateur instrument reveals 8 more stars, nebulosity to the east and west of the cluster, and a diameter of 9 arcminutes. The nebulosity in this region is part of the Gamma Cygni Nebula. The other stars, approximately 3700 light-years from Earth, are mostly blue-white and very hot.\nOther open clusters in Cygnus include Dolidze 9, Collinder 421, Dolidze 11, and Berkeley 90. Dolidze 9, 2800 light-years from Earth and relatively young at 20 million light-years old, is a faint open cluster with up to 22 stars visible in small and medium-sized amateur telescopes. Nebulosity is visible to the north and east of the cluster, which is 7 arcminutes in diameter. The brightest star appears in the eastern part of the cluster and is of the 7th magnitude; another bright star has a yellow hue. Dolidze 11 is an open cluster 400 million years old, farthest away of the three at 3700 light-years. More than 10 stars are visible in an amateur instrument in this cluster, of similar size to Dolidze 9 at 7 arcminutes in diameter, whose brightest star is of magnitude 7.5. It, too, has nebulosity in the east. Collinder 421 is a particularly old open cluster at an age of approximately 1 billion years; it is of magnitude 10.1. 3100 light-years from Earth, more than 30 stars are visible in a diameter of 8 arcseconds. The prominent star in the north of the cluster has a golden color, whereas the stars in the south of the cluster appear orange. Collinder 421 appears to be embedded in nebulosity, which extends past the cluster's borders to its west. Berkeley 90 is a smaller open cluster, with a diameter of 5 arcminutes. More than 16 members appear in an amateur telescope.\nMolecular clouds.\nNGC 6826, the Blinking Planetary Nebula, is a planetary nebula with a magnitude of 8.5, 3200 light-years from Earth. It appears to \"blink\" in the eyepiece of a telescope because its central star is unusually bright (10th magnitude). When an observer focuses on the star, the nebula appears to fade away. Less than one degree from the Blinking Planetary is the double star 16 Cygni.\nThe North America Nebula (NGC 7000) is one of the most well-known nebulae in Cygnus, because it is visible to the unaided eye under dark skies, as a bright patch in the Milky Way. However, its characteristic shape is only visible in long-exposure photographs \u2013 it is difficult to observe in telescopes because of its low surface brightness. It has low surface brightness because it is so large; at its widest, the North America Nebula is 2 degrees across. Illuminated by a hot embedded star of magnitude 6, NGC 7000 is 1500 light-years from Earth.\nTo the south of Epsilon Cygni is the Veil Nebula (NGC 6960, 6979, 6992, and 6995), a 5,000-year-old supernova remnant covering approximately 3 degrees of the sky - it is over 50 light-years long. Because of its appearance, it is also called the Cygnus Loop. The Loop is only visible in long-exposure astrophotographs. However, the brightest portion, NGC 6992, is faintly visible in binoculars, and a dimmer portion, NGC 6960, is visible in wide-angle telescopes.\nThe DR 6 cluster is also nicknamed the \"Galactic Ghoul\" because of the nebula's resemblance to a human face;\nThe Gamma Cygni Nebula (IC 1318) includes both bright and dark nebulae in an area of over 4 degrees. DWB 87 is another of the many bright emission nebulae in Cygnus, 7.8 by 4.3 arcminutes. It is in the Gamma Cygni area. Two other emission nebulae include Sharpless 2-112 and Sharpless 2-115. When viewed in an amateur telescope, Sharpless 2\u2013112 appears to be in a teardrop shape. More of the nebula's eastern portion is visible with an O III (doubly ionized oxygen) filter. There is an orange star of magnitude 10 nearby and a star of magnitude 9 near the nebula's northwest edge. Further to the northwest, there is a dark rift and another bright patch. The whole nebula measures 15 arcminutes in diameter. Sharpless 2\u2013115 is another emission nebula with a complex pattern of light and dark patches. Two pairs of stars appear in the nebula; it is larger near the southwestern pair. The open cluster Berkeley 90 is embedded in this large nebula, which measures 30 by 20 arcminutes.\nAlso of note is the Crescent Nebula (NGC 6888), located between Gamma and Eta Cygni, which was formed by the Wolf\u2013Rayet star HD 192163.\nIn recent years, amateur astronomers have made some notable Cygnus discoveries. The \"Soap bubble nebula\" (PN G75.5+1.7), near the Crescent nebula, was discovered on a digital image by Dave Jurasevich in 2007. In 2011, Austrian amateur Matthias Kronberger discovered a planetary nebula (Kronberger 61, now nicknamed \"The Soccer Ball\") on old survey photos, confirmed recently in images by the Gemini Observatory; both of these are likely too faint to be detected by eye in a small amateur scope.\nBut a much more obscure and relatively 'tiny' object\u2014one which is readily seen in dark skies by amateur telescopes, under good conditions\u2014is the newly discovered nebula (likely reflection type) associated with the star 4 Cygni (HD 183056): an approximately fan-shaped glowing region of several arcminutes' diameter, to the south and west of the fifth-magnitude star. It was first discovered visually near San Jose, California and publicly reported by amateur astronomer Stephen Waldee in 2007, and was confirmed photographically by Al Howard in 2010. California amateur astronomer Dana Patchick also says he detected it on the Palomar Observatory survey photos in 2005 but had not published it for others to confirm and analyze at the time of Waldee's first official notices and later 2010 paper.\nCygnus X is the largest star-forming region in the solar neighborhood and includes not only some of the brightest and most massive stars known (such as Cygnus OB2-12), but also Cygnus OB2, a massive stellar association classified by some authors as a young globular cluster.\nDeep space objects.\nCygnus A is the first radio galaxy discovered; at a distance of 730 million light-years from Earth, it is the closest powerful radio galaxy. In the visible spectrum, it appears as an elliptical galaxy in a small cluster. It is classified as an active galaxy because the supermassive black hole at its nucleus is accreting matter, which produces two jets of matter from the poles. The jets' interaction with the interstellar medium creates radio lobes, one source of radio emissions.\nOther features.\nCygnus is also the apparent source of the WIMP-wind due to the orientation of the solar system's rotation through the galactic halo.\nThe local Orion-Cygnus Arm and the distant Cygnus Arm are two minor galactic arms named after Cygnus for lying in its background.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;zoom=&amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 20h 37m 12s, +42\u00b0 01\u2032 48\u2033&lt;/indicator&gt;"}
{"id": "6422", "revid": "1087343070", "url": "https://en.wikipedia.org/wiki?curid=6422", "title": "Communion", "text": "Communion may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "6423", "revid": "146418", "url": "https://en.wikipedia.org/wiki?curid=6423", "title": "Calorie", "text": "Unit of energy used in nutrition\nThe calorie is a unit of energy that originated from the obsolete caloric theory of heat. For historical reasons, two main definitions of \"calorie\" are in wide use. The large calorie, food calorie, dietary calorie, or kilogram calorie was originally defined as the amount of heat needed to raise the temperature of one kilogram of water by one degree Celsius (or one kelvin). The small calorie or gram calorie was defined as the amount of heat needed to cause the same increase in one gram of water. Thus, 1 large calorie is equal to 1000 small calories.\nIn nutrition and food science, the term \"calorie\" and the symbol \"cal\" may refer to the large unit or to the small unit in different regions of the world. It is generally used in publications and package labels to express the energy value of foods in per serving or per weight, recommended dietary caloric intake, metabolic rates, etc. Some authors recommend the spelling \"Calorie\" and the symbol \"Cal\" (both with a capital C) if the large calorie is meant, to avoid confusion; however, this convention is often ignored.\nIn physics and chemistry the word \"calorie\" and its symbol usually refer to the small unit; the large one being called \"kilocalorie\". However, this unit is not officially part of the metric system (SI), and is regarded as obsolete, having been replaced in many uses by the SI unit of energy, the joule (J).\nThe precise equivalence between calories and joules has varied over the years, but in thermochemistry and nutrition it is now generally assumed that one (small) calorie (\"thermochemical calorie\") is equal to exactly 4.184 J, and therefore one kilocalorie (one large calorie) is 4184 J, or 4.184 kJ.\nHistory.\nThe term \"calorie\" was first introduced by Nicolas Cl\u00e9ment, as a unit of heat energy, in lectures on experimental calorimetry during the years 1819\u20131824. This was the \"large\" calorie. The term (written with lowercase \"c\") entered French and English dictionaries between 1841 and 1867. It comes from la \" calor\"\u00a0'heat'.\nThe same term was used for the \"small\" unit by Pierre Antoine Favre (Chemist) and Johann T. Silbermann (Physicist) in 1852. This unit was used by U.S. physician Joseph Howard Raymond, in his classic 1894 textbook \"A Manual of Human Physiology\". He proposed calling the \"large\" unit \"kilocalorie\", but the term did not catch on until some years later.\nIn 1879, Marcellin Berthelot distinguished between gram-calorie and kilogram-calorie, and proposed using \"Calorie\", with capital \"C\", for the large unit. This usage was adopted by Wilbur Olin Atwater, a professor at Wesleyan University, in 1887, in an influential article on the energy content of food.\nThe small calorie (cal) was recognized as a unit of the CGS system in 1896, alongside the already-existing CGS unit of energy, the erg (first suggested by Clausius in 1864, under the name \"ergon\", and officially adopted in 1882).\nAlready in 1928 there were serious complaints about the possible confusion arising from the two main definitions of the calorie and whether the notion of using the capital letter to distinguish them was sound.\nThe joule was the officially adopted SI unit of energy at the ninth General Conference on Weights and Measures in 1948. The calorie was mentioned in the 7th edition of the SI brochure as an example of a non-SI unit.\nThe alternate spelling calory is considered nonstandard and dated.\nDefinitions.\nThe \"small\" calorie is broadly defined as the amount of energy needed to increase the temperature of 1\u00a0gram of water by 1\u00a0\u00b0C (or 1\u00a0K, which is the same increment, a gradation of one percent of the interval between the melting point and the boiling point of water). The amount depends on the atmospheric pressure and the starting temperature, and different choices of these parameters have resulted in several different precise definitions of the unit.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nThe two definitions most common in older literature appear to be the \"15\u00a0\u00b0C calorie\" and the \"thermochemical calorie\". Until 1948, the latter was defined as 4.1833 international joules; the current standard of 4.184\u00a0J was chosen to have the new thermochemical calorie represent the same quantity of energy as before.\nUsage.\nNutrition.\nIn the United States, in a nutritional context, the \"large\" unit is used almost exclusively. It is generally written \"calorie\" with lowercase \"c\" and symbol \"cal\", even in government publications. The SI unit of energy kilojoule (kJ) may be used instead, in legal or scientific contexts. Most nutritionists prefer the unit kilocalorie to the unit kilojoules, whereas most physiologists prefer to use kilojoules. In the majority of other countries, nutritionists prefer the kilojoule to the kilocalorie.\nIn the European Union, energy on nutrition facts labels is expressed in both kilojoules and kilocalories, abbreviated as \"kJ\" and \"kcal\" respectively.\nIn China, only kilojoules are given.\nFood energy.\nThe unit is most commonly used to express food energy, namely the specific energy (energy per mass) of metabolizing different types of food. For example, fat (lipids) contains 9 kilocalories per gram (kcal/g), while carbohydrates (sugar and starch) and protein contain approximately 4 kcal/g. Alcohol in food contains 7 kcal/g. The \"large\" unit is also used to express recommended nutritional intake or consumption, as in \"calories per day\".\nDieting is the practice of eating food in a regulated way to decrease, maintain, or increase body weight, or to prevent and treat diseases such as diabetes and obesity. As weight loss depends on reducing caloric intake, different kinds of calorie-reduced diets have been shown to be generally effective.\nChemistry and physics.\nIn other scientific contexts, the term \"calorie\" and the symbol \"cal\" almost always refers to the small unit; the \"large\" unit being generally called \"kilocalorie\" with symbol \"kcal\". It is mostly used to express the amount of energy released in a chemical reaction or phase change, typically per mole of substance, as in kilocalories per mole. It is also occasionally used to specify other energy quantities that relate to reaction energy, such as enthalpy of formation and the size of activation barriers. However, it is increasingly being superseded by the SI unit, the joule (J); and metric multiples thereof, such as the kilojoule (kJ).\nThe lingering use in chemistry is largely due to the fact that the energy released by a reaction in aqueous solution, expressed in kilocalories per mole of reagent, is numerically close to the concentration of the reagent, in moles per liter, multiplied by the change in the temperature of the solution, in kelvin or degrees Celsius. However, this estimate assumes that the volumetric heat capacity of the solution is 1 kcal/L/K, which is not exact even for pure water.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6424", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6424", "title": "Corona Australis", "text": "Constellation in the southern celestial hemisphere\nCorona Australis is a constellation in the Southern Celestial Hemisphere. Its Latin name means \"southern crown\", and it is the southern counterpart of Corona Borealis, the northern crown. It is one of the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations. The Ancient Greeks saw Corona Australis as a wreath rather than a crown and associated it with Sagittarius or Centaurus. Other cultures have likened the pattern to a turtle, ostrich nest, a tent, or even a hut belonging to a rock hyrax.\nAlthough fainter than its northern counterpart, the oval- or horseshoe-shaped pattern of its brighter stars renders it distinctive. Alpha and Beta Coronae Australis are the two brightest stars with an apparent magnitude of around 4.1. Epsilon Coronae Australis is the brightest example of a W Ursae Majoris variable in the southern sky. Lying alongside the Milky Way, Corona Australis contains one of the closest star-forming regions to the Solar System\u2014a dusty dark nebula known as the Corona Australis Molecular Cloud, lying about 430 light years away. Within it are stars at the earliest stages of their lifespan. The variable stars R and TY Coronae Australis light up parts of the nebula, which varies in brightness accordingly.\nName.\nThe name of the constellation was entered as \"Corona Australis\" when the International Astronomical Union (IAU) established the 88 modern constellations in 1922.\nIn 1932, the name was instead recorded as \"Corona Austrina\" when the IAU's commission on notation approved a list of four-letter abbreviations for the constellations.\nThe four-letter abbreviations were repealed in 1955. The IAU presently uses \"Corona Australis\" exclusively.\nCharacteristics.\nCorona Australis is a small constellation bordered by Sagittarius to the north, Scorpius to the west, Telescopium to the south, and Ara to the southwest. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CrA\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of four segments (\"illustrated in infobox\"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between 17h 58.3m and 19h 19.0m, while the declination coordinates are between \u221236.77\u00b0 and \u221245.52\u00b0. Covering 128 square degrees, Corona Australis culminates at midnight around the 30th of June and ranks 80th in area. Only visible at latitudes south of 53\u00b0 north, Corona Australis cannot be seen from the British Isles as it lies too far south, but it can be seen from southern Europe and readily from the southern United States.\nFeatures.\nWhile not a bright constellation, Corona Australis is nonetheless distinctive due to its easily identifiable pattern of stars, which has been described as horseshoe- or oval-shaped. Though it has no stars brighter than 4th magnitude, it still has 21 stars visible to the unaided eye (brighter than magnitude 5.5). Nicolas Louis de Lacaille used the Greek letters Alpha through to Lambda to label the most prominent eleven stars in the constellation, designating two stars as Eta and omitting Iota altogether. Mu Coronae Australis, a yellow star of spectral type G5.5III and apparent magnitude 5.21, was labelled by Johann Elert Bode and retained by Benjamin Gould, who deemed it bright enough to warrant naming.\nStars.\nThe only star in the constellation to have received a name is Alfecca Meridiana or Alpha CrA. The name combines the Arabic name of the constellation with the Latin for \"southern\". In Arabic, \"Alfecca\" means \"break\", and refers to the shape of both Corona Australis and Corona Borealis. Also called simply \"Meridiana\", it is a white main sequence star located 125 light years away from Earth, with an apparent magnitude of 4.10 and spectral type A2Va. A rapidly rotating star, it spins at almost 200\u00a0km per second at its equator, making a complete revolution in around 14 hours. Like the star Vega, it has excess infrared radiation, which indicates it may be ringed by a disk of dust. It is currently a main-sequence star, but will eventually evolve into a white dwarf; currently, it has a luminosity 31 times greater, and a radius and mass of 2.3 times that of the Sun. Beta Coronae Australis is an orange giant 474 light years from Earth. Its spectral type is K0II, and it is of apparent magnitude 4.11. Since its formation, it has evolved from a B-type star to a K-type star. Its luminosity class places it as a bright giant; its luminosity is 730 times that of the Sun, designating it one of the highest-luminosity K0-type stars visible to the naked eye. 100 million years old, it has a radius of 43 solar radii (R\u2609) and a mass of between 4.5 and 5 solar masses (M\u2609). Alpha and Beta are so similar as to be indistinguishable in brightness to the naked eye.\nSome of the more prominent double stars include Gamma Coronae Australis\u2014a pair of yellowish white stars 58 light years away from Earth, which orbit each other every 122 years. Widening since 1990, the two stars can be seen as separate with a 100\u00a0mm aperture telescope; they are separated by 1.3 arcseconds at an angle of 61 degrees. They have a combined visual magnitude of 4.2; each component is an F8V dwarf star with a magnitude of 5.01. Epsilon Coronae Australis is an eclipsing binary belonging to a class of stars known as W Ursae Majoris variables. These star systems are known as contact binaries as the component stars are so close together they touch. Varying by a quarter of a magnitude around an average apparent magnitude of 4.83 every seven hours, the star system lies 98 light years away. Its spectral type is F4VFe-0.8+. At the southern end of the crown asterism are the stars Eta\u00b9 and Eta\u00b2 Coronae Australis, which form an optical double. Of magnitude 5.1 and 5.5, they are separable with the naked eye and are both white. Kappa Coronae Australis is an easily resolved optical double\u2014the components are of apparent magnitudes 6.3 and 5.6 and are about 1000 and 150 light years away respectively. They appear at an angle of 359 degrees, separated by 21.6 arcseconds. Kappa\u00b2 is actually the brighter of the pair and is more bluish white, with a spectral type of B9V, while Kappa\u00b9 is of spectral type A0III. Lying 202 light years away, Lambda Coronae Australis is a double splittable in small telescopes. The primary is a white star of spectral type A2Vn and magnitude of 5.1, while the companion star has a magnitude of 9.7. The two components are separated by 29.2 arcseconds at an angle of 214 degrees.\nZeta Coronae Australis is a rapidly rotating main sequence star with an apparent magnitude of 4.8, 221.7 light years from Earth. The star has blurred lines in its hydrogen spectrum due to its rotation. Its spectral type is B9V. Theta Coronae Australis lies further to the west, a yellow giant of spectral type G8III and apparent magnitude 4.62. Corona Australis harbours RX J1856.5-3754, an isolated neutron star that is thought to lie 140 (\u00b140) parsecs, or 460 (\u00b1130) light years, away, with a diameter of 14\u00a0km. It was once suspected to be a strange star, but this has been discounted.\nCorona Australis Molecular Cloud.\nThe Corona Australis Molecular Cloud is a dark molecular cloud just north of Beta Coronae Australis. Illuminated by a number of embedded reflection nebulae the cloud fans out from Epsilon Coronae Australis eastward along the constellation border with Sagittarius. It contains 7000\u00a0M\u2609, Herbig\u2013Haro objects (protostars) and some very young stars, being one of the closest star-forming regions, 430 light years (130 parsecs) to the Solar System, at the surface of the Local Bubble. The first nebulae of the cloud were recorded in 1865 by Johann Friedrich Julius Schmidt.\nBetween Epsilon and Gamma Coronae Australis the cloud consists of the particular dark nebula and star forming region Bernes 157. It is 55 by 18 arcminutes wide and possesses several stars around magnitude 13. These stars are dimmed by up to 8 magnitudes because of the obscuring dust clouds. At the center of the active star-forming region lies the Coronet cluster (also called R CrA Cluster), which is used in studying star and protoplanetary disk formation. R Coronae Australis (R CrA) is an irregular variable star ranging from magnitudes 9.7 to 13.9. Blue-white, it is of spectral type B5IIIpe. A very young star, it is still accumulating interstellar material. It is obscured by, and illuminates, the surrounding nebula, NGC 6729, which brightens and darkens with it. The nebula is often compared to a comet for its appearance in a telescope, as its length is five times its width. Other stars of the cluster include S Coronae Australis, a G-class dwarf and T Tauri star.\nNearby north, another young variable star, TY Coronae Australis, illuminates another nebula: reflection nebula NGC 6726/NGC 6727. TY Coronae Australis ranges irregularly between magnitudes 8.7 and 12.4, and the brightness of the nebula varies with it. Blue-white, it is of spectral type B8e. The largest young stars in the region, R, S, T, TY and VV Coronae Australis, are all ejecting jets of material which cause surrounding dust and gas to coalesce and form Herbig\u2013Haro objects, many of which have been identified nearby.\nNot part of it is the globular cluster known as NGC 6723, which can be seen adjacent to the nebulosity in the neighbouring constellation of Sagittarius, but is much much further away.\nDeep sky objects.\nIC 1297 is a planetary nebula of apparent magnitude 10.7, which appears as a green-hued roundish object in higher-powered amateur instruments. The nebula surrounds the variable star RU Coronae Australis, which has an average apparent magnitude of 12.9 and is a WC class Wolf\u2013Rayet star. IC 1297 is small, at only 7 arcseconds in diameter; it has been described as \"a square with rounded edges\" in the eyepiece, elongated in the north\u2013south direction. Descriptions of its color encompass blue, blue-tinged green, and green-tinged blue.\nCorona Australis' location near the Milky Way means that galaxies are uncommonly seen. NGC 6768 is a magnitude 11.2 object 35\u2032 south of IC 1297. It is made up of two galaxies merging, one of which is an elongated elliptical galaxy of classification E4 and the other a lenticular galaxy of classification S0. IC 4808 is a galaxy of apparent magnitude 12.9 located on the border of Corona Australis with the neighbouring constellation of Telescopium and 3.9 degrees west-southwest of Beta Sagittarii. However, amateur telescopes will only show a suggestion of its spiral structure. It is 1.9 arcminutes by 0.8 arcminutes. The central area of the galaxy does appear brighter in an amateur instrument, which shows it to be tilted northeast\u2013southwest.\nSoutheast of Theta and southwest of Eta lies the open cluster ESO 281-SC24, which is composed of the yellow 9th magnitude star GSC 7914 178 1 and five 10th to 11th magnitude stars. Halfway between Theta Coronae Australis and Theta Scorpii is the dense globular cluster NGC 6541. Described as between magnitude 6.3 and magnitude 6.6, it is visible in binoculars and small telescopes. Around 22000 light years away, it is around 100 light years in diameter. It is estimated to be around 14 billion years old. NGC 6541 appears 13.1 arcminutes in diameter and is somewhat resolvable in large amateur instruments; a 12-inch telescope reveals approximately 100 stars but the core remains unresolved.\nMeteor showers.\nThe Corona Australids are a meteor shower that takes place between 14 and 18 March each year, peaking around 16 March. This meteor shower does not have a high peak hourly rate. In 1953 and 1956, observers noted a maximum of 6 meteors per hour and 4 meteors per hour respectively; in 1955 the shower was \"barely resolved\". However, in 1992, astronomers detected a peak rate of 45 meteors per hour. The Corona Australids' rate varies from year to year. At only six days, the shower's duration is particularly short, and its meteoroids are small; the stream is devoid of large meteoroids. The Corona Australids were first seen with the unaided eye in 1935 and first observed with radar in 1955. Corona Australid meteors have an entry velocity of 45 kilometers per second. In 2006, a shower originating near Beta Coronae Australis was designated as the Beta Coronae Australids. They appear in May, the same month as a nearby shower known as the May Microscopids, but the two showers have different trajectories and are unlikely to be related.\nHistory.\nCorona Australis may have been recorded by ancient Mesopotamians in the MUL.APIN, as a constellation called MA.GUR (\"The Bark\"). However, this constellation, adjacent to SUHUR.MASH (\"The Goat-Fish\", modern Capricornus), may instead have been modern Epsilon Sagittarii. As a part of the southern sky, MA.GUR was one of the fifteen \"stars of Ea\".\nIn the 3rd century BC, the Greek didactic poet Aratus wrote of, but did not name the constellation, instead calling the two crowns \u03a3\u03c4\u03b5\u03c6\u03ac\u03bd\u03bf\u03b9 (\"Stephanoi\"). The Greek astronomer Ptolemy described the constellation in the 2nd century AD, though with the inclusion of Alpha Telescopii, since transferred to Telescopium. Ascribing 13 stars to the constellation, he named it \u03a3\u03c4\u03b5\u03c6\u03ac\u03bd\u03bf\u03c2 \u03bd\u03bf\u03c4\u03b9\u03bf\u03c2 (), \"Southern Wreath\", while other authors associated it with either Sagittarius (having fallen off his head) or Centaurus; with the former, it was called \"Corona Sagittarii\". Similarly, the Romans called Corona Australis the \"Golden Crown of Sagittarius\". It was known as \"Parvum Coelum\" (\"Canopy\", \"Little Sky\") in the 5th century. The 18th-century French astronomer J\u00e9r\u00f4me Lalande gave it the names \"Sertum Australe\" (\"Southern Garland\") and \"Orbiculus Capitis\", while German poet and author Philippus Caesius called it \"Corolla\" (\"Little Crown\") or \"Spira Australis\" (\"Southern Coil\"), and linked it with the Crown of Eternal Life from the New Testament. Seventeenth-century celestial cartographer Julius Schiller linked it to the Diadem of Solomon. Sometimes, Corona Australis was not the wreath of Sagittarius but arrows held in his hand.\nCorona Australis has been associated with the myth of Bacchus and Stimula. Jupiter had impregnated Stimula, causing Juno to become jealous. Juno convinced Stimula to ask Jupiter to appear in his full splendor, which the mortal woman could not handle, causing her to burn. After Bacchus, Stimula's unborn child, became an adult and the god of wine, he honored his deceased mother by placing a wreath in the sky.\nIn Chinese astronomy, the stars of Corona Australis are located within the Black Tortoise of the North (\u5317\u65b9\u7384\u6b66, \"B\u011bi F\u0101ng Xu\u00e1n W\u01d4\"). The constellation itself was known as \"ti'en pieh\" (\"Heavenly Turtle\") and during the Western Zhou period, marked the beginning of winter. However, precession over time has meant that the \"Heavenly River\" (Milky Way) became the more accurate marker to the ancient Chinese and hence supplanted the turtle in this role. Arabic names for Corona Australis include \"Al \u0136ubbah\" \"the Tortoise\", \"Al \u0124ib\u0101\" \"the Tent\" or \"Al Ud\u1e25\u0101 al Na'\u0101m\" \"the Ostrich Nest\". It was later given the name \"Al Ikl\u012bl al Jan\u016bbiyyah\", which the European authors Chilmead, Riccioli and Caesius transliterated as Alachil Elgenubi, Elkleil Elgenubi and Aladil Algenubi respectively.\nThe \u01c0Xam speaking San people of South Africa knew the constellation as \"\u2260nabbe ta !nu\" \"house of branches\"\u2014owned originally by the Dassie (rock hyrax), and the star pattern depicting people sitting in a semicircle around a fire.\nThe indigenous Boorong people of northwestern Victoria saw it as \"Won\", a boomerang thrown by \"Totyarguil\" (Altair). The Aranda people of Central Australia saw Corona Australis as a coolamon carrying a baby, which was accidentally dropped to earth by a group of sky-women dancing in the Milky Way. The impact of the coolamon created Gosses Bluff crater, 175\u00a0km west of Alice Springs. The Torres Strait Islanders saw Corona Australis as part of a larger constellation encompassing part of Sagittarius and the tip of Scorpius's tail; the Pleiades and Orion were also associated. This constellation was Tagai's canoe, crewed by the Pleiades, called the \"Usiam\", and Orion, called the \"Seg\". The myth of Tagai says that he was in charge of this canoe, but his crewmen consumed all of the supplies onboard without asking permission. Enraged, Tagai bound the Usiam with a rope and tied them to the side of the boat, then threw them overboard. Scorpius's tail represents a suckerfish, while Eta Sagittarii and Theta Coronae Australis mark the bottom of the canoe. On the island of Futuna, the figure of Corona Australis was called \"Tanuma\" and in the Tuamotus, it was called \"Na Kaua-ki-Tonga\".\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n\"SIMBAD\"\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 19h 00m 00s, \u221240\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6426", "revid": "1153058020", "url": "https://en.wikipedia.org/wiki?curid=6426", "title": "Corcovado", "text": "Mountain in Rio de Janeiro, home to Christ the Redeemer\nCorcovado (]) which means \"hunchback\" in Portuguese, is a mountain in central Rio de Janeiro, Brazil. It is a 710-metre (2,329\u00a0ft) granite peak located in the Tijuca Forest, a national park.\nCorcovado hill lies just west of the city center but is wholly within the city limits and visible from great distances. It is known worldwide for the statue of Jesus atop its peak, entitled \"Christ the Redeemer\".\nAccess.\nThe peak and statue can be accessed via a narrow road, by the Corcovado Rack Railway, which was opened in 1884 and refurbished in 1980, or by the walking trail on the south side of the mountain that starts from Parque Lage. The railway uses three electrically powered trains, with a capacity of 540 passengers per hour. The rail trip takes approximately 20 minutes and departs every 20 minutes. Due to its limited passenger capacity, the wait to board at the entry station can take several hours. The year-round schedule is 8:30 to 18:30.\nFrom the train terminus and road, the observation deck at the foot of the statue is reached by 223 steps, or by elevators and escalators. Among the most popular year-round tourist attractions in Rio de Janeiro, the Corcovado railway, access roads, and statue platform are commonly crowded.\nAttractions.\nCorcovado's most popular attraction is the statue depicting Jesus at its peak, entitled \"Christ the Redeemer\" (\"),\" and the viewing platform at its peak, drawing over 300,000 visitors per year. The statue was constructed from 1922 to 1931. From the peak's platform the panoramic view includes downtown Rio de Janeiro, Sugarloaf Mountain, the Rodrigo de Freitas lagoon, Copacabana and Ipanema beaches, Maracan\u00e3 Stadium, and several of Rio de Janeiro's favelas. Cloud cover is common in Rio and the view from the platform is often obscured. Sunny days are recommended for optimal viewing.\nNotable past visitors to the mountain peak include Charles Darwin, Pope Pius XII, Pope John Paul II, Alberto Santos-Dumont, Albert Einstein, Diana, Princess of Wales, and General Sherman, among others. An additional attraction of the mountain is rock climbing. The south face had 54 climbing routes in 1992. The easiest way starts from Parque Lage.\nGeology.\nThe peak of Corcovado is a big granite dome, which describes a generally vertical rocky formation. It is claimed to be the highest such formation in Brazil, the second highest being Pedra Agulha, situated near the town of Pancas in Esp\u00edrito Santo.\nReferences in Brazilian culture.\nCorcovado is considered an icon of Brazilian culture. \"Corcovado\" is a 1960 bossa nova song and jazz standard by Ant\u00f4nio Carlos Jobim whose lyrics draw on images of the hill. Corcovado has also been referenced in other artistic works (e.g. the lyrics of Ben Harper, literary works, films, etc.).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6427", "revid": "14264656", "url": "https://en.wikipedia.org/wiki?curid=6427", "title": "Cheddar, Somerset", "text": "Cheddar is a large village and civil parish in the English county of Somerset. It is situated on the southern edge of the Mendip Hills, north-west of Wells, south-east of Weston-super-Mare and south-west of Bristol. The civil parish includes the hamlets of Nyland and Bradley Cross. The parish had a population of 5,755 in 2011 and an acreage of as of 1961.\nCheddar Gorge, on the northern edge of the village, is the largest gorge in the United Kingdom and includes several show caves, including Gough's Cave. The gorge has been a centre of human settlement since Neolithic times, including a Saxon palace. It has a temperate climate and provides a unique geological and biological environment that has been recognised by the designation of several Sites of Special Scientific Interest. It is also the site of several limestone quarries. The village gave its name to Cheddar cheese and has been a centre for strawberry growing. The crop was formerly transported on the Cheddar Valley rail line, which closed in the late 1960s but is now a cycle path. The village is now a major tourist destination with several cultural and community facilities, including the Cheddar Show Caves Museum.\nThe village supports a variety of community groups including religious, sporting and cultural organisations. Several of these are based on the site of the Kings of Wessex Academy, which is the largest educational establishment.\nHistory.\nThe name Cheddar comes from the Old English word \"ceodor\", meaning deep dark cavity or pouch.\nThere is evidence of occupation from the Neolithic period in Cheddar. Britain's oldest complete human skeleton, Cheddar Man, estimated to be 9,000 years old, was found in Cheddar Gorge in 1903. Older remains from the Upper Late Palaeolithic era (12,000\u201313,000 years ago) have been found. There is some evidence of a Bronze Age field system at the Batts Combe quarry site. There is also evidence of Bronze Age barrows at the mound in the Longwood valley, which if man-made it is likely to be a field system. The remains of a Roman villa have been excavated in the grounds of the current vicarage.\nThe village of Cheddar had been important during the Roman and Saxon eras. There was a royal palace at Cheddar during the Saxon period, which was used on three occasions in the 10th century to host the Witenagemot. The ruins of the palace were excavated in the 1960s. They are located on the grounds of the Kings of Wessex Academy, together with a 14th-century chapel dedicated to St. Columbanus. Roman remains have also been uncovered at the site. Cheddar was listed in the Domesday Book of 1086 as \"Ceder\", meaning \"Shear Water\", from the Old English \"scear\" and Old Welsh \"d\u0175r\". An alternative spelling in earlier documents, common through the 1850s is \"Chedder\".\nAs early as 1130\u00a0AD, the Cheddar Gorge was recognised as one of the \"Four wonders of England\". Historically, Cheddar's source of wealth was farming and cheese making for which it was famous as early as 1170\u00a0AD. The parish was part of the Winterstoke Hundred.\nThe manor of Cheddar was deforested in 1337 and Bishop Ralph was granted a licence by the King to create a hunting forest.\nAs early as 1527 there are records of watermills on the river. In the 17th and 18th centuries, there were several watermills which ground corn and made paper, with 13 mills on the Yeo at the peak, declining to seven by 1791 and just three by 1915. In the Victorian era it also became a centre for the production of clothing. The last mill, used as a shirt factory, closed in the early 1950s.\nWilliam Wilberforce saw the poor conditions of the locals when he visited Cheddar in 1789. He inspired Hannah More in her work to improve the conditions of the Mendip miners and agricultural workers. In 1801, of common land were enclosed under the Inclosure Acts.\nTourism of the Cheddar gorge and caves began with the opening of the Cheddar Valley Railway in 1869.\nCheddar, its surrounding villages and specifically the gorge has been subject to flooding. In the Chew Stoke flood of 1968 the flow of water washed large boulders down the gorge, washed away cars, and damaged the cafe and the entrance to Gough's Cave.\nGovernment.\nCheddar is recognised as a village. The adjacent settlement of Axbridge, although only about a third the population of Cheddar, is a town. This apparently illogical situation is explained by the relative importance of the two places in historic times. While Axbridge grew in importance as a centre for cloth manufacturing in the Tudor period and gained a charter from King John, Cheddar remained a more dispersed mining and dairy-farming village. Its population grew with the arrival of the railways in the Victorian era and the advent of tourism.\nThe parish council, which has 15 members who are elected for four years, is responsible for local issues, including setting an annual precept (local rate) to cover the council's operating costs and producing annual accounts for public scrutiny. The parish council evaluates local planning applications and works with the police, district council officers, and neighbourhood watch groups on matters of crime, security, and traffic. The parish council's role also includes initiating projects for the maintenance and repair of parish facilities, as well as consulting with the district council on the maintenance, repair, and improvement of highways, drainage, footpaths, public transport, and street cleaning. Conservation matters (including trees and listed buildings) and environmental issues are also the responsibility of the council.\nThe village is in the 'Cheddar and Shipham' electoral ward. After including Shipham the total population of the ward taken at the 2011 census is 6,842.\nFor local government purposes, since 1 April 2023, the village comes under the unitary authority of Somerset Council. Prior to this, it was part of the non-metropolitan district of Sedgemoor, which was formed on 1 April 1974 under the Local Government Act 1972, having previously been part of Axbridge Rural District. Fire, police and ambulance services are provided jointly with other authorities through the Devon and Somerset Fire and Rescue Service, Avon and Somerset Constabulary and the South Western Ambulance Service.\nIt is also part of the Wells county constituency represented in the House of Commons of the Parliament of the United Kingdom. It elects one Member of Parliament (MP) by the first past the post system of election. Prior to Brexit in 2020, it was part of the South West England constituency of the European Parliament.\nInternational relations.\nCheddar is twinned with Felsberg, Germany and Vernouillet, France, and it has an active programme of exchange visits. Initially, Cheddar twinned with Felsberg in 1984. In 2000, Cheddar twinned with Vernouillet, which had also been twinned with Felsberg. Cheddar also has a friendship link with Ocho Rios in Saint Ann Parish, Jamaica.\nIt is also twinned with the commune of Descartes in the Indre-et-Loire department.\nGeography.\nThe area is underlain by Black Rock slate, Burrington Oolite and Clifton Down Limestone of the Carboniferous Limestone Series, which contain ooliths and fossil debris on top of Old Red Sandstone, and by Dolomitic Conglomerate of the Keuper. Evidence for Variscan orogeny is seen in the sheared rock and cleaved shales. In many places weathering of these strata has resulted in the formation of immature calcareous soils.\nGorge and caves.\nCheddar Gorge, which is located on the edge of the village, is the largest gorge in the United Kingdom.\nThe gorge is the site of the Cheddar Caves, where Cheddar Man was found in 1903. Older remains from the Upper Late Palaeolithic era (12,000\u201313,000 years ago) have been found. The caves, produced by the activity of an underground river, contain stalactites and stalagmites. Gough's Cave, which was discovered in 1903, leads around into the rock-face, and contains a variety of large rock chambers and formations. Cox's Cave, discovered in 1837, is smaller but contains many intricate formations. A further cave houses a children's entertainment walk known as the \"Crystal Quest\".\nCheddar Gorge, including Cox's Cave, Gough's Cave and other attractions, has become a tourist destination, attracting about 500,000 visitors per year.\nIn a 2005 poll of \"Radio Times\" readers, following its appearance on the 2005 television programme \"Seven Natural Wonders\", Cheddar Gorge was named as the second greatest natural wonder in Britain, surpassed only by the Dan yr Ogof caves.\nSites of Special Scientific Interest.\nThere are several large and unique Sites of Special Scientific Interest (SSSI) around the village.\nCheddar Reservoir is a near-circular artificial reservoir operated by Bristol Water. Dating from the 1930s, it has a capacity of 135\u00a0million\u00a0gallons (614,000\u00a0cubic\u00a0metres). The reservoir is supplied with water taken from the Cheddar Yeo, which rises in Gough's Cave in Cheddar Gorge and is a tributary of the River Axe. The inlet grate for the water pipe that is used to transport the water can be seen next to the sensory garden in Cheddar Gorge. It has been designated as a Site of Special Scientific Interest (SSSI) due to its wintering waterfowl populations.\nCheddar Wood and the smaller Macall's Wood form a biological Site of Special Scientific Interest from what remains of the wood of the Bishops of Bath and Wells in the 13th century and of King Edmund the Magnificent's wood in the 10th. During the 19th century, its lower fringes were grubbed out to make strawberry fields. Most of these have been allowed to revert to woodland. The wood was coppiced until 1917. This site compromises a wide range of habitats which include ancient and secondary semi-natural broadleaved woodland, unimproved neutral grassland, and a complex mosaic of calcareous grassland and acidic dry dwarf-shrub heath. Cheddar Wood is one of only a few English stations for starved wood-sedge (\"Carex depauperata\"). Purple gromwell (\"Lithospermum purpurocaeruleum\"), a nationally rare plant, also grows in the wood. Butterflies include silver-washed fritillary (\"Argynnis paphia\"), dark green fritillary (\"Argynnis aglaja\"), pearl-bordered fritillary (\"Boloria euphrosyne\"), holly blue (\"Celastrina argiolus\") and brown argus (\"Aricia agestis\"). The slug \"Arion fasciatus\", which has a restricted distribution in the south of England, and the soldier beetle \"Cantharis fusca\" also occur.\nBy far the largest of the SSSIs is called Cheddar Complex and covers of the gorge, caves and the surrounding area. It is important because of both biological and geological features. It includes four SSSIs, formerly known as Cheddar Gorge SSSI, August Hole/Longwood Swallet SSSI, GB Cavern Charterhouse SSSI and Charterhouse on-Mendip SSSI. It is partly owned by the National Trust who acquired it in 1910 and partly managed by the Somerset Wildlife Trust.\nQuarries.\nClose to the village and gorge are Batts Combe quarry and Callow Rock quarry, two of the active Quarries of the Mendip Hills where limestone is still extracted. Operating since the early 20th century, Batts Combe is owned and operated by Hanson Aggregates. The output in 2005 was around 4,000 tonnes of limestone per day, one third of which was supplied to an on-site lime kiln, which closed in 2009; the remainder was sold as coated or dusted aggregates. The limestone at this site is close to 99\u00a0percent carbonate of calcium and magnesium (dolomite).\nThe Chelmscombe Quarry finished its work as a limestone quarry in the 1950s and was then used by the Central Electricity Generating Board as a tower testing station. During the 1970s and 1980s it was also used to test the ability of containers of radioactive material to withstand impacts and other accidents.\nClimate.\nAlong with the rest of South West England, Cheddar has a temperate climate which is generally wetter and milder than the rest of the country. The annual mean temperature is approximately . Seasonal temperature variation is less extreme than most of the United Kingdom because of the adjacent sea, which moderates temperature. The summer months of July and August are the warmest with mean daily maxima of approximately . In winter mean minimum temperatures of or are common. In the summer the Azores high-pressure system affects the south-west of England. Convective cloud sometimes forms inland, reducing the number of hours of sunshine; annual sunshine rates are slightly less than the regional average of 1,600\u00a0hours. Most of the rainfall in the south-west is caused by Atlantic depressions or by convection. Most of the rainfall in autumn and winter is caused by the Atlantic depressions, which are most active during those seasons. In summer, a large proportion of the rainfall is caused by sun heating the ground leading to convection and to showers and thunderstorms. Average rainfall is around . About 8\u201315 days of snowfall per year is typical. November to March have the highest mean wind speeds, and June to August have the lightest winds. The predominant wind direction is from the south-west.\nDemography.\nThe parish has a population in 2011 of 5,093, with a mean age of 43 years. Residents lived in 2,209 households. The vast majority of households (2,183) gave their ethnic status at the 2001 census as white.\nEconomy.\nThe village gave its name to Cheddar cheese, which is the most popular type of cheese in the United Kingdom. The cheese is now made and consumed worldwide, and only one producer remains in the village.\nSince the 1880s, Cheddar's other main produce has been the strawberry,\nwhich is grown on the south-facing lower slopes of the Mendip hills. As a consequence of its use for transporting strawberries to market, the since-closed Cheddar Valley line became known as \"The Strawberry Line\" after it opened in 1869.\nThe line ran from Yatton to Wells. When the rest of the line was closed and all passenger services ceased, the section of the line between Cheddar and Yatton remained open for goods traffic. It provided a fast link with the main markets for the strawberries in Birmingham and London, but finally closed in 1964, becoming part of the Cheddar Valley Railway Nature Reserve.\nCheddar Ales is a small brewery based in the village, producing beer for local public houses. Tourism is a significant source of employment. Around 15\u00a0percent of employment in Sedgemoor is provided by tourism, but within Cheddar it is estimated to employ as many as 1,000 people.\nThe village also has a youth hostel, and a number of camping and caravan sites.\nCulture and community.\nCheddar has a number of active service clubs including Cheddar Vale Lions Club, Mendip Rotary and Mendip Inner Wheel Club. The clubs raise money for projects in the local community and hold annual events such as a fireworks display, duck races in the Gorge, a dragon boat race on the reservoir and concerts on the grounds of the nearby St Michael's Cheshire Home.\nSeveral notable people have been born or lived in Cheddar. Musician Jack Bessant, the bass guitarist with the band Reef grew up on his parents' strawberry farm, and Matt Goss and Luke Goss, former members of Bros, lived in Cheddar for nine months as children. Trina Gulliver, ten-time World Professional Darts Champion, previously lived in Cheddar until 2017. The comedian Richard Herring grew up in Cheddar. His 2008 Edinburgh Festival Fringe show, \"The Headmaster's Son\" is based on his time at The Kings of Wessex School, where his father Keith was the headmaster. The final performance of this show was held at the school in November 2009. He also visited the school in March 2010 to perform his show \"Hitler Moustache\". In May 2013, a community radio station called Pulse was launched.\nLandmarks.\nThe market cross in Bath Street dates from the 15th century, with the shelter having been rebuilt in 1834. It has a central octagonal pier, a socket raised on four steps, a hexagonal shelter with six arched four-centred openings, shallow two-stage buttresses at each angle, and an embattled parapet. The shaft is crowned by an abacus with figures in niches, probably from the late 19th century, although the cross is now missing. It was rebuilt by Thomas, Marquess of Bath. It is a scheduled monument (Somerset County No\u00a021) and Grade\u00a0II* listed building.\nIn January 2000, the cross was seriously damaged in a traffic accident. By 2002, the cross had been rebuilt and the area around it was redesigned to protect and enhance its appearance.\nThe cross was badly damaged again in March 2012, when a taxi crashed into it late at night demolishing two sides.\nRepair work, which included the addition of wooden-clad steel posts to protect against future crashes, was completed in November 2012 at a cost of \u00a360,000.\nHannah More, a philanthropist and educator, founded a school in the village in the late 18th century for the children of miners. Her first school was located in a 17th-century house. Now named \"Hannah More's Cottage\", the Grade II-listed building is used by the local community as a meeting place.\nTransport.\nThe village is situated on the A371 road which runs from Wincanton, to Weston-super-Mare. It is approximately from the route of the M5 motorway with around a drive to junction 22.\nIt was on the Cheddar Valley line, a railway line that was opened in 1869 and closed in 1963. It became known as The Strawberry Line because of the large volume of locally-grown strawberries that it carried. It ran from Yatton railway station through Cheddar to Wells (Tucker Street) railway station and joined the East Somerset Railway to make a through route via Shepton Mallet (High Street) railway station to Witham. Sections of the now-disused railway have been opened as the Strawberry Line Trail, which currently runs from Yatton to Cheddar. The Cheddar Valley line survived until the \"Beeching Axe\". Towards the end of its life there were so few passengers that diesel railcars were sometimes used. The Cheddar branch closed to passengers on 9 September 1963 and to goods in 1964. The line closed in the 1960s, when it became part of the Cheddar Valley Railway Nature Reserve, and part of the National Cycle Network route\u00a026. The cycle route also intersects with the West Mendip Way and various other footpaths.\nThe principle bus route is hourly service 126 between Weston-super-Mare and Wells operated by First West of England. Other bus routes include the service 668 from Shipham to Street which runs every couple of hours operated by Libra Travel, as well as the college bus service 66 which runs from Axbridge to the Bridgwater Campus of Bridgwater and Taunton College in the mornings and evenings of college term times and is operated by Bakers Dolphin.\nEducation.\nThe first school in Cheddar was set up by Hannah More during the 18th Century, however now Cheddar has three schools belonging to the Cheddar Valley Group of Schools, twelve schools that provide Cheddar Valley's three-tier education system. Cheddar First School has ten classes for children between 4 and 9 years. Fairlands Middle School, a middle school categorised as a middle-deemed-secondary school, has 510 pupils between 9 and 13. Fairlands takes children moving up from Cheddar First School as well as other first schools in the Cheddar Valley. The Kings of Wessex Academy, a coeducational comprehensive school, has been rated as \"good\" by Ofsted. It has 1,176 students aged 13 to 18, including 333 in the sixth form. Kings is a faith school linked to the Church of England. It was awarded the specialist status of Technology College in 2001, enabling it to develop its Information Technology (IT) facilities and improve courses in science, mathematics and design technology. In 2007 it became a foundation school, giving it more control over its own finances. The academy owns and runs a sports centre and swimming pool, Kings Fitness &amp; Leisure, with facilities that are used by students as well as residents. It has since November 2016 been a part of the Wessex Learning Trust which incorporates eight academies from the surrounding area.\nReligious sites.\nThe Church of St Andrew dates from the 14th century. It was restored in 1873 by William Butterfield. It is a Grade\u00a0I listed building and contains some 15th-century stained glass and an altar table of 1631. The chest tomb in the chancel is believed to contain the remains of Sir Thomas Cheddar and is dated 1442. The tower, which rises to , contains a bell dating from 1759 made by Thomas Bilbie of the Bilbie family. The graveyard contains the grave of the hymn writer William Chatterton Dix.\nThere are also churches for Roman Catholic, Methodist and other denominations, including Cheddar Valley Community Church, who not only meet at the Kings of Wessex School on Sunday, but also have their own site on Tweentown for meeting during the week. The Baptist chapel was built in 1831.\nSport.\nKings Fitness &amp; Leisure, situated on the grounds of the Kings of Wessex School, provides a venue for various sports and includes a 20-metre swimming pool, racket sport courts, a sports hall, dance studios and a gym. A youth sports festival was held on Sharpham Road Playing Fields in 2009. In 2010 a skatepark was built in the village, funded by the Cheddar Local Action Team.\nCheddar A.F.C., founded in 1892 and nicknamed \"The Cheesemen\", play in the Western Football League Division One. In 2009 plans were revealed to move the club from its present home at Bowdens Park on Draycott Road to a new larger site.\nCheddar Cricket Club was formed in the late 19th century and moved to Sharpham Road Playing Fields in 1964. They now play in the West of England Premier League Somerset Division. Cheddar Rugby Club, who own part of the Sharpham playing fields, was formed in 1836. The club organises an annual Cheddar Rugby Tournament. Cheddar Lawn Tennis Club, was formed in 1924, and play in the North Somerset League and also has social tennis and coaching. Cheddar Running Club organised an annual half marathon until 2009.\nThe village is both on the route of the West Mendip Way and Samaritans Way South West.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6429", "revid": "27584338", "url": "https://en.wikipedia.org/wiki?curid=6429", "title": "Compact disc", "text": "Digital optical disc data storage format\nThe compact disc (CD) is a digital optical disc data storage format that was co-developed by Philips and Sony to store and play digital audio recordings. In August 1982, the first compact disc was manufactured. It was then released in October 1982 in Japan and branded as \"Digital Audio Compact Disc\". It was released on March 2, 1983 in North America and Europe.\nThe format was later adapted (as CD-ROM) for general-purpose data storage. Several other formats were further derived, including write-once audio and data storage (CD-R), rewritable media (CD-RW), Video CD (VCD), Super Video CD (SVCD), Photo CD, Picture CD, Compact Disc-Interactive (CD-i) and Enhanced Music CD.\nStandard CDs have a diameter of and are designed to hold up to 74 minutes of uncompressed stereo digital audio or about 650\u00a0MiB of data. Capacity is routinely extended to 80 minutes and 700\u00a0MiB by arranging data more closely on the same-sized disc. The Mini CD has various diameters ranging from ; they are sometimes used for CD singles, storing up to 24 minutes of audio, or delivering device drivers.\nAt the time of the technology's introduction in 1982, a CD could store much more data than a personal computer hard disk drive, which would typically hold 10 MiB. By 2010, hard drives commonly offered as much storage space as a thousand CDs, while their prices had plummeted to commodity levels. In 2004, worldwide sales of audio CDs, CD-ROMs, and CD-Rs reached about 30 billion discs. By 2007, 200 billion CDs had been sold worldwide.\nPhysical details.\nA CD is made from thick, polycarbonate plastic, and weighs 14\u201333 grams. From the center outward, components are: the center spindle hole (15\u00a0mm), the first-transition area (clamping ring), the clamping area (stacking ring), the second-transition area (mirror band), the program (data) area, and the rim. The inner program area occupies a radius from 25 to 58\u00a0mm.\nA thin layer of aluminum or, more rarely, gold is applied to the surface, making it reflective. The metal is protected by a film of lacquer normally spin coated directly on the reflective layer. The label is printed on the lacquer layer, usually by screen printing or offset printing.\nCD data is represented as tiny indentations known as \"pits\", encoded in a spiral track moulded into the top of the polycarbonate layer. The areas between pits are known as \"lands\". Each pit is approximately 100\u00a0nm deep by 500\u00a0nm wide, and varies from 850\u00a0nm to 3.5\u00a0\u00b5m in length. The distance between the tracks (the \"pitch\") is 1.6\u00a0\u00b5m.\nWhen playing an audio CD, a motor within the CD player spins the disc to a scanning velocity of 1.2\u20131.4\u00a0m/s (constant linear velocity, CLV)\u2014equivalent to approximately 500 RPM at the inside of the disc, and approximately 200 RPM at the outside edge. The track on the CD begins at the inside and spirals outward so a disc played from beginning to end slows its rotation rate during playback.\nThe program area is 86.05\u00a0cm2 and the length of the recordable spiral is 86.05\u00a0cm2 / 1.6 \u00b5m \n 5.38\u00a0km. With a scanning speed of 1.2\u00a0m/s, the playing time is 74 minutes or 650\u00a0MiB of data on a CD-ROM. A disc with data packed slightly more densely is tolerated by most players (though some old ones fail). Using a linear velocity of 1.2\u00a0m/s and a narrower track pitch of 1.5\u00a0\u00b5m increases the playing time to 80 minutes, and data capacity to 700\u00a0MiB.\nA CD is read by focusing a 780\u00a0nm wavelength (near infrared) semiconductor laser through the bottom of the polycarbonate layer. The change in height between pits and lands results in a difference in the way the light is reflected. Because the pits are indented into the top layer of the disc and are read through the transparent polycarbonate base, the pits form bumps when read. The laser hits the disc, casting a circle of light wider than the modulated spiral track reflecting partially from the lands and partially from the top of any bumps where they are present. As the laser passes over a pit (bump), its height means that the part of the light reflected from its peak is 1/2 wavelength out of phase with the light reflected from the land around it. This causes partial cancellation of the laser's reflection from the surface. By measuring the reflected intensity change with a photodiode, a modulated signal is read back from the disc.\nTo accommodate the spiral pattern of data, the laser is placed on a mobile mechanism within the disc tray of any CD player. This mechanism typically takes the form of a sled that moves along a rail. The sled can be driven by a worm gear or linear motor. Where a worm gear is used, a second shorter-throw linear motor, in the form of a coil and magnet, makes fine position adjustments to track eccentricities in the disk at high speed. Some CD drives (particularly those manufactured by Philips during the 1980s and early 1990s) use a swing arm similar to that seen on a gramophone. This mechanism allows the laser to read information from the center to the edge of a disc without having to interrupt the spinning of the disc itself.\nThe pits and lands do \"not\" directly represent the 0s and 1s of binary data. Instead, non-return-to-zero, inverted encoding is used: a change from either pit to land or land to pit indicates a 1, while no change indicates a series of 0s. There must be at least two, and no more than ten 0s between each 1, which is defined by the length of the pit. This, in turn, is decoded by reversing the eight-to-fourteen modulation used in mastering the disc, and then reversing the cross-interleaved Reed\u2013Solomon coding, finally revealing the raw data stored on the disc. These encoding techniques (defined in the \"Red Book\") were originally designed for CD Digital Audio, but they later became a standard for almost all CD formats (such as CD-ROM).\nIntegrity.\nCDs are susceptible to damage during handling and from environmental exposure. Pits are much closer to the label side of a disc, enabling defects and contaminants on the clear side to be out of focus during playback. Consequently, CDs are more likely to suffer damage on the label side of the disc. Scratches on the clear side can be repaired by refilling them with similar refractive plastic or by careful polishing. The edges of CDs are sometimes incompletely sealed, allowing gases and liquids to enter the CD and corrode the metal reflective layer and/or interfere with the focus of the laser on the pits, a condition known as disc rot. The fungus \"Geotrichum candidum\" has been found\u2014under conditions of high heat and humidity\u2014to consume the polycarbonate plastic and aluminium found in CDs.\nThe data integrity of compact discs can be measured using surface error scanning, which can measure the rates of different types of data errors, known as \"C1\", \"C2\", \"CU\" and extended (finer-grain) error measurements known as \"E11\", \"E12\", \"E21\", \"E22\", \"E31\" and \"E32\", of which higher rates indicate a possibly damaged or unclean data surface, low media quality, deteriorating media and recordable media written to by a malfunctioning CD writer.\nError scanning can reliably predict data losses caused by media deterioration. Support of error scanning differs between vendors and models of optical disc drives, and \"extended\" error scanning (known as \"advanced error scanning\" in Nero DiscSpeed) has only been available on Plextor and some BenQ optical drives so far, as of 2020.\nDisc shapes and diameters.\nThe digital data on a CD begins at the center of the disc and proceeds toward the edge, which allows adaptation to the different sizes available. Standard CDs are available in two sizes. By far, the most common is in diameter, with a 74- or 80-minute audio capacity and a 650 or 700\u00a0MiB (737,280,000-byte) data capacity. Discs are thick, with a center hole. The size of the hole was chosen by Joop Sinjou and based on a Dutch 10-cent coin: a dubbeltje. Philips/Sony patented the physical dimensions.\nThe official Philips history says the capacity was specified by Sony executive Norio Ohga to be able to contain the entirety of Beethoven's Ninth Symphony on one disc. \n This is a myth according to Kees Immink, as the EFM code format had not yet been decided in December 1979, when the 120\u00a0mm size was adopted. The adoption of EFM in June 1980 allowed 30 percent more playing time that would have resulted in 97 minutes for 120\u00a0mm diameter or 74 minutes for a disc as small as . Instead, however, the information density was lowered by 30 percent to keep the playing time at 74 minutes. The 120\u00a0mm diameter has been adopted by subsequent formats, including Super Audio CD, DVD, HD DVD, and Blu-ray Disc. The diameter discs (\"Mini CDs\") can hold up to 24 minutes of music or 210\u00a0MiB.\nLogical format.\nAudio CD.\nThe logical format of an audio CD (officially Compact Disc Digital Audio or CD-DA) is described in a document produced in 1980 by the format's joint creators, Sony and Philips. The document is known colloquially as the \"Red Book\" CD-DA after the color of its cover. The format is a two-channel 16-bit PCM encoding at a 44.1\u00a0kHz sampling rate per channel. Four-channel sound was to be an allowable option within the \"Red Book\" format, but has never been implemented. Monaural audio has no existing standard on a \"Red Book\" CD; thus, the mono source material is usually presented as two identical channels in a standard \"Red Book\" stereo track (i.e., mirrored mono); an MP3 CD, however, can have audio file formats with mono sound.\nCD-Text is an extension of the \"Red Book\" specification for an audio CD that allows for the storage of additional text information (e.g., album name, song name, artist) on a standards-compliant audio CD. The information is stored either in the lead-in area of the CD, where there are roughly five kilobytes of space available or in the subcode channels R to W on the disc, which can store about 31 megabytes.\nCompact Disc + Graphics is a special audio compact disc that contains graphics data in addition to the audio data on the disc. The disc can be played on a regular audio CD player, but when played on a special CD+G player, it can output a graphics signal (typically, the CD+G player is hooked up to a television set or a computer monitor); these graphics are almost exclusively used to display lyrics on a television set for karaoke performers to sing along with. The CD+G format takes advantage of the channels R through W. These six bits store the graphics information.\nCD + Extended Graphics (CD+EG, also known as CD+XG) is an improved variant of the Compact Disc + Graphics (CD+G) format. Like CD+G, CD+EG uses basic CD-ROM features to display text and video information in addition to the music being played. This extra data is stored in subcode channels R-W. Very few, if any, CD+EG discs have been published.\nSuper Audio CD.\nSuper Audio CD (SACD) is a high-resolution, read-only optical audio disc format that was designed to provide higher-fidelity digital audio reproduction than the \"Red Book\". Introduced in 1999, it was developed by Sony and Philips, the same companies that created the \"Red Book\". SACD was in a format war with DVD-Audio, but neither has replaced audio CDs. The SACD standard is referred to as the \"Scarlet Book\" standard.\nTitles in the SACD format can be issued as hybrid discs; these discs contain the SACD audio stream as well as a standard audio CD layer which is playable in standard CD players, thus making them backward compatible.\nCD-MIDI.\nCD-MIDI is a format used to store music-performance data, which upon playback is performed by electronic instruments that synthesize the audio. Hence, unlike the original \"Red Book\" CD-DA, these recordings are not digitally sampled audio recordings. The CD-MIDI format is defined as an extension of the original \"Red Book\".\nCD-ROM.\nFor the first few years of its existence, the CD was a medium used purely for audio. However, in 1988, the \"Yellow Book\" CD-ROM standard was established by Sony and Philips, which defined a non-volatile optical data computer data storage medium using the same physical format as audio compact discs, readable by a computer with a CD-ROM drive.\nVideo CD.\nVideo CD (VCD, View CD, and Compact Disc digital video) is a standard digital format for storing video media on a CD. VCDs are playable in dedicated VCD players, most modern DVD-Video players, personal computers, and some video game consoles. The VCD standard was created in 1993 by Sony, Philips, Matsushita, and JVC and is referred to as the \"White Book\" standard.\nOverall picture quality is intended to be comparable to VHS video. Poorly compressed VCD video can sometimes be of lower quality than VHS video, but VCD exhibits block artifacts rather than analog noise and does not deteriorate further with each use. 352\u00d7240 (or SIF) resolution was chosen because it is half the vertical and half the horizontal resolution of the NTSC video. 352\u00d7288 is a similarly one-quarter PAL/SECAM resolution. This approximates the (overall) resolution of an analog VHS tape, which, although it has double the number of (vertical) scan lines, has a much lower horizontal resolution.\nSuper Video CD.\nSuper Video CD (Super Video Compact Disc or SVCD) is a format used for storing video media on standard compact discs. SVCD was intended as a successor to VCD and an alternative to DVD-Video and falls somewhere between both in terms of technical capability and picture quality.\nSVCD has two-thirds the resolution of DVD, and over 2.7 times the resolution of VCD. One CD-R disc can hold up to 60 minutes of standard-quality SVCD-format video. While no specific limit on SVCD video length is mandated by the specification, one must lower the video bit rate, and therefore quality, to accommodate very long videos. It is usually difficult to fit much more than 100 minutes of video onto one SVCD without incurring a significant quality loss, and many hardware players are unable to play a video with an instantaneous bit rate lower than 300 to 600 kilobits per second.\nPhoto CD.\nPhoto CD is a system designed by Kodak for digitizing and storing photos on a CD. Launched in 1992, the discs were designed to hold nearly 100 high-quality images, scanned prints, and slides using special proprietary encoding. Photo CDs are defined in the \"Beige Book\" and conform to the CD-ROM XA and CD-i Bridge specifications as well. They are intended to play on CD-i players, Photo CD players, and any computer with suitable software (irrespective of operating system). The images can also be printed out on photographic paper with a special Kodak machine. This format is not to be confused with Kodak Picture CD, which is a consumer product in CD-ROM format.\nCD-i.\nThe Philips \"Green Book\" specifies a standard for interactive multimedia compact discs designed for CD-i players (1993). CD-i discs can contain audio tracks that can be played on regular CD players, but CD-i discs are not compatible with most CD-ROM drives and software. The CD-i Ready specification was later created to improve compatibility with audio CD players, and the CD-i Bridge specification was added to create CD-i-compatible discs that can be accessed by regular CD-ROM drives.\nCD-i Ready.\nPhilips defined a format similar to CD-i called CD-i Ready, which puts CD-i software and data into the pregap of track 1. This format was supposed to be more compatible with older audio CD players.\nEnhanced Music CD (CD+).\nEnhanced Music CD, also known as CD Extra or CD Plus, is a format that combines audio tracks and data tracks on the same disc by putting audio tracks in a first session and data in a second session. It was developed by Philips and Sony, and it is defined in the \"Blue Book\".\nVinylDisc.\nVinylDisc is the hybrid of a standard audio CD and the vinyl record. The vinyl layer on the disc's label side can hold approximately three minutes of music.\nManufacture.\nIn 1995, material costs were 30 cents for the jewel case and 10 to 15 cents for the CD. The wholesale cost of CDs was $0.75 to $1.15, while the typical retail price of a prerecorded music CD was $16.98. On average, the store received 35 percent of the retail price, the record company 27 percent, the artist 16 percent, the manufacturer 13 percent, and the distributor 9 percent. When 8-track cartridges, compact cassettes, and CDs were introduced, each was marketed at a higher price than the format they succeeded, even though the cost to produce the media was reduced. This was done because the perceived value increased. This continued from phonograph records to CDs, but was broken when Apple marketed MP3s for $0.99, and albums for $9.99. The incremental cost, though, to produce an MP3 is negligible.\nWritable compact discs.\nRecordable CD.\nRecordable Compact Discs, CD-Rs, are injection-molded with a \"blank\" data spiral. A photosensitive dye is then applied, after which the discs are metalized and lacquer-coated. The write laser of the CD recorder changes the color of the dye to allow the read laser of a standard CD player to see the data, just as it would with a standard stamped disc. The resulting discs can be read by most CD-ROM drives and played in most audio CD players. CD-Rs follow the \"Orange Book\" standard.\nCD-R recordings are designed to be permanent. Over time, the dye's physical characteristics may change causing read errors and data loss until the reading device cannot recover with error correction methods. Errors can be predicted using surface error scanning. The design life is from 20 to 100 years, depending on the quality of the discs, the quality of the writing drive, and storage conditions. However, testing has demonstrated such degradation of some discs in as little as 18 months under normal storage conditions. This failure is known as disc rot, for which there are several, mostly environmental, reasons.\nThe recordable audio CD is designed to be used in a consumer audio CD recorder. These consumer audio CD recorders use SCMS (Serial Copy Management System), an early form of digital rights management (DRM), to conform to the AHRA (Audio Home Recording Act). The Recordable Audio CD is typically somewhat more expensive than CD-R due to lower production volume and a 3 percent AHRA royalty used to compensate the music industry for the making of a copy.\nHigh-capacity recordable CD is a higher-density recording format that can hold 20% more data than conventional discs. The higher capacity is incompatible with some recorders and recording software.\nReWritable CD.\nCD-RW is a re-recordable medium that uses a metallic alloy instead of a dye. The write laser, in this case, is used to heat and alter the properties (amorphous vs. crystalline) of the alloy, and hence change its reflectivity. A CD-RW does not have as great a difference in reflectivity as a pressed CD or a CD-R, and so many earlier CD audio players cannot read CD-RW discs, although most later CD audio players and stand-alone DVD players can. CD-RWs follow the \"Orange Book\" standard.\nThe ReWritable Audio CD is designed to be used in a consumer audio CD recorder, which will not (without modification) accept standard CD-RW discs. These consumer audio CD recorders use the Serial Copy Management System (SCMS), an early form of digital rights management (DRM), to conform to the United States' Audio Home Recording Act (AHRA). The ReWritable Audio CD is typically somewhat more expensive than CD-R due to (a) lower volume and (b) a 3 percent AHRA royalty used to compensate the music industry for the making of a copy.\nCopy protection.\nThe \"Red Book\" audio specification, except for a simple \"anti-copy\" statement in the subcode, does not include any copy protection mechanism. Known at least as early as 2001, attempts were made by record companies to market \"copy-protected\" non-standard compact discs, which cannot be ripped, or copied, to hard drives or easily converted to other formats (like FLAC, MP3 or Vorbis). One major drawback to these copy-protected discs is that most will not play on either computer CD-ROM drives or some standalone CD players that use CD-ROM mechanisms. Philips has stated that such discs are not permitted to bear the trademarked \"Compact Disc Digital Audio\" logo because they violate the \"Red Book\" specifications. Numerous copy-protection systems have been countered by readily available, often free, software, or even by simply turning off automatic AutoPlay to prevent the running of the DRM executable program.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6431", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=6431", "title": "Charles Farrar Browne", "text": "American writer\nCharles Farrar Browne (April 26, 1834 \u2013 March 6, 1867) was an American humor writer, better known under his \"nom de plume\", Artemus Ward, which as a character, an illiterate rube with \"Yankee common sense\", Browne also played in public performances. He is considered to be America's first stand-up comedian. His birth name was Brown but he added the \"e\" after he became famous.\nBiography.\nBrowne was born in Waterford, Maine. He began his career as a compositor and occasional contributor to the daily and weekly journals. In 1858, in \"The Plain Dealer\" newspaper (Cleveland, Ohio), he published the first of the \"Artemus Ward\" series, which, in collected form, achieved great popularity in both America and England.\nBrowne's companion at the \"Plain Dealer\", George Hoyt, wrote: \"his desk was a rickety table which had been whittled and gashed until it looked as if it had been the victim of lightning. His chair was a fit companion thereto, a wabbling, unsteady affair, sometimes with four and sometimes with three legs. But Browne saw neither the table, nor the chair, nor any person who might be near, nothing, in fact, but the funny pictures which were tumbling out of his brain. When writing, his gaunt form looked ridiculous enough. One leg hung over the arm of his chair like a great hook, while he would write away, sometimes laughing to himself, and then slapping the table in the excess of his mirth.\"\nIn 1860, he became editor of the first \"Vanity Fair\", a humorous New York weekly that failed in 1863. At about the same time, he began to appear as a lecturer who, by his droll and eccentric humor, attracted large audiences. Browne was also known as a member of the New York bohemian set which included leader Henry Clapp Jr., Walt Whitman, Fitz Hugh Ludlow, and actress Adah Isaacs Menken.\nIn 1863, Browne came to San Francisco to perform as Artemus Ward. An early expert at show business publicity, Browne sent his manager ahead by several weeks to buy advertising in the local papers and promote the show among prominent citizens for endorsements. On November 13, 1863, Browne stood before a packed crowd at Platt's Music Hall, playing the part of Artemus Ward as an illiterate rube but with \"Yankee common sense.\" Writer Bret Harte was in the audience that night and he described it in \"the Golden Era\" as capturing American speech: \"humor that belongs to the country of boundless prairies, limitless rivers, and stupendous cataracts\u2014that fun which overlies the surface of our national life, which is met in the stage, rail-car, canal and flat-boat, which bursts out over camp-fires and around bar-room stoves.\"\n\"Artemus Ward\" was a favorite author of U.S. President Abraham Lincoln. Before presenting \"The Emancipation Proclamation\" to his Cabinet, Lincoln read to them the latest episode, \"Outrage in Utiky\", also known as \"High-Handed Outrage at Utica\".\nWhen Browne performed in Virginia City, Nevada, he met Mark Twain and the two became friends. In his correspondence with Twain, Browne called him \"My Dearest Love.\" Legend has it that, following a stage performance there, Browne, Twain, and Dan De Quille were trekking on a (drunken) rooftop tour of Virginia City until a town constable threatened to blast all three with a shotgun loaded with rock salt. Browne recommended Twain to the editors of the \"New York Press\" and urged him to journey to New York.\nIn 1866, Browne visited England and attracted a large following to his playing Artemus Ward, both as lecturer and for his literary contributions to \"Punch\". But within a year his health gave way and he died of tuberculosis at Southampton on March 6, 1867.\nIn England Browne was buried at Kensal Green Cemetery, but his remains were removed to the United States in 1868 and buried at Elm Vale Cemetery in Waterford, Maine.\nLegacy.\nIn Cleveland, where Browne started his comedy career, an elementary school is named after him, known as Artemus Ward Elementary on W. 140th Street. In the American Garden of the Cleveland Cultural Gardens in Rockefeller Park, a monument of him was erected, next to Mark Twain.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6432", "revid": "42652532", "url": "https://en.wikipedia.org/wiki?curid=6432", "title": "Caelum", "text": "Constellation in the southern celestial hemisphere\nCaelum is a faint constellation in the southern sky, introduced in the 1750s by Nicolas Louis de Lacaille and counted among the 88 modern constellations. Its name means \"chisel\" in Latin, and it was formerly known as Caelum Sculptorium (\"Engraver's Chisel\"); It is a rare word, unrelated to the far more common Latin \"caelum\", meaning \"sky\", \"heaven\", or \"atmosphere\". It is the eighth-smallest constellation, and subtends a solid angle of around 0.038\u00a0steradians, just less than that of Corona Australis.\nDue to its small size and location away from the plane of the Milky Way, Caelum is a rather barren constellation, with few objects of interest. The constellation's brightest star, Alpha Caeli, is only of magnitude\u00a04.45, and only one other star, (Gamma) \u03b3\u00a01\u00a0Caeli, is brighter than magnitude 5\u00a0. Other notable objects in Caelum are RR\u00a0Caeli, a binary star with one known planet approximately away; X\u00a0Caeli, a Delta Scuti variable that forms an optical double with \u03b3\u00a01\u00a0Caeli; and HE0450-2958, a Seyfert galaxy that at first appeared as just a jet, with no host galaxy visible.\nHistory.\nCaelum was incepted as one of fourteen southern constellations in the 18th century by Nicolas Louis de Lacaille, a French astronomer and celebrated of the Age of Enlightenment.\nIt retains its name \"Burin\" among French speakers, latinized in his catalogue of 1763 as \"Caelum Sculptoris\" (\u201c\"Engraver's Chisel\"\u201d).\nFrancis Baily shortened this name to \"Caelum\", as suggested by John Herschel. In Lacaille's original chart, it was shown as a pair of engraver's tools: a standard burin and more specific shape-forming \u00e9choppe tied by a ribbon, but came to be ascribed a simple chisel. Johann Elert Bode stated the name as plural with a singular possessor, \"Caela Scalptoris\" \u2013 in German (\"die\"\u00a0) \"Grabstichel\" (\u201c\"the Engraver\u2019s Chisels\"\u201d) \u2013 but this did not stick.\nCharacteristics.\nCaelum is bordered by Dorado and Pictor to the south, Horologium and Eridanus to the east, Lepus to the north, and Columba to the west. Covering only 125\u00a0square degrees, it ranks 81st of the 88 modern constellations in size.\nIts main asterism consists of four stars, and twenty stars in total are brighter than magnitude\u00a06.5\u00a0.\nThe constellation's boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are a 12-sided polygon. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 04h 19.5m and 05h 05.1m and declinations of \u00b0 to \u00b0. The International Astronomical Union (IAU) adopted the three-letter abbreviation \u201cCae\u201d for the constellation in 1922.\nIts main stars are visible in favourable conditions and with a clear southern horizon, for part of the year as far as about the 41st parallel north\nThese stars avoid being engulfed by daylight for some of every day (when above the horizon) to viewers in mid- and well-inhabited higher latitudes of the Southern Hemisphere. Caelum shares with (to the north) Taurus, Eridanus and Orion midnight culmination in December (high summer), resulting in this fact. In winter (such as June) the constellation can be observed sufficiently inset from the horizons during its rising before dawn and/or setting after dusk as it culminates then at around mid-day, well above the sun. In South Africa, Argentina, their sub-tropical neighbouring areas and some of Australia in high June the key stars may be traced before dawn in the east; near the equator the stars lose night potential in May to June; they ill-compete with the Sun in northern tropics and sub-tropics from late February to mid-September with March being unfavorable as to post-sunset due to the light of the Milky Way.\nNotable features.\nStars.\nCaelum is a faint constellation: It has no star brighter than magnitude\u00a04 and only two stars brighter than magnitude\u00a05.\nLacaille gave six stars Bayer designations, labeling them Alpha (\u03b1\u00a0) to Zeta (\u03b6\u00a0) in 1756, but omitted Epsilon (\u03b5\u00a0) and designated two adjacent stars as Gamma (\u03b3\u00a0). Bode extended the designations to Rho (\u03c1\u00a0) for other stars, but most of these have fallen out of use. Caelum is too far south for any of its stars to bear Flamsteed designations.\nThe brightest star, (Alpha) \u03b1\u00a0Caeli, is a double star, containing an F-type main-sequence star of magnitude\u00a04.45 and a red dwarf of magnitude\u00a012.5\u00a0, from Earth. (Beta) \u03b2\u00a0Caeli, another F-type star of magnitude\u00a05.05\u00a0, is further away, being located from Earth. Unlike \u03b1, \u03b2\u00a0Caeli is a subgiant star, slightly evolved from the main sequence. (Delta) \u03b4\u00a0Caeli, also of magnitude\u00a05.05\u00a0, is a B-type subgiant and is much farther from Earth, at .\n(Gamma) \u03b3\u00a01\u00a0Caeli is a double-star with a red giant primary of magnitude\u00a04.58 and a secondary of magnitude\u00a08.1\u00a0. The primary is from Earth. The two components are difficult to resolve with small amateur telescopes because of their difference in visual magnitude and their close separation. This star system forms an optical double with the unrelated X\u00a0Caeli (previously named \u03b3\u00a02\u00a0Caeli), a Delta Scuti variable located from Earth. These are a class of short-period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. X\u00a0Caeli itself is also a binary star, specifically a contact binary, meaning that the stars are so close that they share envelopes. The only other variable star in Caelum visible to the naked eye is RV\u00a0Caeli, a pulsating red giant of spectral type M1III, which varies between magnitudes\u00a06.44 and 6.56\u00a0.\nThree other stars in Caelum are still occasionally referred to by their Bayer designations, although they are only on the edge of naked-eye visibility. (Nu) \u03bd\u00a0Caeli is another double star, containing a white giant of magnitude\u00a06.07 and a star of magnitude\u00a010.66, with unknown spectral type. The system is approximately away. (Lambda) \u03bb\u00a0Caeli, at magnitude\u00a06.24, is much redder and farther away, being a red giant around from Earth. (Zeta) \u03b6\u00a0Caeli is even fainter, being only of magnitude\u00a06.36\u00a0. This star, located away, is a K-type subgiant of spectral type K1. The other twelve naked-eye stars in Caelum are not referred to by Bode's Bayer designations anymore, including RV\u00a0Caeli.\nOne of the nearest stars in Caelum is the eclipsing binary star RR\u00a0Caeli, at a distance of . This star system consists of a dim red dwarf and a white dwarf. Despite its closeness to the Earth, the system's apparent magnitude is only 14.40 due to the faintness of its components, and thus it cannot be easily seen with amateur equipment. In 2012, the system was found to contain a giant planet, and there is evidence for a second substellar body. The system is a post-common-envelope binary and is losing angular momentum over time, which will eventually cause mass transfer from the red dwarf to the white dwarf. In approximately 9\u201320 billion years, this will cause the system to become a cataclysmic variable.\nDeep-sky objects.\nDue to its small size and location away from the plane of the Milky Way, Caelum is rather devoid of deep-sky objects, and contains no Messier objects. The only deep-sky object in Caelum to receive much attention is HE0450-2958, an unusual Seyfert galaxy. Originally, the jet's host galaxy proved elusive to find, and this jet appeared to be emanating from nothing. Although it has been suggested that the object is an ejected supermassive black hole, the host is now agreed to be a small galaxy that is difficult to see due to light from the jet and a nearby starburst galaxy.\nThe 13th magnitude planetary nebula PN G243-37.1 is also in the eastern regions of the constellation. It is one of only a few planetary nebulae found in the galactic halo, being light-years below the Milky Way's 1000 light-year-thick disk.\nGalaxies NGC 1595, NGC 1598, and the Carafe galaxy are known as the Carafe group. The Carafe galaxy is a Seyfert galaxy with ring. Its location is 4:28 / -47\u00b054' (2000.0). \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;de=-40.0&amp;zoom=&amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 05h 00m 00s, \u221240\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6433", "revid": "372290", "url": "https://en.wikipedia.org/wiki?curid=6433", "title": "Clarinet", "text": "Single-reed woodwind instrument\nThe clarinet is a single-reed musical instrument in the woodwind family, with a nearly cylindrical bore and a flared bell.\nClarinets comprise a family of instruments of differing sizes and pitches. The clarinet family is the largest woodwind family, ranging from the BB\u266d contrabass to the E\u266d soprano. The B\u266d soprano clarinet is the most common type, and is the instrument usually indicated by the word \"clarinet\".\nGerman instrument maker Johann Christoph Denner is generally credited with inventing the clarinet sometime after 1698 by adding a register key to the chalumeau, an earlier single-reed instrument. Over time, additional keywork and airtight pads were added to improve the tone and playability. Today the clarinet is a standard fixture of the orchestra and concert band and is used in classical music, military bands, klezmer, jazz, and other styles.\nEtymology.\nThe word \"clarinet\" may have entered the English language via the French \"clarinette\" (the feminine diminutive of Old French \"clarin\"), or from Proven\u00e7al \"clarin\" (\"oboe\"), originating from the Latin root \"clarus\" (\"clear\"). The word is related to Middle English \"clarion\", a type of trumpet, the name of which derives from the same root.\nThe earliest mention of the word \"clarinette\" being used for the instrument dates to a 1710 order placed by the Duke of Gronsfeld for two instruments made by Jacob Denner. The English form \"clarinet\" is found as early as 1733, and the now-archaic \"clarionet\" appears from 1784 until the early 20th century.\nA person who plays the clarinet is called a \"clarinetist\" (in North American English), a \"clarinettist\" (in British English), or simply a clarinet player.\nCharacteristics.\nThe clarinet's cylindrical bore is the main reason for its distinctive timbre, which varies between the three main registers (the \"chalumeau\", \"clarion\", and \"altissimo\"). The A and B\u266d clarinets have nearly the same bore and nearly identical tonal quality, although the A typically has a slightly warmer sound. The tone of the E\u266d clarinet is brighter and can be heard through loud orchestral textures. The bass clarinet has a characteristically deep, mellow sound, and the alto clarinet sounds similar to the bass, though not as dark.\nRange.\nClarinets have the largest pitch range of common woodwinds. Nearly all soprano and piccolo clarinets have keywork enabling them to play the E below middle C as their lowest written note. The concert pitch that sounds depends on the individual instrument's transposition (this low E sounds as a concert D3 on a B\u266d soprano clarinet, a whole tone lower than the written note). Some B\u266d clarinets go to a written E\u266d3 to match the range of the A clarinet. Many bass clarinets have additional keywork to written C3. Among the less common members of the clarinet family, contrabass clarinets may have keywork to written D3, C3, or B2; the basset clarinet and basset horn generally go to low C3. Defining the top end of a clarinet's range is difficult, since many advanced players can produce notes well above the highest notes commonly found in method books. G6 is usually the highest note encountered in classical repertoire, but fingerings as high as A7 exist.\nThe range of a clarinet can be divided into three distinct registers:\n*The bridging \"throat\" tones, from written G to B\u266d, are sometimes treated as a separate register\nThe three registers have characteristically different sounds\u2014the chalumeau is rich and dark, the clarion is brighter and sweet, like a trumpet heard from afar, and the altissimo can be piercing and sometimes shrill.\nAcoustics.\nThe production of sound by a clarinet follows these steps:\nIn addition to this primary compression wave, other waves, known as harmonics, are created. Harmonics are caused by factors including the imperfect wobbling and shaking of the reed, the reed sealing the mouthpiece opening for part of the wave cycle (which creates a flattened section of the sound wave), and imperfections (bumps and holes) in the bore. A wide variety of compression waves are created, but only some (primarily the odd harmonics) are reinforced. This in combination with the cut-off frequency (where a significant drop in resonance occurs) results in the characteristic tone of the clarinet.\nThe bore is cylindrical for most of the tube with an inner bore diameter between , but there is a subtle hourglass shape, with the thinnest part below the junction between the upper and lower joint. This hourglass shape, although invisible to the naked eye, helps to correct the pitch and responsiveness of the instrument. The diameter of the bore affects the instrument's sound characteristics. The bell at the bottom of the clarinet flares out to improve the tone and tuning of the lowest notes. The fixed reed and fairly uniform diameter of the clarinet result in an acoustical performance approximating that of a cylindrical stopped pipe. Recorders use a tapered internal bore to overblow at the octave when the thumb/register hole is pinched open, while the clarinet, with its cylindrical bore, overblows at the twelfth.\nMost modern clarinets have \"undercut\" tone holes that improve intonation and sound. Undercutting means chamfering the bottom edge of tone holes inside the bore. Acoustically, this makes the tone hole function as if it were larger, but its main function is to allow the air column to follow the curve up through the tone hole (surface tension) instead of \"blowing past\" it under the increasingly directional frequencies of the upper registers. Covering or uncovering the tone holes varies the length of the pipe, changing the resonant frequencies of the enclosed air column and hence the pitch. The player moves between the chalumeau and clarion registers through use of the register key. The open register key stops the fundamental frequency from being reinforced, making the reed vibrate at three times the frequency, which produces a note a twelfth above the original note.\nMost woodwind instruments have a second register that begins an octave above the first (with notes at twice the frequency of the lower notes). With the aid of an 'octave' or 'register' key, the notes sound an octave higher as the fingering pattern repeats. These instruments are said to overblow at the octave. The clarinet differs, since it acts as a closed-pipe system. The low chalumeau register plays fundamentals, but the clarion (second) register plays the third harmonics, a perfect twelfth higher than the fundamentals. The clarinet is therefore said to overblow at the twelfth. The first several notes of the altissimo (third) range, aided by the register key and venting with the first left-hand hole, play the fifth harmonics, a perfect twelfth plus a major sixth above the fundamentals. The fifth and seventh harmonics are also available, sounding a further sixth and fourth (a flat, diminished fifth) higher respectively; these are the notes of the altissimo register.\nThe lip position and pressure, shaping of the vocal tract, choice of reed and mouthpiece, amount of air pressure created, and evenness of the airflow account for most of the player's ability to control the tone of a clarinet. Their vocal tract will be shaped to resonate at frequencies associated with the tone being produced. Vibrato, a pulsating change of pitch, is rare in classical literature; however, certain performers, such as Richard Stoltzman, use vibrato in classical music. Special fingerings and lip-bending may be used to play microtonal intervals. There have also been efforts to create a quarter tone clarinet.\nConstruction.\nMaterials.\nClarinet bodies have been made from a variety of materials including wood, plastic, hard rubber or Ebonite, metal, and ivory. The vast majority of wooden clarinets are made from blackwood, grenadilla, or, more uncommonly, Honduran rosewood or cocobolo. Historically other woods, particularly boxwood and ebony, were used. Some student clarinets are made of plastic, such as ABS. One of the first such blends of plastic was Resonite, a term originally trademarked by Selmer. The Greenline model by Buffet Crampon is made from a composite of resin and the African blackwood powder left over from the manufacture of wooden clarinets.\nMetal soprano clarinets were popular in the late 19th century, particularly for military use. Metal is still used for the bodies of some contra-alto and contrabass clarinets and the necks and bells of nearly all alto and larger clarinets.\nMouthpieces are generally made of hard rubber, although some inexpensive mouthpieces may be made of plastic. Other materials such as glass, wood, ivory, and metal have also been used. Ligatures are often made of metal and tightened using one or more adjustment screws; other materials include plastic, string, or fabric.\nReed.\nThe clarinet uses a single reed made from the cane of \"Arundo donax\". Reeds may also be manufactured from synthetic materials. The ligature fastens the reed to the mouthpiece. When air is blown through the opening between the reed and the mouthpiece facing, the reed vibrates and produces the clarinet's sound.\nMost players buy manufactured reeds, although many make adjustments to these reeds, and some make their own reeds from cane \"blanks\". Reeds come in varying degrees of hardness, generally indicated on a scale from one (soft) through five (hard). This numbering system is not standardized\u2014reeds with the same number often vary in hardness across manufacturers and models. Reed and mouthpiece characteristics work together to determine ease of playability and tonal characteristics.\nComponents.\nThe reed is attached to the mouthpiece by the ligature, and the top half-inch or so of this assembly is held in the player's mouth. In the past, string was used to bind the reed to the mouthpiece. The formation of the mouth around the mouthpiece and reed is called the embouchure. The reed is on the underside of the mouthpiece, pressing against the player's lower lip, while the top teeth normally contact the top of the mouthpiece (some players roll the upper lip under the top teeth to form what is called a 'double-lip' embouchure). Adjustments in the strength and shape of the embouchure change the tone and intonation. Players sometimes relieve the pressure on the upper teeth and inner lower lip by attaching a pad to the top of the mouthpiece or putting temporary cushioning on the lower teeth.\nThe mouthpiece attaches to the barrel. Tuning can be adjusted by using barrels of varying lengths or by pulling out the barrel to increase the instrument's length. On basset horns and lower clarinets, there is a curved metal neck instead of a barrel.\nThe main body of most clarinets has an upper joint, whose mechanism is mostly operated by the left hand, and a lower joint, mostly operated by the right hand. Some clarinets have a one-piece body. The modern soprano clarinet has numerous tone holes\u2014seven are covered with the fingertips and the rest are operated using a set of 17 keys. The most common system of keys was named the Boehm system by its designer Hyacinthe Klos\u00e9 after flute designer Theobald Boehm, but it is not the same as the Boehm system used on flutes. The other main key system is the Oehler system, which is used mostly in Germany and Austria. The related Albert system is used by some jazz, klezmer, and eastern European folk musicians. The Albert and Oehler systems are both based on the early Mueller system.\nThe cluster of keys at the bottom of the upper joint (protruding slightly beyond the cork of the joint) are known as the trill keys and are operated by the right hand. The entire weight of the smaller clarinets is supported by the right thumb behind the lower joint on what is called the thumb rest. Larger clarinets are supported with a neck strap or a floor peg.\nBelow the main body is a flared end known as the bell. The bell does not amplify the sound but improves the uniformity of the instrument's tone for the lowest notes in each register. For the other notes, the sound is produced almost entirely at the tone holes, and the bell is irrelevant. On basset horns and larger clarinets, the bell curves up and forward and is usually made of metal.\nHistory.\nThe clarinet has its roots in early single-reed instruments used in Ancient Greece and Ancient Egypt. The modern clarinet developed from a Baroque instrument called the chalumeau. This instrument was similar to a recorder, but with a single-reed mouthpiece and a cylindrical bore. Lacking a register key, it was played mainly in its fundamental register, with a limited range of about one and a half octaves. It had eight finger holes, like a recorder, and a written pitch range from F3 to G4. At this time, contrary to modern practice, the reed was placed in contact with the upper lip.\nAround the beginning of the 18th century the German instrument maker Johann Christoph Denner (or possibly his son Jacob Denner) equipped a chalumeau in the alto register with two keys, one of which enabled access to a higher register. This second register did not begin an octave above the first, as with other woodwind instruments, but started an octave and a perfect fifth higher than the first. A second key, at the top, extended the range of the first register to A4 and, together with the register key, to B\u266d4. Later, Denner lengthened the bell and provided it with a third key to extend the pitch range down to E3.\nAfter Denner's innovations, other makers added keys to improve tuning and facilitate fingerings and the chalumeau fell into disuse. The clarinet of the Classical period, as used by Mozart, typically had five keys. Mozart suggested extending the clarinet downwards by four semitones to C3, which resulted in the basset clarinet that was about longer, made first by Theodor Lotz. In 1791 Mozart composed the Concerto for Clarinet and Orchestra in A major for this instrument, with passages ranging down to C3. By the time of Beethoven (c.\u20091780\u20131820), the clarinet was a fixed member in the orchestra.\nThe number of keys was limited because their felt pads did not seal tightly. German clarinetist and master clarinet maker Iwan M\u00fcller remedied this by countersinking the tone holes for the keys and covering the pads with soft leather. These leather pads sealed the holes better than felt, making it possible to equip the instrument with considerably more keys. In 1812 M\u00fcller presented a clarinet with seven finger holes and thirteen keys, which he called \"clarinet omnitonic\" since it was capable of playing in all keys. It was no longer necessary to use differently tuned clarinets for a different keys. M\u00fcller is also considered the inventor of the metal ligature and the thumb rest. During this period the typical embouchure also changed, orienting the mouthpiece with the reed facing downward. This was first recommended in 1782 and became standard by the 1830s.\nIn the late 1830s, German flute maker Theobald B\u00f6hm invented a ring and axle key system for the flute. This key system was first used on the clarinet between 1839 and 1843 by French clarinetist Hyacinthe Klos\u00e9 in collaboration with instrument maker Louis Auguste Buffet. Their design introduced needle springs for the axles, and the ring keys simplified some complicated fingering patterns. The inventors called this the Boehm clarinet, although B\u00f6hm was not involved in its development and the system differed from the one used on the flute. Other key systems have been developed, many built around modifications to the basic Boehm system, including the Full Boehm, Mazzeo, McIntyre, the Benade NX, and the Reform Boehm system, which combined Boehm-system keywork with a German mouthpiece and bore.\nThe Albert clarinet was developed by Eug\u00e8ne Albert in 1848. This model was based on the M\u00fcller clarinet with some changes to keywork, and was also known as the \"simple system\". It included a \"spectacle key\" patented by Adolphe Sax and rollers to improve little-finger movement. After 1861, a \"patent C sharp\" key developed by Joseph Tyler was added to other clarinet models. Improved versions of Albert clarinets were built in Belgium and France for export to the UK and the US.\nAround 1860, clarinettist Carl Baermann and instrument maker Georg Ottensteiner developed the patented Baermann/Ottensteiner clarinet. This instrument had new connecting levers, allowing multiple fingering options to operate some of the pads. The Brahms clarinetist Richard M\u00fchlfeld used this clarinet, and the American clarinet soloist Charles Neidich has used a Baermann-Ottensteiner instrument for playing compositions by Brahms.\nIn the early 20th century, the German clarinetist and clarinet maker Oskar Oehler presented a clarinet using similar fingerings to the Baermann instrument, with significantly more toneholes than the B\u00f6hm model. The new clarinet was called the Oehler system clarinet or German clarinet, while the B\u00f6hm clarinet has since been called the French clarinet. The French clarinet differs from the German not only in fingering but also in sound. Richard Strauss noted that \"French clarinets have a flat, nasal tone, while German ones approximate the singing voice\". Among modern instruments the difference is smaller, although intonation differences persist. The use of Oehler clarinets has continued in German and Austrian orchestras.\nToday the Boehm system is standard everywhere except in Germany and Austria, where the Oehler clarinet is still used. Some contemporary Dixieland players continue to use Albert system clarinets. The Reform Boehm system is also popular in the Netherlands.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n&lt;gallery mode=\"packed\" class=\"float-center\" heights=\"552\" perrow=\"11\" caption=\"Clarinets with different arrangements of keys and holes\" &gt;\nclarinet 4 key anon Bate (2).jpg\nOehler clarinet with a cover on the middle tone hole of the lower joint, dev. 1905 by Oscar Oehler, and with bell mechanism added later to improve deep E and F\nYamaha Clarinet YCL-457II-22 (8K).jpg, Standard German clarinet without cover or bell mechanism.\nBC E13 .jpg\nUsage and repertoire.\nUse of multiple clarinets.\nThe modern orchestral standard of using soprano clarinets in B\u266d and A has to do partly with the history of the instrument and partly with acoustics, aesthetics, and economics. Before about 1800, due to the lack of airtight pads, practical woodwinds could have only a few keys to control accidentals (notes outside their diatonic home scales). The low (chalumeau) register of the clarinet spans a twelfth (an octave plus a perfect fifth) before overblowing, so the clarinet needs keys/holes to produce all nineteen notes in this range. This involves more keywork than on instruments that \"overblow\" at the octave\u2014oboes, flutes, bassoons, and saxophones need only twelve notes before overblowing. Since clarinets with few keys cannot play chromatically, they are limited to playing in closely related keys. For example, an eighteenth-century clarinet in C could play music in F, C, and G (and their relative minors) with good intonation, but with progressive difficulty and poorer intonation as the key moved away from this range. With the advent of airtight pads and improved key technology, more keys were added to woodwinds and the need for clarinets in multiple keys was reduced. The use of instruments in C, B\u266d, and A persisted, with each used as specified by the composer.\nThe lower-pitched clarinets sound \"mellower\" (less bright), and the C clarinet\u2014the highest and brightest sounding of these three\u2014fell out of favor as the other two could cover its range and their sound was considered better. While the clarinet in C began to fall out of general use around 1850, some composers continued to write C parts, e.g., Bizet's Symphony in C (1855), Tchaikovsky's Symphony No. 2 (1872), Smetana's overture to \"The Bartered Bride\" (1866) and \"M\u00e1 Vlast\" (1874), Dvo\u0159\u00e1k's \"Slavonic Dance\" Op. 46, No. 1 (1878), Brahms' Symphony No.\u00a04 (1885), Mahler's Symphony No. 6 (1906), and Strauss' \"Der Rosenkavalier\" (1911).\nWhile technical improvements and an equal-tempered scale reduced the need for two clarinets, the technical difficulty of playing in remote keys persisted, and the A has remained a standard orchestral instrument. By the late 19th century the orchestral clarinet repertoire contained so much music for clarinet in A that it has remained in use.\nClassical music.\nThe orchestra frequently includes two clarinetists, each usually equipped with a B\u266d and an A clarinet, and clarinet parts commonly alternate between the instruments. In the 20th century, Igor Stravinsky, Richard Strauss, and Gustav Mahler employed many different clarinets, including the E\u266d or D soprano clarinets, basset horn, bass clarinet, and/or contrabass clarinet. The practice of using different clarinets to achieve tonal variety was common in 20th-century classical music.\nThe E\u266d clarinet, B\u266d clarinet, alto clarinet, bass clarinet, and contra-alto/contrabass clarinet are commonly used in concert bands, which generally have multiple B\u266d clarinets; there are commonly three or even four B\u266d clarinet parts with two to three players per part.\nThe clarinet is widely used as a solo instrument. The clarinet evolved later than other orchestral woodwind instruments, leaving solo repertoire from the Classical period onward, but few works from the Baroque era. Many clarinet concertos and clarinet sonatas have been written to showcase the instrument, for example those by Mozart and Weber.\nMany works of chamber music have been written for the clarinet. Common combinations are:\nGroups of clarinets playing together have become increasingly popular among clarinet enthusiasts in recent years. Common forms are:\nJazz.\nThe clarinet was a central instrument in jazz, beginning with early jazz players in the 1910s. It remained a signature instrument of the genre through much of the big band era into the 1940s. American players Alphonse Picou, Larry Shields, Jimmie Noone, Johnny Dodds, and Sidney Bechet were all prominent early jazz clarinet players. Swing performers such as Benny Goodman and Artie Shaw rose to prominence in the late 1930s.\nBeginning in the 1940s, the clarinet faded from its prominent position in jazz. By that time, an interest in Dixieland, a revival of traditional New Orleans jazz, had begun. Pete Fountain was one of the best known performers in this genre. The clarinet's place in the jazz ensemble was usurped by the saxophone, which projects a more powerful sound and uses a less complicated fingering system. The clarinet did not entirely disappear from jazz\u2014prominent players since the 1950s include Stan Hasselg\u00e5rd, Jimmy Giuffre, Eric Dolphy (on bass clarinet), Perry Robinson, and John Carter. In the US, the prominent players on the instrument since the 1980s have included Eddie Daniels, Don Byron, Marty Ehrlich, Ken Peplowski, and others playing in both traditional and contemporary styles.\nOther genres.\nThe clarinet is uncommon, but not unheard of, in rock music. Jerry Martini played clarinet on Sly and the Family Stone's 1968 hit, \"Dance to the Music\". The Beatles included a trio of clarinets in \"When I'm Sixty-Four\" from their \"Sgt. Pepper's Lonely Hearts Club Band\" album. A clarinet is prominently featured in what a \"Billboard\" reviewer termed a \"Benny Goodman-flavored clarinet solo\" in \"Breakfast in America\", the title song from the Supertramp album of the same name.\nClarinets feature prominently in klezmer music, which employs a distinctive style of playing. The popular Brazilian music style of choro uses the clarinet, as does Albanian \"saze\" and Greek \"kompania\" folk music, and Bulgarian wedding music. In Turkish folk music, the Albert system clarinet in G is often used, commonly called a \"Turkish clarinet\".\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCited sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "6434", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=6434", "title": "Chojn\u00f3w", "text": "Chojn\u00f3w () (, Silesian German: Hoyn, Silesian language: \"Chojn\u016fw\") is a small town in Legnica County, Lower Silesian Voivodeship, in south-western Poland. It is located on the Skora river, a tributary of the Kaczawa at an average altitude of above sea level. Chojn\u00f3w is the administrative seat of the rural gmina called Gmina Chojn\u00f3w, although the town is not part of its territory and forms a separate urban gmina. As of December 2021, the town has 13,002 inhabitants.\nChojn\u00f3w is located west of Legnica, east from Boles\u0142awiec and north of Z\u0142otoryja, from the A4 motorway. It has railroad connections to Boles\u0142awiec and Legnica.\nHeraldry.\nThe Chojn\u00f3w coat of arms is a blue escutcheon featuring a white castle with three towers. To the right side of the central tower is a silver crescent moon and to its left side a golden sun. In the gate of the castle is a Silesian Eagle on a yellow background. Chojn\u00f3w's motto is \"Friendly City\".\nGeography.\nChojn\u00f3w is located in the Central-Western part of the Lower Silesia region. The Skora (Leather) River flows through the town in a westerly direction. The city of Chojn\u00f3w is in area, including 41% agricultural land.\nChojn\u00f3w has a connection with the major cities of the country (road and rail) and located south of Chojn\u00f3w has the A4 Autostrada. To the South of the town is the surrounding Chojnowska Plain.\nHistory.\nThe town is first mentioned in a Latin mediaeval document issued in Wroc\u0142aw on February 26, 1253, stating, the Silesian Duke Henry III when the town is mentioned under the name Honowo. Possible the name of nearby Hainau Island. The name is of Polish origin, and in more modern records from the 19th century, the Polish name appears as \"Hajn\u00f3w\", while \"Haynau\" is the Germanized version of the original Polish name.\nThe settlement of \"Haynow\" was mentioned in a 1272 deed. It was already called a \"civitas\" in a 1288 document issued by the Piast duke Henry V of Legnica, and officially received town privileges in 1333 from Duke Boles\u0142aw III the Generous. It was part of the duchies of Wroc\u0142aw, G\u0142og\u00f3w and Legnica of fragmented Poland and remained under the rule of the Piast dynasty until 1675. Its population was predominantly Polish. In 1292 the first castellan of Chojn\u00f3w, Bronis\u0142aw Budziwojowic, was mentioned. In the 14th and early 15th centuries Chojn\u00f3w was granted various privileges, including staple right and gold mining right, thanks to which it flourished.\nThe town survived the Hussites, who burned almost the entire town center and castle, but it quickly helped recover its former glory. The largest boom Chojn\u00f3w experienced was in the 16th century, however by the end of that century began to decline due to fires and epidemic, which claimed many victims in 1613. During the Thirty Years War (1618\u20131648), there was another outbreak in the city, it was occupied by the Austrians and Swedes and in 1642 it was also plundered by the Swedes. It remained part of the Piast-ruled Duchy of Legnica until its dissolution in 1675, when it was incorporated to Habsburg-ruled Bohemia.\nIn the 18th century, cloth production developed and a clothmaking school was established in the town. One of two main routes connecting Warsaw and Dresden ran through the town in the 18th century and Kings Augustus II the Strong and Augustus III of Poland traveled that route numerous times. In 1740 the town was captured by Prussia and subsequently annexed in 1742. In 1804 it suffered a flood. During the Napoleonic wars there were more epidemics. In 1813 in Chojn\u00f3w, Napoleon Bonaparte issued instructions regarding the reorganization of the 8th Polish Corps of Prince J\u00f3zef Poniatowski. The event is commemorated by a plaque in the facade of the Piast Castle. A railway line was opened in the 19th century. Sewer, Gas lighting a Newspaper and a hospital soon followed as the towns economy improved.\nThe city was not spared in World War II, with 30% of the town being destroyed on February 10, 1945, when Soviet Red Army troops took the abandoned town. After World War II and the implementation of the Oder-Neisse line in 1945, the town passed to the Republic of Poland. It was repopulated by Poles, expelled from former eastern Poland annexed by the Soviet Union. In 1946 it was renamed \"Chojn\u00f3w\", a more modern version of the old Polish \"Hajn\u00f3w\". Also Greeks, refugees of the Greek Civil War, settled in Chojn\u00f3w.\nPopulation.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nEconomy.\nChojn\u00f3w is an industrial and agricultural town. Among local products are: paper, agricultural machinery, chains, metal furniture for hospitals, equipment for the meat industry, beer, wine, leather clothing, and clothing for infants, children and adults.\nSights and nature.\nAmong the interesting monuments of Chojn\u00f3w are the 13th-century castle of the Dukes of Legnica (currently used as a museum), two old churches, the \"Baszta Tkaczy\" (\"Weavers' Tower\") and preserved fragments of city walls.\nThe biggest green area in Chojn\u00f3w is small forest \"Park Piastowski\" (\"Piast's Park\"), named after Piast dynasty. Wild animals that can be found in the Chojn\u00f3w area are roe deer, foxes, rabbits and wild domestic animals, especially cats.\nCulture and sport.\nEvery year in the first days of June, the \"Days of Chojn\u00f3w\" (\"Dni Chojnowa\") are celebrated. The Whole-Poland bike race \"Masters\" has been organized yearly in Chojn\u00f3w for the past few years.\nChojn\u00f3w has a Municipal sports and recreation center formed in 2008 holding various events, festivals, reviews, exhibitions, and competitions. The regional Museum is housed in the old Piast era castle. The collections include tiles, relics, and the castle garden. Next to the Museum there is a municipal library. In \u015br\u00f3dmiejskim Park, near the Town Hall is the amphitheatre.\nThe local government-run weekly newspaper is Gazeta Chojnowska, which has been published since 1992.\nIt is published biweekly. Editions have a run of 900 copies and it is one of the oldest newspapers in Poland issued without interruption. The \"Chojn\u00f3w\" is the official newspaper of Chojn\u00f3w with copy run of 750 copies.\nEducation.\nIn Chojn\u00f3w, there are two kindergartens, two elementary schools and two middle schools.\nReligion.\nChojn\u00f3w is in the Catholic deanery of Chojn\u00f3w and has two parishes, Immaculate Conception of the Blessed Virgin Mary and also the Holy Apostles Peter and Paul. Both parishes have active congregations.\nThere are also two Congregations of Jehovah's witnesses.\nTwin towns \u2013 sister cities.\nChojn\u00f3w is twinned with:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6435", "revid": "1150861800", "url": "https://en.wikipedia.org/wiki?curid=6435", "title": "Canes Venatici", "text": "Constellation in the northern celestial hemisphere\nCanes Venatici () is one of the 88 constellations designated by the International Astronomical Union (IAU). It is a small northern constellation that was created by Johannes Hevelius in the 17th century. Its name is Latin for 'hunting dogs', and the constellation is often depicted in illustrations as representing the dogs of Bo\u00f6tes the Herdsman, a neighboring constellation.\nCor Caroli is the constellation's brightest star, with an apparent magnitude of 2.9. La Superba (Y\u00a0CVn) is one of the reddest naked-eye stars and one of the brightest carbon stars. The Whirlpool Galaxy is a spiral galaxy tilted face-on to observers on Earth, and was the first galaxy whose spiral nature was discerned. In addition, quasar Ton 618 is one of the most massive black holes with the mass of 66 billion solar masses.\nHistory.\nThe stars of Canes Venatici are not bright. In classical times, they were listed by Ptolemy as unfigured stars below the constellation Ursa Major in his star catalogue.\nIn medieval times, the identification of these stars with the dogs of Bo\u00f6tes arose through a mistranslation: some of Bo\u00f6tes's stars were traditionally described as representing the club (, ) of Bo\u00f6tes. When the Greek astronomer Ptolemy's \"Almagest\" was translated from Greek to Arabic, the translator Hunayn ibn Ishaq did not know the Greek word and rendered it as a similar-sounding compound Arabic word for a kind of weapon, writing , which means 'the staff having a hook'.\nWhen the Arabic text was later translated into Latin, the translator, Gerard of Cremona, mistook ('hook') for ('dogs'). Both written words look the same in Arabic text without diacritics, leading Gerard to write it as ('spearshaft-having dogs').\nIn 1533, the German astronomer Peter Apian depicted Bo\u00f6tes as having two dogs with him.\nThese spurious dogs floated about the astronomical literature until Hevelius decided to make them a separate constellation in 1687. Hevelius chose the name \"Asterion\" for the northern dog and \"Chara\" for the southern dog, as , 'the hunting dogs', in his star atlas.\nIn his star catalogue, the Czech astronomer Anton\u00edn Be\u010dv\u00e1\u0159 assigned the names \"Asterion\" to \u03b2\u00a0CVn and \"Chara\" to \u03b1\u00a0CVn.\nAlthough the International Astronomical Union dropped several constellations in 1930 that were medieval and Renaissance innovations, Canes Venatici survived to become one of the 88 IAU designated constellations.\nNeighbors and borders.\nCanes Venatici is bordered by Ursa Major to the north and west, Coma Berenices to the south, and Bo\u00f6tes to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CVn\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of 14 sides.\nIn the equatorial coordinate system, the right ascension coordinates of these borders lie between 12h 06.2m and 14h 07.3m, while the declination coordinates are between +27.84\u00b0 and +52.36\u00b0. Covering 465 square degrees, it ranks 38th of the 88 constellations in size.\nProminent stars and deep-sky objects.\nStars.\nCanes Venatici contains no very bright stars, Alpha and Beta Canum Venaticorum being only of 3rd and 4th magnitude respectively. Flamsteed catalogued 25 stars in the constellation, labelling them 1 to 25 Canum Venaticorum (CVn); however, 1CVn turned out to be in Ursa Major, 13CVn was in Coma Berenices, and 22CVn did not exist.\nSupervoid.\nThe Giant Void, an extremely large void (part of the universe containing very few galaxies), is within the vicinity of this constellation. It is regarded to be the second largest void ever discovered, slightly larger than the Eridanus Supervoid and smaller than the proposed KBC Void and 1,200 times the volume of expected typical voids. It was discovered in 1988 in a deep-sky survey. Its centre is approximately 1.5 billion light-years away.\nDeep-sky objects.\nCanes Venatici contains five Messier objects, including four galaxies. One of the more significant galaxies in Canes Venatici is the Whirlpool Galaxy (M51, NGC\u00a05194) and NGC 5195, a small barred spiral galaxy that is seen face-on. This was the first galaxy recognised as having a spiral structure, this structure being first observed by Lord Rosse in 1845. It is a face-on spiral galaxy 37\u00a0million light-years from Earth. Widely considered to be one of the most beautiful galaxies visible, M51 has many star-forming regions and nebulae in its arms, coloring them pink and blue in contrast to the older yellow core. M\u00a051 has a smaller companion, NGC\u00a05195, that has very few star-forming regions and thus appears yellow. It is passing behind M\u00a051 and may be the cause of the larger galaxy's prodigious star formation.\nOther notable spiral galaxies in Canes Venatici are the Sunflower Galaxy (M63, NGC\u00a05055), M94 (NGC\u00a04736), and M106 (NGC\u00a04258).\nTon 618 is a hyperluminous quasar and blazar in this constellation, near its border with the neighboring Coma Berenices. It possesses a black hole with a mass 66 billion times that of the Sun, making it one of the most massive black holes ever measured. There is also a Lyman-alpha blob.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 13h 00m 00s, +40\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6436", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6436", "title": "Chamaeleon", "text": "Constellation in the southern celestial hemisphere\nChamaeleon () is a small constellation in the deep southern sky. It is named after the chameleon, a kind of lizard. It was first defined in the 16th century.\nHistory.\nChamaeleon was one of twelve constellations created by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman. It first appeared on a 35-cm diameter celestial globe published in 1597 (or 1598) in Amsterdam by Plancius and Jodocus Hondius. Johann Bayer was the first uranographer to put Chamaeleon in a celestial atlas. It was one of many constellations created by European explorers in the 15th and 16th centuries out of unfamiliar Southern Hemisphere stars.\nFeatures.\nStars.\nThere are four bright stars in Chamaeleon that form a compact diamond-shape approximately 10 degrees from the south celestial pole and about 15 degrees south of Acrux, along the axis formed by Acrux and Gamma Crucis. Alpha Chamaeleontis is a white-hued star of magnitude 4.1, 63 light-years from Earth. Beta Chamaeleontis is a blue-white hued star of magnitude 4.2, 271 light-years from Earth. Gamma Chamaeleontis is a red-hued giant star of magnitude 4.1, 413 light-years from Earth. The other bright star in Chamaeleon is Delta Chamaeleontis, a wide double star. The brighter star is Delta2 Chamaeleontis, a blue-hued star of magnitude 4.4. Delta1 Chamaeleontis, the dimmer component, is an orange-hued giant star of magnitude 5.5. They both lie about 350 light years away.\nChamaeleon is also the location of Cha 110913, a unique dwarf star or proto solar system.\nDeep-sky objects.\nIn 1999, a nearby open cluster was discovered centered on the star \u03b7 Chamaeleontis. The cluster, known as either\nthe Eta Chamaeleontis cluster or Mamajek 1, is 8 million years old, and lies 316 light years from Earth.\nThe constellation contains a number of molecular clouds (the Chamaeleon dark clouds) that are forming low-mass T Tauri stars. The cloud complex lies some 400 to 600 light years from Earth, and contains tens of thousands of solar masses of gas and dust. The most prominent cluster of T Tauri stars and young B-type stars are in the Chamaeleon I cloud, and are associated with the reflection nebula IC 2631.\nChamaeleon contains one planetary nebula, NGC 3195, which is fairly faint. It appears in a telescope at about the same apparent size as Jupiter.\nEquivalents.\nIn Chinese astronomy, the stars that form Chamaeleon were classified as the Little Dipper (\u5c0f\u6597, \"Xi\u01ceod\u01d2u\") among the Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\") by Xu Guangqi. Chamaeleon is sometimes also called the Frying Pan in Australia.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;indicator name=\"01-sky-coordinates\"&gt;&lt;templatestyles src=\"Template:Sky/styles.css\" /&gt;Coordinates: &amp;show_grid=1&amp;show_constellation_lines=1&amp;show_constellation_boundaries=1&amp;show_const_names=1&amp;show_galaxies=1&amp;img_source=IMG_all 11h 00m 00s, \u221280\u00b0 00\u2032 00\u2033&lt;/indicator&gt;"}
{"id": "6437", "revid": "160367", "url": "https://en.wikipedia.org/wiki?curid=6437", "title": "Cholesterol", "text": "Sterol biosynthesized by all animal cells\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nCholesterol is the principal sterol of all higher animals, distributed in body tissues, especially the brain and spinal cord, and in animal fats and oils. Cholesterol is biosynthesized by all animal cells and is an essential structural component of animal cell membranes.\nCholesterol also serves as a precursor for the biosynthesis of steroid hormones, bile acid and vitamin D. Cholesterol is the principal sterol synthesized by all animals. In vertebrates, hepatic cells typically produce the greatest amounts. It is absent among prokaryotes (bacteria and archaea), although there are some exceptions, such as \"Mycoplasma\", which require cholesterol for growth.\nFran\u00e7ois Poulletier de la Salle first identified cholesterol in solid form in gallstones in 1769. However, it was not until 1815 that chemist Michel Eug\u00e8ne Chevreul named the compound \"cholesterine\".\nEtymology.\nThe word \"cholesterol\" comes from Ancient Greek \"chole-\" 'bile' and \"stereos\" 'solid', followed by the chemical suffix \"-ol\" for an alcohol.\nPhysiology.\nCholesterol is essential for all animal life, with each cell capable of synthesizing it by way of a complex 37-step process. This begins with the mevalonate or HMG-CoA reductase pathway, the target of statin drugs, which encompasses the first 18 steps. This is followed by 19 additional steps to convert the resulting lanosterol into cholesterol.\nA human male weighing 68\u00a0kg (150\u00a0lb) normally synthesizes about 1 gram (1,000\u00a0mg) of cholesterol per day, and his body contains about 35 g, mostly contained within the cell membranes. Typical daily cholesterol dietary intake for a man in the United States is 307\u00a0mg.\nMost ingested cholesterol is esterified, which causes it to be poorly absorbed by the gut. The body also compensates for absorption of ingested cholesterol by reducing its own cholesterol synthesis. For these reasons, cholesterol in food, seven to ten hours after ingestion, has little, if any effect on concentrations of cholesterol in the blood. However, during the first seven hours after ingestion of cholesterol, as absorbed fats are being distributed around the body within extracellular water by the various lipoproteins (which transport all fats in the water outside cells), the concentrations increase.\nPlants make cholesterol in very small amounts. In larger quantities they produce phytosterols, chemically similar substances which can compete with cholesterol for reabsorption in the intestinal tract, thus potentially reducing cholesterol reabsorption. When intestinal lining cells absorb phytosterols, in place of cholesterol, they usually excrete the phytosterol molecules back into the GI tract, an important protective mechanism. The intake of naturally occurring phytosterols, which encompass plant sterols and stanols, ranges between \u2248200\u2013300\u00a0mg/day depending on eating habits. Specially designed vegetarian experimental diets have been produced yielding upwards of 700\u00a0mg/day.\nFunction.\nMembranes.\nCholesterol composes about 30% of all animal cell membranes. It is required to build and maintain membranes and modulates membrane fluidity over the range of physiological temperatures. The hydroxyl group of each cholesterol molecule interacts with water molecules surrounding the membrane, as do the polar heads of the membrane phospholipids and sphingolipids, while the bulky steroid and the hydrocarbon chain are embedded in the membrane, alongside the nonpolar fatty-acid chain of the other lipids. Through the interaction with the phospholipid fatty-acid chains, cholesterol increases membrane packing, which both alters membrane fluidity and maintains membrane integrity so that animal cells do not need to build cell walls (like plants and most bacteria). The membrane remains stable and durable without being rigid, allowing animal cells to change shape and animals to move.\nThe structure of the tetracyclic ring of cholesterol contributes to the fluidity of the cell membrane, as the molecule is in a \"trans\" conformation making all but the side chain of cholesterol rigid and planar. In this structural role, cholesterol also reduces the permeability of the plasma membrane to neutral solutes, hydrogen ions, and sodium ions.\nSubstrate presentation.\nCholesterol regulates the biological process of substrate presentation and the enzymes that use substrate presentation as a mechanism of their activation. Phospholipase D2 (PLD2) is a well-defined example of an enzyme activated by substrate presentation. The enzyme is palmitoylated causing the enzyme to traffic to cholesterol dependent lipid domains sometimes called \"lipid rafts\". The substrate of phospholipase D is phosphatidylcholine (PC) which is unsaturated and is of low abundance in lipid rafts. PC localizes to the disordered region of the cell along with the polyunsaturated lipid phosphatidylinositol 4,5-bisphosphate (PIP2). PLD2 has a PIP2 binding domain. When PIP2 concentration in the membrane increases, PLD2 leaves the cholesterol-dependent domains and binds to PIP2 where it then gains access to its substrate PC and commences catalysis based on substrate presentation.\nSignaling.\nCholesterol is also implicated in cell signaling processes, assisting in the formation of lipid rafts in the plasma membrane, which brings receptor proteins in close proximity with high concentrations of second messenger molecules. In multiple layers, cholesterol and phospholipids, both electrical insulators, can facilitate speed of transmission of electrical impulses along nerve tissue. For many neuron fibers, a myelin sheath, rich in cholesterol since it is derived from compacted layers of Schwann cell or oligodendrocyte membranes, provides insulation for more efficient conduction of impulses. Demyelination (loss of myelin) is believed to be part of the basis for multiple sclerosis.\nCholesterol binds to and affects the gating of a number of ion channels such as the nicotinic acetylcholine receptor, GABAA receptor, and the inward-rectifier potassium channel. Cholesterol also activates the estrogen-related receptor alpha (ERR\u03b1), and may be the endogenous ligand for the receptor. The constitutively active nature of the receptor may be explained by the fact that cholesterol is ubiquitous in the body. Inhibition of ERR\u03b1 signaling by reduction of cholesterol production has been identified as a key mediator of the effects of statins and bisphosphonates on bone, muscle, and macrophages. On the basis of these findings, it has been suggested that the ERR\u03b1 should be de-orphanized and classified as a receptor for cholesterol.\nChemical precursor.\nWithin cells, cholesterol is also a precursor molecule for several biochemical pathways. For example, it is the precursor molecule for the synthesis of vitamin D in the calcium metabolism and all steroid hormones, including the adrenal gland hormones cortisol and aldosterone, as well as the sex hormones progesterone, estrogens, and testosterone, and their derivatives.\nEpidermis.\nThe stratum corneum is the outermost layer of the epidermis. It is composed of terminally differentiated and enucleated corneocytes that reside within a lipid matrix, like \"bricks and mortar.\" Together with ceramides and free fatty acids, cholesterol forms the lipid mortar, a water-impermeable barrier that prevents evaporative water loss. As a general rule of thumb, the epidermal lipid matrix is composed of an equimolar mixture of ceramides (~50% by weight), cholesterol (~ 25% by weight), and free fatty acids (~15% by weight), with smaller quantities of other lipids also being present. Cholesterol sulfate reaches its highest concentration in the granular layer of the epidermis. Steroid sulfate sulfatase then decreases its concentration in the stratum corneum, the outermost layer of the epidermis. The relative abundance of cholesterol sulfate in the epidermis varies across different body sites with the heel of the foot having the lowest concentration. \nMetabolism.\nCholesterol is recycled in the body. The liver excretes cholesterol into biliary fluids, which are then stored in the gallbladder, which then excretes them in a non-esterified form (via bile) into the digestive tract. Typically, about 50% of the excreted cholesterol is reabsorbed by the small intestine back into the bloodstream.\nBiosynthesis and regulation.\nBiosynthesis.\nAll animal cells (exceptions exist within the invertebrates) manufacture cholesterol, for both membrane structure and other uses, with relative production rates varying by cell type and organ function. About 80% of total daily cholesterol production occurs in the liver and the intestines; other sites of higher synthesis rates include the brain, the adrenal glands, and the reproductive organs.\nSynthesis within the body starts with the mevalonate pathway where two molecules of acetyl CoA condense to form acetoacetyl-CoA. This is followed by a second condensation between acetyl CoA and acetoacetyl-CoA to form 3-hydroxy-3-methylglutaryl CoA (HMG-CoA).\nThis molecule is then reduced to mevalonate by the enzyme HMG-CoA reductase. Production of mevalonate is the rate-limiting and irreversible step in cholesterol synthesis and is the site of action for statins (a class of cholesterol-lowering drugs).\nMevalonate is finally converted to isopentenyl pyrophosphate (IPP) through two phosphorylation steps and one decarboxylation step that requires ATP.\nThree molecules of isopentenyl pyrophosphate condense to form farnesyl pyrophosphate through the action of geranyl transferase.\nTwo molecules of farnesyl pyrophosphate then condense to form squalene by the action of squalene synthase in the endoplasmic reticulum.\nOxidosqualene cyclase then cyclizes squalene to form lanosterol.\nFinally, lanosterol is converted to cholesterol via either of two pathways, the Bloch pathway, or the Kandutsch-Russell pathway.\nThe final 19 steps to cholesterol contain NADPH and oxygen to help oxidize methyl groups for removal of carbons, mutases to move alkene groups, and NADH to help reduce ketones.\nKonrad Bloch and Feodor Lynen shared the Nobel Prize in Physiology or Medicine in 1964 for their discoveries concerning some of the mechanisms and methods of regulation of cholesterol and fatty acid metabolism.\nRegulation of cholesterol synthesis.\nBiosynthesis of cholesterol is directly regulated by the cholesterol levels present, though the homeostatic mechanisms involved are only partly understood. A higher intake of food leads to a net decrease in endogenous production, whereas a lower intake of food has the opposite effect. The main regulatory mechanism is the sensing of intracellular cholesterol in the endoplasmic reticulum by the protein SREBP (sterol regulatory element-binding protein 1 and 2). In the presence of cholesterol, SREBP is bound to two other proteins: SCAP (SREBP cleavage-activating protein) and INSIG-1. When cholesterol levels fall, INSIG-1 dissociates from the SREBP-SCAP complex, which allows the complex to migrate to the Golgi apparatus. Here SREBP is cleaved by S1P and S2P (site-1 protease and site-2 protease), two enzymes that are activated by SCAP when cholesterol levels are low.\nThe cleaved SREBP then migrates to the nucleus and acts as a transcription factor to bind to the sterol regulatory element (SRE), which stimulates the transcription of many genes. Among these are the low-density lipoprotein (LDL) receptor and HMG-CoA reductase. The LDL receptor scavenges circulating LDL from the bloodstream, whereas HMG-CoA reductase leads to an increase in endogenous production of cholesterol. A large part of this signaling pathway was clarified by Dr. Michael S. Brown and Dr. Joseph L. Goldstein in the 1970s. In 1985, they received the Nobel Prize in Physiology or Medicine for their work. Their subsequent work shows how the SREBP pathway regulates the expression of many genes that control lipid formation and metabolism and body fuel allocation.\nCholesterol synthesis can also be turned off when cholesterol levels are high. HMG-CoA reductase contains both a cytosolic domain (responsible for its catalytic function) and a membrane domain. The membrane domain senses signals for its degradation. Increasing concentrations of cholesterol (and other sterols) cause a change in this domain's oligomerization state, which makes it more susceptible to destruction by the proteasome. This enzyme's activity can also be reduced by phosphorylation by an AMP-activated protein kinase. Because this kinase is activated by AMP, which is produced when ATP is hydrolyzed, it follows that cholesterol synthesis is halted when ATP levels are low.\nPlasma transport and regulation of absorption.\nAs an isolated molecule, cholesterol is only minimally soluble in water, or hydrophilic. Because of this, it dissolves in blood at exceedingly small concentrations. To be transported effectively, cholesterol is instead packaged within lipoproteins, complex discoidal particles with exterior amphiphilic proteins and lipids, whose outward-facing surfaces are water-soluble and inward-facing surfaces are lipid-soluble. This allows it to travel through the blood via emulsification. Unbound cholesterol, being amphipathic, is transported in the monolayer surface of the lipoprotein particle along with phospholipids and proteins. Cholesterol esters bound to fatty acid, on the other hand, are transported within the fatty hydrophobic core of the lipoprotein, along with triglyceride.\nThere are several types of lipoproteins in the blood. In order of increasing density, they are chylomicrons, very-low-density lipoprotein (VLDL), intermediate-density lipoprotein (IDL), low-density lipoprotein (LDL), and high-density lipoprotein (HDL). Lower protein/lipid ratios make for less dense lipoproteins. Cholesterol within different lipoproteins is identical, although some is carried as its native \"free\" alcohol form (the cholesterol-OH group facing the water surrounding the particles), while others as fatty acyl esters, known also as cholesterol esters, within the particles.\nLipoprotein particles are organized by complex apolipoproteins, typically 80\u2013100 different proteins per particle, which can be recognized and bound by specific receptors on cell membranes, directing their lipid payload into specific cells and tissues currently ingesting these fat transport particles. These surface receptors serve as unique molecular signatures, which then help determine fat distribution delivery throughout the body.\nChylomicrons, the least dense cholesterol transport molecules, contain apolipoprotein B-48, apolipoprotein C, and apolipoprotein E (the principal cholesterol carrier in the brain) in their shells. Chylomicrons carry fats from the intestine to muscle and other tissues in need of fatty acids for energy or fat production. Unused cholesterol remains in more cholesterol-rich chylomicron remnants, and taken up from here to the bloodstream by the liver.\nVLDL molecules are produced by the liver from triacylglycerol and cholesterol which was not used in the synthesis of bile acids. These molecules contain apolipoprotein B100 and apolipoprotein E in their shells, and can be degraded by lipoprotein lipase on the artery wall to IDL. This arterial wall cleavage allows absorption of triacylglycerol and increases the concentration of circulating cholesterol. IDL molecules are then consumed in two processes: half is metabolized by HTGL and taken up by the LDL receptor on the liver cell surfaces, while the other half continues to lose triacylglycerols in the bloodstream until they become cholesterol-laden LDL particles.\nLDL particles are the major blood cholesterol carriers. Each one contains approximately 1,500 molecules of cholesterol ester. LDL molecule shells contain just one molecule of apolipoprotein B100, recognized by LDL receptors in peripheral tissues. Upon binding of apolipoprotein B100, many LDL receptors concentrate in clathrin-coated pits. Both LDL and its receptor form vesicles within a cell via endocytosis. These vesicles then fuse with a lysosome, where the lysosomal acid lipase enzyme hydrolyzes the cholesterol esters. The cholesterol can then be used for membrane biosynthesis or esterified and stored within the cell, so as to not interfere with the cell membranes.\nLDL receptors are used up during cholesterol absorption, and its synthesis is regulated by SREBP, the same protein that controls the synthesis of cholesterol \"de novo\", according to its presence inside the cell. A cell with abundant cholesterol will have its LDL receptor synthesis blocked, to prevent new cholesterol in LDL molecules from being taken up. Conversely, LDL receptor synthesis proceeds when a cell is deficient in cholesterol.\nWhen this process becomes unregulated, LDL molecules without receptors begin to appear in the blood. These LDL molecules are oxidized and taken up by macrophages, which become engorged and form foam cells. These foam cells often become trapped in the walls of blood vessels and contribute to atherosclerotic plaque formation. Differences in cholesterol homeostasis affect the development of early atherosclerosis (carotid intima-media thickness). These plaques are the main causes of heart attacks, strokes, and other serious medical problems, leading to the association of so-called LDL cholesterol (actually a lipoprotein) with \"bad\" cholesterol.\nHDL particles are thought to transport cholesterol back to the liver, either for excretion or for other tissues that synthesize hormones, in a process known as reverse cholesterol transport (RCT). Large numbers of HDL particles correlates with better health outcomes, whereas low numbers of HDL particles is associated with atheromatous disease progression in the arteries.\nMetabolism, recycling and excretion.\nCholesterol is susceptible to oxidation and easily forms oxygenated derivatives called oxysterols. Three different mechanisms can form these: autoxidation, secondary oxidation to lipid peroxidation, and cholesterol-metabolizing enzyme oxidation. A great interest in oxysterols arose when they were shown to exert inhibitory actions on cholesterol biosynthesis. This finding became known as the \"oxysterol hypothesis\". Additional roles for oxysterols in human physiology include their participation in bile acid biosynthesis, function as transport forms of cholesterol, and regulation of gene transcription.\nIn biochemical experiments radiolabelled forms of cholesterol, such as tritiated-cholesterol are used. These derivatives undergo degradation upon storage and it is essential to purify cholesterol prior to use. Cholesterol can be purified using small Sephadex LH-20 columns.\nCholesterol is oxidized by the liver into a variety of bile acids. These, in turn, are conjugated with glycine, taurine, glucuronic acid, or sulfate. A mixture of conjugated and nonconjugated bile acids, along with cholesterol itself, is excreted from the liver into the bile. Approximately 95% of the bile acids are reabsorbed from the intestines, and the remainder are lost in the feces. The excretion and reabsorption of bile acids forms the basis of the enterohepatic circulation, which is essential for the digestion and absorption of dietary fats. Under certain circumstances, when more concentrated, as in the gallbladder, cholesterol crystallises and is the major constituent of most gallstones (lecithin and bilirubin gallstones also occur, but less frequently). Every day, up to 1 g of cholesterol enters the colon. This cholesterol originates from the diet, bile, and desquamated intestinal cells, and can be metabolized by the colonic bacteria. Cholesterol is converted mainly into coprostanol, a nonabsorbable sterol that is excreted in the feces.\nAlthough cholesterol is a steroid generally associated with mammals, the human pathogen \"Mycobacterium tuberculosis\" is able to completely degrade this molecule and contains a large number of genes that are regulated by its presence. Many of these cholesterol-regulated genes are homologues of fatty acid \u03b2-oxidation genes, but have evolved in such a way as to bind large steroid substrates like cholesterol.\nDietary sources.\nAnimal fats are complex mixtures of triglycerides, with lesser amounts of both the phospholipids and cholesterol molecules from which all animal (and human) cell membranes are constructed. Since all animal cells manufacture cholesterol, all animal-based foods contain cholesterol in varying amounts. Major dietary sources of cholesterol include red meat, egg yolks and whole eggs, liver, kidney, giblets, fish oil, and butter. Human breast milk also contains significant quantities of cholesterol.\nPlant cells synthesize cholesterol as a precursor for other compounds, such as phytosterols and steroidal glycoalkaloids, with cholesterol remaining in plant foods only in minor amounts or absent. Some plant foods, such as avocado, flax seeds and peanuts, contain phytosterols, which compete with cholesterol for absorption in the intestines, and reduce the absorption of both dietary and bile cholesterol. A typical diet contributes on the order of 0.2 gram of phytosterols, which is not enough to have a significant impact on blocking cholesterol absorption. Phytosterols intake can be supplemented through the use of phytosterol-containing functional foods or dietary supplements that are recognized as having potential to reduce levels of LDL-cholesterol.\nMedical guidelines and recommendations.\nIn 2015, the United States Department of Agriculture Dietary Guidelines Advisory Committee (DGAC) recommended that Americans eat as little dietary cholesterol as possible, because most foods that are rich in cholesterol are also high in saturated fat and thereby may increase the risk of cardiovascular disease.\nA 2013 report by the American Heart Association and the American College of Cardiology recommended focusing on healthy dietary patterns rather than specific cholesterol limits, as they are hard for clinicians and consumers to implement. They recommend the DASH and Mediterranean diet, which are low in cholesterol. A 2017 review by the American Heart Association recommends switching saturated fats for polyunsaturated fats to reduce cardiovascular disease risk.\nSome supplemental guidelines have recommended doses of phytosterols in the 1.6\u20133.0\u00a0grams per day range (Health Canada, EFSA, ATP III, FDA). A recent meta-analysis demonstrating a 12% reduction in LDL-cholesterol at a mean dose of 2.1\u00a0grams per day. However, the benefits of a diet supplemented with phytosterols have also been questioned.\nClinical significance.\nHypercholesterolemia.\nAccording to the lipid hypothesis, elevated levels of cholesterol in the blood lead to atherosclerosis which may increase the risk of heart attack, stroke, and peripheral artery disease. Since higher blood LDL \u2013 especially higher LDL concentrations and smaller LDL particle size \u2013 contributes to this process more than the cholesterol content of the HDL particles, LDL particles are often termed \"bad cholesterol\". High concentrations of functional HDL, which can remove cholesterol from cells and atheromas, offer protection and are commonly referred to as \"good cholesterol\". These balances are mostly genetically determined, but can be changed by body composition, medications, diet, and other factors. A 2007 study demonstrated that blood total cholesterol levels have an exponential effect on cardiovascular and total mortality, with the association more pronounced in younger subjects. Because cardiovascular disease is relatively rare in the younger population, the impact of high cholesterol on health is larger in older people.\nElevated levels of the lipoprotein fractions, LDL, IDL and VLDL, rather than the total cholesterol level, correlate with the extent and progress of atherosclerosis. Conversely, the total cholesterol can be within normal limits, yet be made up primarily of small LDL and small HDL particles, under which conditions atheroma growth rates are high. A \"post hoc\" analysis of the IDEAL and the EPIC prospective studies found an association between high levels of HDL cholesterol (adjusted for apolipoprotein A-I and apolipoprotein B) and increased risk of cardiovascular disease, casting doubt on the cardioprotective role of \"good cholesterol\".\nAbout one in 250 individuals can have a genetic mutation for the LDL cholesterol receptor that causes them to have familial hypercholesterolemia. Inherited high cholesterol can also include genetic mutations in the PCSK9 gene and the gene for apolipoprotein B.\nElevated cholesterol levels are treated with a strict diet consisting of low saturated fat, trans fat-free, low cholesterol foods, often followed by one of various hypolipidemic agents, such as statins, fibrates, cholesterol absorption inhibitors, monoclonal antibody therapy (PCSK9 inhibitors), nicotinic acid derivatives or bile acid sequestrants. There are several international guidelines on the treatment of hypercholesterolaemia.\nHuman trials using HMG-CoA reductase inhibitors, known as statins, have repeatedly confirmed that changing lipoprotein transport patterns from unhealthy to healthier patterns significantly lowers cardiovascular disease event rates, even for people with cholesterol values currently considered low for adults. Studies have shown that reducing LDL cholesterol levels by about 38.7\u00a0mg/dL with the use of statins can reduce cardiovascular disease and stroke risk by about 21%. Studies have also found that statins reduce atheroma progression. As a result, people with a history of cardiovascular disease may derive benefit from statins irrespective of their cholesterol levels (total cholesterol below 5.0\u00a0mmol/L [193\u00a0mg/dL]), and in men without cardiovascular disease, there is benefit from lowering abnormally high cholesterol levels (\"primary prevention\"). Primary prevention in women was originally practiced only by extension of the findings in studies on men, since, in women, none of the large statin trials conducted prior to 2007 demonstrated a significant reduction in overall mortality or in cardiovascular endpoints. Meta-analyses have demonstrated significant reductions in all-cause and cardiovascular mortality, without significant heterogeneity by sex.\nThe 1987 report of National Cholesterol Education Program, Adult Treatment Panels suggests the total blood cholesterol level should be: &lt; 200\u00a0mg/dL normal blood cholesterol, 200\u2013239\u00a0mg/dL borderline-high, &gt; 240\u00a0mg/dL high cholesterol. The American Heart Association provides a similar set of guidelines for total (fasting) blood cholesterol levels and risk for heart disease: Statins are effective in lowering LDL cholesterol and widely used for primary prevention in people at high risk of cardiovascular disease, as well as in secondary prevention for those who have developed cardiovascular disease.\nMore current testing methods determine LDL (\"bad\") and HDL (\"good\") cholesterol separately, allowing cholesterol analysis to be more nuanced. The desirable LDL level is considered to be less than 100\u00a0mg/dL (2.6 mmol/L), although a newer upper limit of 70\u00a0mg/dL (1.8\u00a0mmol/L) can be considered in higher-risk individuals based on some of the above-mentioned trials. A ratio of total cholesterol to HDL\u2014another useful measure\u2014of far less than 5:1 is thought to be healthier.\nTotal cholesterol is defined as the sum of HDL, LDL, and VLDL. Usually, only the total, HDL, and triglycerides are measured. For cost reasons, the VLDL is usually estimated as one-fifth of the triglycerides and the LDL is estimated using the Friedewald formula (or a variant): estimated LDL = [total cholesterol] \u2212 [total HDL] \u2212 [estimated VLDL]. Direct LDL measures are used when triglycerides exceed 400\u00a0mg/dL. The estimated VLDL and LDL have more error when triglycerides are above 400\u00a0mg/dL.\nIn the Framingham Heart Study, each 10\u00a0mg/dL (0.6 mmol/L) increase in total cholesterol levels increased 30-year overall mortality by 5% and CVD mortality by 9%. While subjects over the age of 50 had an 11% increase in overall mortality, and a 14% increase in cardiovascular disease mortality per 1\u00a0mg/dL (0.06 mmol/L) year drop in total cholesterol levels. The researchers attributed this phenomenon to reverse causation, whereby the disease itself increases risk of death, as well as changes a myriad of factors, such as weight loss and the inability to eat, which lower serum cholesterol. This effect was also shown in men of all ages and women over 50 in the Vorarlberg Health Monitoring and Promotion Programme. These groups were more likely to die of cancer, liver diseases, and mental diseases with very low total cholesterol, of 186\u00a0mg/dL (10.3 mmol/L) and lower. This result indicates the low-cholesterol effect occurs even among younger respondents, contradicting the previous assessment among cohorts of older people that this is a marker for frailty occurring with age.\nHypocholesterolemia.\nAbnormally low levels of cholesterol are termed \"hypocholesterolemia\". Research into the causes of this state is relatively limited, but some studies suggest a link with depression, cancer, and cerebral hemorrhage. In general, the low cholesterol levels seem to be a consequence, rather than a cause, of an underlying illness. A genetic defect in cholesterol synthesis causes Smith\u2013Lemli\u2013Opitz syndrome, which is often associated with low plasma cholesterol levels. Hyperthyroidism, or any other endocrine disturbance which causes upregulation of the LDL receptor, may result in hypocholesterolemia.\nCholesterol testing.\nThe American Heart Association recommends testing cholesterol every 4\u20136 years for people aged 20 years or older. A separate set of American Heart Association guidelines issued in 2013 indicates that people taking statin medications should have their cholesterol tested 4\u201312 weeks after their first dose and then every 3\u201312 months thereafter. For men ages 45 to 65 and women ages 55 to 65, a cholesterol test should occur every 1-2 years, and for seniors over age 65, an annual test should be performed.\nA blood sample after 12-hours of fasting is taken by a healthcare professional from an arm vein to measure a lipid profile for a) total cholesterol, b) HDL cholesterol, c) LDL cholesterol, and d) triglycerides. Results may be expressed as \"calculated\", indicating a calculation of total cholesterol, HDL, and triglycerides.\nCholesterol is tested to determine for \"normal\" or \"desirable\" levels if a person has a total cholesterol of 5.2\u00a0mmol/L or less (200\u00a0mg/dL), an HDL value of more than 1\u00a0mmol/L (40\u00a0mg/dL, \"the higher, the better\"), an LDL value of less than 2.6\u00a0mmol/L (100\u00a0mg/dL), and a triglycerides level of less than 1.7\u00a0mmol/L (150\u00a0mg/dL). Blood cholesterol in people with lifestyle, aging, or cardiovascular risk factors, such as diabetes mellitus, hypertension, family history of coronary artery disease, or angina, are evaluated at different levels.\nInteractive pathway map.\n\"Click on genes, proteins and metabolites below to link to respective articles.\" \nStatin Pathway edit\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCholesteric liquid crystals.\nSome cholesterol derivatives (among other simple cholesteric lipids) are known to generate the liquid crystalline \"cholesteric phase\". The cholesteric phase is, in fact, a chiral nematic phase, and it changes colour when its temperature changes. This makes cholesterol derivatives useful for indicating temperature in liquid-crystal display thermometers and in temperature-sensitive paints.\nStereoisomers.\nCholesterol has 256 stereoisomers that arise from its eight stereocenters, although only two of the stereoisomers have biochemical significance (\"nat\"-cholesterol and \"ent\"-cholesterol, for \"natural\" and \"enantiomer\", respectively), and only one occurs naturally (\"nat\"-cholesterol).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6438", "revid": "1159898791", "url": "https://en.wikipedia.org/wiki?curid=6438", "title": "Chromosome", "text": "DNA molecule containing genetic material of a cell\nA chromosome is a long DNA molecule with part or all of the genetic material of an organism. In most chromosomes the very long thin DNA fibers are coated with packaging proteins; in eukaryotic cells the most important of these proteins are the histones. These proteins, aided by chaperone proteins, bind to and condense the DNA molecule to maintain its integrity. These chromosomes display a complex three-dimensional structure, which plays a significant role in transcriptional regulation.\nChromosomes are normally visible under a light microscope only during the metaphase of cell division (where all chromosomes are aligned in the center of the cell in their condensed form). Before this happens, each chromosome is duplicated (S phase), and both copies are joined by a centromere, resulting either in an X-shaped structure (pictured above), if the centromere is located equatorially, or a two-arm structure, if the centromere is located distally. The joined copies are now called sister chromatids. During metaphase the X-shaped structure is called a metaphase chromosome, which is highly condensed and thus easiest to distinguish and study. In animal cells, chromosomes reach their highest compaction level in anaphase during chromosome segregation.\nChromosomal recombination during meiosis and subsequent sexual reproduction play a significant role in genetic diversity. If these structures are manipulated incorrectly, through processes known as chromosomal instability and translocation, the cell may undergo mitotic catastrophe. Usually, this will make the cell initiate apoptosis leading to its own death, but sometimes mutations in the cell hamper this process and thus cause progression of cancer.\nSome use the term chromosome in a wider sense, to refer to the individualized portions of chromatin in cells, either visible or not under light microscopy. Others use the concept in a narrower sense, to refer to the individualized portions of chromatin during cell division, visible under light microscopy due to high condensation.\nEtymology.\nThe word \"chromosome\" () comes from the Greek (\"chroma\", \"colour\") and (\"soma\", \"body\"), describing their strong staining by particular dyes. The term was coined by the German anatomist Heinrich Wilhelm Waldeyer, referring to the term chromatin, which was introduced by Walther Flemming.\nSome of the early karyological terms have become outdated. For example, Chromatin (Flemming 1880) and Chromosom (Waldeyer 1888), both ascribe color to a non-colored state.\nHistory of discovery.\nOtto B\u00fctschli was the first scientist to recognize the structures now known as chromosomes.\nIn a series of experiments beginning in the mid-1880s, Theodor Boveri gave definitive contributions to elucidating that chromosomes are the vectors of heredity, with two notions that became known as 'chromosome continuity' and 'chromosome individuality'.\nWilhelm Roux suggested that each chromosome carries a different genetic configuration, and Boveri was able to test and confirm this hypothesis. Aided by the rediscovery at the start of the 1900s of Gregor Mendel's earlier work, Boveri was able to point out the connection between the rules of inheritance and the behaviour of the chromosomes. Boveri influenced two generations of American cytologists: Edmund Beecher Wilson, Nettie Stevens, Walter Sutton and Theophilus Painter were all influenced by Boveri (Wilson, Stevens, and Painter actually worked with him).\nIn his famous textbook \"The Cell in Development and Heredity\", Wilson linked together the independent work of Boveri and Sutton (both around 1902) by naming the chromosome theory of inheritance the Boveri\u2013Sutton chromosome theory (the names are sometimes reversed). Ernst Mayr remarks that the theory was hotly contested by some famous geneticists: William Bateson, Wilhelm Johannsen, Richard Goldschmidt and T.H. Morgan, all of a rather dogmatic turn of mind. Eventually, complete proof came from chromosome maps in Morgan's own lab.\nThe number of human chromosomes was published in 1923 by Theophilus Painter. By inspection through the microscope, he counted 24 pairs, which would mean 48 chromosomes. His error was copied by others and it was not until 1956 that the true number, 46, was determined by Indonesia-born cytogeneticist Joe Hin Tjio.\nProkaryotes.\nThe prokaryotes\u00a0\u2013 bacteria and archaea\u00a0\u2013 typically have a single circular chromosome, but many variations exist. The chromosomes of most bacteria, which some authors prefer to call genophores, can range in size from only 130,000 base pairs in the endosymbiotic bacteria \"Candidatus Hodgkinia cicadicola\" and \"Candidatus Tremblaya princeps\", to more than 14,000,000 base pairs in the soil-dwelling bacterium \"Sorangium cellulosum\". Spirochaetes of the genus \"Borrelia\" are a notable exception to this arrangement, with bacteria such as \"Borrelia burgdorferi\", the cause of Lyme disease, containing a single \"linear\" chromosome.\nStructure in sequences.\nProkaryotic chromosomes have less sequence-based structure than eukaryotes. Bacteria typically have a one-point (the origin of replication) from which replication starts, whereas some archaea contain multiple replication origins. The genes in prokaryotes are often organized in operons, and do not usually contain introns, unlike eukaryotes.\nDNA packaging.\nProkaryotes do not possess nuclei. Instead, their DNA is organized into a structure called the nucleoid. The nucleoid is a distinct structure and occupies a defined region of the bacterial cell. This structure is, however, dynamic and is maintained and remodeled by the actions of a range of histone-like proteins, which associate with the bacterial chromosome. In archaea, the DNA in chromosomes is even more organized, with the DNA packaged within structures similar to eukaryotic nucleosomes.\nCertain bacteria also contain plasmids or other extrachromosomal DNA. These are circular structures in the cytoplasm that contain cellular DNA and play a role in horizontal gene transfer. In prokaryotes (see nucleoids) and viruses, the DNA is often densely packed and organized; in the case of archaea, by homology to eukaryotic histones, and in the case of bacteria, by histone-like proteins.\nBacterial chromosomes tend to be tethered to the plasma membrane of the bacteria. In molecular biology application, this allows for its isolation from plasmid DNA by centrifugation of lysed bacteria and pelleting of the membranes (and the attached DNA).\nProkaryotic chromosomes and plasmids are, like eukaryotic DNA, generally supercoiled. The DNA must first be released into its relaxed state for access for transcription, regulation, and replication.\nEukaryotes.\nEach eukaryotic chromosome consists of a long linear DNA molecule associated with proteins, forming a compact complex of proteins and DNA called \"chromatin.\" Chromatin contains the vast majority of the DNA of an organism, but a small amount inherited maternally, can be found in the mitochondria. It is present in most cells, with a few exceptions, for example, red blood cells.\nHistones are responsible for the first and most basic unit of chromosome organization, the nucleosome.\nEukaryotes (cells with nuclei such as those found in plants, fungi, and animals) possess multiple large linear chromosomes contained in the cell's nucleus. Each chromosome has one centromere, with one or two arms projecting from the centromere, although, under most circumstances, these arms are not visible as such. In addition, most eukaryotes have a small circular mitochondrial genome, and some eukaryotes may have additional small circular or linear cytoplasmic chromosomes.\nIn the nuclear chromosomes of eukaryotes, the uncondensed DNA exists in a semi-ordered structure, where it is wrapped around histones (structural proteins), forming a composite material called chromatin.\nInterphase chromatin.\nThe packaging of DNA into nucleosomes causes a 10 nanometer fibre which may further condense up to 30\u00a0nm fibres Most of the euchromatin in interphase nuclei appears to be in the form of 30-nm fibers. Chromatin structure is the more decondensed state, i.e. the 10-nm conformation allows transcription.\nDuring interphase (the period of the cell cycle where the cell is not dividing), two types of chromatin can be distinguished:\nMetaphase chromatin and division.\nIn the early stages of mitosis or meiosis (cell division), the chromatin double helix become more and more condensed. They cease to function as accessible genetic material (transcription stops) and become a compact transportable form. The loops of 30-nm chromatin fibers are thought to fold upon themselves further to form the compact metaphase chromosomes of mitotic cells. The DNA is thus condensed about 10,000 fold.\nThe chromosome scaffold, which is made of proteins such as condensin, TOP2A and KIF4, plays an important role in holding the chromatin into compact chromosomes. Loops of 30\u00a0nm structure further condense with scaffold into higher order structures.\nThis highly compact form makes the individual chromosomes visible, and they form the classic four-arm structure, a pair of sister chromatids attached to each other at the centromere. The shorter arms are called \"p arms\" (from the French \"petit\", small) and the longer arms are called \"q arms\" (\"q\" follows \"p\" in the Latin alphabet; q-g \"grande\"; alternatively it is sometimes said q is short for \"queue\" meaning tail in French). This is the only natural context in which individual chromosomes are visible with an optical microscope.\nMitotic metaphase chromosomes are best described by a linearly organized longitudinally compressed array of consecutive chromatin loops.\nDuring mitosis, microtubules grow from centrosomes located at opposite ends of the cell and also attach to the centromere at specialized structures called kinetochores, one of which is present on each sister chromatid. A special DNA base sequence in the region of the kinetochores provides, along with special proteins, longer-lasting attachment in this region. The microtubules then pull the chromatids apart toward the centrosomes, so that each daughter cell inherits one set of chromatids. Once the cells have divided, the chromatids are uncoiled and DNA can again be transcribed. In spite of their appearance, chromosomes are structurally highly condensed, which enables these giant DNA structures to be contained within a cell nucleus.\nHuman chromosomes.\nChromosomes in humans can be divided into two types: autosomes (body chromosome(s)) and allosome (sex chromosome(s)). Certain genetic traits are linked to a person's sex and are passed on through the sex chromosomes. The autosomes contain the rest of the genetic hereditary information. All act in the same way during cell division. Human cells have 23 pairs of chromosomes (22 pairs of autosomes and one pair of sex chromosomes), giving a total of 46 per cell. In addition to these, human cells have many hundreds of copies of the mitochondrial genome. Sequencing of the human genome has provided a great deal of information about each of the chromosomes. Below is a table compiling statistics for the chromosomes, based on the Sanger Institute's human genome information in the Vertebrate Genome Annotation (VEGA) database. Number of genes is an estimate, as it is in part based on gene predictions. Total chromosome length is an estimate as well, based on the estimated size of unsequenced heterochromatin regions.\nBased on the micrographic characteristics of size, position of the centromere and sometimes the presence of a chromosomal satellite, the human chromosomes are classified into the following groups:\nKaryotype.\nIn general, the karyotype is the characteristic chromosome complement of a eukaryote species. The preparation and study of karyotypes is part of cytogenetics.\nAlthough the replication and transcription of DNA is highly standardized in eukaryotes, the same cannot be said for their karyotypes, which are often highly variable. There may be variation between species in chromosome number and in detailed organization.\nIn some cases, there is significant variation within species. Often there is:\n1. variation between the two sexes\n2. variation between the germline and soma (between gametes and the rest of the body)\n3. variation between members of a population, due to balanced genetic polymorphism\n4. geographical variation between races\n5. mosaics or otherwise abnormal individuals.\nAlso, variation in karyotype may occur during development from the fertilized egg.\nThe technique of determining the karyotype is usually called \"karyotyping\". Cells can be locked part-way through division (in metaphase) in vitro (in a reaction vial) with colchicine. These cells are then stained, photographed, and arranged into a \"karyogram\", with the set of chromosomes arranged, autosomes in order of length, and sex chromosomes (here X/Y) at the end.\nLike many sexually reproducing species, humans have special gonosomes (sex chromosomes, in contrast to autosomes). These are XX in females and XY in males. \nHistory and analysis techniques.\nInvestigation into the human karyotype took many years to settle the most basic question: \"How many chromosomes does a normal diploid human cell contain?\" In 1912, Hans von Winiwarter reported 47 chromosomes in spermatogonia and 48 in oogonia, concluding an XX/XO sex determination mechanism. Painter in 1922 was not certain whether the diploid number of man is 46 or 48, at first favouring 46. He revised his opinion later from 46 to 48, and he correctly insisted on humans having an XX/XY system.\nNew techniques were needed to definitively solve the problem:\nIt took until 1954 before the human diploid number was confirmed as 46. Considering the techniques of Winiwarter and Painter, their results were quite remarkable. Chimpanzees, the closest living relatives to modern humans, have 48 chromosomes as do the other great apes: in humans two chromosomes fused to form chromosome 2.\nAberrations.\nChromosomal aberrations are disruptions in the normal chromosomal content of a cell and are a major cause of genetic conditions in humans, such as Down syndrome, although most aberrations have little to no effect. Some chromosome abnormalities do not cause disease in carriers, such as translocations, or chromosomal inversions, although they may lead to a higher chance of bearing a child with a chromosome disorder. Abnormal numbers of chromosomes or chromosome sets, called aneuploidy, may be lethal or may give rise to genetic disorders. Genetic counseling is offered for families that may carry a chromosome rearrangement.\nThe gain or loss of DNA from chromosomes can lead to a variety of genetic disorders. Human examples include:\nSperm aneuploidy.\nExposure of males to certain lifestyle, environmental and/or occupational hazards may increase the risk of aneuploid spermatozoa. In particular, risk of aneuploidy is increased by tobacco smoking, and occupational exposure to benzene, insecticides, and perfluorinated compounds. Increased aneuploidy is often associated with increased DNA damage in spermatozoa.\nNumber in various organisms.\nIn eukaryotes.\nThe number of chromosomes in eukaryotes is highly variable (see table). In fact, chromosomes can fuse or break and thus evolve into novel karyotypes. Chromosomes can also be fused artificially. For example, the 16 chromosomes of yeast have been fused into one giant chromosome and the cells were still viable with only somewhat reduced growth rates.\nThe tables below give the total number of chromosomes (including sex chromosomes) in a cell nucleus. For example, most eukaryotes are diploid, like humans who have 22 different types of autosomes, each present as two homologous pairs, and two sex chromosomes. This gives 46 chromosomes in total. Other organisms have more than two copies of their chromosome types, such as bread wheat, which is \"hexaploid\" and has six copies of seven different chromosome types\u00a0\u2013 42 chromosomes in total. \nNormal members of a particular eukaryotic species all have the same number of nuclear chromosomes (see the table). Other eukaryotic chromosomes, i.e., mitochondrial and plasmid-like small chromosomes, are much more variable in number, and there may be thousands of copies per cell.\nAsexually reproducing species have one set of chromosomes that are the same in all body cells. However, asexual species can be either haploid or diploid.\nSexually reproducing species have somatic cells (body cells), which are diploid [2n] having two sets of chromosomes (23 pairs in humans), one set from the mother and one from the father. Gametes, reproductive cells, are haploid [n]: They have one set of chromosomes. Gametes are produced by meiosis of a diploid germline cell. During meiosis, the matching chromosomes of father and mother can exchange small parts of themselves (crossover), and thus create new chromosomes that are not inherited solely from either parent. When a male and a female gamete merge (fertilization), a new diploid organism is formed.\nSome animal and plant species are polyploid [Xn]: They have more than two sets of homologous chromosomes. Plants important in agriculture such as tobacco or wheat are often polyploid, compared to their ancestral species. Wheat has a haploid number of seven chromosomes, still seen in some cultivars as well as the wild progenitors. The more-common pasta and bread wheat types are polyploid, having 28 (tetraploid) and 42 (hexaploid) chromosomes, compared to the 14 (diploid) chromosomes in the wild wheat.\nIn prokaryotes.\nProkaryote species generally have one copy of each major chromosome, but most cells can easily survive with multiple copies. For example, \"Buchnera\", a symbiont of aphids has multiple copies of its chromosome, ranging from 10\u2013400 copies per cell. However, in some large bacteria, such as \"Epulopiscium fishelsoni\" up to 100,000 copies of the chromosome can be present. Plasmids and plasmid-like small chromosomes are, as in eukaryotes, highly variable in copy number. The number of plasmids in the cell is almost entirely determined by the rate of division of the plasmid\u00a0\u2013 fast division causes high copy number.\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6439", "revid": "15449111", "url": "https://en.wikipedia.org/wiki?curid=6439", "title": "Charge", "text": "Charge or charged may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "6440", "revid": "41991464", "url": "https://en.wikipedia.org/wiki?curid=6440", "title": "Colonna family", "text": "Italian noble family\nThe House of Colonna, also known as \"Sciarrillo\" or \"Sciarra\", is an Italian noble family, forming part of the papal nobility. It was powerful in medieval and Renaissance Rome, supplying one pope (Martin V) and many other church and political leaders. The family is notable for its bitter feud with the Orsini family over influence in Rome, until it was stopped by papal bull in 1511. In 1571, the heads of both families married nieces of Pope Sixtus V. Thereafter, historians recorded that \"no peace had been concluded between the princes of Christendom, in which they had not been included by name\".\nHistory.\nOrigins.\nAccording to tradition, the Colonna family is a branch of the Counts of Tusculum \u2014 by Peter (1099\u20131151) son of Gregory III, called Peter \"de Columna\" from his property the Columna Castle in Colonna, in the Alban Hills. Further back, they trace their lineage past the Counts of Tusculum via Lombard and Italo-Roman nobles, merchants, and clergy through the Early Middle Ages \u2014 ultimately claiming origins from the Julio-Claudian dynasty and the gens Julia whose origin is lost in the mists of time but which entered the annals for the first time in 489 BC with the consulship of Gaius Julius Iulus.\nThe first cardinal from the family was appointed in 1206, when Giovanni Colonna di Carbognano was made Cardinal Deacon of SS. Cosma e Damiano. For many years, Cardinal Giovanni di San Paolo (elevated in 1193) was identified as a member of the Colonna family and therefore its first representative in the College of Cardinals, but modern scholars have established that this was based on false information from the beginning of the 16th century.\nGiovanni Colonna (born c. 1206) nephew of Cardinal Giovanni Colonna di Carbognano, made his solemn vows as a Dominican around 1228 and received his theological and philosophical training at the Roman \"studium\" of Santa Sabina, the forerunner of the Pontifical University of Saint Thomas Aquinas, \"Angelicum\". He served as the Provincial of the Roman province of the Dominican Order and led the provincial chapter of 1248 at Anagni. Colonna was appointed as Archbishop of Messina in 1255.\nMargherita Colonna (died 1248) was a member of the Franciscan Order. She was beatified by Pope Pius IX in 1848.\nAt this time, a rivalry began with the pro-papal Orsini family, leaders of the Guelph faction. This reinforced the pro-Emperor Ghibelline course that the Colonna family followed throughout the period of conflict between the Papacy and the Holy Roman Empire. Ironically according to their own family legend, the Orsini are also descended from the Julio-Claudian dynasty of ancient Rome.\nColonna versus Papacy.\nIn 1297, Cardinal Jacopo disinherited his brothers Ottone, Matteo, and Landolfo of their lands. The latter three appealed to Pope Boniface VIII, who ordered Jacopo to return the land, and furthermore hand over the family's strongholds of Colonna, Palestrina, and other towns to the Papacy. Jacopo refused; in May, Boniface removed him from the College of Cardinals and excommunicated him and his followers.\nThe Colonna family (aside from the three brothers allied with the Pope) declared that Boniface had been elected illegally following the unprecedented abdication of Pope Celestine V. The dispute led to open warfare, and in September, Boniface appointed Landolfo to the command of his army, to put down the revolt of Landolfo's own Colonna relatives. By the end of 1298, Landolfo had captured Colonna, Palestrina and other towns, and razed them to the ground. The family's lands were distributed among Landolfo and his loyal brothers; the rest of the family fled Italy.\nThe exiled Colonnas allied with the Pope's other great enemy, Philip IV of France, who in his youth had been tutored by Cardinal Egidio Colonna. In September 1303, Sciarra and Philipp's advisor, Guillaume de Nogaret, led a small force into Anagni to arrest Boniface VIII and bring him to France, where he was to stand trial. The two managed to apprehend the pope, and Sciarra reportedly slapped the pope in the face in the process, which was accordingly dubbed the \"Outrage of Anagni\". The attempt eventually failed after a few days, when locals freed the pope. However, Boniface VIII died on 11 October, allowing France to dominate his weaker successors during the Avignon papacy.\nLate Middle Ages.\nThe family remained at the centre of civic and religious life throughout the late Middle Ages. Cardinal Egidio Colonna died at the papal court in Avignon in 1314. An Augustinian, he had studied theology in Paris under St. Thomas of Aquinas to become one of the most authoritative thinkers of his time.\nIn the 14th century, the family sponsored the decoration of the Church of San Giovanni, most notably the floor mosaics.\nIn 1328, Louis IV of Germany marched into Italy for his coronation as Holy Roman Emperor. As Pope John XXII was residing in Avignon and had publicly declared that he would not crown Louis, the King decided to be crowned by a member of the Roman aristocracy, who proposed Sciarra Colonna. In honor of this event, the Colonna family was granted the privilege of using the imperial pointed crown on top of their coat of arms.\nThe celebrated poet Petrarch, was a great friend of the family, in particular of Giovanni Colonna and often lived in Rome as a guest of the family. He composed a number of sonnets for special occasions within the Colonna family, including \"Colonna the Glorious, the great Latin name upon which all our hopes rest\". In this period, the Colonna started claiming they were descendants of the Julio-Claudian dynasty.\nAt the Council of Constance, the Colonna finally succeeded in their papal ambitions when Oddone Colonna was elected on 14 November 1417. As Martin V, he reigned until his death on 20 February 1431.\nEarly modern period.\nVittoria Colonna became famous in the sixteenth century as a poet and a figure in literate circles.\nIn 1627 Anna Colonna, daughter of Filippo I Colonna, married Taddeo Barberini of the family Barberini; nephew of Pope Urban VIII.\nIn 1728, the Carbognano branch (Colonna di Sciarra) of the Colonna family added the name Barberini to its family name when Giulio Cesare Colonna di Sciarra married Cornelia Barberini, daughter of the last male Barberini to hold the name and granddaughter of Maffeo Barberini (son of Taddeo Barberini).\nCurrent status.\nThe Colonna family have been Prince Assistants to the Papal Throne since 1710, though their papal princely title only dates from 1854.\nThe family residence in Rome, the Palazzo Colonna, is open to the public every Saturday morning.\nThe main 'Colonna di Paliano' line is represented today by Prince Marcantonio Colonna di Paliano, Prince and Duke of Paliano (b. 1948), whose heir is Don Giovanni Andrea Colonna di Paliano (b. 1975), and by Don Prospero Colonna di Paliano, Prince of Avella (b. 1956), whose heir is Don Filippo Colonna di Paliano (b. 1995).\nThe 'Colonna di Stigliano' line is represented by Don Prospero Colonna di Stigliano, Prince of Stigliano (b. 1938), whose heir is his nephew Don Stefano Colonna di Stigliano (b. 1975) principe frederico giuseppe born 1954 \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6443", "revid": "10951369", "url": "https://en.wikipedia.org/wiki?curid=6443", "title": "Ceuta", "text": "Spanish autonomous city in North Africa\nCeuta (, , ]; ) is a Spanish autonomous city on the north coast of Africa.\nBordered by Morocco, it lies along the boundary between the Mediterranean Sea and the Atlantic Ocean. It is one of several Spanish territories in Africa and, along with Melilla and the Canary Islands, one of only a few that are permanently inhabited by a civilian population. It was a regular municipality belonging to the province of C\u00e1diz prior to the passing of its Statute of Autonomy in March 1995, henceforth becoming an autonomous city.\nCeuta, like Melilla and the Canary Islands, was classified as a free port before Spain joined the European Union. Its population consists mainly of Christians and Muslims. There is also a small minority of Sephardic Jews and Sindhi Hindus, the latter of whom originate from current-day Pakistan.\nSpanish is the only official language, but Darija Arabic is prominent as well.\nNames.\nThe name Abyla has been said to have been a Punic name (\"Lofty Mountain\" or \"Mountain of God\") for Jebel Musa, the southern Pillar of Hercules. The name of the mountain was in fact \"Habenna\" (, , \"Stone\" or \"Stele\") or \"\u02beAbin-\u1e25\u012bq\" (, , \"Rock of the Bay\"), in reference to the nearby Bay of Benz\u00fa. The name was hellenized variously as \"\u00c1pini\" (Greek: ), \"Ab\u00fdla\" (), \"Ab\u00fdl\u0113\" (), \"Abl\u00fdx\" (), and \"Abil\u0113 St\u1e17l\u0113\" (, \"Pillar of Abyla\") and in Latin as ' (\"Mount Abyla\") or ' (\"the Pillar of Abyla\").\nThe settlement below Jebel Musa was later renamed for the seven hills around the site, collectively referred to as the \"Seven Brothers\" (Greek: , \u00a0; ). In particular, the Roman stronghold at the site took the name \"Fort at the Seven Brothers\" (). This was gradually shortened to Septem ( \"S\u00e9pton\") or, occasionally, Septum or Septa. These clipped forms continued as Berber \"Sebta\" and Arabic \"Sabtan\" or \"Sabtah\" (), which themselves became in Portuguese (pronounced\u00a0]) and Spanish (locally ]).\nHistory.\nAncient.\nControlling access between the Atlantic Ocean and the Mediterranean Sea, the Strait of Gibraltar is an important military and commercial chokepoint. The Phoenicians realized the extremely narrow isthmus joining the Peninsula of Almina to the African mainland makes Ceuta eminently defensible and established an outpost there early in the 1st millenniumBC. The Greek geographers record it by variations of \"Abyla\", the ancient name of nearby Jebel Musa. Beside Calpe, the other Pillar of Hercules now known as the Rock of Gibraltar, the Phoenicians established Kart at what is now San Roque, Spain. Other good anchorages nearby became Phoenician and then Carthaginian ports at what are now Tangiers and C\u00e1diz.\nAfter Carthage's destruction in the Punic Wars, most of northwest Africa was left to the Roman client states of Numidia and\u2014around Abyla\u2014Mauretania. Punic culture continued to thrive in what the Romans knew as \"Septem\". After the Battle of Thapsus in 46\u00a0BC, Caesar and his heirs began annexing north Africa directly as Roman provinces but, as late as Augustus, most of Septem's Berber residents continued to speak and write in Punic.\nCaligula assassinated the Mauretanian king Ptolemy in AD40 and seized his kingdom, which Claudius organized in AD\u00a042, placing Septem in the province of Tingitana and raising it to the level of a colony. It subsequently was romanized and thrived into the late 3rd century, trading heavily with Roman Spain and becoming well known for its salted fish. Roads connected it overland with Tingis (Tangiers) and Volubilis. Under Theodosius I in the late 4th century, Septem still had 10,000 inhabitants, nearly all Christian citizens speaking African Romance, a local dialect of Latin.\nMedieval.\nVandals, probably invited by Count Boniface as protection against the empress dowager, crossed the strait near Tingis around 425 and swiftly overran Roman North Africa. Their king Gaiseric focused his attention on the rich lands around Carthage; although the Romans eventually accepted his conquests and he continued to raid them anyway, he soon lost control of Tingis and Septem in a series of Berber revolts. When Justinian decided to reconquer the Vandal lands, his victorious general Belisarius continued along the coast, making Septem a westernmost outpost of the Byzantine Empire around 533. Unlike the former ancient Roman administration, however, Eastern Rome did not push far into hinterland and made the more defensible Septem their regional capital in place of Tingis.\nEpidemics, less capable successors and overstretched supply lines forced a retrenchment and left Septem isolated. It is likely that its count (\"\") was obliged to pay homage to the Visigoth Kingdom in Spain in the early 7th century. There are no reliable contemporary accounts of the end of the Islamic conquest of the Maghreb around 710. Instead, the rapid Muslim conquest of Spain produced romances concerning Count Julian of Septem and his betrayal of Christendom in revenge for the dishonor that befell his daughter at King Roderick's court. Allegedly with Julian's encouragement and instructions, the Berber convert and freedman Tariq ibn Ziyad took his garrison from Tangiers across the strait and overran the Spanish so swiftly that both he and his master Musa bin Nusayr fell afoul of a jealous caliph, who stripped them of their wealth and titles.\nAfter the death of Julian, sometimes also described as a king of the Ghomara Berbers, Berber converts to Islam took direct control of what they called Sebta. It was then destroyed during their great revolt against the Umayyad Caliphate around 740. Sebta subsequently remained a small village of Muslims and Christians surrounded by ruins until its resettlement in the 9th century by M\u00e2jakas, chief of the Majkasa Berber tribe, who started the short-lived Banu Isam dynasty. His great-grandson briefly allied his tribe with the Idrisids, but Banu Isam rule ended in 931 when he abdicated in favor of Abd ar-Rahman III, the Umayyad ruler of C\u00f3rdoba.\nChaos ensued with the fall of the Caliphate of C\u00f3rdoba in 1031. Following this, Ceuta and Muslim Iberia were controlled by successive North African dynasties. Starting in 1084, the Almoravid Berbers ruled the region until 1147, when the Almohads conquered the land. Apart from Ibn Hud's rebellion in 1232, they ruled until the Tunisian Hafsids established control. The Hafsids' influence in the west rapidly waned, and Ceuta's inhabitants eventually expelled them in 1249. After this, a period of political instability persisted, under competing interests from the Marinids and Granada as well as autonomous rule under the native Banu al-Azafi. The Fez finally conquered the region in 1387, with assistance from Aragon.\nPortuguese.\nOn the morning of 21 August 1415, King John I of Portugal led his sons and their assembled forces in a surprise assault that would come to be known as the Conquest of Ceuta. The battle was almost anticlimactic, because the 45,000 men who traveled on 200 Portuguese ships caught the defenders of Ceuta off guard and suffered only eight casualties. By nightfall the town was captured. On the morning of 22 August, Ceuta was in Portuguese hands. \u00c1lvaro Vaz de Almada, 1st Count of Avranches was asked to hoist what was to become the flag of Ceuta, which is identical to the flag of Lisbon, but in which the coat of arms derived from that of the Kingdom of Portugal was added to the center; the original Portuguese flag and coat of arms of Ceuta remained unchanged, and the modern-day Ceuta flag features the configuration of the Portuguese shield.\nJohn's son Henry the Navigator distinguished himself in the battle, being wounded during the conquest. The looting of the city proved to be less profitable than expected for John I; he decided to keep the city to pursue further enterprises in the area.\nFrom 1415 to 1437, Pedro de Meneses became the first governor of Ceuta.\nThe Marinid Sultanate started the 1419 siege but was defeated by the first governor of Ceuta before reinforcements arrived in the form of John, Constable of Portugal and his brother Henry the Navigator who were sent with troops to defend Ceuta.\nUnder King John I's son, Duarte, the colony at Ceuta rapidly became a drain on the Portuguese treasury. Trans-Saharan trade journeyed instead to Tangier. It was soon realized that without the city of Tangier, possession of Ceuta was worthless. In 1437, Duarte's brothers Henry the Navigator and Fernando, the Saint Prince persuaded him to launch an attack on the Marinid sultanate. The resulting Battle of Tangier (1437), led by Henry, was a debacle. In the resulting treaty, Henry promised to deliver Ceuta back to the Marinids in return for allowing the Portuguese army to depart unmolested, which he reneged on.\nPossession of Ceuta would indirectly lead to further Portuguese expansion. The main area of Portuguese expansion, at this time, was the coast of the Maghreb, where there was grain, cattle, sugar, and textiles, as well as fish, hides, wax, and honey.\nCeuta had to endure alone for 43 years, until the position of the city was consolidated with the taking of Ksar es-Seghir (1458), Arzila and Tangier (1471) by the Portuguese.\nThe city was recognized as a Portuguese possession by the Treaty of Alc\u00e1\u00e7ovas (1479) and by the Treaty of Tordesillas (1494).\nIn the 1540s the Portuguese began building the Royal Walls of Ceuta as they are today including bastions, a navigable moat and a drawbridge. Some of these bastions are still standing, like the bastions of Coraza Alta, Bandera and Mallorquines.\nLu\u00eds de Cam\u00f5es lived in Ceuta between 1549 and 1551, losing his right eye in battle, which influenced his work of poetry \"Os Lus\u00edadas\".\nIberian Union.\nIn 1578 King Sebastian of Portugal died at the Battle of Alc\u00e1cer Quibir (known as the Battle of Three Kings) in what is today northern Morocco, without descendants, triggering the 1580 Portuguese succession crisis. His granduncle, the elderly Cardinal Henry, succeeded him as King, but Henry also had no descendants, having taken holy orders. When the cardinal-king died two years after Sebastian's death, three grandchildren of King Manuel I of Portugal claimed the throne: Infanta Catarina, Duchess of Braganza; Ant\u00f3nio, Prior of Crato; and Philip II of Spain (Uncle of former King Sebastian of Portugal), who would prevail and be crowned King Philip I of Portugal in 1581, uniting the two crowns and overseas empires in what is historically referred to as the \"Iberian Union\".\nDuring the Iberian Union 1580 to 1640, Ceuta attracted many settlers of Spanish origin. Ceuta became the only city of the Portuguese Empire that sided with Spain, when Portugal regained its independence in the Portuguese Restoration War of 1640.\nSpanish.\nOn 1 January 1668, King Afonso VI of Portugal recognised the formal allegiance of Ceuta to Spain and ceded Ceuta to King Carlos II of Spain by the Treaty of Lisbon.\nThe city was attacked by Moroccan forces under Moulay Ismail during the Siege of Ceuta (1694\u20131727). During the longest siege in history, the city underwent changes leading to the loss of its Portuguese character. While most of the military operations took place around the Royal Walls of Ceuta, there were also small-scale penetrations by Spanish forces at various points on the Moroccan coast, and seizure of shipping in the Strait of Gibraltar.\nDuring the Napoleonic Wars (1803-1815), Spain allowed Britain to occupy Ceuta. Occupation began in 1810, with Ceuta being returned at the conclusion of the Wars.\nDisagreements regarding the border of Ceuta resulted in the Hispano-Moroccan War (1859\u201360), which ended at the Battle of Tetu\u00e1n.\nIn July 1936, General Francisco Franco took command of the Spanish Army of Africa and rebelled against the Spanish republican government; his military uprising led to the Spanish Civil War of 1936\u20131939. Franco transported troops to mainland Spain in an airlift using transport aircraft supplied by Germany and Italy. Ceuta became one of the first battlegrounds of the uprising: General Franco's rebel nationalist forces seized Ceuta, while at the same time the city came under fire from the air and sea forces of the official republican government.\nThe Llano Amarillo monument was erected to honor Francisco Franco, it was inaugurated on 13 July 1940. The tall obelisk has since been abandoned, but the shield symbols of the Falange and Imperial Eagle remain visible.\nFollowing the 1947 Partition of India, a substantial number of Sindhi Hindus from current-day Pakistan settled in Ceuta, adding up to a small Hindu community that had existed in Ceuta since 1893, connected to Gibraltar's.\nWhen Spain recognized the independence of Spanish Morocco in 1956, Ceuta and the other remained under Spanish rule. Spain considered them integral parts of the Spanish state, but Morocco has disputed this point.\nCulturally, modern Ceuta is part of the Spanish region of Andalusia. It was attached to the province of C\u00e1diz until 1925, the Spanish coast being only 20\u00a0km (12.5 miles) away. It is a cosmopolitan city, with a large ethnic Arab-Berber Muslim minority as well as Sephardic Jewish and Hindu minorities.\nOn 5 November 2007, King Juan Carlos I visited the city, sparking great enthusiasm from the local population and protests from the Moroccan government. It was the first time a Spanish head of state had visited Ceuta in 80 years.\nSince 2010, Ceuta (and Melilla) have declared the Muslim holiday of Eid al-Adha, or Feast of the Sacrifice, an official public holiday. It is the first time a non-Christian religious festival has been officially celebrated in Spanish ruled territory since the Reconquista.\nGeography.\nCeuta is separated by from the province of C\u00e1diz on the Spanish mainland by the Strait of Gibraltar and it shares a land border with M'diq-Fnideq Prefecture in the Kingdom of Morocco. It has an area of . It is dominated by Monte Anyera, a hill along its western frontier with Morocco, which is guarded by a Spanish military fort. Monte Hacho on the Peninsula of Almina overlooking the port is one of the possible locations of the southern pillar of the Pillars of Hercules of Greek legend (the other possibility being Jebel Musa).\nImportant Bird Area.\nThe Ceuta Peninsula has been recognised as an Important Bird Area (IBA) by BirdLife International because the site is part of a migratory bottleneck, or choke point, at the western end of the Mediterranean for large numbers of raptors, storks and other birds flying between Europe and Africa. These include European honey buzzards, black kites, short-toed snake eagles, Egyptian vultures, griffon vultures, black storks, white storks and Audouin's gulls.\nClimate.\nCeuta has a maritime-influenced Mediterranean climate, similar to nearby Spanish and Moroccan cities such as Tarifa, Algeciras or Tangiers. The average diurnal temperature variation is relatively low; the average annual temperature is with average yearly highs of and lows of though the Ceuta weather station has only been in operation since 2003. Ceuta has relatively mild winters for the latitude, while summers are warm yet milder than in the interior of Southern Spain, due to the moderating effect of the Straits of Gibraltar. Summers are very dry, but yearly precipitation is still at , which could be considered a humid climate if the summers were not so arid.\nGovernment and administration.\nSince 1995, Ceuta is, along with Melilla, one of the two autonomous cities of Spain.\nCeuta is known officially in Spanish as (English: \"Autonomous City of Ceuta\"), with a rank between a standard municipality and an autonomous community. Ceuta is part of the territory of the European Union. The city was a free port before Spain joined the European Union in 1986. Now it has a low-tax system within the Economic and Monetary Union of the European Union.\nSince 1979, Ceuta has held elections to its 25-seat assembly every four years. The leader of its government was the Mayor until the Autonomy Statute provided for the new title of Mayor-President. As of 2011[ [update]], the People's Party (PP) won 18 seats, keeping Juan Jes\u00fas Vivas as Mayor-President, which he has been since 2001. The remaining seats are held by the regionalist Caballas Coalition (4) and the Socialist Workers' Party (PSOE, 3).\nOwing to its small population, Ceuta elects only one member of the Congress of Deputies, the lower house of the Spanish legislature. As of the November 2019[ [update]] election, this post is held by Mar\u00eda Teresa L\u00f3pez of Vox.\nCeuta is subdivided into 63 (\"neighborhoods\"), such as Barriada de Berizu, Barriada de P. Alfonso, Barriada del Sarchal, and El Hacho.\nCeuta maintains its own police force.\nDefence and Civil Guard.\nThe defence of the enclave is the responsibility of the Spanish Armed Forces' General Command of Ceuta (COMGECEU). The Spanish Army's combat components of the command include:\nThe command also includes its headquarters battalion as well as logistics elements.\nIn 2023, the Spanish Navy replaced the \"Aresa\"-class patrol boat \"P-114\" in the territory with the \"Rodman\"-class patrol boat \"Isla de Le\u00f3n\".\nCeuta itself is only distant from the main Spanish naval base at Rota on the Spanish mainland. The Spanish Air Force's Mor\u00f3n Air Base is also within proximity.\nThe Civil Guard is responsible for border security and protects both the territory's fortified land border as well as its maritime approaches against frequent, and sometimes significant, migrant incursions.\nEconomy.\nThe official currency of Ceuta is the euro. It is part of a special low tax zone in Spain. Ceuta is one of two Spanish port cities on the northern shore of Africa, along with Melilla. They are historically military strongholds, free ports, oil ports, and also fishing ports. Today the economy of the city depends heavily on its port (now in expansion) and its industrial and retail centres. Ceuta Heliport is now used to connect the city to mainland Spain by air. Lidl, Decathlon and El Corte Ingl\u00e9s have branches in Ceuta. There is also a casino.\nBorder trade between Ceuta and Morocco is active because of advantage of tax-free status. Thousands of Moroccan women are involved in the cross-border porter trade daily, as porteadoras. The Moroccan dirham is used in such trade, even though prices are marked in euros.\nTransport.\nThe city's Port of Ceuta receives high numbers of ferries each day from Algeciras in Andalusia in the south of Spain. The closest airport is Sania Ramel Airport in Morocco.\nA single road border checkpoint to the south of Ceuta near Fnideq allows for cars and pedestrians to travel between Morocco and Ceuta. An additional border crossing for pedestrians exists between Benz\u00fa and Belyounech on the northern coast. The rest of the border is closed and inaccessible.\nThere is a bus service throughout the city, and while it does not pass into neighbouring Morocco, it services both frontier crossings.\nHospitals.\nThe following hospitals are located within Ceuta:\nDemographics.\nAs of 2018, its population was 85,144.\nDue to its location, Ceuta is home to a mixed ethnic and religious population. The two main religious groups are Christians and Muslims. As of 2006 approximately 50% of the population was Christian and approximately 48% Muslim. As of a 2018 estimate, around 67.8% of the city's population were born in Ceuta.\nSpanish is the primary and official language of the enclave. Moroccan Arabic (Darija) is widely spoken. In 2021, the Council of Europe demanded that Spain formally recognize the language by 2023.\nReligion.\nChristianity has been present in Ceuta continuously from late antiquity, as evidenced by the ruins of a basilica in downtown Ceuta and accounts of the martyrdom of St. Daniel Fasanella and his Franciscans in 1227 during the Almohad Caliphate.\nThe town's Grand Mosque had been built over a Byzantine-era church. In 1415, the year of the city's conquest, the Portuguese converted the Grand Mosque into Ceuta Cathedral. The present form of the cathedral dates to refurbishments undertaken in the late 17th century, combining baroque and neoclassical elements. It was dedicated to StMary of the Assumption in 1726.\nThe Roman Catholic Diocese of Ceuta was established in 1417. It incorporated the suppressed Diocese of Tanger in 1570. The Diocese of Ceuta was a suffragan of Lisbon until 1675, when it became a suffragan of Seville. In 1851, Ceuta's administration was notionally merged into the Diocese of C\u00e1diz and Ceuta as part of a concordat between Spain and the Holy See; the union was not actually accomplished, however, until 1879.\nSmall Jewish and Hindu minorities are also present in the city.\nRoman Catholicism is the largest religion in Ceuta. In 2019, the proportion of Ceutans that identify themselves as Roman Catholic was 60.0%. The next largest religion was Islam (36.7%) and only 3,4% of people considered themselves as non-religious (1,5% atheist and \n1,9% as non-religious) \nMigration.\nLike Melilla, Ceuta attracts African migrants both Christians (Pentecostals mostly) and Muslims who try to use it as an entry to Europe. As a result, the enclave is surrounded by double fences that are high, and hundreds of migrants congregate near the fences waiting for a chance to cross them. The fences are regularly stormed by migrants trying to claim asylum once they enter Ceuta.\nEducation.\nThe University of Granada offers undergraduate programs at their campus in Ceuta. Like all areas of Spain, Ceuta is also served by the National University of Distance Education (UNED).\nWhile primary and secondary education are generally offered in Spanish only, a growing number of schools are entering the Bilingual Education Program.\nTwin towns and sister cities.\nCeuta is twinned with:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDispute with Morocco.\nThe government of Morocco has repeatedly called for Spain to transfer the sovereignty of Ceuta and Melilla, along with uninhabited islets such as the islands of Alhucemas, Velez and the Perejil island, drawing comparisons with Spain's territorial claim to Gibraltar. In both cases, the national governments and local populations of the disputed territories reject these claims by a large majority. The Spanish position is that both Ceuta and Melilla are integral parts of Spain, and have been since the 16th century, centuries prior to Morocco's independence from Spain and France in 1956, whereas Gibraltar, being a British Overseas Territory, is not and never has been part of the United Kingdom. Morocco has claimed the territories are colonies. One of the chief arguments used by Morocco to reclaim Ceuta comes from geography, as this exclave, which is surrounded by Morocco and the Mediterranean Sea, has no territorial continuity with the rest of Spanish territory. This argument was originally developed by one of the founders of the Moroccan Istiqlal Party, Alal-El Faasi, who openly advocated the Moroccan conquest of Ceuta and other territories under Spanish rule.\nIn 1986, Spain entered the North Atlantic Treaty Organization.\nHowever Ceuta and Melilla are not under NATO protection since Article 6 of the treaty limits the coverage to Europe and North America and islands north of the Tropic of Cancer.\nThis contrasts with French Algeria which was explicitly included in the treaty.\nLegal experts have interpreted that other articles could cover the Spanish North African cities but this interpretation has not been tested in practice. On the occasion of NATO's Madrid Summit in 2022, the issue of the protection Ceuta and Melilla was a prominent one with NATO Secretary General Jens Stoltenberg stating: \"On which territories NATO protects and Ceuta and Melilla, NATO is there to protect all Allies against any threats. At the end of the day, it will always be a political decision to invoke Article 5, but rest assured NATO is there to protect and defend all Allies\".\nOn 21 December 2020, following the affirmations of the Moroccan Prime Minister, Saadeddine Othmani, stating that Ceuta and Melilla \"are Moroccan as the Sahara [is]\", Spain urgently summoned the Moroccan ambassador to convey that Spain expects all its partners to respect the sovereignty and territorial integrity of its territory in Africa and asked for explanations of Othmani's words.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6444", "revid": "33625371", "url": "https://en.wikipedia.org/wiki?curid=6444", "title": "Cleopatra (disambiguation)", "text": "Cleopatra (69\u201330 BC) was the last active Ptolemaic ruler of Egypt before it became a Roman province.\nCleopatra may also refer to: for\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nGiven name.\nFrom the Greek name \u039a\u03bb\u03b5\u03bf\u03c0\u03ac\u03c4\u03c1\u03b1 (Kleopatra) meaning \"glory of the father\", derived from \u03ba\u03bb\u03ad\u03bf\u03c2 (kleos) meaning \"glory\" combined with \u03c0\u03b1\u03c4\u03ae\u03c1 (pater) meaning \"father\" (genitive \u03c0\u03b1\u03c4\u03c1\u03cc\u03c2). \nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "6445", "revid": "18701033", "url": "https://en.wikipedia.org/wiki?curid=6445", "title": "Carcinogen", "text": "Substance, radionuclide, or radiation directly involved in causing cancer\nA carcinogen is any substance, radionuclide, or radiation that promotes carcinogenesis (the formation of cancer). This may be due to the ability to damage the genome or to the disruption of cellular metabolic processes. Several radioactive substances are considered carcinogens, but their carcinogenic activity is attributed to the radiation, for example gamma rays and alpha particles, which they emit. Common examples of non-radioactive carcinogens are inhaled asbestos, certain dioxins, and tobacco smoke. Although the public generally associates carcinogenicity with synthetic chemicals, it is equally likely to arise from both natural and synthetic substances. Carcinogens are not necessarily immediately toxic; thus, their effect can be insidious.\nCarcinogens, as mentioned, are agents in the environment capable of contributing to cancer growth. Carcinogens can be categorized into two different types: activation-dependent and activation-independent, and each nature impacts their level and type of influence when it comes to promoting cancer growth. Activation-dependent carcinogens require metabolic activation or modification to induce cancer, while activation-independents ones do not. Examples of activation-dependent carcinogens range from certain viruses, such as HPV, to consumed alcohol, to excessive amounts of red and processed meats, impacting a person's health in ways they may not immediately associate with cancer. Activation-independent carcinogens, such as ultraviolet rays or nitrosamines in tobacco products, possess characteristics enabling them to interact directly with DNA and other cellular components to cause harm. These include not requiring metabolic action or molecular changes to act, which complements their ability to be electrically excited, permitting them to interact with oxygen and nitrogen atoms in negatively charged cellular environments. This type of interaction leads to the alteration of DNA nucleotide bases, causing disarrangement of that genetic material. This disarrangement is also responsible for the formation of DNA adducts, segments of DNA which bind to carcinogens, which furthers harm. Eventually, failure in DNA repair mechanisms will lead to a buildup of DNA damage and potentially the development of cancer.\nCancer is any disease in which normal cells are damaged and do not undergo programmed cell death as fast as they divide via mitosis. Carcinogens may increase the risk of cancer by altering cellular metabolism or damaging DNA directly in cells, which interferes with biological processes, and induces the uncontrolled, malignant division, ultimately leading to the formation of tumors. Usually, severe DNA damage leads to programmed cell death, but if the programmed cell death pathway is damaged, then the cell cannot prevent itself from becoming a cancer cell.\nThere are many natural carcinogens. Aflatoxin B1, which is produced by the fungus \"Aspergillus flavus\" growing on stored grains, nuts and peanut butter, is an example of a potent, naturally occurring microbial carcinogen. Certain viruses such as hepatitis B and human papilloma virus have been found to cause cancer in humans. The first one shown to cause cancer in animals is Rous sarcoma virus, discovered in 1910 by Peyton Rous. Other infectious organisms which cause cancer in humans include some bacteria (e.g. \"Helicobacter pylori\" ) and helminths (e.g. \"Opisthorchis viverrini\" and \"Clonorchis sinensis\").\nDioxins and dioxin-like compounds, benzene, kepone, EDB, and asbestos have all been classified as carcinogenic. As far back as the 1930s, industrial smoke and tobacco smoke were identified as sources of dozens of carcinogens, including benzo[\"a\"]pyrene, tobacco-specific nitrosamines such as nitrosonornicotine, and reactive aldehydes such as formaldehyde, which is also a hazard in embalming and making plastics. Vinyl chloride, from which PVC is manufactured, is a carcinogen and thus a hazard in PVC production.\nCo-carcinogens are chemicals that do not necessarily cause cancer on their own but promote the activity of other carcinogens in causing cancer.\nAfter the carcinogen enters the body, the body makes an attempt to eliminate it through a process called biotransformation. The purpose of these reactions is to make the carcinogen more water-soluble so that it can be removed from the body. However, in some cases, these reactions can also convert a less toxic carcinogen into a more toxic carcinogen.\nDNA is nucleophilic; therefore, soluble carbon electrophiles are carcinogenic, because DNA attacks them. For example, some alkenes are toxicated by human enzymes to produce an electrophilic epoxide. DNA attacks the epoxide, and is bound permanently to it. This is the mechanism behind the carcinogenicity of benzo[\"a\"]pyrene in tobacco smoke, other aromatics, aflatoxin and mustard gas.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n IUPAC definition\n Carcinogenicity: Ability or tendency to produce cancer.\nNote: In general, polymers are not known as carcinogens or mutagens,however, residual monomers or additives [in polymers] can cause genetic mutations.\nRadiation.\nCERCLA identifies all radionuclides as carcinogens, although the nature of the emitted radiation (alpha, beta, gamma, or neutron and the radioactive strength), its consequent capacity to cause ionization in tissues, and the magnitude of radiation exposure, determine the potential hazard. Carcinogenicity of radiation depends on the type of radiation, type of exposure, and penetration. For example, alpha radiation has low penetration and is not a hazard outside the body, but emitters are carcinogenic when inhaled or ingested. For example, Thorotrast, a (incidentally radioactive) suspension previously used as a contrast medium in x-ray diagnostics, is a potent human carcinogen known because of its retention within various organs and persistent emission of alpha particles. Low-level ionizing radiation may induce irreparable DNA damage (leading to replicational and transcriptional errors needed for neoplasia or may trigger viral interactions) leading to pre-mature aging and cancer.\nNot all types of electromagnetic radiation are carcinogenic. Low-energy waves on the electromagnetic spectrum including radio waves, microwaves, infrared radiation and visible light are thought not to be, because they have insufficient energy to break chemical bonds. Evidence for carcinogenic effects of non-ionizing radiation is generally inconclusive, though there are some documented cases of radar technicians with prolonged high exposure experiencing significantly higher cancer incidence.\nHigher-energy radiation, including ultraviolet radiation (present in sunlight), x-rays, and gamma radiation, generally \"is\" carcinogenic, if received in sufficient doses. For most people, ultraviolet radiations from sunlight is the most common cause of skin cancer. In Australia, where people with pale skin are often exposed to strong sunlight, melanoma is the most common cancer diagnosed in people aged 15\u201344 years.\nSubstances or foods irradiated with electrons or electromagnetic radiation (such as microwave, X-ray or gamma) are not carcinogenic. In contrast, non-electromagnetic neutron radiation produced inside nuclear reactors can produce secondary radiation through nuclear transmutation.\nIn prepared food.\nChemicals used in processed and cured meat such as some brands of bacon, sausages and ham may produce carcinogens. For example, nitrites used as food preservatives in cured meat such as bacon have also been noted as being carcinogenic with demographic links, but not causation, to colon cancer. Cooking food at high temperatures, for example grilling or barbecuing meats, may also lead to the formation of minute quantities of many potent carcinogens that are comparable to those found in cigarette smoke (i.e., benzo[\"a\"]pyrene). Charring of food looks like coking and tobacco pyrolysis, and produces carcinogens. There are several carcinogenic pyrolysis products, such as polynuclear aromatic hydrocarbons, which are converted by human enzymes into epoxides, which attach permanently to DNA. Pre-cooking meats in a microwave oven for 2\u20133 minutes before grilling shortens the time on the hot pan, and removes heterocyclic amine (HCA) precursors, which can help minimize the formation of these carcinogens.\nBaking, grilling or broiling food, especially starchy foods, until a toasted crust is formed generates significant concentrations of acrylamide. This discovery in 2002 led to international health concerns. Subsequent research has however found that it is not likely that the acrylamides in burnt or well-cooked food cause cancer in humans; Cancer Research UK categorizes the idea that burnt food causes cancer as a \"myth\".\nIn cigarettes.\nThere is a strong association of smoking with lung cancer; the risk of developing lung cancer increases significantly in smokers. A large number of known carcinogens are found in cigarette smoke. Potent carcinogens found in cigarette smoke include polycyclic aromatic hydrocarbons (PAH, such as benzo(a)pyrene), benzene, and nitrosamine.\nMechanisms of carcinogenicity.\nCarcinogens can be classified as genotoxic or nongenotoxic. Genotoxins cause irreversible genetic damage or mutations by binding to DNA. Genotoxins include chemical agents like N-nitroso-N-methylurea (NMU) or non-chemical agents such as ultraviolet light and ionizing radiation. Certain viruses can also act as carcinogens by interacting with DNA.\nNongenotoxins do not directly affect DNA but act in other ways to promote growth. These include hormones and some organic compounds.\nClassification.\nInternational Agency for Research on Cancer.\nThe International Agency for Research on Cancer (IARC) is an intergovernmental agency established in 1965, which forms part of the World Health Organization of the United Nations. It is based in Lyon, France. Since 1971 it has published a series of \"Monographs on the Evaluation of Carcinogenic Risks to Humans\" that have been highly influential in the classification of possible carcinogens.\nGlobally Harmonized System.\nThe Globally Harmonized System of Classification and Labelling of Chemicals (GHS) is a United Nations initiative to attempt to harmonize the different systems of assessing chemical risk which currently exist (as of March 2009) around the world. It classifies carcinogens into two categories, of which the first may be divided again into subcategories if so desired by the competent regulatory authority:\nU.S. National Toxicology Program.\nThe National Toxicology Program of the U.S. Department of Health and Human Services is mandated to produce a biennial \"Report on Carcinogens\". As of June 2011, the latest edition was the 12th report (2011). It classifies carcinogens into two groups:\nAmerican Conference of Governmental Industrial Hygienists.\nThe American Conference of Governmental Industrial Hygienists (ACGIH) is a private organization best known for its publication of threshold limit values (TLVs) for occupational exposure and monographs on workplace chemical hazards. It assesses carcinogenicity as part of a wider assessment of the occupational hazards of chemicals.\nEuropean Union.\nThe European Union classification of carcinogens is contained in the Regulation (EC) No 1272/2008. It consists of three categories:\nThe former European Union classification of carcinogens was contained in the Dangerous Substances Directive and the Dangerous Preparations Directive. It also consisted of three categories:\nThis assessment scheme is being phased out in favor of the GHS scheme (see above), to which it is very close in category definitions.\nSafe Work Australia.\nUnder a previous name, the NOHSC, in 1999 Safe Work Australia published the Approved Criteria for Classifying Hazardous Substances [NOHSC:1008(1999)].\nSection 4.76 of this document outlines the criteria for classifying carcinogens as approved by the Australian government. This classification consists of three categories:\nCommon carcinogens.\nOccupational carcinogens.\nOccupational carcinogens are agents that pose a risk of cancer in several specific work-locations:\nDisclaimer: \"The following list is far from being exhaustive.\"\nMajor carcinogens implicated in the four most common cancers worldwide.\nIn this section, the carcinogens implicated as the main causative agents of the four most common cancers worldwide are briefly described. These four cancers are lung, breast, colon, and stomach cancers. Together they account for about 41% of worldwide cancer incidence and 42% of cancer deaths (for more detailed information on the carcinogens implicated in these and other cancers, see references).\nLung cancer.\nLung cancer (pulmonary carcinoma) is the most common cancer in the world, both in terms of cases (1.6 million cases; 12.7% of total cancer cases) and deaths (1.4 million deaths; 18.2% of total cancer deaths). Lung cancer is largely caused by tobacco smoke. Risk estimates for lung cancer in the United States indicate that tobacco smoke is responsible for 90% of lung cancers. Other factors are implicated in lung cancer, and these factors can interact synergistically with smoking so that total attributable risk adds up to more than 100%. These factors include occupational exposure to carcinogens (about 9-15%), radon (10%) and outdoor air pollution (1-2%). Tobacco smoke is a complex mixture of more than 5,300 identified chemicals. The most important carcinogens in tobacco smoke have been determined by a \"Margin of Exposure\" approach. Using this approach, the most important tumorigenic compounds in tobacco smoke were, in order of importance, acrolein, formaldehyde, acrylonitrile, 1,3-butadiene, cadmium, acetaldehyde, ethylene oxide, and isoprene. Most of these compounds cause DNA damage by forming DNA adducts or by inducing other alterations in DNA. DNA damages are subject to error-prone DNA repair or can cause replication errors. Such errors in repair or replication can result in mutations in tumor suppressor genes or oncogenes leading to cancer.\nBreast cancer.\nBreast cancer is the second most common cancer [(1.4 million cases, 10.9%), but ranks 5th as cause of death (458,000, 6.1%)]. Increased risk of breast cancer is associated with persistently elevated blood levels of estrogen. Estrogen appears to contribute to breast carcinogenesis by three processes; (1) the metabolism of estrogen to genotoxic, mutagenic carcinogens, (2) the stimulation of tissue growth, and (3) the repression of phase II detoxification enzymes that metabolize ROS leading to increased oxidative DNA damage. The major estrogen in humans, estradiol, can be metabolized to quinone derivatives that form adducts with DNA. These derivatives can cause depurination, the removal of bases from the phosphodiester backbone of DNA, followed by inaccurate repair or replication of the apurinic site leading to mutation and eventually cancer. This genotoxic mechanism may interact in synergy with estrogen receptor-mediated, persistent cell proliferation to ultimately cause breast cancer. Genetic background, dietary practices and environmental factors also likely contribute to the incidence of DNA damage and breast cancer risk.\nColon cancer.\nColorectal cancer is the third most common cancer [1.2 million cases (9.4%), 608,000 deaths (8.0%)]. Tobacco smoke may be responsible for up to 20% of colorectal cancers in the United States. In addition, substantial evidence implicates bile acids as an important factor in colon cancer. Twelve studies (summarized in Bernstein et al.) indicate that the bile acids deoxycholic acid (DCA) or lithocholic acid (LCA) induce production of DNA-damaging reactive oxygen species or reactive nitrogen species in human or animal colon cells. Furthermore, 14 studies showed that DCA and LCA induce DNA damage in colon cells. Also 27 studies reported that bile acids cause programmed cell death (apoptosis). Increased apoptosis can result in selective survival of cells that are resistant to induction of apoptosis. Colon cells with reduced ability to undergo apoptosis in response to DNA damage would tend to accumulate mutations, and such cells may give rise to colon cancer. Epidemiologic studies have found that fecal bile acid concentrations are increased in populations with a high incidence of colon cancer. Dietary increases in total fat or saturated fat result in elevated DCA and LCA in feces and elevated exposure of the colon epithelium to these bile acids. When the bile acid DCA was added to the standard diet of wild-type mice invasive colon cancer was induced in 56% of the mice after 8 to 10 months. Overall, the available evidence indicates that DCA and LCA are centrally important DNA-damaging carcinogens in colon cancer.\nStomach cancer.\nStomach cancer is the fourth most common cancer [990,000 cases (7.8%), 738,000 deaths (9.7%)]. \"Helicobacter pylori\" infection is the main causative factor in stomach cancer. Chronic gastritis (inflammation) caused by \"H. pylori\" is often long-standing if not treated. Infection of gastric epithelial cells with \"H. pylori\" results in increased production of reactive oxygen species (ROS). ROS cause oxidative DNA damage including the major base alteration 8-hydroxydeoxyguanosine (8-OHdG). 8-OHdG resulting from ROS is increased in chronic gastritis. The altered DNA base can cause errors during DNA replication that have mutagenic and carcinogenic potential. Thus \"H. pylori\"-induced ROS appear to be the major carcinogens in stomach cancer because they cause oxidative DNA damage leading to carcinogenic mutations. Diet is thought to be a contributing factor in stomach cancer - in Japan where very salty pickled foods are popular, the incidence of stomach cancer is high. Preserved meat such as bacon, sausages, and ham increases the risk while a diet high in fresh fruit and vegetables may reduce the risk. The risk also increases with age.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6446", "revid": "2666701", "url": "https://en.wikipedia.org/wiki?curid=6446", "title": "Camouflage", "text": "Concealment in plain sight by any means, e.g. colour, pattern and shape\nCamouflage is the use of any combination of materials, coloration, or illumination for concealment, either by making animals or objects hard to see, or by disguising them as something else. Examples include the leopard's spotted coat, the battledress of a modern soldier, and the leaf-mimic katydid's wings. A third approach, motion dazzle, confuses the observer with a conspicuous pattern, making the object visible but momentarily harder to locate, as well as making general aiming easier. The majority of camouflage methods aim for crypsis, often through a general resemblance to the background, high contrast disruptive coloration, eliminating shadow, and countershading. In the open ocean, where there is no background, the principal methods of camouflage are transparency, silvering, and countershading, while the ability to produce light is among other things used for counter-illumination on the undersides of cephalopods such as squid. Some animals, such as chameleons and octopuses, are capable of actively changing their skin pattern and colours, whether for camouflage or for signalling. It is possible that some plants use camouflage to evade being eaten by herbivores.\nMilitary camouflage was spurred by the increasing range and accuracy of firearms in the 19th century. In particular the replacement of the inaccurate musket with the rifle made personal concealment in battle a survival skill. In the 20th century, military camouflage developed rapidly, especially during the First World War. On land, artists such as Andr\u00e9 Mare designed camouflage schemes and observation posts disguised as trees. At sea, merchant ships and troop carriers were painted in dazzle patterns that were highly visible, but designed to confuse enemy submarines as to the target's speed, range, and heading. During and after the Second World War, a variety of camouflage schemes were used for aircraft and for ground vehicles in different theatres of war. The use of radar since the mid-20th century has largely made camouflage for fixed-wing military aircraft obsolete.\nNon-military use of camouflage includes making cell telephone towers less obtrusive and helping hunters to approach wary game animals. Patterns derived from military camouflage are frequently used in fashion clothing, exploiting their strong designs and sometimes their symbolism. Camouflage themes recur in modern art, and both figuratively and literally in science fiction and works of literature.\nHistory.\nIn ancient Greece, Aristotle (384\u2013322 BC) commented on the colour-changing abilities, both for camouflage and for signalling, of cephalopods including the octopus, in his \"Historia animalium\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The octopus\u00a0... seeks its prey by so changing its colour as to render it like the colour of the stones adjacent to it; it does so also when alarmed.\nCamouflage has been a topic of interest and research in zoology for well over a century. According to Charles Darwin's 1859 theory of natural selection, features such as camouflage evolved by providing individual animals with a reproductive advantage, enabling them to leave more offspring, on average, than other members of the same species. In his \"Origin of Species\", Darwin wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When we see leaf-eating insects green, and bark-feeders mottled-grey; the alpine ptarmigan white in winter, the red-grouse the colour of heather, and the black-grouse that of peaty earth, we must believe that these tints are of service to these birds and insects in preserving them from danger. Grouse, if not destroyed at some period of their lives, would increase in countless numbers; they are known to suffer largely from birds of prey; and hawks are guided by eyesight to their prey, so much so, that on parts of the Continent persons are warned not to keep white pigeons, as being the most liable to destruction. Hence I can see no reason to doubt that natural selection might be most effective in giving the proper colour to each kind of grouse, and in keeping that colour, when once acquired, true and constant.\nThe English zoologist Edward Bagnall Poulton studied animal coloration, especially camouflage. In his 1890 book \"The Colours of Animals\", he classified different types such as \"special protective resemblance\" (where an animal looks like another object), or \"general aggressive resemblance\" (where a predator blends in with the background, enabling it to approach prey). His experiments showed that swallow-tailed moth pupae were camouflaged to match the backgrounds on which they were reared as larvae. Poulton's \"general protective resemblance\" was at that time considered to be the main method of camouflage, as when Frank Evers Beddard wrote in 1892 that \"tree-frequenting animals are often green in colour. Among vertebrates numerous species of parrots, iguanas, tree-frogs, and the green tree-snake are examples\". Beddard did however briefly mention other methods, including the \"alluring coloration\" of the flower mantis and the possibility of a different mechanism in the orange tip butterfly. He wrote that \"the scattered green spots upon the under surface of the wings might have been intended for a rough sketch of the small flowerets of the plant [an umbellifer], so close is their mutual resemblance.\" He also explained the coloration of sea fish such as the mackerel: \"Among pelagic fish it is common to find the upper surface dark-coloured and the lower surface white, so that the animal is inconspicuous when seen either from above or below.\"\nThe artist Abbott Handerson Thayer formulated what is sometimes called Thayer's Law, the principle of countershading. However, he overstated the case in the 1909 book \"Concealing-Coloration in the Animal Kingdom\", arguing that \"All patterns and colors whatsoever of all animals that ever preyed or are preyed on are under certain normal circumstances obliterative\" (that is, cryptic camouflage), and that \"Not one 'mimicry' mark, not one 'warning color'...\u00a0nor any 'sexually selected' color, exists anywhere in the world where there is not every reason to believe it the very best conceivable device for the concealment of its wearer\", and using paintings such as \"Peacock in the Woods\" (1907) to reinforce his argument. Thayer was roundly mocked for these views by critics including Teddy Roosevelt.\nThe English zoologist Hugh Cott's 1940 book \"Adaptive Coloration in Animals\" corrected Thayer's errors, sometimes sharply: \"Thus we find Thayer straining the theory to a fantastic extreme in an endeavour to make it cover almost every type of coloration in the animal kingdom.\" Cott built on Thayer's discoveries, developing a comprehensive view of camouflage based on \"maximum disruptive contrast\", countershading and hundreds of examples. The book explained how disruptive camouflage worked, using streaks of boldly contrasting colour, paradoxically making objects less visible by breaking up their outlines. While Cott was more systematic and balanced in his view than Thayer, and did include some experimental evidence on the effectiveness of camouflage, his 500-page textbook was, like Thayer's, mainly a natural history narrative which illustrated theories with examples.\nExperimental evidence that camouflage helps prey avoid being detected by predators was first provided in 2016, when ground-nesting birds (plovers and coursers) were shown to survive according to how well their egg contrast matched the local environment.\nEvolution.\nAs there is a lack of evidence for camouflage in the fossil record, studying the evolution of camouflage strategies is very difficult. Furthermore, camouflage traits must be both adaptable (provide a fitness gain in a given environment) and heritable (in other words, the trait must undergo positive selection). Thus, studying the evolution of camouflage strategies requires an understanding of the genetic components and various ecological pressures that drive crypsis. \nFossil history.\nCamouflage is a soft-tissue feature that is rarely preserved in the fossil record, but rare fossilised skin samples from the Cretaceous period show that some marine reptiles were countershaded. The skins, pigmented with dark-coloured eumelanin, reveal that both leatherback turtles and mosasaurs had dark backs and light bellies. There is fossil evidence of camouflaged insects going back over 100\u00a0million years, for example lacewings larvae that stick debris all over their bodies much as their modern descendants do, hiding them from their prey. Dinosaurs appear to have been camouflaged, as a 120\u00a0million year old fossil of a \"Psittacosaurus\" has been preserved with countershading.\nGenetics.\nCamouflage does not have a single genetic origin. However, studying the genetic components of camouflage in specific organisms illuminates the various ways that crypsis can evolve among lineages. \nMany cephalopods have the ability to actively camouflage themselves, controlling crypsis through neural activity. For example, the genome of the common cuttlefish includes 16 copies of the reflectin gene, which grants the organism remarkable control over coloration and iridescence. The reflectin gene is thought to have originated through transposition from symbiotic \"Aliivibrio fischeri\" bacteria, which provide bioluminescence to its hosts. While not all cephalopods use active camouflage, ancient cephalopods may have inherited the gene horizontally from symbiotic \"A. fischeri\", with divergence occurred through subsequent gene duplication (such as in the case of \"Sepia officinalis\") or gene loss (as with cephalopods with no active camouflage capabilities).[3] This is unique as an instance of camouflage arising as an instance of horizontal gene transfer from an endosymbiont.\u00a0However, other methods of horizontal gene transfer are common in the evolution of camouflage strategies in other lineages. Peppered moths and walking stick insects both have camouflage-related genes that stem from transposition events.\nThe Agouti genes are orthologous genes involved in camouflage across many lineages. They produce yellow and red coloration (phaeomelanin), and work in competition with other genes that produce black (melanin) and brown (eumelanin) colours. In eastern deer mice, over a period of about 8000 years the single agouti gene developed 9 mutations that each made expression of yellow fur stronger under natural selection, and largely eliminated melanin-coding black fur coloration. On the other hand, all black domesticated cats have deletions of the agouti gene that prevent its expression, meaning no yellow or red color is produced. The evolution, history and widespread scope of the agouti gene shows that different organisms often rely on orthologous or even identical genes to develop a variety of camouflage strategies.\nEcology.\nWhile camouflage can increase an organism's fitness, it has genetic and energetic costs. There is a trade-off between detectability and mobility. Species camouflaged to fit a specific microhabitat are less likely to be detected when in that microhabitat, but must spend energy to reach, and sometimes to remain in, such areas. Outside the microhabitat, the organism has a higher chance of detection. Generalized camouflage allows species to avoid predation over a wide range of habitat backgrounds, but is less effective. The development of generalized or specialized camouflage strategies is highly dependent on the biotic and abiotic composition of the surrounding environment. \nThere are many examples of the tradeoffs between specific and general cryptic patterning. \"Phestilla melanocrachia\", a species of nudibranch that feeds on stony coral, utilizes specific cryptic patterning in reef ecosystems. The nudibranch syphons pigments from the consumed coral into the epidermis, adopting the same shade as the consumed coral. This allows the nudibranch to change colour (mostly between black and orange) depending on the coral system that it inhabits. However, \"P. melanocrachia\" can only feed and lay eggs on the branches of host-coral, \"Platygyra carnosa\", which limits the geographical range and efficacy in nudibranch nutritional crypsis. Furthermore, the nudibranch colour change is not immediate, and switching between coral hosts when in search for new food or shelter can be costly.\nThe costs associated with distractive or disruptive crypsis are more complex than the costs associated with background matching. Disruptive patterns distort the body outline, making it harder to precisely identify and locate. However, disruptive patterns result in higher predation. Disruptive patterns that specifically involve visible symmetry (such as in some butterflies) reduce survivability and increase predation. Some researchers argue that because wing-shape and color pattern are genetically linked, it is genetically costly to develop asymmetric wing colorations that would enhance the efficacy of disruptive cryptic patterning. Symmetry does not carry a high survival cost for butterflies and moths that their predators views from above on a homogeneous background, such as the bark of a tree. On the other hand, natural selection drives species with variable backgrounds and habitats to move symmetrical patterns away from the centre of the wing and body, disrupting their predators' symmetry recognition. \u00a0 \u00a0\nPrinciples.\nCamouflage can be achieved by different methods, described below. Most of the methods help to hide against a background; but mimesis and motion dazzle protect without hiding. Methods may be applied on their own or in combination. Many mechanisms are visual, but some research has explored the use of techniques against olfactory (scent) and acoustic (sound) detection. Methods may also apply to military equipment.\nResemblance to surroundings.\nSome animals' colours and patterns resemble a particular natural background. This is an important component of camouflage in all environments. For instance, tree-dwelling parakeets are mainly green; woodcocks of the forest floor are brown and speckled; reedbed bitterns are streaked brown and buff; in each case the animal's coloration matches the hues of its habitat. Similarly, desert animals are almost all desert coloured in tones of sand, buff, ochre, and brownish grey, whether they are mammals like the gerbil or fennec fox, birds such as the desert lark or sandgrouse, or reptiles like the skink or horned viper. Military uniforms, too, generally resemble their backgrounds; for example khaki uniforms are a muddy or dusty colour, originally chosen for service in South Asia. Many moths show industrial melanism, including the peppered moth which has coloration that blends in with tree bark. The coloration of these insects evolved between 1860 and 1940 to match the changing colour of the tree trunks on which they rest, from pale and mottled to almost black in polluted areas. This is taken by zoologists as evidence that camouflage is influenced by natural selection, as well as demonstrating that it changes where necessary to resemble the local background.\nDisruptive coloration.\nDisruptive patterns use strongly contrasting, non-repeating markings such as spots or stripes to break up the outlines of an animal or military vehicle, or to conceal telltale features, especially by masking the eyes, as in the common frog. Disruptive patterns may use more than one method to defeat visual systems such as edge detection. Predators like the leopard use disruptive camouflage to help them approach prey, while potential prey use it to avoid detection by predators. Disruptive patterning is common in military usage, both for uniforms and for military vehicles. Disruptive patterning, however, does not always achieve crypsis on its own, as an animal or a military target may be given away by factors like shape, shine, and shadow.\nThe presence of bold skin markings does not in itself prove that an animal relies on camouflage, as that depends on its behaviour. For example, although giraffes have a high contrast pattern that could be disruptive coloration, the adults are very conspicuous when in the open. Some authors have argued that adult giraffes are cryptic, since when standing among trees and bushes they are hard to see at even a few metres' distance. However, adult giraffes move about to gain the best view of an approaching predator, relying on their size and ability to defend themselves, even from lions, rather than on camouflage. A different explanation is implied by young giraffes being far more vulnerable to predation than adults. More than half of all giraffe calves die within a year, and giraffe mothers hide their newly born calves, which spend much of the time lying down in cover while their mothers are away feeding. The mothers return once a day to feed their calves with milk. Since the presence of a mother nearby does not affect survival, it is argued that these juvenile giraffes must be very well camouflaged; this is supported by coat markings being strongly inherited.\nThe possibility of camouflage in plants has been little studied until the late 20th century. Leaf variegation with white spots may serve as camouflage in forest understory plants, where there is a dappled background; leaf mottling is correlated with closed habitats. Disruptive camouflage would have a clear evolutionary advantage in plants: they would tend to escape from being eaten by herbivores. Another possibility is that some plants have leaves differently coloured on upper and lower surfaces or on parts such as veins and stalks to make green-camouflaged insects conspicuous, and thus benefit the plants by favouring the removal of herbivores by carnivores. These hypotheses are testable.\nEliminating shadow.\nSome animals, such as the horned lizards of North America, have evolved elaborate measures to eliminate shadow. Their bodies are flattened, with the sides thinning to an edge; the animals habitually press their bodies to the ground; and their sides are fringed with white scales which effectively hide and disrupt any remaining areas of shadow there may be under the edge of the body. The theory that the body shape of the horned lizards which live in open desert is adapted to minimise shadow is supported by the one species which lacks fringe scales, the roundtail horned lizard, which lives in rocky areas and resembles a rock. When this species is threatened, it makes itself look as much like a rock as possible by curving its back, emphasizing its three-dimensional shape. Some species of butterflies, such as the speckled wood, \"Pararge aegeria\", minimise their shadows when perched by closing the wings over their backs, aligning their bodies with the sun, and tilting to one side towards the sun, so that the shadow becomes a thin inconspicuous line rather than a broad patch. Similarly, some ground-nesting birds, including the European nightjar, select a resting position facing the sun. Eliminating shadow was identified as a principle of military camouflage during the Second World War.\nDistraction.\nMany prey animals have conspicuous high-contrast markings which paradoxically attract the predator's gaze. These distractive markings may serve as camouflage by distracting the predator's attention from recognising the prey as a whole, for example by keeping the predator from identifying the prey's outline. Experimentally, search times for blue tits increased when artificial prey had distractive markings.\nSelf-decoration.\nSome animals actively seek to hide by decorating themselves with materials such as twigs, sand, or pieces of shell from their environment, to break up their outlines, to conceal the features of their bodies, and to match their backgrounds. For example, a caddisfly larva builds a decorated case and lives almost entirely inside it; a decorator crab covers its back with seaweed, sponges, and stones. The nymph of the predatory masked bug uses its hind legs and a 'tarsal fan' to decorate its body with sand or dust. There are two layers of bristles (trichomes) over the body. On these, the nymph spreads an inner layer of fine particles and an outer layer of coarser particles. The camouflage may conceal the bug from both predators and prey.\nSimilar principles can be applied for military purposes, for instance when a sniper wears a ghillie suit designed to be further camouflaged by decoration with materials such as tufts of grass from the sniper's immediate environment. Such suits were used as early as 1916, the British army having adopted \"coats of motley hue and stripes of paint\" for snipers. Cott takes the example of the larva of the blotched emerald moth, which fixes a screen of fragments of leaves to its specially hooked bristles, to argue that military camouflage uses the same method, pointing out that the \"device is ... essentially the same as one widely practised during the Great War for the concealment, not of caterpillars, but of caterpillar-tractors, [gun] battery positions, observation posts and so forth.\"\nCryptic behaviour.\nMovement catches the eye of prey animals on the lookout for predators, and of predators hunting for prey. Most methods of crypsis therefore also require suitable cryptic behaviour, such as lying down and keeping still to avoid being detected, or in the case of stalking predators such as the tiger, moving with extreme stealth, both slowly and quietly, watching its prey for any sign they are aware of its presence. As an example of the combination of behaviours and other methods of crypsis involved, young giraffes seek cover, lie down, and keep still, often for hours until their mothers return; their skin pattern blends with the pattern of the vegetation, while the chosen cover and lying position together hide the animals' shadows. The flat-tail horned lizard similarly relies on a combination of methods: it is adapted to lie flat in the open desert, relying on stillness, its cryptic coloration, and concealment of its shadow to avoid being noticed by predators. In the ocean, the leafy sea dragon sways mimetically, like the seaweeds amongst which it rests, as if rippled by wind or water currents. Swaying is seen also in some insects, like Macleay's spectre stick insect, \"Extatosoma tiaratum\". The behaviour may be motion crypsis, preventing detection, or motion masquerade, promoting misclassification (as something other than prey), or a combination of the two.\nMotion camouflage.\nMost forms of camouflage are ineffective when the camouflaged animal or object moves, because the motion is easily seen by the observing predator, prey or enemy. However, insects such as hoverflies and dragonflies use motion camouflage: the hoverflies to approach possible mates, and the dragonflies to approach rivals when defending territories. Motion camouflage is achieved by moving so as to stay on a straight line between the target and a fixed point in the landscape; the pursuer thus appears not to move, but only to loom larger in the target's field of vision. The same method can be used for military purposes, for example by missiles to minimise their risk of detection by an enemy. However, missile engineers, and animals such as bats, use the method mainly for its efficiency rather than camouflage.\nChangeable skin coloration.\nAnimals such as chameleon, frog, flatfish such as the peacock flounder, squid, octopus and even the isopod idotea balthica actively change their skin patterns and colours using special chromatophore cells to resemble their current background, or, as in most chameleons, for signalling. However, Smith's dwarf chameleon does use active colour change for camouflage.\nEach chromatophore contains pigment of only one colour. In fish and frogs, colour change is mediated by a type of chromatophore known as melanophores that contain dark pigment. A melanophore is star-shaped; it contains many small pigmented organelles which can be dispersed throughout the cell, or aggregated near its centre. When the pigmented organelles are dispersed, the cell makes a patch of the animal's skin appear dark; when they are aggregated, most of the cell, and the animal's skin, appears light. In frogs, the change is controlled relatively slowly, mainly by hormones. In fish, the change is controlled by the brain, which sends signals directly to the chromatophores, as well as producing hormones.\nThe skins of cephalopods such as the octopus contain complex units, each consisting of a chromatophore with surrounding muscle and nerve cells. The cephalopod chromatophore has all its pigment grains in a small elastic sac, which can be stretched or allowed to relax under the control of the brain to vary its opacity. By controlling chromatophores of different colours, cephalopods can rapidly change their skin patterns and colours.\nOn a longer timescale, animals like the Arctic hare, Arctic fox, stoat, and rock ptarmigan have snow camouflage, changing their coat colour (by moulting and growing new fur or feathers) from brown or grey in the summer to white in the winter; the Arctic fox is the only species in the dog family to do so. However, Arctic hares which live in the far north of Canada, where summer is very short, remain white year-round.\nThe principle of varying coloration either rapidly or with the changing seasons has military applications. \"Active camouflage\" could in theory make use of both dynamic colour change and counterillumination. Simple methods such as changing uniforms and repainting vehicles for winter have been in use since World War II. In 2011, BAE Systems announced their Adaptiv infrared camouflage technology. It uses about 1,000 hexagonal panels to cover the sides of a tank. The Peltier plate panels are heated and cooled to match either the vehicle's surroundings (crypsis), or an object such as a car (mimesis), when viewed in infrared.\nCountershading.\nCountershading uses graded colour to counteract the effect of self-shadowing, creating an illusion of flatness. Self-shadowing makes an animal appear darker below than on top, grading from light to dark; countershading 'paints in' tones which are darkest on top, lightest below, making the countershaded animal nearly invisible against a suitable background. Thayer observed that \"Animals are painted by Nature, darkest on those parts which tend to be most lighted by the sky's light, and \"vice versa\"\". Accordingly, the principle of countershading is sometimes called \"Thayer's Law\". Countershading is widely used by terrestrial animals, such as gazelles and grasshoppers; marine animals, such as sharks and dolphins; and birds, such as snipe and dunlin.\nCountershading is less often used for military camouflage, despite Second World War experiments that showed its effectiveness. English zoologist Hugh Cott encouraged the use of methods including countershading, but despite his authority on the subject, failed to persuade the British authorities. Soldiers often wrongly viewed camouflage netting as a kind of invisibility cloak, and they had to be taught to look at camouflage practically, from an enemy observer's viewpoint. At the same time in Australia, zoologist William John Dakin advised soldiers to copy animals' methods, using their instincts for wartime camouflage.\nThe term countershading has a second meaning unrelated to \"Thayer's Law\". It is that the upper and undersides of animals such as sharks, and of some military aircraft, are different colours to match the different backgrounds when seen from above or from below. Here the camouflage consists of two surfaces, each with the simple function of providing concealment against a specific background, such as a bright water surface or the sky. The body of a shark or the fuselage of an aircraft is not gradated from light to dark to appear flat when seen from the side. The camouflage methods used are the matching of background colour and pattern, and disruption of outlines.\nCounter-illumination.\nCounter-illumination means producing light to match a background that is brighter than an animal's body or military vehicle; it is a form of active camouflage. It is notably used by some species of squid, such as the firefly squid and the midwater squid. The latter has light-producing organs (photophores) scattered all over its underside; these create a sparkling glow that prevents the animal from appearing as a dark shape when seen from below. Counterillumination camouflage is the likely function of the bioluminescence of many marine organisms, though light is also produced to attract or to detect prey and for signalling.\nCounterillumination has rarely been used for military purposes. \"Diffused lighting camouflage\" was trialled by Canada's National Research Council during the Second World War. It involved projecting light on to the sides of ships to match the faint glow of the night sky, requiring awkward external platforms to support the lamps. The Canadian concept was refined in the American Yehudi lights project, and trialled in aircraft including B-24 Liberators and naval Avengers. The planes were fitted with forward-pointing lamps automatically adjusted to match the brightness of the night sky. This enabled them to approach much closer to a target \u2013 within \u2013 before being seen. Counterillumination was made obsolete by radar, and neither diffused lighting camouflage nor Yehudi lights entered active service.\nTransparency.\nMany marine animals that float near the surface are highly transparent, giving them almost perfect camouflage. However, transparency is difficult for bodies made of materials that have different refractive indices from seawater. Some marine animals such as jellyfish have gelatinous bodies, composed mainly of water; their thick mesogloea is acellular and highly transparent. This conveniently makes them buoyant, but it also makes them large for their muscle mass, so they cannot swim fast, making this form of camouflage a costly trade-off with mobility. Gelatinous planktonic animals are between 50 and 90 percent transparent. A transparency of 50 percent is enough to make an animal invisible to a predator such as cod at a depth of ; better transparency is required for invisibility in shallower water, where the light is brighter and predators can see better. For example, a cod can see prey that are 98 percent transparent in optimal lighting in shallow water. Therefore, sufficient transparency for camouflage is more easily achieved in deeper waters.\nSome tissues such as muscles can be made transparent, provided either they are very thin or organised as regular layers or fibrils that are small compared to the wavelength of visible light. A familiar example is the transparency of the lens of the vertebrate eye, which is made of the protein crystallin, and the vertebrate cornea which is made of the protein collagen. Other structures cannot be made transparent, notably the retinas or equivalent light-absorbing structures of eyes \u2013 they must absorb light to be able to function. The camera-type eye of vertebrates and cephalopods must be completely opaque. Finally, some structures are visible for a reason, such as to lure prey. For example, the nematocysts (stinging cells) of the transparent siphonophore \"Agalma okenii\" resemble small copepods. Examples of transparent marine animals include a wide variety of larvae, including radiata (coelenterates), siphonophores, salps (floating tunicates), gastropod molluscs, polychaete worms, many shrimplike crustaceans, and fish; whereas the adults of most of these are opaque and pigmented, resembling the seabed or shores where they live. Adult comb jellies and jellyfish obey the rule, often being mainly transparent. Cott suggests this follows the more general rule that animals resemble their background: in a transparent medium like seawater, that means being transparent. The small Amazon river fish \"Microphilypnus amazonicus\" and the shrimps it associates with, \"Pseudopalaemon gouldingi\", are so transparent as to be \"almost invisible\"; further, these species appear to select whether to be transparent or more conventionally mottled (disruptively patterned) according to the local background in the environment.\nSilvering.\nWhere transparency cannot be achieved, it can be imitated effectively by silvering to make an animal's body highly reflective. At medium depths at sea, light comes from above, so a mirror oriented vertically makes animals such as fish invisible from the side. Most fish in the upper ocean such as sardine and herring are camouflaged by silvering.\nThe marine hatchetfish is extremely flattened laterally, leaving the body just millimetres thick, and the body is so silvery as to resemble aluminium foil. The mirrors consist of microscopic structures similar to those used to provide structural coloration: stacks of between 5 and 10 crystals of guanine spaced about &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444 of a wavelength apart to interfere constructively and achieve nearly 100 per cent reflection. In the deep waters that the hatchetfish lives in, only blue light with a wavelength of 500 nanometres percolates down and needs to be reflected, so mirrors 125 nanometres apart provide good camouflage.\nIn fish such as the herring which live in shallower water, the mirrors must reflect a mixture of wavelengths, and the fish accordingly has crystal stacks with a range of different spacings. A further complication for fish with bodies that are rounded in cross-section is that the mirrors would be ineffective if laid flat on the skin, as they would fail to reflect horizontally. The overall mirror effect is achieved with many small reflectors, all oriented vertically. Silvering is found in other marine animals as well as fish. The cephalopods, including squid, octopus and cuttlefish, have multilayer mirrors made of protein rather than guanine.\nUltra-blackness.\nSome deep sea fishes have very black skin, reflecting under 0.5% of ambient light. This can prevent detection by predators or prey fish which use bioluminescence for illumination. \"Oneirodes\" had a particularly black skin which reflected only 0.044% of 480\u00a0nm wavelength light. The ultra-blackness is achieved with a thin but continuous layer of particles in the dermis, melanosomes. These particles both absorb most of the light, and are sized and shaped so as to scatter rather than reflect most of the rest. Modelling suggests that this camouflage should reduce the distance at which such a fish can be seen by a factor of 6 compared to a fish with a nominal 2% reflectance. Species with this adaptation are widely dispersed in various orders of the phylogenetic tree of bony fishes (Actinopterygii), implying that natural selection has driven the convergent evolution of ultra-blackness camouflage independently many times.\nMimesis.\nIn mimesis (also called \"masquerade\"), the camouflaged object looks like something else which is of no special interest to the observer. Mimesis is common in prey animals, for example when a peppered moth caterpillar mimics a twig, or a grasshopper mimics a dry leaf. It is also found in nest structures; some eusocial wasps, such as \"Leipomeles dorsata\", build a nest envelope in patterns that mimic the leaves surrounding the nest.\nMimesis is also employed by some predators and parasites to lure their prey. For example, a flower mantis mimics a particular kind of flower, such as an orchid. This tactic has occasionally been used in warfare, for example with heavily armed Q-ships disguised as merchant ships.\nThe common cuckoo, a brood parasite, provides examples of mimesis both in the adult and in the egg. The female lays her eggs in nests of other, smaller species of bird, one per nest. The female mimics a sparrowhawk. The resemblance is sufficient to make small birds take action to avoid the apparent predator. The female cuckoo then has time to lay her egg in their nest without being seen to do so. The cuckoo's egg itself mimics the eggs of the host species, reducing its chance of being rejected.\nMotion dazzle.\nMost forms of camouflage are made ineffective by movement: a deer or grasshopper may be highly cryptic when motionless, but instantly seen when it moves. But one method, motion dazzle, requires rapidly moving bold patterns of contrasting stripes. Motion dazzle may degrade predators' ability to estimate the prey's speed and direction accurately, giving the prey an improved chance of escape. Motion dazzle distorts speed perception and is most effective at high speeds; stripes can also distort perception of size (and so, perceived range to the target). As of 2011, motion dazzle had been proposed for military vehicles, but never applied. Since motion dazzle patterns would make animals more difficult to locate accurately when moving, but easier to see when stationary, there would be an evolutionary trade-off between motion dazzle and crypsis.\nAn animal that is commonly thought to be dazzle-patterned is the zebra. The bold stripes of the zebra have been claimed to be disruptive camouflage, background-blending and countershading. After many years in which the purpose of the coloration was disputed, an experimental study by Tim Caro suggested in 2012 that the pattern reduces the attractiveness of stationary models to biting flies such as horseflies and tsetse flies. However, a simulation study by Martin How and Johannes Zanker in 2014 suggests that when moving, the stripes may confuse observers, such as mammalian predators and biting insects, by two visual illusions: the wagon-wheel effect, where the perceived motion is inverted, and the barberpole illusion, where the perceived motion is in a wrong direction.\nApplications.\nMilitary.\nBefore 1800.\nShip camouflage was occasionally used in ancient times. Philostratus (c.\u2009172\u2013250 AD) wrote in his \"Imagines\" that Mediterranean pirate ships could be painted blue-gray for concealment. Vegetius (c.\u2009360\u2013400\u00a0AD) says that \"Venetian blue\" (sea green) was used in the Gallic Wars, when Julius Caesar sent his \"speculatoria navigia\" (reconnaissance boats) to gather intelligence along the coast of Britain; the ships were painted entirely in bluish-green wax, with sails, ropes and crew the same colour. There is little evidence of military use of camouflage on land before 1800, but two unusual ceramics show men in Peru's Mochica culture from before 500\u00a0AD, hunting birds with blowpipes which are fitted with a kind of shield near the mouth, perhaps to conceal the hunters' hands and faces. Another early source is a 15th-century French manuscript, \"The Hunting Book of Gaston Phebus\", showing a horse pulling a cart which contains a hunter armed with a crossbow under a cover of branches, perhaps serving as a hide for shooting game. Jamaican Maroons are said to have used plant materials as camouflage in the First Maroon War (c.\u20091655\u20131740).\n19th-century origins.\nThe development of military camouflage was driven by the increasing range and accuracy of infantry firearms in the 19th century. In particular the replacement of the inaccurate musket with weapons such as the Baker rifle made personal concealment in battle essential. Two Napoleonic War skirmishing units of the British Army, the 95th Rifle Regiment and the 60th Rifle Regiment, were the first to adopt camouflage in the form of a rifle green jacket, while the Line regiments continued to wear scarlet tunics. A contemporary study in 1800 by the English artist and soldier Charles Hamilton Smith provided evidence that grey uniforms were less visible than green ones at a range of 150 yards.\nIn the American Civil War, rifle units such as the 1st United States Sharp Shooters (in the Federal army) similarly wore green jackets while other units wore more conspicuous colours. The first British Army unit to adopt khaki uniforms was the Corps of Guides at Peshawar, when Sir Harry Lumsden and his second in command, William Hodson introduced a \"drab\" uniform in 1848. Hodson wrote that it would be more appropriate for the hot climate, and help make his troops \"invisible in a land of dust\". Later they improvised by dyeing cloth locally. Other regiments in India soon adopted the khaki uniform, and by 1896 khaki drill uniform was used everywhere outside Europe; by the Second Boer War six years later it was used throughout the British Army.\nDuring the late 19th century camouflage was applied to British coastal fortifications. The fortifications around Plymouth, England were painted in the late 1880s in \"irregular patches of red, brown, yellow and green.\" From 1891 onwards British coastal artillery was permitted to be painted in suitable colours \"to harmonise with the surroundings\" and by 1904 it was standard practice that artillery and mountings should be painted with \"large irregular patches of different colours selected to suit local conditions.\"\nFirst World War.\nIn the First World War, the French army formed a camouflage corps, led by Lucien-Victor Guirand de Sc\u00e9vola, employing artists known as \"camoufleurs\" to create schemes such as tree observation posts and covers for guns. Other armies soon followed them. The term \"camouflage\" probably comes from \"camoufler\", a Parisian slang term meaning \"to disguise\", and may have been influenced by \"camouflet\", a French term meaning \"smoke blown in someone's face\". The English zoologist John Graham Kerr, artist Solomon J. Solomon and the American artist Abbott Thayer led attempts to introduce scientific principles of countershading and disruptive patterning into military camouflage, with limited success. In early 1916 the Royal Naval Air Service began to create dummy air fields to draw the attention of enemy planes to empty land. They created decoy homes and lined fake runways with flares, which were meant to help protect real towns from night raids. This strategy was not common practice and did not succeed at first, but in 1918 it caught the Germans off guard multiple times.\nShip camouflage was introduced in the early 20th century as the range of naval guns increased, with ships painted grey all over. In April 1917, when German U-boats were sinking many British ships with torpedoes, the marine artist Norman Wilkinson devised dazzle camouflage, which paradoxically made ships more visible but harder to target. In Wilkinson's own words, dazzle was designed \"not for low visibility, but in such a way as to break up her form and thus confuse a submarine officer as to the course on which she was heading\".\nSecond World War.\nIn the Second World War, the zoologist Hugh Cott, a prot\u00e9g\u00e9 of Kerr, worked to persuade the British army to use more effective camouflage methods, including countershading, but, like Kerr and Thayer in the First World War, with limited success. For example, he painted two rail-mounted coastal guns, one in conventional style, one countershaded. In aerial photographs, the countershaded gun was essentially invisible. The power of aerial observation and attack led every warring nation to camouflage targets of all types. The Soviet Union's Red Army created the comprehensive doctrine of \"Maskirovka\" for military deception, including the use of camouflage. For example, during the Battle of Kursk, General Katukov, the commander of the Soviet 1st Tank Army, remarked that the enemy \"did not suspect that our well-camouflaged tanks were waiting for him. As we later learned from prisoners, we had managed to move our tanks forward unnoticed\". The tanks were concealed in previously prepared defensive emplacements, with only their turrets above ground level. In the air, Second World War fighters were often painted in ground colours above and sky colours below, attempting two different camouflage schemes for observers above and below. Bombers and night fighters were often black, while maritime reconnaissance planes were usually white, to avoid appearing as dark shapes against the sky. For ships, dazzle camouflage was mainly replaced with plain grey in the Second World War, though experimentation with colour schemes continued.\nAs in the First World War, artists were pressed into service; for example, the surrealist painter Roland Penrose became a lecturer at the newly founded Camouflage Development and Training Centre at Farnham Castle, writing the practical \"Home Guard Manual of Camouflage\". The film-maker Geoffrey Barkas ran the Middle East Command Camouflage Directorate during the 1941\u20131942 war in the Western Desert, including the successful deception of Operation Bertram. Hugh Cott was chief instructor; the artist camouflage officers, who called themselves \"camoufleurs\", included Steven Sykes and Tony Ayrton. In Australia, artists were also prominent in the Sydney Camouflage Group, formed under the chairmanship of Professor William John Dakin, a zoologist from Sydney University. Max Dupain, Sydney Ure Smith, and William Dobell were among the members of the group, which worked at Bankstown Airport, RAAF Base Richmond and Garden Island Dockyard. In the United States, artists like John Vassos took a certificate course in military and industrial camouflage at the American School of Design with Baron Nicholas Cerkasoff, and went on to create camouflage for the Air Force.\nAfter 1945.\nCamouflage has been used to protect military equipment such as vehicles, guns, ships, aircraft and buildings as well as individual soldiers and their positions.\nVehicle camouflage methods begin with paint, which offers at best only limited effectiveness. Other methods for stationary land vehicles include covering with improvised materials such as blankets and vegetation, and erecting nets, screens and soft covers which may suitably reflect, scatter or absorb near infrared and radar waves. Some military textiles and vehicle camouflage paints also reflect infrared to help provide concealment from night vision devices.\nAfter the Second World War, radar made camouflage generally less effective, though coastal boats are sometimes painted like land vehicles. Aircraft camouflage too came to be seen as less important because of radar, and aircraft of different air forces, such as the Royal Air Force's Lightning, were often uncamouflaged.\nMany camouflaged textile patterns have been developed to suit the need to match combat clothing to different kinds of terrain (such as woodland, snow, and desert). The design of a pattern effective in all terrains has proved elusive. The American Universal Camouflage Pattern of 2004 attempted to suit all environments, but was withdrawn after a few years of service. Terrain-specific patterns have sometimes been developed but are ineffective in other terrains. The problem of making a pattern that works at different ranges has been solved with multiscale designs, often with a pixellated appearance and designed digitally, that provide a fractal-like range of patch sizes so they appear disruptively coloured both at close range and at a distance. The first genuinely digital camouflage pattern was the Canadian Disruptive Pattern (CADPAT), issued to the army in 2002, soon followed by the American Marine pattern (MARPAT). A pixellated appearance is not essential for this effect, though it is simpler to design and to print.\nHunting.\nHunters of game have long made use of camouflage in the form of materials such as animal skins, mud, foliage, and green or brown clothing to enable them to approach wary game animals. Field sports such as driven grouse shooting conceal hunters in hides (also called blinds or shooting butts). Modern hunting clothing makes use of fabrics that provide a disruptive camouflage pattern; for example, in 1986 the hunter Bill Jordan created cryptic clothing for hunters, printed with images of specific kinds of vegetation such as grass and branches.\nCivil structures.\nCamouflage is occasionally used to make built structures less conspicuous: for example, in South Africa, towers carrying cell telephone antennae are sometimes camouflaged as tall trees with plastic branches, in response to \"resistance from the community\". Since this method is costly (a figure of three times the normal cost is mentioned), alternative forms of camouflage can include using neutral colours or familiar shapes such as cylinders and flagpoles. Conspicuousness can also be reduced by siting masts near, or on, other structures.\nAutomotive manufacturers often use patterns to disguise upcoming products. This camouflage is designed to obfuscate the vehicle's visual lines, and is used along with padding, covers, and decals. The patterns' purpose is to prevent visual observation (and to a lesser degree photography), that would subsequently enable reproduction of the vehicle's form factors.\nFashion, art and society.\nMilitary camouflage patterns influenced fashion and art from the time of the First World War onwards. Gertrude Stein recalled the cubist artist Pablo Picasso's reaction in around 1915:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I very well remember at the beginning of the war being with Picasso on the boulevard Raspail when the first camouflaged truck passed. It was at night, we had heard of camouflage but we had not seen it and Picasso amazed looked at it and then cried out, yes it is we who made it, that is cubism.\nIn 1919, the attendants of a \"dazzle ball\", hosted by the Chelsea Arts Club, wore dazzle-patterned black and white clothing. The ball influenced fashion and art via postcards and magazine articles. The \"Illustrated London News\" announced:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The scheme of decoration for the great fancy dress ball given by the Chelsea Arts Club at the Albert Hall, the other day, was based on the principles of \"Dazzle\", the method of \"camouflage\" used during the war in the painting of ships\u00a0... The total effect was brilliant and fantastic.\nMore recently, fashion designers have often used camouflage fabric for its striking designs, its \"patterned disorder\" and its symbolism. Camouflage clothing can be worn largely for its symbolic significance rather than for fashion, as when, during the late 1960s and early 1970s in the United States, anti-war protestors often ironically wore military clothing during demonstrations against the American involvement in the Vietnam War.\nModern artists such as Ian Hamilton Finlay have used camouflage to reflect on war. His 1973 screenprint of a tank camouflaged in a leaf pattern, \"Arcadia\", is described by the Tate as drawing \"an ironic parallel between this idea of a natural paradise and the camouflage patterns on a tank\". The title refers to the Utopian Arcadia of poetry and art, and the \"memento mori\" Latin phrase \"Et in Arcadia ego\" which recurs in Hamilton Finlay's work. In science fiction, \"Camouflage\" is a novel about shapeshifting alien beings by Joe Haldeman. The word is used more figuratively in works of literature such as Thaisa Frank's collection of stories of love and loss, \"A Brief History of Camouflage\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6449", "revid": "45808397", "url": "https://en.wikipedia.org/wiki?curid=6449", "title": "Clock", "text": "Instrument for measuring, keeping or indicating time\nA clock, or a timepiece, is a device used to measure and indicate time. The clock is one of the oldest human inventions, meeting the need to measure intervals of time shorter than the natural units such as the day, the lunar month, and the year. Devices operating on several physical processes have been used over the millennia.\nSome predecessors to the modern clock may be considered \"clocks\" that are based on movement in nature: A sundial shows the time by displaying the position of a shadow on a flat surface. There is a range of duration timers, a well-known example being the hourglass. Water clocks, along with sundials, are possibly the oldest time-measuring instruments. A major advance occurred with the invention of the verge escapement, which made possible the first mechanical clocks around 1300 in Europe, which kept time with oscillating timekeepers like balance wheels.\nTraditionally, in horology (the study of timekeeping), the term \"clock\" was used for a striking clock, while a clock that did not strike the hours audibly was called a timepiece. This distinction is no longer made. Watches and other timepieces that can be carried on one's person are usually not referred to as clocks. Spring-driven clocks appeared during the 15th century. During the 15th and 16th centuries, clockmaking flourished. The next development in accuracy occurred after 1656 with the invention of the pendulum clock by Christiaan Huygens. A major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The mechanism of a timepiece with a series of gears driven by a spring or weights is referred to as clockwork; the term is used by extension for a similar mechanism not used in a timepiece. The electric clock was patented in 1840, and electronic clocks were introduced in the 20th century, becoming widespread with the development of small battery-powered semiconductor devices.\nThe timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates at a particular frequency.\nThis object can be a pendulum, a tuning fork, a quartz crystal, or the vibration of electrons in atoms as they emit microwaves, the last of which is so precise that it serves as the definition of the second.\nClocks have different ways of displaying the time. Analog clocks indicate time with a traditional clock face and moving hands. Digital clocks display a numeric representation of time. Two numbering systems are in use: 12-hour time notation and 24-hour notation. Most digital clocks use electronic mechanisms and LCD, LED, or VFD displays. For the blind and for use over telephones, speaking clocks state the time audibly in words. There are also clocks for the blind that have displays that can be read by touch.\nEtymology.\nThe word \"clock\" derives from the medieval Latin word for 'bell'\u2014\u2014and has cognates in many European languages. Clocks spread to England from the Low Countries, so the English word came from the Middle Low German and Middle Dutch .\nThe word derives from the Middle English , Old North French , or Middle Dutch , all of which mean 'bell'.\nHistory of time-measuring devices.\nSundials.\nThe apparent position of the Sun in the sky moves over the course of each day, reflecting the rotation of the Earth. Shadows cast by stationary objects move correspondingly, so their positions can be used to indicate the time of day. A sundial shows the time by displaying the position of a shadow on a (usually) flat surface, which has markings that correspond to the hours. Sundials can be horizontal, vertical, or in other orientations. Sundials were widely used in ancient times. With the knowledge of latitude, a well-constructed sundial can measure local solar time with reasonable accuracy, within a minute or two. Sundials continued to be used to monitor the performance of clocks until the 1830s, when the use of the telegraph and trains standardized time and time zones between cities.\nDevices that measure duration, elapsed time and intervals.\nMany devices can be used to mark the passage of time without respect to reference time (time of day, hours, minutes, etc.) and can be useful for measuring duration or intervals. Examples of such duration timers are candle clocks, incense clocks and the hourglass. Both the candle clock and the incense clock work on the same principle wherein the consumption of resources is more or less constant allowing reasonably precise and repeatable estimates of time passages. In the hourglass, fine sand pouring through a tiny hole at a constant rate indicates an arbitrary, predetermined passage of time. The resource is not consumed but re-used.\nWater clocks.\nWater clocks, along with the sundials, are possibly the oldest time-measuring instruments, with the only exceptions being the day counting tally stick. Given their great antiquity, where and when they first existed is not known and is perhaps unknowable. The bowl-shaped outflow is the simplest form of a water clock and is known to have existed in Babylon and in Egypt around the 16th century BC. Other regions of the world, including India and China, also have early evidence of water clocks, but the earliest dates are less certain. Some authors, however, write about water clocks appearing as early as 4000 BC in these regions of the world.\nGreek astronomer Andronicus of Cyrrhus supervised the construction of the Tower of the Winds in Athens in the 1st century B.C. The Greek and Roman civilizations advanced water clock design with improved accuracy. These advances were passed on through Byzantine and Islamic times, eventually making their way back to Europe. Independently, the Chinese developed their own advanced water clocks\uff08\u6c34\u9418\uff09in 725 AD, passing their ideas on to Korea and Japan.\nSome water clock designs were developed independently and some knowledge was transferred through the spread of trade. Pre-modern societies do not have the same precise timekeeping requirements that exist in modern industrial societies, where every hour of work or rest is monitored, and work may start or finish at any time regardless of external conditions. Instead, water clocks in ancient societies were used mainly for astrological reasons. These early water clocks were calibrated with a sundial. While never reaching the level of accuracy of a modern timepiece, the water clock was the most accurate and commonly used timekeeping device for millennia, until it was replaced by the more accurate pendulum clock in 17th-century Europe.\nIslamic civilization is credited with further advancing the accuracy of clocks with elaborate engineering. In 797 (or possibly 801), the Abbasid caliph of Baghdad, Harun al-Rashid, presented Charlemagne with an Asian elephant named Abul-Abbas together with a \"particularly elaborate example\" of a water clock. Pope Sylvester II introduced clocks to northern and western Europe around 1000 AD.\nMechanical water clocks.\nThe first known geared clock was invented by the great mathematician, physicist, and engineer Archimedes during the 3rd century BC. Archimedes created his astronomical clock that was also a cuckoo clock with birds singing and moving every hour. It is the first carillon clock as it plays music and simultaneously with a person blinking his eyes surprised by the singing birds. Archimedes clock works with a system of four weights, counter weights, and strings regulated by a system of floats in a water container with siphons that regulate the automatic continuation of the clock. The principles of this type of clocks are described by the mathematician and physicist Hero, who says that some of them work with a chain that turns a gear of the mechanism. Another Greek clock probably constructed at the time of Alexander was in Gaza, described by Procopius. The Gaza clock was probably a Meteoroskopeion, i.e. a building showing the celestial phenomena and the time. It had pointer for the time and some automations similar to the Archimedes clock. There were 12 doors opening one every hour with Hercules performing his labors, the Lion at one o'clock, etc., and at night a lamp becomes visible every hour, with 12 windows opening to show the time.\nA water-powered cogwheel clock was created in China by Yi Xing and Liang Lingzan. This is not considered an escapement mechanism clock as it was unidirectional, the Song dynasty polymath and genius Su Song (1020\u20131101) incorporated it into his monumental innovation of the astronomical clock-tower of Kaifeng in 1088. His astronomical clock and rotating armillary sphere still relied on the use of either flowing water during the spring, summer, autumn seasons and liquid mercury during the freezing temperature of winter (i.e. hydraulics). \nIn Su Song's waterwheel linkwork device, the action of the escapement's arrest and release was achieved by gravity exerted periodically as the continuous flow of liquid filled containers of a limited size. In a single line of evolution, Su Song's clock therefore united the concept of the clepsydra and the mechanical clock into one device run by mechanics and hydraulics. In his memorial, Su Song wrote about this concept:According to your servant's opinion there have been many systems and designs for astronomical instruments during past dynasties all differing from one another in minor respects. But the principle of the use of water-power for the driving mechanism has always been the same. The heavens move without ceasing but so also does water flow (and fall). Thus if the water is made to pour with perfect evenness, then the comparison of the rotary movements (of the heavens and the machine) will show no discrepancy or contradiction; for the unresting follows the unceasing.\nSong was also strongly influenced by the earlier armillary sphere created by Zhang Sixun (976 AD), who also employed the escapement mechanism and used liquid mercury instead of water in the waterwheel of his astronomical clock tower. The mechanical clockworks for Su Song's astronomical tower featured a great driving-wheel that was 11 feet in diameter, carrying 36 scoops, into each of which water poured at a uniform rate from the \"constant-level tank\". The main driving shaft of iron, with its cylindrical necks supported on iron crescent-shaped bearings, ended in a pinion, which engaged a gear wheel at the lower end of the main vertical transmission shaft. This great astronomical hydromechanical clock tower was about ten metres high (about 30 feet) and featured a clock escapement and was indirectly powered by a rotating wheel either with falling water and liquid mercury. A full-sized working replica of Su Song's clock exists in the Republic of China (Taiwan)'s National Museum of Natural Science, Taichung city. This full-scale, fully functional replica, approximately 12 meters (39 feet) in height, was constructed from Su Song's original descriptions and mechanical drawings.\nIn the 12th century, Al-Jazari, an engineer from Mesopotamia (lived 1136\u20131206) who worked for Artuqid king of Diyar-Bakr, Nasir al-Din, made numerous clocks of all shapes and sizes. The most reputed clocks included the elephant, scribe, and castle clocks, some of which have been successfully reconstructed. As well as telling the time, these grand clocks were symbols of status, grandeur and wealth of the Urtuq State.\nFully mechanical.\nThe word (from the Greek \u2014'hour', and \u2014'to tell') was used to describe early mechanical clocks, but the use of this word (still used in several Romance languages) for all timekeepers conceals the true nature of the mechanisms. For example, there is a record that in 1176 Sens Cathedral in France installed an 'horologe' but the mechanism used is unknown. According to Jocelyn de Brakelond, in 1198 during a fire at the abbey of St Edmundsbury (now Bury St Edmunds), the monks \"ran to the clock\" to fetch water, indicating that their water clock had a reservoir large enough to help extinguish the occasional fire. The word \"clock\" (via Medieval Latin from Old Irish , both meaning 'bell'), which gradually supersedes \"horologe\", suggests that it was the sound of bells which also characterized the prototype mechanical clocks that appeared during the 13th century in Europe.\nIn Europe, between 1280 and 1320, there was an increase in the number of references to clocks and horologes in church records, and this probably indicates that a new type of clock mechanism had been devised. Existing clock mechanisms that used water power were being adapted to take their driving power from falling weights. This power was controlled by some form of oscillating mechanism, probably derived from existing bell-ringing or alarm devices. This controlled release of power \u2013 the escapement \u2013 marks the beginning of the true mechanical clock, which differed from the previously mentioned cogwheel clocks. The verge escapement mechanism appeared during the surge of true mechanical clock development, which did not need any kind of fluid power, like water or mercury, to work.\nThese mechanical clocks were intended for two main purposes: for signalling and notification (e.g., the timing of services and public events), and for modeling the solar system. The former purpose is administrative, the latter arises naturally given the scholarly interests in astronomy, science, astrology, and how these subjects integrated with the religious philosophy of the time. The astrolabe was used both by astronomers and astrologers, and it was natural to apply a clockwork drive to the rotating plate to produce a working model of the solar system.\nSimple clocks intended mainly for notification were installed in towers, and did not always require faces or hands. They would have announced the canonical hours or intervals between set times of prayer. Canonical hours varied in length as the times of sunrise and sunset shifted. The more sophisticated astronomical clocks would have had moving dials or hands, and would have shown the time in various time systems, including Italian hours, canonical hours, and time as measured by astronomers at the time. Both styles of clock started acquiring extravagant features such as automata.\nIn 1283, a large clock was installed at Dunstable Priory in Bedfordshire in southern England; its location above the rood screen suggests that it was not a water clock. In 1292, Canterbury Cathedral installed a 'great horloge'. Over the next 30 years there are mentions of clocks at a number of ecclesiastical institutions in England, Italy, and France. In 1322, a new clock was installed in Norwich, an expensive replacement for an earlier clock installed in 1273. This had a large (2 metre) astronomical dial with automata and bells. The costs of the installation included the full-time employment of two clockkeepers for two years.\nAstronomical.\nAn elaborate water clock, the 'Cosmic Engine', was invented by Su Song, a Chinese polymath, designed and constructed in China in 1092. This great astronomical hydromechanical clock tower was about ten metres high (about 30 feet) and was indirectly powered by a rotating wheel with falling water and liquid mercury, which turned an armillary sphere capable of calculating complex astronomical problems.\nIn Europe, there were the clocks constructed by Richard of Wallingford in Albans by 1336, and by Giovanni de Dondi in Padua from 1348 to 1364. They no longer exist, but detailed descriptions of their design and construction survive, and modern reproductions have been made. They illustrate how quickly the theory of the mechanical clock had been translated into practical constructions, and also that one of the many impulses to their development had been the desire of astronomers to investigate celestial phenomena.\nThe Astrarium of Giovanni Dondi dell'Orologio was a complex astronomical clock built between 1348 and 1364 in Padua, Italy, by the doctor and clock-maker Giovanni Dondi dell'Orologio. The Astrarium had seven faces and 107 moving gears; it showed the positions of the sun, the moon and the five planets then known, as well as religious feast days. The astrarium stood about 1 metre high, and consisted of a seven-sided brass or iron framework resting on 7 decorative paw-shaped feet. The lower section provided a 24-hour dial and a large calendar drum, showing the fixed feasts of the church, the movable feasts, and the position in the zodiac of the moon's ascending node. The upper section contained 7 dials, each about 30 cm in diameter, showing the positional data for the Primum Mobile, Venus, Mercury, the moon, Saturn, Jupiter, and Mars. Directly above the 24-hour dial is the dial of the Primum Mobile, so called because it reproduces the diurnal motion of the stars and the annual motion of the sun against the background of stars. Each of the 'planetary' dials used complex clockwork to produce reasonably accurate models of the planets' motion. These agreed reasonably well both with Ptolemaic theory and with observations.\nWallingford's clock had a large astrolabe-type dial, showing the sun, the moon's age, phase, and node, a star map, and possibly the planets. In addition, it had a wheel of fortune and an indicator of the state of the tide at London Bridge. Bells rang every hour, the number of strokes indicating the time. Dondi's clock was a seven-sided construction, 1 metre high, with dials showing the time of day, including minutes, the motions of all the known planets, an automatic calendar of fixed and movable feasts, and an eclipse prediction hand rotating once every 18 years. It is not known how accurate or reliable these clocks would have been. They were probably adjusted manually every day to compensate for errors caused by wear and imprecise manufacture. Water clocks are sometimes still used today, and can be examined in places such as ancient castles and museums. The Salisbury Cathedral clock, built in 1386, is considered to be the world's oldest surviving mechanical clock that strikes the hours.\nSpring-driven.\nClockmakers developed their art in various ways. Building smaller clocks was a technical challenge, as was improving accuracy and reliability. Clocks could be impressive showpieces to demonstrate skilled craftsmanship, or less expensive, mass-produced items for domestic use. The escapement in particular was an important factor affecting the clock's accuracy, so many different mechanisms were tried.\nSpring-driven clocks appeared during the 15th century, although they are often erroneously credited to Nuremberg watchmaker Peter Henlein (or Henle, or Hele) around 1511. The earliest existing spring driven clock is the chamber clock given to Phillip the Good, Duke of Burgundy, around 1430, now in the Germanisches Nationalmuseum. Spring power presented clockmakers with a new problem: how to keep the clock movement running at a constant rate as the spring ran down. This resulted in the invention of the \"stackfreed\" and the fusee in the 15th century, and many other innovations, down to the invention of the modern \"going barrel\" in 1760.\nEarly clock dials did not indicate minutes and seconds. A clock with a dial indicating minutes was illustrated in a 1475 manuscript by Paulus Almanus, and some 15th-century clocks in Germany indicated minutes and seconds.\nAn early record of a seconds hand on a clock dates back to about 1560 on a clock now in the Fremersdorf collection.\nDuring the 15th and 16th centuries, clockmaking flourished, particularly in the metalworking towns of Nuremberg and Augsburg, and in Blois, France. Some of the more basic table clocks have only one time-keeping hand, with the dial between the hour markers being divided into four equal parts making the clocks readable to the nearest 15 minutes. Other clocks were exhibitions of craftsmanship and skill, incorporating astronomical indicators and musical movements. The cross-beat escapement was invented in 1584 by Jost B\u00fcrgi, who also developed the remontoire. B\u00fcrgi's clocks were a great improvement in accuracy as they were correct to within a minute a day. These clocks helped the 16th-century astronomer Tycho Brahe to observe astronomical events with much greater precision than before.\nPendulum.\nThe next development in accuracy occurred after 1656 with the invention of the pendulum clock. Galileo had the idea to use a swinging bob to regulate the motion of a time-telling device earlier in the 17th century. Christiaan Huygens, however, is usually credited as the inventor. He determined the mathematical formula that related pendulum length to time (about 99.4\u00a0cm or 39.1\u00a0inches for the one second movement) and had the first pendulum-driven clock made. The first model clock was built in 1657 in the Hague, but it was in England that the idea was taken up. The longcase clock (also known as the \"grandfather clock\") was created to house the pendulum and works by the English clockmaker William Clement in 1670 or 1671. It was also at this time that clock cases began to be made of wood and clock faces to use enamel as well as hand-painted ceramics.\nIn 1670, William Clement created the anchor escapement, an improvement over Huygens' crown escapement. Clement also introduced the pendulum suspension spring in 1671. The concentric minute hand was added to the clock by Daniel Quare, a London clockmaker and others, and the second hand was first introduced.\nHairspring.\nIn 1675, Huygens and Robert Hooke invented the spiral balance spring, or the hairspring, designed to control the oscillating speed of the balance wheel. This crucial advance finally made accurate pocket watches possible. The great English clockmaker Thomas Tompion, was one of the first to use this mechanism successfully in his pocket watches, and he adopted the minute hand which, after a variety of designs were trialled, eventually stabilised into the modern-day configuration. The rack and snail striking mechanism for striking clocks, was introduced during the 17th century and had distinct advantages over the 'countwheel' (or 'locking plate') mechanism. During the 20th century there was a common misconception that Edward Barlow invented \"rack and snail\" striking. In fact, his invention was connected with a repeating mechanism employing the rack and snail. The repeating clock, that chimes the number of hours (or even minutes) on demand was invented by either Quare or Barlow in 1676. George Graham invented the deadbeat escapement for clocks in 1720.\nMarine chronometer.\nA major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The position of a ship at sea could be determined with reasonable accuracy if a navigator could refer to a clock that lost or gained less than about 10 seconds per day. This clock could not contain a pendulum, which would be virtually useless on a rocking ship. In 1714, the British government offered large financial rewards to the value of 20,000 pounds for anyone who could determine longitude accurately. John Harrison, who dedicated his life to improving the accuracy of his clocks, later received considerable sums under the Longitude Act.\nIn 1735, Harrison built his first chronometer, which he steadily improved on over the next thirty years before submitting it for examination. The clock had many innovations, including the use of bearings to reduce friction, weighted balances to compensate for the ship's pitch and roll in the sea and the use of two different metals to reduce the problem of expansion from heat. The chronometer was tested in 1761 by Harrison's son and by the end of 10 weeks the clock was in error by less than 5 seconds.\nMass production.\nThe British had dominated watch manufacture for much of the 17th and 18th centuries, but maintained a system of production that was geared towards high quality products for the elite. Although there was an attempt to modernise clock manufacture with mass-production techniques and the application of duplicating tools and machinery by the British Watch Company in 1843, it was in the United States that this system took off. In 1816, Eli Terry and some other Connecticut clockmakers developed a way of mass-producing clocks by using interchangeable parts. Aaron Lufkin Dennison started a factory in 1851 in Massachusetts that also used interchangeable parts, and by 1861 was running a successful enterprise incorporated as the Waltham Watch Company.\nEarly electric.\nIn 1815, Francis Ronalds published the first electric clock powered by dry pile batteries. Alexander Bain, Scottish clockmaker, patented the electric clock in 1840. The electric clock's mainspring is wound either with an electric motor or with an electromagnet and armature. In 1841, he first patented the electromagnetic pendulum. By the end of the nineteenth century, the advent of the dry cell battery made it feasible to use electric power in clocks. Spring or weight driven clocks that use electricity, either alternating current (AC) or direct current (DC), to rewind the spring or raise the weight of a mechanical clock would be classified as an electromechanical clock. This classification would also apply to clocks that employ an electrical impulse to propel the pendulum. In electromechanical clocks the electricity serves no time keeping function. These types of clocks were made as individual timepieces but more commonly used in synchronized time installations in schools, businesses, factories, railroads and government facilities as a master clock and slave clocks.\nWhere an AC electrical supply of stable frequency is available, timekeeping can be maintained very reliably by using a synchronous motor, essentially counting the cycles. The supply current alternates with an accurate frequency of 50\u00a0hertz in many countries, and 60\u00a0hertz in others. While the frequency may vary slightly during the day as the load changes, generators are designed to maintain an accurate number of cycles over a day, so the clock may be a fraction of a second slow or fast at any time, but will be perfectly accurate over a long time. The rotor of the motor rotates at a speed that is related to the alternation frequency. Appropriate gearing converts this rotation speed to the correct ones for the hands of the analog clock. Time in these cases is measured in several ways, such as by counting the cycles of the AC supply, vibration of a tuning fork, the behaviour of quartz crystals, or the quantum vibrations of atoms. Electronic circuits divide these high-frequency oscillations to slower ones that drive the time display.\nQuartz.\nThe piezoelectric properties of crystalline quartz were discovered by Jacques and Pierre Curie in 1880. The first crystal oscillator was invented in 1917 by Alexander M. Nicholson, after which the first quartz crystal oscillator was built by Walter G. Cady in 1921. In 1927 the first quartz clock was built by Warren Marrison and J.W. Horton at Bell Telephone Laboratories in Canada. The following decades saw the development of quartz clocks as precision time measurement devices in laboratory settings\u2014the bulky and delicate counting electronics, built with vacuum tubes at the time, limited their practical use elsewhere. The National Bureau of Standards (now NIST) based the time standard of the United States on quartz clocks from late 1929 until the 1960s, when it changed to atomic clocks. In 1969, Seiko produced the world's first quartz wristwatch, the Astron. Their inherent accuracy and low cost of production resulted in the subsequent proliferation of quartz clocks and watches.\nAtomic.\nCurrently, atomic clocks are the most accurate clocks in existence. They are considerably more accurate than quartz clocks as they can be accurate to within a few seconds over trillions of years. Atomic clocks were first theorized by Lord Kelvin in 1879. In the 1930s the development of magnetic resonance created practical method for doing this. A prototype ammonia maser device was built in 1949 at the U.S. National Bureau of Standards (NBS, now NIST). Although it was less accurate than existing quartz clocks, it served to demonstrate the concept. The first accurate atomic clock, a caesium standard based on a certain transition of the caesium-133 atom, was built by Louis Essen in 1955 at the National Physical Laboratory in the UK. Calibration of the caesium standard atomic clock was carried out by the use of the astronomical time scale \"ephemeris time\" (ET). As of 2013, the most stable atomic clocks are ytterbium clocks, which are stable to within less than two parts in 1 quintillion ().\nOperation.\nThe invention of the mechanical clock in the 13th century initiated a change in timekeeping methods from continuous processes, such as the motion of the gnomon's shadow on a sundial or the flow of liquid in a water clock, to periodic oscillatory processes, such as the swing of a pendulum or the vibration of a quartz crystal, which had the potential for more accuracy. All modern clocks use oscillation.\nAlthough the mechanisms they use vary, all oscillating clocks, mechanical, electric, and atomic, work similarly and can be divided into analogous parts. They consist of an object that repeats the same motion over and over again, an \"oscillator\", with a precisely constant time interval between each repetition, or 'beat'. Attached to the oscillator is a \"controller\" device, which sustains the oscillator's motion by replacing the energy it loses to friction, and converts its oscillations into a series of pulses. The pulses are then counted by some type of \"counter\", and the number of counts is converted into convenient units, usually seconds, minutes, hours, etc. Finally some kind of \"indicator\" displays the result in human readable form.\nPower source.\n&lt;templatestyles src=\"Flowlist/styles.css\" /&gt;* In mechanical clocks, the power source is typically either a weight suspended from a cord or chain wrapped around a pulley, sprocket or drum; or a spiral spring called a mainspring. Mechanical clocks must be \"wound\" periodically, usually by turning a knob or key or by pulling on the free end of the chain, to store energy in the weight or spring to keep the clock running.\nOscillator.\nThe timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates repetitively at a precisely constant frequency.\nThe advantage of a harmonic oscillator over other forms of oscillator is that it employs resonance to vibrate at a precise natural resonant frequency or \"beat\" dependent only on its physical characteristics, and resists vibrating at other rates. The possible precision achievable by a harmonic oscillator is measured by a parameter called its Q, or quality factor, which increases (other things being equal) with its resonant frequency. This is why there has been a long-term trend toward higher frequency oscillators in clocks. Balance wheels and pendulums always include a means of adjusting the rate of the timepiece. Quartz timepieces sometimes include a rate screw that adjusts a capacitor for that purpose. Atomic clocks are primary standards, and their rate cannot be adjusted.\nSynchronized or slave clocks.\nSome clocks rely for their accuracy on an external oscillator; that is, they are automatically synchronized to a more accurate clock:\nController.\nThis has the dual function of keeping the oscillator running by giving it 'pushes' to replace the energy lost to friction, and converting its vibrations into a series of pulses that serve to measure the time.\nIn mechanical clocks, the low Q of the balance wheel or pendulum oscillator made them very sensitive to the disturbing effect of the impulses of the escapement, so the escapement had a great effect on the accuracy of the clock, and many escapement designs were tried. The higher Q of resonators in electronic clocks makes them relatively insensitive to the disturbing effects of the drive power, so the driving oscillator circuit is a much less critical component.\nCounter chain.\nThis counts the pulses and adds them up to get traditional time units of seconds, minutes, hours, etc. It usually has a provision for \"setting\" the clock by manually entering the correct time into the counter.\nIndicator.\nThis displays the count of seconds, minutes, hours, etc. in a human readable form.\nTypes.\nClocks can be classified by the type of time display, as well as by the method of timekeeping.\nTime display methods.\nAnalog.\nAnalog clocks usually use a clock face which indicates time using rotating pointers called \"hands\" on a fixed numbered dial or dials. The standard clock face, known universally throughout the world, has a short \"hour hand\" which indicates the hour on a circular dial of 12 hours, making two revolutions per day, and a longer \"minute hand\" which indicates the minutes in the current hour on the same dial, which is also divided into 60 minutes. It may also have a \"second hand\" which indicates the seconds in the current minute. The only other widely used clock face today is the 24 hour analog dial, because of the use of 24 hour time in military organizations and timetables. Before the modern clock face was standardized during the Industrial Revolution, many other face designs were used throughout the years, including dials divided into 6, 8, 10, and 24 hours. During the French Revolution the French government tried to introduce a 10-hour clock, as part of their decimal-based metric system of measurement, but it did not achieve widespread use. An Italian 6 hour clock was developed in the 18th century, presumably to save power (a clock or watch striking 24 times uses more power).\nAnother type of analog clock is the sundial, which tracks the sun continuously, registering the time by the shadow position of its gnomon. Because the sun does not adjust to daylight saving time, users must add an hour during that time. Corrections must also be made for the equation of time, and for the difference between the longitudes of the sundial and of the central meridian of the time zone that is being used (i.e. 15 degrees east of the prime meridian for each hour that the time zone is ahead of GMT). Sundials use some or part of the 24 hour analog dial. There also exist clocks which use a digital display despite having an analog mechanism\u2014these are commonly referred to as flip clocks. Alternative systems have been proposed. For example, the \"Twelv\" clock indicates the current hour using one of twelve colors, and indicates the minute by showing a proportion of a circular disk, similar to a moon phase.\nDigital.\nDigital clocks display a numeric representation of time. Two numeric display formats are commonly used on digital clocks:\nMost digital clocks use electronic mechanisms and LCD, LED, or VFD displays; many other display technologies are used as well (cathode-ray tubes, nixie tubes, etc.). After a reset, battery change or power failure, these clocks without a backup battery or capacitor either start counting from 12:00, or stay at 12:00, often with blinking digits indicating that the time needs to be set. Some newer clocks will reset themselves based on radio or Internet time servers that are tuned to national atomic clocks. Since the introduction of digital clocks in the 1960s, there has been a notable decline in the use of analog clocks.\nSome clocks, called 'flip clocks', have digital displays that work mechanically. The digits are painted on sheets of material which are mounted like the pages of a book. Once a minute, a page is turned over to reveal the next digit. These displays are usually easier to read in brightly lit conditions than LCDs or LEDs. Also, they do not go back to 12:00 after a power interruption. Flip clocks generally do not have electronic mechanisms. Usually, they are driven by AC-synchronous motors.\nHybrid (analog-digital).\nClocks with analog quadrants, with a digital component, usually minutes and hours displayed analogously and seconds displayed in digital mode.\nAuditory.\nFor convenience, distance, telephony or blindness, auditory clocks present the time as sounds. The sound is either spoken natural language, (e.g. \"The time is twelve thirty-five\"), or as auditory codes (e.g. number of sequential bell rings on the hour represents the number of the hour like the bell, Big Ben). Most telecommunication companies also provide a speaking clock service as well.\nWord.\nWord clocks are clocks that display the time visually using sentences. E.g.: \"It's about three o'clock.\" These clocks can be implemented in hardware or software.\nProjection.\nSome clocks, usually digital ones, include an optical projector that shines a magnified image of the time display onto a screen or onto a surface such as an indoor ceiling or wall. The digits are large enough to be easily read, without using glasses, by persons with moderately imperfect vision, so the clocks are convenient for use in their bedrooms. Usually, the timekeeping circuitry has a battery as a backup source for an uninterrupted power supply to keep the clock on time, while the projection light only works when the unit is connected to an A.C. supply. Completely battery-powered portable versions resembling flashlights are also available.\nTactile.\nAuditory and projection clocks can be used by people who are blind or have limited vision. There are also clocks for the blind that have displays that can be read by using the sense of touch. Some of these are similar to normal analog displays, but are constructed so the hands can be felt without damaging them. Another type is essentially digital, and uses devices that use a code such as Braille to show the digits so that they can be felt with the fingertips.\nMulti-display.\nSome clocks have several displays driven by a single mechanism, and some others have several completely separate mechanisms in a single case. Clocks in public places often have several faces visible from different directions, so that the clock can be read from anywhere in the vicinity; all the faces show the same time. Other clocks show the current time in several time-zones. Watches that are intended to be carried by travellers often have two displays, one for the local time and the other for the time at home, which is useful for making pre-arranged phone calls. Some equation clocks have two displays, one showing mean time and the other solar time, as would be shown by a sundial. Some clocks have both analog and digital displays. Clocks with Braille displays usually also have conventional digits so they can be read by sighted people.\nPurposes.\nClocks are in homes, offices and many other places; smaller ones (watches) are carried on the wrist or in a pocket; larger ones are in public places, e.g. a railway station or church. A small clock is often shown in a corner of computer displays, mobile phones and many MP3 players.\nThe primary purpose of a clock is to \"display\" the time. Clocks may also have the facility to make a loud alert signal at a specified time, typically to waken a sleeper at a preset time; they are referred to as \"alarm clocks\". The alarm may start at a low volume and become louder, or have the facility to be switched off for a few minutes then resume. Alarm clocks with visible indicators are sometimes used to indicate to children too young to read the time that the time for sleep has finished; they are sometimes called \"training clocks\".\nA clock mechanism may be used to \"control\" a device according to time, e.g. a central heating system, a VCR, or a time bomb (see: digital counter). Such mechanisms are usually called timers. Clock mechanisms are also used to drive devices such as solar trackers and astronomical telescopes, which have to turn at accurately controlled speeds to counteract the rotation of the Earth.\nMost digital computers depend on an internal signal at constant frequency to synchronize processing; this is referred to as a clock signal. (A few research projects are developing CPUs based on asynchronous circuits.) Some equipment, including computers, also maintains time and date for use as required; this is referred to as time-of-day clock, and is distinct from the system clock signal, although possibly based on counting its cycles.\nIn Chinese culture, giving a clock () is often taboo, especially to the elderly as the term for this act is a homophone with the term for the act of attending another's funeral (). \nThis homonymic pair works in both Mandarin and Cantonese, although in most parts of China only clocks and large bells, and not watches, are called \"zhong\", and watches are commonly given as gifts in China.\nHowever, should such a gift be given, the \"unluckiness\" of the gift can be countered by exacting a small monetary payment so the recipient is buying the clock and thereby counteracting the (\"give\") expression of the phrase.\nTime standards.\nFor some scientific work timing of the utmost accuracy is essential. It is also necessary to have a standard of the maximum accuracy against which working clocks can be calibrated. An ideal clock would give the time to unlimited accuracy, but this is not realisable. Many physical processes, in particular including some transitions between atomic energy levels, occur at exceedingly stable frequency; counting cycles of such a process can give a very accurate and consistent time\u2014clocks which work this way are usually called atomic clocks. Such clocks are typically large, very expensive, require a controlled environment, and are far more accurate than required for most purposes; they are typically used in a standards laboratory.\nNavigation.\nUntil advances in the late twentieth century, navigation depended on the ability to measure latitude and longitude. Latitude can be determined through celestial navigation; the measurement of longitude requires accurate knowledge of time. This need was a major motivation for the development of accurate mechanical clocks. John Harrison created the first highly accurate marine chronometer in the mid-18th century. The Noon gun in Cape Town still fires an accurate signal to allow ships to check their chronometers. Many buildings near major ports used to have (some still do) a large ball mounted on a tower or mast arranged to drop at a pre-determined time, for the same purpose. While satellite navigation systems such as GPS require unprecedentedly accurate knowledge of time, this is supplied by equipment on the satellites; vehicles no longer need timekeeping equipment.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6451", "revid": "16185737", "url": "https://en.wikipedia.org/wiki?curid=6451", "title": "Charles Proteus Steinmetz", "text": "German-American mathematician and electrical engineer (1865\u20131923)\nCharles Proteus Steinmetz (born Karl August Rudolph Steinmetz; April 9, 1865 \u2013 October 26, 1923) was a German-American mathematician and electrical engineer and professor at Union College. He fostered the development of alternating current that made possible the expansion of the electric power industry in the United States, formulating mathematical theories for engineers. He made ground-breaking discoveries in the understanding of hysteresis that enabled engineers to design better electromagnetic apparatus equipment, especially electric motors for use in industry.\nAt the time of his death, Steinmetz held over 200 patents. A genius in both mathematics and electronics, he did work that earned him the nicknames \"Forger of Thunderbolts\" and \"The Wizard of Schenectady\". Steinmetz's equation, Steinmetz solids, Steinmetz curves, and Steinmetz equivalent circuit are all named after him, as are numerous honors and scholarships, including the IEEE Charles Proteus Steinmetz Award, one of the highest technical recognitions given by the Institute of Electrical and Electronics Engineers professional society.\nEarly life and education.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nSteinmetz was born Karl August Rudolph Steinmetz on April 9, 1865, in Breslau, Province of Silesia, Prussia (now Wroc\u0142aw, Poland) the son of Caroline (Neubert) and Karl Heinrich Steinmetz. He was baptized as a Lutheran into the Evangelical Church of Prussia. Steinmetz, who stood only tall as an adult, had dwarfism, hunchback, and hip dysplasia, as did his father and grandfather. Steinmetz attended Johannes Gymnasium and astonished his teachers with his proficiency in mathematics and physics.\nFollowing the Gymnasium, Steinmetz went on to the University of Breslau to begin work on his undergraduate degree in 1883. He was on the verge of finishing his doctorate in 1888 when he came under investigation by the German police for activities on behalf of a socialist university group and articles he had written for a local socialist newspaper.\nPolitical persecution and emigration.\nAs socialist meetings and press had been banned in Germany, Steinmetz fled to Z\u00fcrich in 1889 to escape possible arrest. Cornell University Professor Ronald R. Kline, author of \"Steinmetz: Engineer and Socialist\", points to other factors which reinforced Steinmetz's decision to leave his homeland such financial problems and the prospect of a more harmonious life with his socialist friends and supporters than the stressful domestic circumstances of his father's household.\nFaced with an expiring visa, he emigrated to the United States in 1889. He changed his first name to \"Charles\" in order to sound more American, and chose the middle name \"Proteus\", a wise hunchbacked character from the \"Odyssey\" who knew many secrets, after a childhood epithet given by classmates Steinmetz felt suited him.\nPolitical activism in the USA.\nSteinmetz was politically active in the US as a technocratic socialist for over thirty years. Following the Bolshevik introduction of a technocratic plan to electrify Russia, Steinmetz spoke of Lenin alongside Albert Einstein as the \"two greatest minds of our time.\"\nHe believed in a corporatist industrial government also covering its human wellfare function.\nA member of the original Technical Alliance, which also included Thorstein Veblen and Leland Olds, Steinmetz had great faith in the ability of machines to eliminate human toil and create abundance for all. He put it this way: \"Some day we [will] make the good things of life for everybody.\"\nElectrical engineering.\nSteinmetz is known for his contribution in three major fields of alternating current (AC) systems theory: hysteresis, steady-state analysis, and transients.\nAC hysteresis theory.\nShortly after arriving in the United States, Steinmetz went to work for Rudolf Eickemeyer in Yonkers, New York, and published in the field of magnetic hysteresis, earning worldwide professional recognition. Eickemeyer's firm developed transformers for use in the transmission of electrical power among many other mechanical and electrical devices. In 1893 Eickemeyer's company, along with all of its patents and designs, was bought by the newly formed General Electric Company, where Steinmetz quickly became known as the engineering wizard in GE's engineering community.\nAC steady state circuit theory.\nSteinmetz's work revolutionized AC circuit theory and analysis, which had been carried out using complicated, time-consuming calculus-based methods. In the groundbreaking paper, \"Complex Quantities and Their Use in Electrical Engineering\", presented at a July 1893 meeting published in the American Institute of Electrical Engineers (AIEE), Steinmetz simplified these complicated methods to \"a simple problem of algebra\". He systematized the use of complex number phasor representation in electrical engineering education texts, whereby the lower-case letter \"j\" is used to designate the 90-degree rotation operator in AC system analysis. His seminal books and many other AIEE papers \"taught a whole generation of engineers how to deal with AC phenomena\".\nAC transient theory.\nSteinmetz also greatly advanced the understanding of lightning. His systematic experiments resulted in the first laboratory created \"man-made lightning\", earning him the nickname the \"Forger of Thunderbolts\". These were conducted in a football field-sized laboratory at General Electric, using 120,000 volt generators. He also erected a lightning tower to attract natural lightning to study its patterns and effects, which resulted in several theories.\nProfessional life.\nSteinmetz acted in the following professional capacities:\nHe was granted an honorary degree from Harvard University in 1901 and a doctorate from Union College in 1903.\nSteinmetz wrote 13 books and 60 articles, not exclusively about engineering. He was a member and adviser to the fraternity Phi Gamma Delta at Union College, whose chapter house was one of the first electrified residences.\nWhile serving as president of the Schenectady Board of Education, Steinmetz introduced numerous progressive reforms, including extended school hours, school meals, school nurses, special classes for the children of immigrants, and the distribution of free textbooks.\nPersonal life.\nSteinmetz was affected by kyphosis, as was his father and grandfather. In spite of his love for children and family life, Steinmetz remained unmarried, to prevent his spinal deformity from being passed to any offspring.\nWhen Joseph LeRoy Hayden, a loyal and hardworking lab assistant, announced that he would marry and look for his own living quarters, Steinmetz made the unusual proposal of opening his large home, complete with research lab, greenhouse, and office to the Haydens and their prospective family. Hayden favored the idea, but his future wife was wary of the unorthodox arrangement. She agreed after Steinmetz's assurance that she could run the house as she saw fit.\nAfter an uneasy start, the arrangement worked well for all parties, especially after three Hayden children were born. Steinmetz legally adopted Joseph Hayden as his son, becoming grandfather to the youngsters, entertaining them with fantastic stories and spectacular scientific demonstrations. The unusual, harmonious living arrangement lasted for the rest of Steinmetz's life.\nSteinmetz founded America's first glider club, but none of its prototypes \"could be dignified with the term 'flight'\".\nSteinmetz was a lifelong agnostic. He died on October 26, 1923, and was buried in Vale Cemetery in Schenectady.\nLegacy.\nSteinmetz earned wide recognition among the scientific community and numerous awards and honors both during his life and posthumously.\nSteinmetz's equation, derived from his experiments, defines the approximate heat energy due to magnetic hysteresis released, per cycle per unit volume of magnetic material. A Steinmetz solid is the solid body generated by the intersection of two or three cylinders of equal radius at right angles. Steinmetz' equivalent circuit is still widely used for the design and testing of induction machines.\nOne of the highest technical recognitions given by the Institute of Electrical and Electronics Engineers, the \"IEEE Charles Proteus Steinmetz Award\", is given for major contributions to standardization within the field of electrical and electronics engineering. Other awards include the Certificate of Merit of Franklin Institute, 1908; the Elliott Cresson Medal, 1913; and the Cedergren Medal, 1914.\nThe Charles P. Steinmetz Memorial Lecture series was begun in his honor in 1925, sponsored by the Schenectady branch of the IEEE. Through 2017 seventy-three gatherings have taken place, held almost exclusively at Union College, featuring notable figures such as Nobel laureate experimental physicist Robert A. Millikan, helicopter inventor Igor Sikorsky, nuclear submarine pioneer Admiral Hyman G. Rickover (1963), Nobel-winning semiconductor inventor William Shockley, and Internet \"founding father\" Leonard Kleinrock.\nSteinmetz's connection to Union is further celebrated with the annual Steinmetz Symposium, a day-long event in which Union undergraduates give presentations on research they have done. Steinmetz Hall, which houses the Union College computer center, is named after him.\nThe Charles P. Steinmetz Scholarship is awarded annually by the college, underwritten since its inception in 1923 by the General Electric Company. An additional Charles P. Steinmetz Memorial Scholarship was later established at Union by Marjorie Hayden, daughter of Joseph and Corrine Hayden, and is awarded to students majoring in engineering or physics.\nA 1914 \"Duplex Drive Brougham\" Detroit Electric automobile that once belonged to Steinmetz was purchased by Union College in 1971, and restored for use in campus ceremonies. The Steinmetz car is permanent displayed in the first-floor corridor between the Wold Center and F.W. Olin building.\nA Chicago public high school, Steinmetz College Prep, is named for him, as well as a Schenectady public school, the Steinmetz Career and Leadership Academy, formerly Steinmetz Middle-School.\nA public park in north Schenectady, New York was named for him in 1931.\nIn 1983, the US Post Office included Steinmetz in a series of postage stamps commemorating American inventors.\nIn May 2015, a life-size bronze statue of Charles Steinmetz meeting Thomas Edison by sculptor and caster Dexter Benedict was unveiled on a plaza on the corner of Erie Boulevards and South Ferry Street in Schenectady.\nIn popular culture.\nSteinmetz is featured in John Dos Passos' \"U.S.A.\" trilogy in one of the biographies. He also serves as a major character in Starling Lawrence's \"The Lightning Keeper\".\nSteinmetz is a major character in the novel \"Electric City\" by Elizabeth Rosner.\nMoe sarcastically refers to Curly as a \"Steinmetz\" in the 1944 Three Stooges short \"Busy Buddies\".\nSteinmetz was portrayed in 1959 by the actor Rod Steiger in the CBS television anthology series, \"The Joseph Cotten Show\". The episode focused on his socialist activities in Germany.\nA famous anecdote about Steinmetz concerns a troubleshooting consultation at Henry Ford's River Rouge Plant. A humorous aspect of the story is the \"itemized bill\" he submitted for the work performed.\n\"...at Schenectady, as 'Abdu'l-Bah\u00e1 was being shown around the General Electric Works by Steinmetz, this 'wizard of electricity' was observed to be eagerly absorbing 'Abdu'l-Bah\u00e1's elucidation of electricity. The Rev. Moore, Unitarian clergyman who was present at the time, testified to me: 'Steinmetz's jaw seemed to drop open as he drank in 'Abdu'l-Bah\u00e1's talk.' The author of this statement was Stanwood Cobb, who related this in his: Memories of 'Abdu'l-Bah\u00e1, who was Head of the Bah\u00e1'\u00ed, 1892-1921 and traveled in North America in 1912 when this incident occurred.\nBibliography.\nPatents.\nAt the time of his death, Steinmetz held over 200 patents:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nWorks.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6452", "revid": "34435404", "url": "https://en.wikipedia.org/wiki?curid=6452", "title": "Charles Martel", "text": "Frankish military and political leader (c. 688\u2013741)\nCharles Martel (c.\u2009688 \u2013 22 October 741) or Charles the Hammer was a Frankish political and military leader who, as Duke and Prince of the Franks and Mayor of the Palace, was the de facto ruler of Francia from 718 until his death. He was a son of the Frankish statesman Pepin of Herstal and Pepin's mistress, a noblewoman named Alpaida. Charles, also known as \"The Hammer\" (in Old French, \"Martel\"), successfully asserted his claims to power as successor to his father as the power behind the throne in Frankish politics. Continuing and building on his father's work, he restored centralized government in Francia and began the series of military campaigns that re-established the Franks as the undisputed masters of all Gaul. According to a near-contemporary source, the \"Liber Historiae Francorum\", Charles was \"a warrior who was uncommonly ... effective in battle\".\nMartel gained a very consequential victory against an Umayyad invasion of Aquitaine at the Battle of Tours, at a time when the Umayyad Caliphate controlled most of the Iberian Peninsula. Alongside his military endeavours, Charles has been traditionally credited with a seminal role in the development of the Frankish system of feudalism.\nAt the end of his reign, Charles divided Francia between his sons, Carloman and Pepin. The latter became the first king of the Carolingian dynasty. Pepin's son Charlemagne, grandson of Charles, extended the Frankish realms and became the first emperor in the West since the fall of Rome.\nBackground.\nCharles, nicknamed \"Martel\", or \"Charles the Hammer\" in later chronicles, was the illegitimate son of Pepin of Herstal and his mistress, possible second wife, Alpaida. He had a brother named Childebrand, who later became the Frankish \"dux\" (that is, \"duke\") of Burgundy.\nOlder historiography commonly describes Charles as \"illegitimate\", but the dividing line between wives and concubines was not clear-cut in eighth-century Francia. It is likely that the accusation of \"illegitimacy\" derives from the desire of Pepin's first wife Plectrude to see her progeny as heirs to Pepin's power.\nAfter the reign of Dagobert I (629\u2013639) the Merovingians effectively ceded power to the Pippinid Mayors of the Palace, who ruled the Frankish realm of Austrasia in all but name. They controlled the royal treasury, dispensed patronage, and granted land and privileges in the name of the figurehead king. Charles' father, Pepin of Herstal, was able to unite the Frankish realm by conquering Neustria and Burgundy. Pepin was the first to call himself Duke and Prince of the Franks, a title later taken up by Charles.\nContesting for power.\nIn December 714, Pepin of Herstal died. A few months before his death and shortly after the murder of his son Grimoald the Younger, he had, at his wife Plectrude's urging, designated Theudoald, his grandson by their late son Grimoald, his heir in the entire realm. This was immediately opposed by the Austrasian nobles because Theudoald was a child of only eight years of age. To prevent Charles using this unrest to his own advantage, Plectrude had him imprisoned in Cologne, the city which was intended to be her capital. This prevented an uprising on his behalf in Austrasia, but not in Neustria.\nCivil war of 715\u2013718.\nPepin's death occasioned open conflict between his heirs and the Neustrian nobles who sought political independence from Austrasian control. In 715, Dagobert III named Ragenfrid mayor of their palace, effectively declaring political independence. On 26 September 715, Ragenfrid's Neustrians met the young Theudoald's forces at the Battle of Compi\u00e8gne. Theudoald was defeated and fled back to Cologne.\nBefore the end of the year, Charles Martel had escaped from prison and been acclaimed mayor by the nobles of Austrasia. That same year, Dagobert III died and the Neustrians proclaimed Chilperic II, the cloistered son of Childeric II, as king.\nBattle of Cologne.\nIn 716, Chilperic and Ragenfrid together led an army into Austrasia intent on seizing the Pippinid wealth at Cologne. The Neustrians allied with another invading force under Redbad, King of the Frisians and met Charles in battle near Cologne, which was still held by Plectrude. Charles had little time to gather men, or prepare, and the result was inevitable. The Frisians held off Charles, while the king and his mayor besieged Plectrude at Cologne, where she bought them off with a substantial portion of Pepin's treasure. After that they withdrew. The Battle of Cologne is the only defeat of Charles Martel's career.\nBattle of Ambl\u00e8ve.\nCharles retreated to the hills of the Eifel to gather men, and train them. Having made the proper preparations, in April 716, he fell upon the triumphant army near Malmedy as it was returning to its own province. In the ensuing Battle of Ambl\u00e8ve, Martel attacked as the enemy rested at midday. According to one source, he split his forces into several groups which fell at them from many sides. Another suggests that while this was his intention, he then decided, given the enemy's unpreparedness, this was not necessary. In any event, the suddenness of the assault led them to believe they were facing a much larger host. Many of the enemy fled and Martel's troops gathered the spoils of the camp. Martel's reputation increased considerably as a result, and he attracted more followers. This battle is often considered by historians as the turning point in Charles's struggle.\nBattle of Vincy.\nRichard Gerberding points out that up to this time, much of Martel's support was probably from his mother's kindred in the lands around Liege. After Ambl\u00e8ve, he seems to have won the backing of the influential Willibrord, founder of the Abbey of Echternach. The abbey had been built on land donated by Plectrude's mother, Irmina of Oeren, but most of Willibrord's missionary work had been carried out in Frisia. In joining Chilperic and Ragenfrid, Radbod of Frisia sacked Utrecht, burning churches and killing many missionaries. Willibrord and his monks were forced to flee to Echternach. Gerberding suggests that Willibrord had decided that the chances of preserving his life's work were better with a successful field commander like Martel than with Plectrude in Cologne. Willibrord subsequently baptized Martel's son Pepin. Gerberding suggests a likely date of Easter 716. Martel also received support from bishop Pepo of Verdun.\nCharles took time to rally more men and prepare. By the following spring, Charles had attracted enough support to invade Neustria. Charles sent an envoy who proposed a cessation of hostilities if Chilperic would recognize his rights as mayor of the palace in Austrasia. The refusal was not unexpected but served to impress upon Martel's forces the unreasonableness of the Neustrians. They met near Cambrai at the Battle of Vincy on 21 March 717. The victorious Martel pursued the fleeing king and mayor to Paris, but as he was not yet prepared to hold the city, he turned back to deal with Plectrude and Cologne. He took the city and dispersed her adherents. Plectrude was allowed to retire to a convent. Theudoald lived to 741 under his uncle's protection, a kindness unusual for those times, when mercy to a former gaoler, or a potential rival, was rare.\nConsolidation of power.\nUpon this success, Charles proclaimed Chlothar IV king of Austrasia in opposition to Chilperic and deposed Rigobert, archbishop of Reims, replacing him with Milo, a lifelong supporter.\nIn 718, Chilperic responded to Charles' new ascendancy by making an alliance with Odo the Great (or Eudes, as he is sometimes known), the duke of Aquitaine, who had become independent during the civil war in 715, but was again defeated, at the Battle of Soissons, by Charles. Chilperic fled with his ducal ally to the land south of the Loire and Ragenfrid fled to Angers. Soon Chlotar IV died and Odo surrendered King Chilperic in exchange for Charles recognizing his dukedom. Charles recognized Chilperic as king of the Franks in return for legitimate royal affirmation of his own mayoralty over all the kingdoms.\nWars of 718\u2013732.\nBetween 718 and 732, Charles secured his power through a series of victories. Having unified the Franks under his banner, Charles was determined to punish the Saxons who had invaded Austrasia. Therefore, late in 718, he laid waste their country to the banks of the Weser, the Lippe, and the Ruhr. He defeated them in the Teutoburg Forest and thus secured the Frankish border in the name of King Chlotaire.\nWhen the Frisian leader Radbod died in 719, Charles seized West Frisia without any great resistance on the part of the Frisians, who had been subjected to the Franks but had rebelled upon the death of Pippin. When Chilperic II died in 721, Charles appointed as his successor the son of Dagobert III, Theuderic IV, who was still a minor, and who occupied the throne from 721 to 737. Charles was now appointing the kings whom he supposedly served (\"rois fain\u00e9ants\") although they were mere figureheads. By the end of his reign, he didn't appoint any at all. At this time, Charles again marched against the Saxons. Then the Neustrians rebelled under Ragenfrid, who had left the county of Anjou. They were easily defeated in 724 but Ragenfrid gave up his sons as hostages in turn for keeping his county. This ended the civil wars of Charles' reign.\nThe next six years were devoted in their entirety to assuring Frankish authority over the neighboring political groups. Between 720 and 723, Charles was fighting in Bavaria, where the Agilolfing dukes had gradually evolved into independent rulers, recently in alliance with Liutprand the Lombard. He forced the Alemanni to accompany him, and Duke Hugbert submitted to Frankish suzerainty. In 725 he brought back the Agilolfing Princess Swanachild as a second wife.\nIn 725 and 728, he again entered Bavaria but, in 730, he marched against Lantfrid, Duke of Alemannia, who had also become independent, and killed him in battle. He forced the Alemanni to capitulate to Frankish suzerainty and did not appoint a successor to Lantfrid. Thus, southern Germany once more became part of the Frankish kingdom, as had northern Germany during the first years of the reign.\nAquitaine and the Battle of Tours in 732.\nIn 731, after defeating the Saxons, Charles turned his attention to the rival southern realm of Aquitaine, and crossed the Loire, breaking the treaty with Duke Odo. The Franks ransacked Aquitaine twice, and captured Bourges, although Odo retook it. The \"Continuations of Fredegar\" allege that Odo called on assistance from the recently established emirate of al-Andalus, but there had been Arab raids into Aquitaine from the 720s onwards. Indeed, the anonymous Chronicle of 754 records a victory for Odo in 721 at the Battle of Toulouse, while the \"Liber Pontificalis\" records that Odo had killed 375,000 Saracens. It is more likely that this invasion or raid took place in revenge for Odo's support for a rebel Berber leader named Munnuza.\nWhatever the precise circumstances were, it is clear that an army under the leadership of Abd al-Rahman al-Ghafiqi headed north, and after some minor engagements marched on the wealthy city of Tours. According to British medieval historian Paul Fouracre, \"Their campaign should perhaps be interpreted as a long-distance raid rather than the beginning of a war\". They were, however, defeated by the army of Charles at the Battle of Tours (known in France as the Battle of Poitiers), at a location between the French cities of Tours and Poitiers, in a victory described by the \"Continuations of Fredegar\". According to the historian Bernard Bachrach, the Arab army, mostly mounted, failed to break through the Frankish infantry. News of this battle spread, and may be recorded in Bede's \"Ecclesiastical History\" (Book V, ch. 23). However, it is not given prominence in Arabic sources from the period.\nDespite his victory, Charles did not gain full control of Aquitaine, and Odo remained duke until 735.\nWars of 732\u2013737.\nBetween his victory of 732 and 735, Charles reorganized the kingdom of Burgundy, replacing the counts and dukes with his loyal supporters, thus strengthening his hold on power. He was forced, by the ventures of Bubo, Duke of the Frisians, to invade independent-minded Frisia again in 734. In that year, he slew the duke at the Battle of the Boarn. Charles ordered the Frisian pagan shrines destroyed, and so wholly subjugated the populace that the region was peaceful for twenty years after.\nIn 735, Duke Odo of Aquitaine died. Though Charles wished to rule the duchy directly and went there to elicit the submission of the Aquitanians, the aristocracy proclaimed Odo's son, Hunald I of Aquitaine, as duke, and Charles and Hunald eventually recognised each other's position.\nInterregnum (737\u2013741).\nIn 737, at the tail end of his campaigning in Provence and Septimania, the Merovingian king, Theuderic IV, died. Charles, titling himself \"maior domus\" and \"princeps et dux Francorum\", did not appoint a new king and nobody acclaimed one. The throne lay vacant until Charles' death. The interregnum, the final four years of Charles' life, was relatively peaceful although in 738 he compelled the Saxons of Westphalia to submit and pay tribute and in 739 he checked an uprising in Provence where some rebels united under the leadership of Maurontus.\nCharles used the relative peace to set about integrating the outlying realms of his empire into the Frankish church. He erected four dioceses in Bavaria (Salzburg, Regensburg, Freising, and Passau) and gave them Boniface as archbishop and metropolitan over all Germany east of the Rhine, with his seat at Mainz. Boniface had been under his protection from 723 on. Indeed, the saint himself explained to his old friend, Daniel of Winchester, that without it he could neither administer his church, defend his clergy nor prevent idolatry.\nIn 739, Pope Gregory III begged Charles for his aid against Liutprand, but Charles was loath to fight his onetime ally and ignored the plea. Nonetheless, the pope's request for Frankish protection showed how far Charles had come from the days when he was tottering on excommunication, and set the stage for his son and grandson to assert themselves in the peninsula.\nDeath and transition in rule.\nCharles Martel died on 22 October 741, at Quierzy-sur-Oise in what is today the Aisne \"d\u00e9partement\" in the Picardy region of France. He was buried at Saint Denis Basilica in Paris.\nHis territories had been divided among his adult sons a year earlier: to Carloman he gave Austrasia, Alemannia, and Thuringia, and to Pippin the Younger Neustria, Burgundy, Provence, and Metz and Trier in the \"Mosel duchy\". Grifo was given several lands throughout the kingdom, but at a later date, just before Charles died.\nLegacy.\nEarlier in his life Charles Martel had many internal opponents and felt the need to appoint his own kingly claimant, Chlotar IV. Later, however, the dynamics of rulership in Francia had changed, and no hallowed Merovingian ruler was required. Charles divided his realm among his sons without opposition (though he ignored his young son Bernard). For many historians, Charles Martel laid the foundations for his son Pepin's rise to the Frankish throne in 751, and his grandson Charlemagne's imperial acclamation in 800. However, for Paul Fouracre, while Charles was \"the most effective military leader in Francia\", his career \"finished on a note of unfinished business\".\nFamily and children.\nCharles Martel married twice, his first wife being Rotrude of Treves, daughter either of Lambert II, Count of Hesbaye, or of Leudwinus, Count of Treves. They had the following children:\nMost of the children married and had issue. Hiltrud married Odilo I (Duke of Bavaria). Landrade was once believed to have married a Sigrand (Count of Hesbania) but Sigrand's wife was more likely the sister of Rotrude. Auda married Thierry IV (Count of Autun and Toulouse).\nCharles also married a second time, to Swanhild and they had a child named Grifo.\nCharles Martel also had a known mistress, Ruodhaid, with whom he had:\nReputation and historiography.\nMilitary victories.\nFor early medieval authors, Charles Martel was famous for his military victories. Paul the Deacon for instance attributed a victory against the Saracens actually won by Odo of Aquitaine to Charles. However, alongside this there soon developed a darker reputation, for his alleged abuse of church property. A ninth-century text, the \"Visio Eucherii\", possibly written by Hincmar of Reims, portrayed Martel as suffering in hell for this reason. According to British medieval historian Paul Fouracre, this was \"the single most important text in the construction of Charles Martel's reputation as a seculariser or despoiler of church lands\".\nBy the eighteenth century, historians such as Edward Gibbon had begun to portray the Frankish leader as the saviour of Christian Europe from a full-scale Islamic invasion. In Gibbon's \"The Decline And Fall Of The Roman Empire\" he wonders whether without Charles' victory, \"Perhaps the interpretation of the Koran would now be taught in the schools of Oxford\".\nIn the nineteenth century, the German historian Heinrich Brunner argued that Charles had confiscated church lands in order to fund military reforms that allowed him to defeat the Arab conquests, in this way brilliantly combining two traditions about the ruler. However, Fouracre argued that \"...there is not enough evidence to show that there was a decisive change either in the way in which the Franks fought, or in the way in which they organised the resources needed to support their warriors.\"\nMany twentieth-century European historians continued to develop Gibbon's perspectives, such as French medievalist Christian Pfister, who wrote in 1911 that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nSimilarly, William E. Watson, who wrote of the battle's importance in Frankish and world history in 1993, suggested that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Had Charles Martel suffered at Tours-Poitiers the fate of King Roderick at the Rio Barbate, it is doubtful that a \"do-nothing\" sovereign of the Merovingian realm could have later succeeded where his talented major domus had failed. Indeed, as Charles was the progenitor of the Carolingian line of Frankish rulers and grandfather of Charlemagne, one can even say with a degree of certainty that the subsequent history of the West would have proceeded along vastly different currents had 'Abd al-Rahman been victorious at Tours-Poitiers in 732.\"\nAnd in 1993, the influential political scientist Samuel Huntington saw the battle of Tours as marking the end of the \"Arab and Moorish surge west and north\".\nOther recent historians, however, argue that the importance of the battle is dramatically overstated, both for European history in general and for Charles Martel's reign in particular. This view is typified by Alessandro Barbero, who in 2004 wrote,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Today, historians tend to play down the significance of the battle of Poitiers, pointing out that the purpose of the Arab force defeated by Charles Martel was not to conquer the Frankish kingdom, but simply to pillage the wealthy monastery of St-Martin of Tours\".\nSimilarly, in 2002 Toma\u017e Mastnak wrote: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"The continuators of Fredegar's chronicle, who probably wrote in the mid-eighth century, pictured the battle as just one of many military encounters between Christians and Saracens\u2014moreover, as only one in a series of wars fought by Frankish princes for booty and territory... One of Fredegar's continuators presented the battle of Poitiers as what it really was: an episode in the struggle between Christian princes as the Carolingians strove to bring Aquitaine under their rule.\"\nMore recently, the memory of Charles Martel has been appropriated by far right and white nationalist groups, such as the 'Charles Martel Group' in France, and by Australian Brenton Harrison Tarrant, the perpetrator of the Christchurch mosque shootings at Al Noor Mosque and Linwood Islamic Centre in Christchurch, New Zealand, in 2019. The memory of Charles Martel is a topic of debate in contemporary French politics on both the right and the left.\nOrder of the Genet.\nIn the seventeenth century, a legend emerged that Charles Martel had formed the first regular order of knights in France. In 1620, Andre Favyn stated (without providing a source) that among the spoils Charles Martel's forces captured after the Battle of Tours were many genets (raised for their fur) and several of their pelts. Charles Martel gave these furs to leaders amongst his army, forming the first order of knighthood, the Order of the Genet. Favyn's claim was then repeated and elaborated in later works in English, for instance by Elias Ashmole in 1672, and James Coats in 1725.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n "}
{"id": "6456", "revid": "16185737", "url": "https://en.wikipedia.org/wiki?curid=6456", "title": "Charles Edward Jones", "text": "American astronaut (1952\u20132001)\nColonel Charles Edward (\"Chuck\") Jones (November 8, 1952 \u2013 September 11, 2001) was a United States Air Force officer, an aeronautical engineer, computer programmer, and an astronaut in the USAF Manned Spaceflight Engineer Program. He was killed during the September 11 attacks, aboard American Airlines Flight 11.\nLife.\nCharles Edward Jones was born November 8, 1952, in Clinton, Indiana. He graduated from Wichita East High School in 1970, earned a Bachelor of Science degree in Astronautical Engineering from the United States Air Force Academy in 1974, and received a Master of Science degree in Astronautics from Massachusetts Institute of Technology (MIT) in 1980. He entered the USAF Manned Spaceflight Engineer program in 1982, and was scheduled to fly on mission STS-71-B in December 1986, but the mission was canceled after the \"Challenger\" Disaster in January 1986. He left the Manned Spaceflight Engineer program in 1987.\nHe later worked for Defense Intelligence Agency (DIA), Bolling Air Force Base in Washington, D.C., and was Systems Program Director for Intelligence and Information Systems, Hanscom Air Force Base, Massachusetts.\nHe was killed at the age of 48 in the attacks of September 11, 2001, aboard American Airlines Flight 11. He had been living as a retired U.S. Air Force Colonel in Bedford, Massachusetts, at the time of his death. He was survived by his wife Jeanette.\nAt the National 9/11 Memorial, Jones is memorialized at the North Pool, on Panel N-74.\nReferences.\nInline citations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "6458", "revid": "28568042", "url": "https://en.wikipedia.org/wiki?curid=6458", "title": "Ceramic", "text": "Inorganic, nonmetallic solid prepared by the action of heat\nA ceramic is any of the various hard, brittle, heat-resistant and corrosion-resistant materials made by shaping and then firing an inorganic, nonmetallic material, such as clay, at a high temperature. Common examples are earthenware, porcelain, and brick.\nThe earliest ceramics made by humans were pottery objects (pots, vessels, or vases) or figurines made from clay, either by itself or mixed with other materials like silica, hardened and sintered in fire. Later, ceramics were glazed and fired to create smooth, colored surfaces, decreasing porosity through the use of glassy, amorphous ceramic coatings on top of the crystalline ceramic substrates. Ceramics now include domestic, industrial, and building products, as well as a wide range of materials developed for use in advanced ceramic engineering, such as in semiconductors.\nThe word \"ceramic\" comes from the Ancient Greek word (), meaning \"of or for pottery\" (from \" \"\" ()\"\u00a0'potter's clay, tile, pottery'). The earliest known mention of the root \"ceram-\" is the Mycenaean Greek , workers of ceramic written in Linear B syllabic script. The word \"ceramic\" can be used as an adjective to describe a material, product or process, or it may be used as a noun, either singular, or more commonly, as the plural noun \"ceramics\".\nMaterials.\nCeramic material is an inorganic, non-metallic oxide, nitride, or carbide material. Some elements, such as carbon or silicon, may be considered ceramics. Ceramic materials are brittle, hard, strong in compression, and weak in shearing and tension. They withstand chemical erosion that occurs in other materials subjected to acidic or caustic environments. Ceramics generally can withstand very high temperatures, ranging from 1,000\u00a0\u00b0C to 1,600\u00a0\u00b0C (1,800\u00a0\u00b0F to 3,000\u00a0\u00b0F).\nThe crystallinity of ceramic materials varies widely. Most often, fired ceramics are either vitrified or semi-vitrified as is the case with earthenware, stoneware, and porcelain. Varying crystallinity and electron composition in the ionic and covalent bonds cause most ceramic materials to be good thermal and electrical insulators (researched in ceramic engineering). With such a large range of possible options for the composition/structure of a ceramic (nearly all of the elements, nearly all types of bonding, and all levels of crystallinity), the breadth of the subject is vast, and identifiable attributes (hardness, toughness, electrical conductivity) are difficult to specify for the group as a whole. General properties such as high melting temperature, high hardness, poor conductivity, high moduli of elasticity, chemical resistance and low ductility are the norm, with known exceptions to each of these rules (piezoelectric ceramics, glass transition temperature, superconductive ceramics). Many composites, such as fiberglass and carbon fiber, while containing ceramic materials are not considered to be part of the ceramic family.\nHighly oriented crystalline ceramic materials are not amenable to a great range of processing. Methods for dealing with them tend to fall into one of two categories \u2013 either make the ceramic in the desired shape, by reaction \"in situ\", or by \"forming\" powders into the desired shape, and then sintering to form a solid body. Ceramic forming techniques include shaping by hand (sometimes including a rotation process called \"throwing\"), slip casting, tape casting (used for making very thin ceramic capacitors), injection molding, dry pressing, and other variations. \nMany ceramics experts do not consider materials with amorphous (noncrystalline) character (i.e., glass) to be ceramics even though glassmaking involves several steps of the ceramic process and its mechanical properties are similar to ceramic materials. However, heat treatments can convert glass into a semi-crystalline material known as glass-ceramic. \nTraditional ceramic raw materials include clay minerals such as kaolinite, whereas more recent materials include aluminium oxide, more commonly known as alumina. Modern ceramic materials, which are classified as advanced ceramics, include silicon carbide and tungsten carbide. Both are valued for their abrasion resistance and are therefore used in applications such as the wear plates of crushing equipment in mining operations. Advanced ceramics are also used in the medical, electrical, electronics, and armor industries.\nHistory.\nHuman beings appear to have been making their own ceramics for at least 26,000 years, subjecting clay and silica to intense heat to fuse and form ceramic materials. The earliest found so far were in southern central Europe and were sculpted figures, not dishes. The earliest known pottery was made by mixing animal products with clay and fired at up to . While pottery fragments have been found up to 19,000 years old, it was not until about 10,000 years later that regular pottery became common. An early people that spread across much of Europe is named after its use of pottery, the Corded Ware culture. These early Indo-European peoples decorated their pottery by wrapping it with rope, while still wet. When the ceramics were fired, the rope burned off but left a decorative pattern of complex grooves on the surface.\nThe invention of the wheel eventually led to the production of smoother, more even pottery using the wheel-forming (throwing) technique, like the pottery wheel. Early ceramics were porous, absorbing water easily. It became useful for more items with the discovery of glazing techniques, coating pottery with silicon, bone ash, or other materials that could melt and reform into a glassy surface, making a vessel less pervious to water. \nArchaeology.\nCeramic artifacts have an important role in archaeology for understanding the culture, technology, and behavior of peoples of the past. They are among the most common artifacts to be found at an archaeological site, generally in the form of small fragments of broken pottery called sherds. Processing of collected sherds can be consistent with two main types of analysis: technical and traditional.\nThe traditional analysis involves sorting ceramic artifacts, sherds, and larger fragments into specific types based on style, composition, manufacturing, and morphology. By creating these typologies, it is possible to distinguish between different cultural styles, the purpose of the ceramic, and the technological state of the people among other conclusions. Besides, by looking at stylistic changes in ceramics over time is it possible to separate (seriate) the ceramics into distinct diagnostic groups (assemblages). A comparison of ceramic artifacts with known dated assemblages allows for a chronological assignment of these pieces.\nThe technical approach to ceramic analysis involves a finer examination of the composition of ceramic artifacts and sherds to determine the source of the material and through this the possible manufacturing site. Key criteria are the composition of the clay and the temper used in the manufacture of the article under study: the temper is a material added to the clay during the initial production stage, and it is used to aid the subsequent drying process. Types of temper include shell pieces, granite fragments, and ground sherd pieces called 'grog'. Temper is usually identified by microscopic examination of the tempered material. Clay identification is determined by a process of refiring the ceramic and assigning a color to it using Munsell Soil Color notation. By estimating both the clay and temper compositions, and locating a region where both are known to occur, an assignment of the material source can be made. From the source assignment of the artifact, further investigations can be made into the site of manufacture.\nProperties.\nThe physical properties of any ceramic substance are a direct result of its crystalline structure and chemical composition. Solid-state chemistry reveals the fundamental connection between microstructure and properties, such as localized density variations, grain size distribution, type of porosity, and second-phase content, which can all be correlated with ceramic properties such as mechanical strength \u03c3 by the Hall-Petch equation, hardness, toughness, dielectric constant, and the optical properties exhibited by transparent materials.\nCeramography is the art and science of preparation, examination, and evaluation of ceramic microstructures. Evaluation and characterization of ceramic microstructures are often implemented on similar spatial scales to that used commonly in the emerging field of nanotechnology: from nanometers to tens of micrometers (\u00b5m). This is typically somewhere between the minimum wavelength of visible light and the resolution limit of the naked eye.\nThe microstructure includes most grains, secondary phases, grain boundaries, pores, micro-cracks, structural defects, and hardness micro indentions. Most bulk mechanical, optical, thermal, electrical, and magnetic properties are significantly affected by the observed microstructure. The fabrication method and process conditions are generally indicated by the microstructure. The root cause of many ceramic failures is evident in the cleaved and polished microstructure. Physical properties which constitute the field of materials science and engineering include the following:\nMechanical properties.\nMechanical properties are important in structural and building materials as well as textile fabrics. In modern materials science, fracture mechanics is an important tool in improving the mechanical performance of materials and components. It applies the physics of stress and strain, in particular the theories of elasticity and plasticity, to the microscopic crystallographic defects found in real materials in order to predict the macroscopic mechanical failure of bodies. Fractography is widely used with fracture mechanics to understand the causes of failures and also verify the theoretical failure predictions with real-life failures.\nCeramic materials are usually ionic or covalent bonded materials. A material held together by either type of bond will tend to fracture before any plastic deformation takes place, which results in poor toughness in these materials. Additionally, because these materials tend to be porous, the pores and other microscopic imperfections act as stress concentrators, decreasing the toughness further, and reducing the tensile strength. These combine to give catastrophic failures, as opposed to the more ductile failure modes of metals.\nThese materials do show plastic deformation. However, because of the rigid structure of crystalline material, there are very few available slip systems for dislocations to move, and so they deform very slowly.\nTo overcome the brittle behavior, ceramic material development has introduced the class of ceramic matrix composite materials, in which ceramic fibers are embedded and with specific coatings are forming fiber bridges across any crack. This mechanism substantially increases the fracture toughness of such ceramics. Ceramic disc brakes are an example of using a ceramic matrix composite material manufactured with a specific process.\nIce-templating for enhanced mechanical properties.\nIf a ceramic is subjected to substantial mechanical loading, it can undergo a process called ice-templating, which allows some control of the microstructure of the ceramic product and therefore some control of the mechanical properties. Ceramic engineers use this technique to tune the mechanical properties to their desired application. Specifically, the strength is increased when this technique is employed. Ice templating allows the creation of macroscopic pores in a unidirectional arrangement. The applications of this oxide strengthening technique are important for solid oxide fuel cells and water filtration devices.\nTo process a sample through ice templating, an aqueous colloidal suspension is prepared to contain the dissolved ceramic powder evenly dispersed throughout the colloid, for example Yttria-stabilized zirconia (YSZ). The solution is then cooled from the bottom to the top on a platform that allows for unidirectional cooling. This forces ice crystals to grow in compliance with the unidirectional cooling, and these ice crystals force the dissolved YSZ particles to the solidification front of the solid-liquid interphase boundary, resulting in pure ice crystals lined up unidirectionally alongside concentrated pockets of colloidal particles. The sample is then heated and at the same the pressure is reduced enough to force the ice crystals to sublime and the YSZ pockets begin to anneal together to form macroscopically aligned ceramic microstructures. The sample is then further sintered to complete the evaporation of the residual water and the final consolidation of the ceramic microstructure.\nDuring ice-templating, a few variables can be controlled to influence the pore size and morphology of the microstructure. These important variables are the initial solids loading of the colloid, the cooling rate, the sintering temperature and duration, and the use of certain additives which can influence the microstructural morphology during the process. A good understanding of these parameters is essential to understanding the relationships between processing, microstructure, and mechanical properties of anisotropically porous materials.\nElectrical properties.\nSemiconductors.\nSome ceramics are semiconductors. Most of these are transition metal oxides that are II-VI semiconductors, such as zinc oxide. While there are prospects of mass-producing blue LEDs from zinc oxide, ceramicists are most interested in the electrical properties that show grain boundary effects. One of the most widely used of these is the varistor. These are devices that exhibit the property that resistance drops sharply at a certain threshold voltage. Once the voltage across the device reaches the threshold, there is a breakdown of the electrical structure in the vicinity of the grain boundaries, which results in its electrical resistance dropping from several megohms down to a few hundred ohms. The major advantage of these is that they can dissipate a lot of energy, and they self-reset; after the voltage across the device drops below the threshold, its resistance returns to being high. This makes them ideal for surge-protection applications; as there is control over the threshold voltage and energy tolerance, they find use in all sorts of applications. The best demonstration of their ability can be found in electrical substations, where they are employed to protect the infrastructure from lightning strikes. They have rapid response, are low maintenance, and do not appreciably degrade from use, making them virtually ideal devices for this application. Semiconducting ceramics are also employed as gas sensors. When various gases are passed over a polycrystalline ceramic, its electrical resistance changes. With tuning to the possible gas mixtures, very inexpensive devices can be produced.\nSuperconductivity.\nUnder some conditions, such as extremely low temperatures, some ceramics exhibit high-temperature superconductivity. The reason for this is not understood, but there are two major families of superconducting ceramics.\nFerroelectricity and supersets.\nPiezoelectricity, a link between electrical and mechanical response, is exhibited by a large number of ceramic materials, including the quartz used to measure time in watches and other electronics. Such devices use both properties of piezoelectrics, using electricity to produce a mechanical motion (powering the device) and then using this mechanical motion to produce electricity (generating a signal). The unit of time measured is the natural interval required for electricity to be converted into mechanical energy and back again.\nThe piezoelectric effect is generally stronger in materials that also exhibit pyroelectricity, and all pyroelectric materials are also piezoelectric. These materials can be used to inter-convert between thermal, mechanical, or electrical energy; for instance, after synthesis in a furnace, a pyroelectric crystal allowed to cool under no applied stress generally builds up a static charge of thousands of volts. Such materials are used in motion sensors, where the tiny rise in temperature from a warm body entering the room is enough to produce a measurable voltage in the crystal.\nIn turn, pyroelectricity is seen most strongly in materials that also display the ferroelectric effect, in which a stable electric dipole can be oriented or reversed by applying an electrostatic field. Pyroelectricity is also a necessary consequence of ferroelectricity. This can be used to store information in ferroelectric capacitors, elements of ferroelectric RAM.\nThe most common such materials are lead zirconate titanate and barium titanate. Aside from the uses mentioned above, their strong piezoelectric response is exploited in the design of high-frequency loudspeakers, transducers for sonar, and actuators for atomic force and scanning tunneling microscopes.\nPositive thermal coefficient.\nTemperature increases can cause grain boundaries to suddenly become insulating in some semiconducting ceramic materials, mostly mixtures of heavy metal titanates. The critical transition temperature can be adjusted over a wide range by variations in chemistry. In such materials, current will pass through the material until joule heating brings it to the transition temperature, at which point the circuit will be broken and current flow will cease. Such ceramics are used as self-controlled heating elements in, for example, the rear-window defrost circuits of automobiles.\nAt the transition temperature, the material's dielectric response becomes theoretically infinite. While a lack of temperature control would rule out any practical use of the material near its critical temperature, the dielectric effect remains exceptionally strong even at much higher temperatures. Titanates with critical temperatures far below room temperature have become synonymous with \"ceramic\" in the context of ceramic capacitors for just this reason.\nOptical properties.\nOptically transparent materials focus on the response of a material to incoming light waves of a range of wavelengths. Frequency selective optical filters can be utilized to alter or enhance the brightness and contrast of a digital image. Guided lightwave transmission via frequency selective waveguides involves the emerging field of fiber optics and the ability of certain glassy compositions as a transmission medium for a range of frequencies simultaneously (multi-mode optical fiber) with little or no interference between competing wavelengths or frequencies. This resonant mode of energy and data transmission via electromagnetic (light) wave propagation, though low powered, is virtually lossless. Optical waveguides are used as components in Integrated optical circuits (e.g. light-emitting diodes, LEDs) or as the transmission medium in local and long haul optical communication systems. Also of value to the emerging materials scientist is the sensitivity of materials to radiation in the thermal infrared (IR) portion of the electromagnetic spectrum. This heat-seeking ability is responsible for such diverse optical phenomena as night-vision and IR luminescence.\nThus, there is an increasing need in the military sector for high-strength, robust materials which have the capability to transmit light (electromagnetic waves) in the visible (0.4 \u2013 0.7 micrometers) and mid-infrared (1 \u2013 5 micrometers) regions of the spectrum. These materials are needed for applications requiring transparent armor, including next-generation high-speed missiles and pods, as well as protection against improvised explosive devices (IED).\nIn the 1960s, scientists at General Electric (GE) discovered that under the right manufacturing conditions, some ceramics, especially aluminium oxide (alumina), could be made translucent. These translucent materials were transparent enough to be used for containing the electrical plasma generated in high-pressure sodium street lamps. During the past two decades, additional types of transparent ceramics have been developed for applications such as nose cones for heat-seeking missiles, windows for fighter aircraft, and scintillation counters for computed tomography scanners.\nOther ceramic materials, generally requiring greater purity in their make-up than those above, include forms of several chemical compounds, including:\nProducts.\nBy usage.\nFor convenience, ceramic products are usually divided into four main types; these are shown below with some examples:\nCeramics made with clay.\nFrequently, the raw materials of modern ceramics do not include clays.\nThose that do have been classified as:\nClassification.\nCeramics can also be classified into three distinct material categories: \nEach one of these classes can be developed into unique material properties.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
